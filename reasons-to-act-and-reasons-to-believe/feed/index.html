<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Hawthorne and Stanley&#8217;s Knowledge Principle for Good Reasons</title>
	<atom:link href="http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Certain Doubts &#187; Neta on Stanley &#38; Hawthorne</title>
		<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/#comment-7402</link>
		<dc:creator><![CDATA[Certain Doubts &#187; Neta on Stanley &#38; Hawthorne]]></dc:creator>
		<pubDate>Wed, 19 Sep 2007 19:06:55 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=723#comment-7402</guid>
		<description><![CDATA[[...] emology&#160;  		Ram just sent me a response to the S&#038;H really nice piece discussed here, and I thought posting it would generate further discussion of the piece.  So here it is i [...]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;] emology&nbsp;</p>
<p> 		Ram just sent me a response to the S&#38;H really nice piece discussed here, and I thought posting it would generate further discussion of the piece.  So here it is i [&#8230;]</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/#comment-7408</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Thu, 02 Aug 2007 12:23:14 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=723#comment-7408</guid>
		<description><![CDATA[Hi John, the connection between rationality and reasons is complicated, which is why I restricted the discussion to a case where we were dealing with transmission principles.  In such cases, for the belief to be rational, it needs to be based on the reasons for it, and even if somehow the transmitted rationality isn&#039;t sufficient for the belief to be rational, it is at least necessary.

I agree about your case: if you use them in a plan, your plan won&#039;t be rational.  You would be just guessing at the true conditionals, and so whatever is required of beliefs in order for a plan to be rational isn&#039;t found in your example.  On the latter point, about adding good reasons for believing the conditionals, it&#039;s an interesting question whether a refinement of that view can provide an adequate theory here.  I think the answer is &quot;yes&quot;, and that critics of the view haven&#039;t been sufficiently attentive to the different kinds of rationality that the view might appeal to.  But I&#039;m not trying to push that view here; in fact, the planning example raises some worries for it as well.]]></description>
		<content:encoded><![CDATA[<p>Hi John, the connection between rationality and reasons is complicated, which is why I restricted the discussion to a case where we were dealing with transmission principles.  In such cases, for the belief to be rational, it needs to be based on the reasons for it, and even if somehow the transmitted rationality isn&#8217;t sufficient for the belief to be rational, it is at least necessary.</p>
<p>I agree about your case: if you use them in a plan, your plan won&#8217;t be rational.  You would be just guessing at the true conditionals, and so whatever is required of beliefs in order for a plan to be rational isn&#8217;t found in your example.  On the latter point, about adding good reasons for believing the conditionals, it&#8217;s an interesting question whether a refinement of that view can provide an adequate theory here.  I think the answer is &#8220;yes&#8221;, and that critics of the view haven&#8217;t been sufficiently attentive to the different kinds of rationality that the view might appeal to.  But I&#8217;m not trying to push that view here; in fact, the planning example raises some worries for it as well.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: john</title>
		<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/#comment-7403</link>
		<dc:creator><![CDATA[john]]></dc:creator>
		<pubDate>Wed, 01 Aug 2007 20:32:06 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=723#comment-7403</guid>
		<description><![CDATA[hi jon
a few quick reactions
first it would be good to be more explicit about how you think &#039;being rational&#039; connects to &#039;being appropriate to treat p as a reason&#039;. our topic was the latter but your puzzle is posed in terms of the former

suppose i am playing chess and form a long term plan. i play x thinking my opponent will respond with y, which i will respond to my z which my opponent will respond to with w...
suppose further that i don&#039;t in fact know that my opponent would respond to z with w. then it is really appropriate for me to use the proposition &#039;if i play x the sequence xyzw will ensue&#039; as a reason for playing x? we say &#039;no&#039;, and this still sounds good to me. quite compatibly with that we can say that I have good reason to think that my opponent would respond to z with w&#039; -- the reasons may include propositions that are known that make this epistemically likely (even if not known). that a proposition cannot properly function as a reason does not entail that one is not justified/rational in believing it]]></description>
		<content:encoded><![CDATA[<p>hi jon<br />
a few quick reactions<br />
first it would be good to be more explicit about how you think &#8216;being rational&#8217; connects to &#8216;being appropriate to treat p as a reason&#8217;. our topic was the latter but your puzzle is posed in terms of the former</p>
<p>suppose i am playing chess and form a long term plan. i play x thinking my opponent will respond with y, which i will respond to my z which my opponent will respond to with w&#8230;<br />
suppose further that i don&#8217;t in fact know that my opponent would respond to z with w. then it is really appropriate for me to use the proposition &#8216;if i play x the sequence xyzw will ensue&#8217; as a reason for playing x? we say &#8216;no&#8217;, and this still sounds good to me. quite compatibly with that we can say that I have good reason to think that my opponent would respond to z with w&#8217; &#8212; the reasons may include propositions that are known that make this epistemically likely (even if not known). that a proposition cannot properly function as a reason does not entail that one is not justified/rational in believing it</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/#comment-7412</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Tue, 31 Jul 2007 17:40:40 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=723#comment-7412</guid>
		<description><![CDATA[You need multi-premise closure to do this, for all the parts of the plan in question.  That principle causes problems in the preface paradox.]]></description>
		<content:encoded><![CDATA[<p>You need multi-premise closure to do this, for all the parts of the plan in question.  That principle causes problems in the preface paradox.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike</title>
		<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/#comment-7411</link>
		<dc:creator><![CDATA[Mike]]></dc:creator>
		<pubDate>Tue, 31 Jul 2007 16:56:30 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=723#comment-7411</guid>
		<description><![CDATA[&lt;i&gt;. . . itâ€™s not the conditionals that I think arenâ€™t known. Itâ€™s the consequent that is inferred from the conditional and the other information available.&lt;/i&gt;

Help me out here; here&#039;s an example.

C. If I study for the test, I will pass the test.

Let S1 = I will pass the test.

So here I am studying for the exam. You want to say that I (might well) know C, but I don&#039;t know S1? That&#039;s hard to see. After all, if you ask me whether I know I am studying for the exam, I will of course say yes. So I am in this situation. I know I am studying, and I know that C, but I don&#039;t know that S1. I don&#039;t think you&#039;d need a controversial closure principle to be worried about that conclusion. It sure seems like I know S1. What am I missing here?]]></description>
		<content:encoded><![CDATA[<p><i>. . . itâ€™s not the conditionals that I think arenâ€™t known. Itâ€™s the consequent that is inferred from the conditional and the other information available.</i></p>
<p>Help me out here; here&#8217;s an example.</p>
<p>C. If I study for the test, I will pass the test.</p>
<p>Let S1 = I will pass the test.</p>
<p>So here I am studying for the exam. You want to say that I (might well) know C, but I don&#8217;t know S1? That&#8217;s hard to see. After all, if you ask me whether I know I am studying for the exam, I will of course say yes. So I am in this situation. I know I am studying, and I know that C, but I don&#8217;t know that S1. I don&#8217;t think you&#8217;d need a controversial closure principle to be worried about that conclusion. It sure seems like I know S1. What am I missing here?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/#comment-7410</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Tue, 31 Jul 2007 16:39:00 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=723#comment-7410</guid>
		<description><![CDATA[Mike, it&#039;s not the conditionals that I think aren&#039;t known.  It&#039;s the consequent that is inferred from the conditional and the other information available.]]></description>
		<content:encoded><![CDATA[<p>Mike, it&#8217;s not the conditionals that I think aren&#8217;t known.  It&#8217;s the consequent that is inferred from the conditional and the other information available.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike</title>
		<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/#comment-7409</link>
		<dc:creator><![CDATA[Mike]]></dc:creator>
		<pubDate>Tue, 31 Jul 2007 16:17:12 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=723#comment-7409</guid>
		<description><![CDATA[&lt;i&gt;But if propositional reasons have to be known to be true in order to be good reasons for believe, weâ€™ll have problems here. Ask me whatâ€™s going to happen over the next 10 years. I tell you Iâ€™m going to take step S1, then S2, then S3, thereby securing goal G. Now, which of these beliefs are rational and which arenâ€™t? One doesnâ€™t have to be much of a skeptic to deny that every belief short of the last one about achieving G counts as knowledge.&lt;/i&gt;

Compare the case in which the hunch that a restaurant is on street S leads one to mistakenly take road S. The criticism does seem apt that the person did not know it was on S. As I read your case, the same criticism is not appropriate for these conditionals, since it seems like a pretty sure thing that for each Sn, if you take the steps to Sn you will arrive at Sn.  You say,

&lt;i&gt;if I try at all, S1 will be accomplished; if S1 is accomplished and and I try some more, S2 will obtain; etc. Oneâ€™s reasoning here is explicit, I will suppose: one resolves to try, and by MP concludes that S1 is in the bag. Same with the next level of trying, and so S2 is no problem. Etc&lt;/i&gt;

So, these conditionals do look like things you know. But make more explicit that you do not know them. So, I have a hunch that if I try to achieve S1 by doing D1, I will achieve it. Suppose that&#039;s true for every Sn. It is clear here that I do not know the conditional are true. Now, if I set about achieving G on this plan, my chances are close to nil of getting to G. I am open to the criticism, I think, that I acted on conditionals that I did not know were true.]]></description>
		<content:encoded><![CDATA[<p><i>But if propositional reasons have to be known to be true in order to be good reasons for believe, weâ€™ll have problems here. Ask me whatâ€™s going to happen over the next 10 years. I tell you Iâ€™m going to take step S1, then S2, then S3, thereby securing goal G. Now, which of these beliefs are rational and which arenâ€™t? One doesnâ€™t have to be much of a skeptic to deny that every belief short of the last one about achieving G counts as knowledge.</i></p>
<p>Compare the case in which the hunch that a restaurant is on street S leads one to mistakenly take road S. The criticism does seem apt that the person did not know it was on S. As I read your case, the same criticism is not appropriate for these conditionals, since it seems like a pretty sure thing that for each Sn, if you take the steps to Sn you will arrive at Sn.  You say,</p>
<p><i>if I try at all, S1 will be accomplished; if S1 is accomplished and and I try some more, S2 will obtain; etc. Oneâ€™s reasoning here is explicit, I will suppose: one resolves to try, and by MP concludes that S1 is in the bag. Same with the next level of trying, and so S2 is no problem. Etc</i></p>
<p>So, these conditionals do look like things you know. But make more explicit that you do not know them. So, I have a hunch that if I try to achieve S1 by doing D1, I will achieve it. Suppose that&#8217;s true for every Sn. It is clear here that I do not know the conditional are true. Now, if I set about achieving G on this plan, my chances are close to nil of getting to G. I am open to the criticism, I think, that I acted on conditionals that I did not know were true.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Clayton</title>
		<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/#comment-7407</link>
		<dc:creator><![CDATA[Clayton]]></dc:creator>
		<pubDate>Mon, 30 Jul 2007 17:37:04 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=723#comment-7407</guid>
		<description><![CDATA[Yes, well, I&#039;m afraid we&#039;ll have to repay that debt $10 at a time.

I look forward to the post on excusability.  I&#039;ve been trying to formulate precisely arguments to block their appeal to excusability to deal with Gettier and Gettierish cases.]]></description>
		<content:encoded><![CDATA[<p>Yes, well, I&#8217;m afraid we&#8217;ll have to repay that debt $10 at a time.</p>
<p>I look forward to the post on excusability.  I&#8217;ve been trying to formulate precisely arguments to block their appeal to excusability to deal with Gettier and Gettierish cases.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/#comment-7406</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Mon, 30 Jul 2007 17:27:29 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=723#comment-7406</guid>
		<description><![CDATA[Hi Clayton, I thought it was 10K you owed me, but oh well... :-)

On the probabilistic point, the story doesn&#039;t contain any beliefs like that, so it would count as a rational reconstruction as well.  I&#039;m assuming it&#039;s a bad idea to try to solve the preface paradox by saying that if the beliefs had been slightly different, everything would be OK.  I&#039;m assuming, that is, that a solution to preface must begin by granting the data that the beliefs are knowingly inconsistent and yet rational.

I like your $10 example, though I think H&#038;S will appeal to the excusability factor to explain it away.  That&#039;s what I&#039;m going to post about next:  the claimed connection between anti-luminosity and the need for excusability conditions for correct norms.  I don&#039;t think the conclusion follows here, but that&#039;s another post.]]></description>
		<content:encoded><![CDATA[<p>Hi Clayton, I thought it was 10K you owed me, but oh well&#8230; ðŸ™‚</p>
<p>On the probabilistic point, the story doesn&#8217;t contain any beliefs like that, so it would count as a rational reconstruction as well.  I&#8217;m assuming it&#8217;s a bad idea to try to solve the preface paradox by saying that if the beliefs had been slightly different, everything would be OK.  I&#8217;m assuming, that is, that a solution to preface must begin by granting the data that the beliefs are knowingly inconsistent and yet rational.</p>
<p>I like your $10 example, though I think H&amp;S will appeal to the excusability factor to explain it away.  That&#8217;s what I&#8217;m going to post about next:  the claimed connection between anti-luminosity and the need for excusability conditions for correct norms.  I don&#8217;t think the conclusion follows here, but that&#8217;s another post.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Clayton</title>
		<link>http://certaindoubts.com/reasons-to-act-and-reasons-to-believe/#comment-7405</link>
		<dc:creator><![CDATA[Clayton]]></dc:creator>
		<pubDate>Mon, 30 Jul 2007 17:09:11 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=723#comment-7405</guid>
		<description><![CDATA[Sorry,

To complete that thought...

I don&#039;t see why H&#038;S have to say that plans based on probabilistic propositions are rational in only an &#039;honorific&#039; sense.  I&#039;m not sure I see the step that leads  from:
&lt;i&gt;Such rational reconstruction does give us one way to save the knowledge requirement, just as it gives us a way to try to escape the preface paradox&lt;/i&gt;
to
&lt;i&gt;So I donâ€™t think rational reconstruction is a plausible way out.&lt;/i&gt;

There is, I think, a very obvious objection to the position that H&#038;S are developing, which is that it&#039;s hard to understand why the mere fact that p isn&#039;t known is sufficient grounds for saying that p oughtn&#039;t figure in practical reasoning since we know that p might fail to be knowledge for reasons wholly unconnected to the accuracy of the belief and the strength of grounds for holding it.  If I believe that I&#039;m repaying a debt to you on our brief jaunt to the land of fake bills by giving you a genuine $10 at lunch, I can&#039;t see what&#039;s defective about relying on the premise &quot;I&#039;ll hereby repay Jon by handing him this bill&quot; in my reasoning.]]></description>
		<content:encoded><![CDATA[<p>Sorry,</p>
<p>To complete that thought&#8230;</p>
<p>I don&#8217;t see why H&amp;S have to say that plans based on probabilistic propositions are rational in only an &#8216;honorific&#8217; sense.  I&#8217;m not sure I see the step that leads  from:<br />
<i>Such rational reconstruction does give us one way to save the knowledge requirement, just as it gives us a way to try to escape the preface paradox</i><br />
to<br />
<i>So I donâ€™t think rational reconstruction is a plausible way out.</i></p>
<p>There is, I think, a very obvious objection to the position that H&amp;S are developing, which is that it&#8217;s hard to understand why the mere fact that p isn&#8217;t known is sufficient grounds for saying that p oughtn&#8217;t figure in practical reasoning since we know that p might fail to be knowledge for reasons wholly unconnected to the accuracy of the belief and the strength of grounds for holding it.  If I believe that I&#8217;m repaying a debt to you on our brief jaunt to the land of fake bills by giving you a genuine $10 at lunch, I can&#8217;t see what&#8217;s defective about relying on the premise &#8220;I&#8217;ll hereby repay Jon by handing him this bill&#8221; in my reasoning.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
