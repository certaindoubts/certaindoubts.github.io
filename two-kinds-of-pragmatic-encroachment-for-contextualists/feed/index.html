<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Actual or Perceived Stakes? &#8212; for Contextualists</title>
	<atom:link href="http://certaindoubts.com/two-kinds-of-pragmatic-encroachment-for-contextualists/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/two-kinds-of-pragmatic-encroachment-for-contextualists/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Keith</title>
		<link>http://certaindoubts.com/two-kinds-of-pragmatic-encroachment-for-contextualists/#comment-115</link>
		<dc:creator><![CDATA[Keith]]></dc:creator>
		<pubDate>Wed, 23 Jun 2004 02:03:52 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=27#comment-115</guid>
		<description><![CDATA[Unaware of Fakes Vs. Unaware of Stakes

On Matt&#039;s comment (5, above).  I think there&#039;s a huge difference between being wrong about stakes (or the like) vs. being wrong about whether the subject is in a Gettier situation.

So, start with a Gettier situation -- I&#039;ve always used Ginet&#039;s fake barns case for this purpose.  [Actually, I modify it somewhat, since some people have reported to me that they don&#039;t have the no-knowledge intuition in the case as it&#039;s best known (from Goldman).  So, imagine that Henry is not only in a region filled with fake barns, but that he&#039;s actually been fooled by *many* of those fakes.  But the speaker is talking about the one incident where Henry was looking a real barn, and so is describing a true belief of Henry&#039;s when she says, &quot;Henry knew he was seeing a barn.&quot;]  The speaker, we&#039;ll suppose, doesn&#039;t know about all the fakes.

Here, I&#039;ve always supposed the speaker is just wrong about whether Henry knows.  In fact, such cases have long been my reason for not going in for a simple relevant alternatives theory -- by which I mean one according to which the content of a given knowledge attribution can be given by specifying what range of alternatives is relevant in context.  For here, we must suppose that *it was a fake barn* is a relevant alternative to explain why the claim was false.  But, on the *simple* RA, we&#039;d need to suppose that that alternative is *not* relevant to explain why the claim is rationally made.  Thus, I&#039;ve thought that what context selects is not a range of rel alt&#039;s, as on simple RA, but at most a standard for relevance.  (This is in 1992 &amp; 1994 PPR papers.)  But anyway, the key point here is that the subject just didn&#039;t know, by any reasonable standards, and he or anybody else who says he knows is wrong, however reasonable they are in issuing the knowledge attribution if they&#039;re unaware of the fakes.

But being unaware of what the stakes are is a completely different matter to me.  If a speaker is unaware of the high stakes the subject faces, though the subject knows about them, I&#039;m inclined to think the standards that govern this speaker&#039;s claim are not driven up by the high stakes.  In Matt&#039;s case, where the speaker thinks the stakes are high for the subject, but they in fact are not, I think the standards that govern the speaker&#039;s claim will typically be very high.

Why the difference in treatment?  Well, the fakes vs. the stakes are falling on opposite sides of what for me (&amp; my intuitions) is a great divide.  The fakes are affecting (by bringing down) how strong an epistemic position the subject is in.  High stakes typically work (though a bit indirectly) by raising the standards for how well-positioned the subject must be for the speaker&#039;s claim to be true.  The standards in play are a matter of what the speaker means, and so are less plausibly affected by things the speaker is oblivious to.  But how well positioned the subject actually is is something that anybody who is unaware of the fakes is likely to be very wrong about.]]></description>
		<content:encoded><![CDATA[<p>Unaware of Fakes Vs. Unaware of Stakes</p>
<p>On Matt&#8217;s comment (5, above).  I think there&#8217;s a huge difference between being wrong about stakes (or the like) vs. being wrong about whether the subject is in a Gettier situation.</p>
<p>So, start with a Gettier situation &#8212; I&#8217;ve always used Ginet&#8217;s fake barns case for this purpose.  [Actually, I modify it somewhat, since some people have reported to me that they don&#8217;t have the no-knowledge intuition in the case as it&#8217;s best known (from Goldman).  So, imagine that Henry is not only in a region filled with fake barns, but that he&#8217;s actually been fooled by *many* of those fakes.  But the speaker is talking about the one incident where Henry was looking a real barn, and so is describing a true belief of Henry&#8217;s when she says, &#8220;Henry knew he was seeing a barn.&#8221;]  The speaker, we&#8217;ll suppose, doesn&#8217;t know about all the fakes.</p>
<p>Here, I&#8217;ve always supposed the speaker is just wrong about whether Henry knows.  In fact, such cases have long been my reason for not going in for a simple relevant alternatives theory &#8212; by which I mean one according to which the content of a given knowledge attribution can be given by specifying what range of alternatives is relevant in context.  For here, we must suppose that *it was a fake barn* is a relevant alternative to explain why the claim was false.  But, on the *simple* RA, we&#8217;d need to suppose that that alternative is *not* relevant to explain why the claim is rationally made.  Thus, I&#8217;ve thought that what context selects is not a range of rel alt&#8217;s, as on simple RA, but at most a standard for relevance.  (This is in 1992 &#038; 1994 PPR papers.)  But anyway, the key point here is that the subject just didn&#8217;t know, by any reasonable standards, and he or anybody else who says he knows is wrong, however reasonable they are in issuing the knowledge attribution if they&#8217;re unaware of the fakes.</p>
<p>But being unaware of what the stakes are is a completely different matter to me.  If a speaker is unaware of the high stakes the subject faces, though the subject knows about them, I&#8217;m inclined to think the standards that govern this speaker&#8217;s claim are not driven up by the high stakes.  In Matt&#8217;s case, where the speaker thinks the stakes are high for the subject, but they in fact are not, I think the standards that govern the speaker&#8217;s claim will typically be very high.</p>
<p>Why the difference in treatment?  Well, the fakes vs. the stakes are falling on opposite sides of what for me (&#038; my intuitions) is a great divide.  The fakes are affecting (by bringing down) how strong an epistemic position the subject is in.  High stakes typically work (though a bit indirectly) by raising the standards for how well-positioned the subject must be for the speaker&#8217;s claim to be true.  The standards in play are a matter of what the speaker means, and so are less plausibly affected by things the speaker is oblivious to.  But how well positioned the subject actually is is something that anybody who is unaware of the fakes is likely to be very wrong about.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/two-kinds-of-pragmatic-encroachment-for-contextualists/#comment-114</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Mon, 21 Jun 2004 18:49:10 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=27#comment-114</guid>
		<description><![CDATA[Matt--you say,
&lt;blockquote&gt;at least two kinds of evidence seem relevant to rationality of action in a case in which a subject knows or justifiably believes a lot is at stake for her in whether p – evidence about what’s at stake for her in whether p and evidence about p. If evidence about stakes isn’t evidence about p, I can’t see how to avoid bad results like the ones I have described. It would be a nice surprise, though, for the proponent of pragmatic encroachment if evidence about what’s at stake in whether p could count as evidence about p. &lt;/blockquote&gt;

I think there can be evidence about the stakes of p that is not evidence relevant for p. That&#039;s because you can have evidence about the stakes of p that don&#039;t meet your threshold of concern with respect to what degree you are a risk-taker.  So the evidence has to be evidence that the stakes are higher than you can tolerate, and the evidence has to be sufficiently strong to convince you that the stakes really are that high.  And we&#039;ll have to add some clause about basing your worries on the evidence as well.]]></description>
		<content:encoded><![CDATA[<p>Matt&#8211;you say,</p>
<blockquote><p>at least two kinds of evidence seem relevant to rationality of action in a case in which a subject knows or justifiably believes a lot is at stake for her in whether p – evidence about what’s at stake for her in whether p and evidence about p. If evidence about stakes isn’t evidence about p, I can’t see how to avoid bad results like the ones I have described. It would be a nice surprise, though, for the proponent of pragmatic encroachment if evidence about what’s at stake in whether p could count as evidence about p. </p></blockquote>
<p>I think there can be evidence about the stakes of p that is not evidence relevant for p. That&#8217;s because you can have evidence about the stakes of p that don&#8217;t meet your threshold of concern with respect to what degree you are a risk-taker.  So the evidence has to be evidence that the stakes are higher than you can tolerate, and the evidence has to be sufficiently strong to convince you that the stakes really are that high.  And we&#8217;ll have to add some clause about basing your worries on the evidence as well.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: mcgrath</title>
		<link>http://certaindoubts.com/two-kinds-of-pragmatic-encroachment-for-contextualists/#comment-8691</link>
		<dc:creator><![CDATA[mcgrath]]></dc:creator>
		<pubDate>Mon, 21 Jun 2004 15:53:37 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=27#comment-8691</guid>
		<description><![CDATA[That&#039;s right; I don&#039;t side with Jason yet.  I would need to see some explanation of how actual but unperceived stakes could make a difference to knowledge.  Jason suggests that being unaware of stakes shouldn&#039;t have a positive epistemic effect.  However, unawareness of defeaters can have a positive effect on justification.  If, as I am inclined to think, stakes affect the justification condition on knowledge, rather than the fourth condition, then unawareness of stakes can have a positive effect on knowledge.  (Thus, Turri&#039;s Gettier analogy might not be apt.)

I wonder what Jason would think of a case in which the subject justifiably but incorrectly took the case to be a high stakes one.  I would think that in such a case it would take more evidence/better epistemic position to know.  If not, we can have situations in which one can be fully justified (justified well-enough to know, absent 4th condition problems) in believing that a certain act is best while not being rational to perform that act.  This sounds pretty bad to me.

One last response to Jon:  at least two kinds of evidence seem relevant to rationality of action in a case in which a subject knows or justifiably believes a lot is at stake for her in whether p -- evidence about what&#039;s at stake for her in whether p and evidence about p.  If evidence about stakes isn&#039;t evidence about p, I can&#039;t see how to avoid bad results like the ones I have described.  It would be a nice surprise, though, for the proponent of pragmatic encroachment if evidence about what&#039;s at stake in whether p could count as evidence about p.  The SSI theorist could then handle Keith&#039;s &quot;third-person&quot; cases better.

A question for Keith.  Suppose a third party speaker is mistaken about what is at stake for a subject S in whether p, but S is not.  In fact, S has little at stake in whether p, though the speaker believes S has a great deal at stake.  Suppose also that S has good evidence for p.  The speaker then thinks of various counterpossibilities of S&#039;s error.  It seems to me that for Keith this should normally raise the standards associated with &#039;know&#039; in the speaker&#039;s mouth.  As Keith suggests, what affects a speaker&#039;s meaning depends not on the facts but on the speaker&#039;s beliefs, doubts, etc.  And if the standards are raised, the speaker will speak truly in saying, &quot;S doesn&#039;t know that p.&quot;  Doesn&#039;t this seem wrong?  Similarly, if the speaker mistakenly thought nothing much was at stake for S in whether p, she would not speak truly in saying, &quot;S knows that p.&quot;

I have in mind the Cohen 1999 paper on contextualism and the Gettier problem.  Cohen argued that a contextualist solution (like Lewis&#039;s) to the Gettier problem is implausible:  when the third party speaker wrongly believes a subject isn&#039;t in a Gettier case the speaker can&#039;t speak truly in saying &quot;S knows.&quot;  I would think that it would be every bit as implausible -- though I don&#039;t recall if Cohen makes this point -- to think a speaker who wrongly believed a subject was in a Gettier could speak truly in saying &quot;S doesn&#039;t know.&quot;

Keith, if you think Cohen&#039;s argument works for the Gettier problem, why doesn&#039;t the parallel argument above work to show that contextualist maneuvers are useless for explaining the epistemic relevance of stakes?]]></description>
		<content:encoded><![CDATA[<p>That&#8217;s right; I don&#8217;t side with Jason yet.  I would need to see some explanation of how actual but unperceived stakes could make a difference to knowledge.  Jason suggests that being unaware of stakes shouldn&#8217;t have a positive epistemic effect.  However, unawareness of defeaters can have a positive effect on justification.  If, as I am inclined to think, stakes affect the justification condition on knowledge, rather than the fourth condition, then unawareness of stakes can have a positive effect on knowledge.  (Thus, Turri&#8217;s Gettier analogy might not be apt.)</p>
<p>I wonder what Jason would think of a case in which the subject justifiably but incorrectly took the case to be a high stakes one.  I would think that in such a case it would take more evidence/better epistemic position to know.  If not, we can have situations in which one can be fully justified (justified well-enough to know, absent 4th condition problems) in believing that a certain act is best while not being rational to perform that act.  This sounds pretty bad to me.</p>
<p>One last response to Jon:  at least two kinds of evidence seem relevant to rationality of action in a case in which a subject knows or justifiably believes a lot is at stake for her in whether p &#8212; evidence about what&#8217;s at stake for her in whether p and evidence about p.  If evidence about stakes isn&#8217;t evidence about p, I can&#8217;t see how to avoid bad results like the ones I have described.  It would be a nice surprise, though, for the proponent of pragmatic encroachment if evidence about what&#8217;s at stake in whether p could count as evidence about p.  The SSI theorist could then handle Keith&#8217;s &#8220;third-person&#8221; cases better.</p>
<p>A question for Keith.  Suppose a third party speaker is mistaken about what is at stake for a subject S in whether p, but S is not.  In fact, S has little at stake in whether p, though the speaker believes S has a great deal at stake.  Suppose also that S has good evidence for p.  The speaker then thinks of various counterpossibilities of S&#8217;s error.  It seems to me that for Keith this should normally raise the standards associated with &#8216;know&#8217; in the speaker&#8217;s mouth.  As Keith suggests, what affects a speaker&#8217;s meaning depends not on the facts but on the speaker&#8217;s beliefs, doubts, etc.  And if the standards are raised, the speaker will speak truly in saying, &#8220;S doesn&#8217;t know that p.&#8221;  Doesn&#8217;t this seem wrong?  Similarly, if the speaker mistakenly thought nothing much was at stake for S in whether p, she would not speak truly in saying, &#8220;S knows that p.&#8221;</p>
<p>I have in mind the Cohen 1999 paper on contextualism and the Gettier problem.  Cohen argued that a contextualist solution (like Lewis&#8217;s) to the Gettier problem is implausible:  when the third party speaker wrongly believes a subject isn&#8217;t in a Gettier case the speaker can&#8217;t speak truly in saying &#8220;S knows.&#8221;  I would think that it would be every bit as implausible &#8212; though I don&#8217;t recall if Cohen makes this point &#8212; to think a speaker who wrongly believed a subject was in a Gettier could speak truly in saying &#8220;S doesn&#8217;t know.&#8221;</p>
<p>Keith, if you think Cohen&#8217;s argument works for the Gettier problem, why doesn&#8217;t the parallel argument above work to show that contextualist maneuvers are useless for explaining the epistemic relevance of stakes?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/two-kinds-of-pragmatic-encroachment-for-contextualists/#comment-113</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Sun, 20 Jun 2004 21:16:45 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=27#comment-113</guid>
		<description><![CDATA[Matt M.:  This case is a very good one.  What it shows, I think, is that anyone who appeals to salience better say exactly what is involved in the risks of error becoming salient.  In the case you suggest, I think it makes no sense for John to say anything at all if risks haven&#039;t come to play some role in his thinking.  He can&#039;t tell Mary not to worry unless he has some vague sense that there is something in the neighborhood regarding which reassurance is relevant.  I think his remark, as you put it in his mouth, shows that he doesn&#039;t think the risks in question are significant enough to do any further checking.  When Mary rebukes him, he&#039;s either changing his mind about the significance of the risks of being wrong or he&#039;s just acquiescing in the socially prescribed way when other people have worries that we don&#039;t share.  Or perhaps, he was disingenuous or guilty of something like repression or suppression of his own worries--we often do that when risks become clear to us, apparently hoping they won&#039;t be so serious if we don&#039;t acknowledge them!

But:  you&#039;re right to complain!  I don&#039;t have a general account with the implications I claim, and until I produce such an account, there&#039;s not enough reason to think epistemicism can be saved in this way.  In particular, though, I don&#039;t think a proper account of salience requires that a person think about explicit counterpossibilities and be worried specifically about them.   To repeat, though, I owe you a proper formulation, and when I get one, we&#039;ll be in a better position to make progress here...

I notice, however, that you pass on the question Jason raises, about whether actual stakes or perceived stakes do the work to elicit pragmatic encroachment.  Your discussion focuses on things within the cognitive purview of the agents in question, and I infer in the conversational way that you don&#039;t see how to get the explanation to work when the information is not within the cognitive purview of the agents.  That would mean, of course, that you do not side with Jason yet.  Am I right, or is my conversational implicature here incorrect?]]></description>
		<content:encoded><![CDATA[<p>Matt M.:  This case is a very good one.  What it shows, I think, is that anyone who appeals to salience better say exactly what is involved in the risks of error becoming salient.  In the case you suggest, I think it makes no sense for John to say anything at all if risks haven&#8217;t come to play some role in his thinking.  He can&#8217;t tell Mary not to worry unless he has some vague sense that there is something in the neighborhood regarding which reassurance is relevant.  I think his remark, as you put it in his mouth, shows that he doesn&#8217;t think the risks in question are significant enough to do any further checking.  When Mary rebukes him, he&#8217;s either changing his mind about the significance of the risks of being wrong or he&#8217;s just acquiescing in the socially prescribed way when other people have worries that we don&#8217;t share.  Or perhaps, he was disingenuous or guilty of something like repression or suppression of his own worries&#8211;we often do that when risks become clear to us, apparently hoping they won&#8217;t be so serious if we don&#8217;t acknowledge them!</p>
<p>But:  you&#8217;re right to complain!  I don&#8217;t have a general account with the implications I claim, and until I produce such an account, there&#8217;s not enough reason to think epistemicism can be saved in this way.  In particular, though, I don&#8217;t think a proper account of salience requires that a person think about explicit counterpossibilities and be worried specifically about them.   To repeat, though, I owe you a proper formulation, and when I get one, we&#8217;ll be in a better position to make progress here&#8230;</p>
<p>I notice, however, that you pass on the question Jason raises, about whether actual stakes or perceived stakes do the work to elicit pragmatic encroachment.  Your discussion focuses on things within the cognitive purview of the agents in question, and I infer in the conversational way that you don&#8217;t see how to get the explanation to work when the information is not within the cognitive purview of the agents.  That would mean, of course, that you do not side with Jason yet.  Am I right, or is my conversational implicature here incorrect?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: mcgrath</title>
		<link>http://certaindoubts.com/two-kinds-of-pragmatic-encroachment-for-contextualists/#comment-8550</link>
		<dc:creator><![CDATA[mcgrath]]></dc:creator>
		<pubDate>Sun, 20 Jun 2004 18:54:00 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=27#comment-8550</guid>
		<description><![CDATA[An invariantist should be able to explain how having a lot at stake in whether p can matter to knowledge that p.  I can see how this explanation might go when a subject is aware of what&#039;s at stake for him/her in whether p.  Here&#039;s how Jeremy Fantl and I saw the matter in our 2002 PR paper.  When you are aware that a great deal is at stake for you in whether p, this, together with your evidence regarding p, can make a difference to what you should do.  This should be pretty uncontroversial.  But knowing what is at stake in whether p may give you knowledge that (if p, then a certain act A is best).  Now, suppose knowledge that p was a matter of purely epistemic standing regarding p, and not of evidence about what is at stake for you.  Then there will be cases in which one knows that p, knows that (if p, then A is best), and so knows that A is best, and yet is not rational to do p.  This strikes me and Fantl and absurd.  If you know that something is best, you are rational to do it.  What I&#039;d like to see is a similar argument connecting knowledge that p with high stakes of which one isn&#039;t aware.

On Jon Kvanvig&#039;s evidential model of salience, I guess I don&#039;t see how knowing about what one&#039;s stakes in a high stakes situation is guaranteed to make counterpossibilies of error salient (and to keep them salient).  Suppose Mary and John don&#039;t know, at t1, that so much is riding on whether the plane stops in Chicago.  Now suppose, at t2, they gain this information (their boss calls them on a cell phone).  Why must counterpossibilities of error become salient?  We can imagine John not worrying:

John:  &quot;Well, there&#039;s no use worrying about it; no doubt, it stops in Chicago -- that&#039;s what&#039;s on Smith&#039;s itinerary.&quot;

Mary might then rebuke him at t3:

Mary:  &quot;John, obviously we have a few minutes; we should go check at the counter.&quot;
John:  &quot;You&#039;re right, we should.&quot;

Surely John was rational to check further, not only at t3 but also at t2 (though not at t1).  I think we don&#039;t want to make people automatically rational in their decisions, by over-emphasizing subjective factors.  Now, if John is rational to check further at t2, then if we are to avoid saying &quot;John knows staying in line is best but he ought to check further,&quot; we have to concede that John fails to know.  But counterpossibilities aren&#039;t salient to John at t2.  So epistemicism, I think, will have to go.]]></description>
		<content:encoded><![CDATA[<p>An invariantist should be able to explain how having a lot at stake in whether p can matter to knowledge that p.  I can see how this explanation might go when a subject is aware of what&#8217;s at stake for him/her in whether p.  Here&#8217;s how Jeremy Fantl and I saw the matter in our 2002 PR paper.  When you are aware that a great deal is at stake for you in whether p, this, together with your evidence regarding p, can make a difference to what you should do.  This should be pretty uncontroversial.  But knowing what is at stake in whether p may give you knowledge that (if p, then a certain act A is best).  Now, suppose knowledge that p was a matter of purely epistemic standing regarding p, and not of evidence about what is at stake for you.  Then there will be cases in which one knows that p, knows that (if p, then A is best), and so knows that A is best, and yet is not rational to do p.  This strikes me and Fantl and absurd.  If you know that something is best, you are rational to do it.  What I&#8217;d like to see is a similar argument connecting knowledge that p with high stakes of which one isn&#8217;t aware.</p>
<p>On Jon Kvanvig&#8217;s evidential model of salience, I guess I don&#8217;t see how knowing about what one&#8217;s stakes in a high stakes situation is guaranteed to make counterpossibilies of error salient (and to keep them salient).  Suppose Mary and John don&#8217;t know, at t1, that so much is riding on whether the plane stops in Chicago.  Now suppose, at t2, they gain this information (their boss calls them on a cell phone).  Why must counterpossibilities of error become salient?  We can imagine John not worrying:</p>
<p>John:  &#8220;Well, there&#8217;s no use worrying about it; no doubt, it stops in Chicago &#8212; that&#8217;s what&#8217;s on Smith&#8217;s itinerary.&#8221;</p>
<p>Mary might then rebuke him at t3:</p>
<p>Mary:  &#8220;John, obviously we have a few minutes; we should go check at the counter.&#8221;<br />
John:  &#8220;You&#8217;re right, we should.&#8221;</p>
<p>Surely John was rational to check further, not only at t3 but also at t2 (though not at t1).  I think we don&#8217;t want to make people automatically rational in their decisions, by over-emphasizing subjective factors.  Now, if John is rational to check further at t2, then if we are to avoid saying &#8220;John knows staying in line is best but he ought to check further,&#8221; we have to concede that John fails to know.  But counterpossibilities aren&#8217;t salient to John at t2.  So epistemicism, I think, will have to go.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Matt Davidson</title>
		<link>http://certaindoubts.com/two-kinds-of-pragmatic-encroachment-for-contextualists/#comment-112</link>
		<dc:creator><![CDATA[Matt Davidson]]></dc:creator>
		<pubDate>Sun, 20 Jun 2004 06:07:37 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=27#comment-112</guid>
		<description><![CDATA[If you are unaware, but ought to be aware--say you took a bunch of sedatives so that you didn&#039;t have to worry about your responsibilities, the contextualist may want to say that you have a higher standard for knowledge.  Suppose you have an undefeated  justified belief that the stakes are high, but you&#039;ve managed to push this to the back of your mind, as it were; this still might change the content of &quot;knows&quot; in your idiolect.

Also, insofar as the contextualist wants the semantics of &quot;knows&quot; to be sensitive to the internal epistemic architecture of the subject, I would expect lots of intersubjectivity in terms of which relation &quot;knows&quot; expresses.

I also think that to the extent the internalist has generally &quot;internalist&quot; intuitions in various areas--in semantics in particular--contextualism may be the view that is most congenial to the internalist.  It is consistent with semantic content being very sensitive to speaker intention, and fits better with this view than an invariantist approach.]]></description>
		<content:encoded><![CDATA[<p>If you are unaware, but ought to be aware&#8211;say you took a bunch of sedatives so that you didn&#8217;t have to worry about your responsibilities, the contextualist may want to say that you have a higher standard for knowledge.  Suppose you have an undefeated  justified belief that the stakes are high, but you&#8217;ve managed to push this to the back of your mind, as it were; this still might change the content of &#8220;knows&#8221; in your idiolect.</p>
<p>Also, insofar as the contextualist wants the semantics of &#8220;knows&#8221; to be sensitive to the internal epistemic architecture of the subject, I would expect lots of intersubjectivity in terms of which relation &#8220;knows&#8221; expresses.</p>
<p>I also think that to the extent the internalist has generally &#8220;internalist&#8221; intuitions in various areas&#8211;in semantics in particular&#8211;contextualism may be the view that is most congenial to the internalist.  It is consistent with semantic content being very sensitive to speaker intention, and fits better with this view than an invariantist approach.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/two-kinds-of-pragmatic-encroachment-for-contextualists/#comment-111</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Sun, 20 Jun 2004 03:31:22 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=27#comment-111</guid>
		<description><![CDATA[Keith--I think your ambivalence for the contextualist position here is exactly right.  That&#039;s because I see no reason that a contextualist must insist that the answer is the same in every case, for every subject.  If salience of the chance of error plays much of a role for the contextualist in determining when standards are raised, then it is clear that the chance of error could be salient for one speaker and not for another.  More generally, though, I don&#039;t see why, even apart from an appeal to salience, the function on whatever collage of factors makes standards rise and fall has to yield the same answer for every speaker.

Here, I think, things are harder for SSI-ers.  I think they must plump for one view or the other, either actual or perceived high stakes.  And of course, as the comments show, my own view has to plump for perceived self-interest, but my position may seem akin to showing up at the border all alone to stop the invading hordes...

But on the relationship between contextualism and SSI, I don&#039;t mean to claim that the difference I&#039;m seeing is a reason to favor contextualism (and I&#039;m not claiming the opposite either).  I&#039;m only trying to explain why you ought to be ambivalent on the issue, since you like contextualism, and the SSI-ers shouldn&#039;t be.]]></description>
		<content:encoded><![CDATA[<p>Keith&#8211;I think your ambivalence for the contextualist position here is exactly right.  That&#8217;s because I see no reason that a contextualist must insist that the answer is the same in every case, for every subject.  If salience of the chance of error plays much of a role for the contextualist in determining when standards are raised, then it is clear that the chance of error could be salient for one speaker and not for another.  More generally, though, I don&#8217;t see why, even apart from an appeal to salience, the function on whatever collage of factors makes standards rise and fall has to yield the same answer for every speaker.</p>
<p>Here, I think, things are harder for SSI-ers.  I think they must plump for one view or the other, either actual or perceived high stakes.  And of course, as the comments show, my own view has to plump for perceived self-interest, but my position may seem akin to showing up at the border all alone to stop the invading hordes&#8230;</p>
<p>But on the relationship between contextualism and SSI, I don&#8217;t mean to claim that the difference I&#8217;m seeing is a reason to favor contextualism (and I&#8217;m not claiming the opposite either).  I&#8217;m only trying to explain why you ought to be ambivalent on the issue, since you like contextualism, and the SSI-ers shouldn&#8217;t be.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
