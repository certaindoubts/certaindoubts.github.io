<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>perception &#8211; </title>
	<atom:link href="http://certaindoubts.com/category/perception/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 01:35:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>Out with the old &#8230;</title>
		<link>http://certaindoubts.com/out-with-the-old/</link>
		<comments>http://certaindoubts.com/out-with-the-old/#comments</comments>
		<pubDate>Tue, 31 Dec 2013 22:11:59 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[perception]]></category>
		<category><![CDATA[skepticism]]></category>
		<category><![CDATA[cognitive science]]></category>
		<category><![CDATA[experimental philosophy]]></category>
		<category><![CDATA[inference]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4222</guid>
		<description><![CDATA[&#8230; skeptical arguments. A new paper of mine, &#8220;Skeptical Appeal: The Source-Content Bias&#8221; (forthcoming in Cognitive Science), uncovers a subtle mechanism that triggers knowledge-denial and contributes to the appeal of classic skeptical arguments. The mechanism is an interaction between two factors. &#8230; <a class="more-link" href="http://certaindoubts.com/out-with-the-old/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>&#8230; skeptical arguments.</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2013/12/images.jpeg"><img class=" wp-image-4224     alignleft" alt="car_theft" src="http://certaindoubts.com/wp-content/uploads/2013/12/images.jpeg" width="179" height="118" /></a></p>
<p><a style="font-size: 16px;line-height: 1.4em" href="http://certaindoubts.com/wp-content/uploads/2013/12/images-2.jpeg"><img class="    alignnone" alt="big_cat" src="http://certaindoubts.com/wp-content/uploads/2013/12/images-2.jpeg" width="180" height="119" /></a></p>
<p>A new paper of mine, &#8220;<span style="color: #3366ff"><a title="Skeptical Appeal: The Source-Content Bias" href="http://john.turri.org/research/Appeal.pdf" target="_blank"><span style="color: #3366ff">Skeptical Appeal: The Source-Content Bias</span></a></span>&#8221; (forthcoming in <em>Cognitive Science</em>), uncovers a subtle mechanism that triggers knowledge-denial and contributes to the appeal of classic skeptical arguments.</p>
<p>The mechanism is an interaction between two factors. First, people evaluate inferential belief more harshly than perceptual belief. Second, people evaluate inferential belief more harshly when its content is negative (i.e. that something is not the case) than when it’s positive (i.e. that something is the case). That is, our cognitive evaluations are biased against this specific combination of source and content.</p>
<p>The skeptic exploits, perhaps unwittingly, the source-content bias. It just so happens that certain skeptical arguments tend to focus our attention on negative inferential beliefs, and we are especially prone to doubt that such beliefs count as knowledge.</p>
<p>Philosophers have long appreciated that research into features of language might help shed light on skeptical appeal (e.g. Cohen/DeRose/Lewis style contextualism, or invariantist proposals that invoke pragmatics). My New Year&#8217;s resolution: to keep firmly in mind that philosophically-informed research into features of our psychology can be equally helpful.</p>
<p>Who&#8217;ll join me?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/out-with-the-old/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>Wishful Thinking Problems for Reliabilism</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/</link>
		<comments>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comments</comments>
		<pubDate>Mon, 26 Mar 2012 16:00:56 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[perception]]></category>
		<category><![CDATA[reliabilism]]></category>
		<category><![CDATA[wishful thinking]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369</guid>
		<description><![CDATA[Phenomenal conservatism and dogmatism get a bad rep for allowing some cases of wishful thinking to provide prima facie justification.  In this post, I argue that reliabilism has wishful thinking problems that are even worse. Contrast direct and indirect wishful &#8230; <a class="more-link" href="http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Phenomenal conservatism and dogmatism get a bad rep for allowing some cases of wishful thinking to provide prima facie justification.  In this post, I argue that reliabilism has wishful thinking problems that are even worse.</p>
<p>Contrast direct and indirect wishful thinking.  The former occurs when one bases a belief that P directly on one’s desire (wish, lust, etc.) that P.  The latter occurs in any other way.  For our purposes, we can assume all cases of indirect wishful thinking fit this pattern: a desire that P causally influences the way things seem, and then a belief that P is based directly on the seeming that is so influenced.  For example, I might base my belief that the nugget is gold on its seeming that the nugget is gold, where I have that seeming, not because of relevant expertise, but because I’m lusting for gold.  Lyons holds that, as a matter of fact, most wishful thinking is indirect in this way, which sounds plausible to me.  Seemings Internalism (SI) holds that seemings necessarily provide prima facie justification.  (SI is inclusive of dogmatism and phenomenal conservatism.)  Hence, SI seems committed to allowing indirect wishful thinking to provide prima facie justification.</p>
<p>Says Lyons: “For SI to bite the bullet here would be for it to hold that the epistemology of (typical) wishful thinking perfectly parallels the epistemology of (typical) perception: an agent has an appearance as of <em>p</em>, which <em>prima facie</em> justifies her in believing that <em>p</em>.  I myself would think that this bullet just can’t be bitten, that an epistemology that licences wishful thinking in this way simply can’t be taken seriously” (pg 299 of <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1533-6077.2011.00205.x/abstract">this paper</a>).  Note that Lyons doesn’t claim that, given SI, typical cases of wishful thinking result in <em>ultima facie</em> justification.  Since it’s plausible that typical wishful thinkers have defeaters for their wishful thinking, the latter claim is dubious.</p>
<p>I agree with Lyons that it is counterintuitive to allow indirect wishful thinking to prima facie justify its content; however, reliabilists suffer from wishful thinking problems that are <em>worse</em>.  I admit it’s bad to allow typical cases of <em>indirect </em>wishful thinking to provide <em>prima facie</em> justification.  It’s worse, in my mind, to allow possible cases of <em>direct </em>wishful thinking to provide <em>ultima facie</em> justification.  Proponents of SI can say that it is impossible for desires, by themselves, to be an acceptable basis for beliefs.  Reliabilists can’t say that.  (I think the same holds for externalism more generally and possibly also for some versions of internalism.)<span id="more-3369"></span></p>
<p>To see the basic point, start with a simple version of indicator reliabilism.  On such a view, a desire that P will justify a belief that P just in case that desire is a reliable indicator of P.  Epistemic angels can bring about the required reliability by organizing the world to ensure that desires (within a certain domain) regularly come to pass.  The modal profile of P can ensure that any basis of P, including a desire for P, is a trivially reliable indicator for P.  Since Goedel’s first incompleteness theorem is necessarily true, there’s never a case in which you will be led astray by believing the theorem on the basis of desiring or wishing it to be true.  The modal profile of certain contingent truths also can make desires trivially reliable indicators of P, but I won’t go into the details here.  More sophisticated indicator reliabilisms will give more subtle accounts of reliability, but give me an account and I’ll give you a possible case in which the view allows a belief to be ultima facie justified on the basis of a desire.</p>
<p>Depending on what they say about process individuation, process reliabilists may approve of actual cases of direct wishful thinking.  A process can be wrong every time it takes a desire as an input, but still be reliable overall if desires rarely get used as inputs.  For example, I might use process R 100 times.  It&#8217;s output might be mistaken both times it took a desire as an input, but be very reliable because it was correct in all 98 other uses.  Suppose that desires do sometimes causally influence the way things seem (which Lyons accepts) and that this happens in a very small number of times relative to the number of perceptual seemings we have (which seems plausible).  When desires do get involved, are those desires unusual inputs to the normal—and reliable—process of perception or do they always indicate that a different process is at work?  I don’t think reliabilists say enough about process individuation for us to say one way or another.  But if desires are unusual inputs to a normal reliable process, then process reliabilists are committed to allowing <em>direct</em> wishful thinking to provide <em>ultima facie </em>justification in the actual world.</p>
<p>So here’s a challenge, reliabilists.  Give me a proposed account of process individuation that doesn’t allow any actual wishful thinking to count as justified, and I’ll show you that there is a possible process that (i) takes at least one desire as an input and (ii) produces mostly true beliefs (or satisfies whatever account of reliability you put forward).</p>
<p>(I’ve assumed that the relevant sort of reliability is reliability in the world of the process being evaluated (what Lyons calls “in situ” reliability).  Alternative views hold that what matters is reliability in the actual world.  Such versions of reliabilism probably don’t have wishful thinking problems, unless their account of process individuation forces them to approve of some actual case of wishful thinking.  But they achieve this advantage by relying on the most implausible feature of their view, namely that processes that don’t exist can’t yield justified beliefs.  Possible processes that don’t exist can’t yield justified beliefs, because they aren’t reliable in the actual world.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/feed/</wfw:commentRss>
		<slash:comments>11</slash:comments>
		</item>
		<item>
		<title>Reliability and Cognitive Penetration</title>
		<link>http://certaindoubts.com/reliability-and-cognitive-penetration/</link>
		<comments>http://certaindoubts.com/reliability-and-cognitive-penetration/#respond</comments>
		<pubDate>Tue, 13 Mar 2012 22:42:46 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[memory]]></category>
		<category><![CDATA[perception]]></category>
		<category><![CDATA[cognitive penetration]]></category>
		<category><![CDATA[reliabilism]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3325</guid>
		<description><![CDATA[Can a subject’s beliefs, desires, fears, or goals causally influence the way things seem to her?  Suppose that the answer is yes.  That is, suppose that a subject’s mental states can penetrate the way things seem to her.  What are &#8230; <a class="more-link" href="http://certaindoubts.com/reliability-and-cognitive-penetration/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Can a subject’s beliefs, desires, fears, or goals causally influence the way things seem to her?  Suppose that the answer is yes.  That is, suppose that a subject’s mental states can <em>penetrate</em> the way things seem to her.  What are the epistemic implications of this cognitive penetration?  This question is becoming a ‘hot’ topic in epistemology these days, though it has been around in various forms for decades at least.  My tentative plan is to write two blog posts on this topic.  Both are responses to Jack Lyons&#8217; <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1533-6077.2011.00205.x/abstract">very helpful paper</a>, but I hope the wider significance of the posts will be apparent.  In this post, I will argue, contra Lyons, that we have no reason to think reliability explains which instances of cognitive penetration are benign and which are malignant.  In the next blog post, I’ll argue that reliabilism has cognitive penetration problems of its own.<span id="more-3325"></span></p>
<p>It’s clear that some instances of cognitive penetration are perfectly benign and, sometimes, even epistemically beneficial.  It seems to me that I ate cereal for breakfast now because this morning I (rationally) formed the belief that I ate cereal for breakfast.  The previous belief makes it seem to me that I ate cereal for breakfast now.  If this kind of penetration isn’t benign (or beneficial), then one wonders whether any of our memorial beliefs are justified.  On the other hand, some cases of cognitive penetration apparently pose a problem for anyone who, <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1520-8583.2010.00202.x/abstract">like me</a>, wants to hold that all (perceptual) seemings prima facie justify.  If my lust for gold causes it to seem that the yellow nugget is gold, then most of us feel some hesitancy in allowing that such a seeming provides even prima facie justification that the nugget is gold.</p>
<p>So there are good cases of cognitive penetration and there are (apparently) bad cases.  What explains this difference?  Jack holds that it is explained by reliability (see section 4).  In the “good cases”, such as ordinary memorial belief formation, the reliability of the relevant process is high.  In the bad cases, the reliability of the relevant process is low.  If Jack could make good on these claims, it would be a real win for reliabilism; however, Jack is writing checks that reliabilism can’t cash (yet).  The problem is that whether reliability can explain the difference between the good and bad cases depends almost entirely on how one individuates processes, and it is far from clear that there is a sensible way of individuating processes that allows reliability to track the goodness/badness of cognitive penetration.</p>
<p>To see the problem, consider this question: are cognitively penetrated processes different processes than the ones that aren’t cognitively penetrated?  Since I don’t think an “it depends” answer will help the reliabilist much, I’m going to ignore it.  Suppose that the reliabilist says &#8220;no&#8221;.  This means that cognitively penetrated processes are identical to the ones that aren’t penetrated.  Hence, the reliability of those processes also will be identical to the reliability of the processes that aren’t penetrated.  Presumably, those processes will be reliable.  But then the bad cases of penetration would yield justified beliefs because they are produced by reliable processes.  So if the reliabilist is trying to explain the difference between the good and bad penetration, he shouldn’t say “no” to this question.</p>
<p>Suppose the reliabilist says, “yes, cognitively penetrated processes are different processes than non-penetrated processes.”  Now we are faced with a different question: Do the good cases of cognitive penetration involve different processes than the bad cases?  Again, I ignore the “it depends” answer.  If the reliabilist says “no,” she is stuck with a similar problem to what she faced by saying “no” to the previous question.  If the good and bad cases involve the same process, then the good and bad cases will be equally reliable and either the good cases will involve unreliable processes or the bad cases will involve reliable processes.  Either way, reliability can’t explain the difference between the good and bad cases of cognitive penetration.  So if the reliabilist is trying to explain this difference, she shouldn’t say “no” to this question either.</p>
<p>If the reliabilist is trying to explain the relevant difference, she needs to hold that, “yes, the good cases of cognitive penetration involve different processes than the bad cases of cognitive penetration.”  For the sake of keeping this blog post less long, I’ll just declare three things I think are true: 1) The required account of process individuation would likely need to individuate processes fairly narrowly.  2) No one, Jack included, has identified a way of individuating processes (i) that meets the above requirements for explaining the relevant difference; (ii) that is not ad hoc; and (iii) that is empirically adequate.  3) We won’t be in position to affirm that reliability (of processes) explains the difference between good and bad penetration until we have discovered a way of individuating process that at least plausibly satisfies (i)-(iii).  I conclude that we have no reason to think that reliability really does explain the difference between the good and bad cases of cognitive penetration.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/reliability-and-cognitive-penetration/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>An Epistemological Argument for Disjunctivism</title>
		<link>http://certaindoubts.com/an-epistemological-argument-for-disjunctivism/</link>
		<comments>http://certaindoubts.com/an-epistemological-argument-for-disjunctivism/#comments</comments>
		<pubDate>Sat, 16 Oct 2010 03:22:23 +0000</pubDate>
		<dc:creator><![CDATA[Clayton Littlejohn]]></dc:creator>
				<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[knowledge]]></category>
		<category><![CDATA[perception]]></category>
		<category><![CDATA[skepticism]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=2233</guid>
		<description><![CDATA[I&#8217;ve been thinking a bit about McDowell&#8217;s epistemological argument for the disjunctive conception of experience. One reaction I&#8217;ve come across in conversation is basically that McDowell derives an implausible claim about the nature of experience from implausible claims about perceptual &#8230; <a class="more-link" href="http://certaindoubts.com/an-epistemological-argument-for-disjunctivism/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I&#8217;ve been thinking a bit about McDowell&#8217;s epistemological argument for the disjunctive conception of experience.  One reaction I&#8217;ve come across in conversation is basically that McDowell derives an implausible claim about the nature of experience from implausible claims about perceptual knowledge and justification.  It&#8217;s not a surprise that you get a crazy view out when you put strange assumptions in.  While I&#8217;m not completely sold on experiential disjunctivism, I&#8217;m pretty sympathetic to some McDowellish assumptions.  Thought I&#8217;d explain why, see if there is a way of defending McDowell from his critics, and (finally) bring out a flaw in his argument that I think hasn&#8217;t been discussed in the literature.<br />
<span id="more-2233"></span></p>
<p>This is the sort of reasoning that McDowell thinks stinks: </p>
<blockquote><p>If there is a cat in the corner and it looks to you as if there is, you have good reason to believe there is a cat in the corner. Indeed, you might have good enough reason to believe this. Since it can look to you as if there is a cat there even if the nearest cat is miles away, experience can provide you with a sufficiently good reason for belief even if there is no cat. The reasons provided by veridical experience give you the right to believe. The same is true for the reasons subjectively indistinguishable hallucination provide. If so, the justificatory work is done by the elements common to hallucination and perception. These elements do their justificatory work just as well in cases of perception and hallucination. After all, you have the same evidence either way. </p></blockquote>
<p>The conditions that distinguish veridical experience from hallucination are essential to perceptual knowledge. Knowledge, he says, is a standing in the space of reasons. As he sees it, Same Reasons leads to skepticism. To avoid skepticism, he accepts: </p>
<blockquote><p>The evidence veridical experience provides is ‘better’ than the evidence provided by subjectively indistinguishable hallucination in the sense that veridical experience provides evidence that hallucination does not (Better Reasons). </p></blockquote>
<p>Consider as an alternative view: </p>
<blockquote><p>If two individuals have the same evidence, the same reasons bear on their beliefs and it is impossible for two individuals to have different evidence if these individuals are non-factive mental duplicates (Mentalism).</p></blockquote>
<p>Mentalism (so understood) would accept: </p>
<blockquote><p>Veridical experience and subjectively indistinguishable hallucination provide you with the same evidence for your worldly beliefs (Same Reasons).</p></blockquote>
<p>Same Reasons, McDowell would say, leads to skepticism.  I think he&#8217;s right.  I would go further than rejecting Same Reasons and would endorse: </p>
<blockquote><p>Only in the case of veridical perception do you have good enough reason for your worldly beliefs. If you believe on the basis of hallucination, you cannot believe with justification. You can believe with sufficient justification if your experience is veridical (Good Enough). </p></blockquote>
<p>Now, it is not enough to simply endorse Better Reasons and Good Enough.   If you were to say that the nature of the psychological states and events by virtue of which it looks to you as if such and such is the case are the same in the case of perception and hallucination, the view leads right back to skepticism. On such a view, the qualities by virtue of which your reasons are thought to be better would be blankly external to you. For McDowell, this is verboten: </p>
<blockquote><p>The root idea is that one’s epistemic standing … cannot intelligibly be constituted, even in part, by matters blankly external to how it is with one subjectively. For how could such matters be other than beyond one’s ken? And how could matters beyond one’s ken make any difference to one’s epistemic standing? … But the disjunctive conception of appearances shows a way to detach this “internalist” intuition from the requirement of a non-question begging demonstration. When someone has a fact made manifest to him, the obtaining of this fact contributes to his epistemic standing on the question. But the obtaining of the fact is precisely not blankly external to his subjectivity, as it would be if the truth about that were exhausted by the highest common factor.</p></blockquote>
<p>To reject the skeptical view, you have to endorse: </p>
<blockquote><p>An appearance can either be a mere appearance, as with hallucination, or a fact made perceptually manifest. The nature of the psychological states and events by virtue of it looks to you as if p depends upon whether you are hallucinating or your experience is veridical (Disjunctivism). </p></blockquote>
<p>We can summarize McDowell&#8217;s epistemological argument for Disjunctivism as follows. Given the internalist intuition that epistemic standing cannot be constituted by factors blankly external to you or beyond your ken, Same Reasons leads to skepticism. Knowledge is an epistemic standing. Same Reasons says that the conditions essential to this standing are blankly external to you in the case of veridical experience. If you endorse Better Reasons but deny Disjunctivism, you do not avoid the skeptical consequences of Same Reasons because your view commits you to saying that the conditions essential to knowledge are beyond your ken even in cases of veridical experience. The only alternative to skepticism is a view that combines Better Reasons with Disjunctivism. So, on the plausible assumption that we have perceptual knowledge, we have to reject the traditional conception of experience.</p>
<p><strong>Better Reasons</strong><br />
I think there&#8217;s a quick and compelling argument for Better Reasons.  </p>
<p>(1) I know non-inferentially that I have hands.<br />
(2) If I know I have hands non-inferentially, I believe that I have hands, this belief is non-inferentially justified, and this belief is true.<br />
(3) If I believe that I have hands, this belief is non-inferentially justified, and this belief is true, then my evidence includes the proposition that I have hands.<br />
(4) My evidence includes the proposition that I have hands.<br />
(5) My evidence includes the proposition that I have hands only if I have hands.<br />
(C) Thus, it is possible for two individuals to differ evidentially without differing mentally&#8211;the proposition that I have hands is not evidence that my handless mental duplicates have.</p>
<p>The argument rests on these assumptions:<br />
(i) If you know p non-inferentially, p is part of your evidence.<br />
(ii) p is part of your evidence only if p is true.<br />
(iii) The scope of non-inferential knowledge is broad enough that we can know non-inferentially those propositions we come to believe by taking experience at face value.</p>
<p>Combined, we know things our deceived counterparts do not.  I&#8217;ve defending (ii) elsewhere.  I think (iii) is pretty plausible, if you think that perceptual experience provides us with knowledge we could not gain from introspection alone.  As for (i), you can find support for that in the thought that your evidence will include those reasons you can treat as reasons and rely on without needing independent and antecedent reasons.  What you know non-inferentially will play that role.  With the case for Better Reasons before us, we can now see why McDowell is right that Same Reasons leads to skepticism.  To assert that Same Reasons is true, you either need to say that we cannot have non-inferential knowledge of the external world (and that&#8217;s close to saying that we cannot have perceptual knowledge) or say that you can know something non-inferentially without what you know being part of your evidence.  Since what you can treat as a reason without needing independent/antecedent justification looks evidence, I&#8217;ll wait to see what others say evidence has to be before elaborating.</p>
<p><strong>The Dilemma</strong><br />
On one horn you have someone like Conee who thinks that Better Reasons could not be true, not even if Disjunctivism is true.  On the other, you have McDowell.  Better Reasons, if true, requires Disjunctivism.  Let&#8217;s start with Conee&#8217;s objection.  </p>
<p><strong>Conee</strong><br />
In explaining how it is possible to have the kind of knowledge the skeptic denies we could have, McDowell rejects Same Reasons and argues that Disjunctivism is needed to explain Better Reasons. Nothing could be a reason that contributes to the justificatory standing of your belief unless that reason is part of your basis for believing. For reasons we have touched on, having such a reason requires having a kind of unmediated, unbroken mental contact with the facts you come to know via perceptual experience. Conee objects to this on the grounds that Disjunctivism could not explain Better Reasons because such an explanation would run afoul of the following principle: </p>
<blockquote><p>A subject’s justification for a belief is not stronger than a second subject’s justification for the same belief, if their respective justifications are prone to being equally well defeated by the same defeaters (Defeat).</p></blockquote>
<p>If Defeat says that two reasons defeated by the same defeater cannot differ in strength, the principle is not very plausible. A full house is stronger than a pair even if four aces would beat both hands.  On a more charitable reading, Defeat says that the justification provided by two conscious experiences is equally strong if these justifications are liable to defeat by all the same defeaters. This is more plausible, but still hardly self-evident. </p>
<p>He thinks veridical perceptual experience and subjectively indistinguishable hallucination are equally well defeated by the same defeaters because they are subjectively indistinguishable. If his objection is sound, it shows that if two conscious experiences are indistinguishable, the reasons they provide for your beliefs are equally strong and these experiences will justify the same beliefs to the same degree. Consider two theses about indiscriminability and justification: </p>
<p>Transitivity-i: (x)(y)(z)[(Ixy &amp;, Iyz) &#8211;&gt; Ixz)].<br />
Transitivity-j: (x)(y)(z)[(Jxy &amp; Jyz)&#8211;&gt; Jxz)]. </p>
<p>According to Transitivity-i, a and c must be indiscriminable or indistinguishable for you if you cannot distinguish a from b and cannot distinguish b from c. According to Transitivity-j, if a and b justify the same (i.e., justify the same beliefs to the same degree) and b and c justify the same, a and c must justify the same as well. Arguably, Transitivity-i is false. Suppose a, b, and c are perceptual experiences you have while looking at three different paint chips in good viewing conditions. It seems possible for a and b to be indiscriminable, b and c to be indiscriminable, even if you can discriminate a from c. If these chips differ only slightly, you might be unable to distinguish the first from the second and the second from the third even if you can discriminate the first from the third by sight. What goes for the chips goes for the perceptual experiences of the chips. Although it seems that Transitivity-i is false, Transitivity-j is true. For Transitivity-j to be false, there would have to be some proposition, p, such that the degrees to which a and c justified belief in p differed even though both a and c justified belief in p to the same degree that b does. This is impossible. </p>
<p>With this in mind, I shall argue that Conee cannot use Defeat to show that Disjunctivism cannot explain Better Reasons. His objection assumes:<br />
(1) (x)(y)(Ixy &#8211;&gt; Jxy).<br />
Let me introduce a further assumption:<br />
(2) (x)(y)(~Ixy&#8211;&gt; ~Jxy).<br />
The justification for (2) is that in discriminating between two things, you can know that these two things are distinct. If you can discriminate between a and c, you will have stronger reasons for believing that you are undergoing a while undergoing a than you will have for believing that you are undergoing some experience you can knowingly discriminate from a (e.g., c). </p>
<p>If Transitivity-i is false, we can coherently suppose that a is indiscriminable from b, b is indiscriminable from c, but you can discriminate between a and c. (1) entails that a and b justify the same beliefs to the same degree. It also entails that b and c justify the same beliefs to the same degree. It follows by Transitivity-j that a and c justify the same beliefs to the same degree. But, if (2) is correct, this contradicts the further assumption that a and c are experiences that you can discriminate between. The most obvious way to avoid this contradiction is to deny (1). If (1) is false, Conee&#8217;s Defeat principle is no threat to Better Reasons. His objection was that McDowell&#8217;s view implied that it is possible for indistinguishable states to provide different reasons for belief, reasons that differed in strength. His objection assumed that indistinguishable states can be defeated by precisely the same considerations and that states that can be defeated by precisely the same considerations cannot offer reasons that differ in strength. We know now that these assumptions cannot both be correct. Either the reasons provided by two indistinguishable states are not defeated by the very same considerations or the reasons provided by two states can be defeated by the same considerations even if these states provide different reasons. </p>
<p><strong>McDowell</strong><br />
Nothing in the arguments for Better Reasons told us anything about the nature of perceptual experience. If the traditional view of experience is left in place, all is lost. Why is that? Remember that McDowell wanted to hold onto the internalist thought that your epistemic standing cannot be constituted even partially by matters blankly external to you. Why not? Because, he says, such matters are beyond your ken and what is beyond your ken cannot make any difference to your epistemic standing.</p>
<p>If I understand the reasoning right, it goes something like this:<br />
(1) If q is blankly external to your subjectivity, q is beyond your ken.<br />
(2) If q is beyond your ken, q cannot make a difference to your epistemic standing.<br />
(3) Thus, if q is blankly external to your subjectivity, q cannot make a difference to your epistemic standing.</p>
<p>What does it actually mean to say that something is blankly external to your subjectivity? One interpretation that seems plausible is given by van Cleve&#8211;q is blankly external to your subjectivity iff a complete description of your psychological states neither entails q nor ~q. What does it mean to say that q is beyond your ken? Whatever it means, we know that McDowell&#8217;s conclusion is that whether you know something cannot depend upon q if q is beyond your ken. And, so, let us say that if q is beyond your ken, you are not in a position to know q non-inferentially. If, however, you are in a position to know q non-inferentially, q is not beyond your ken.</p>
<p>We can now restate the argument as follows:<br />
(4) If a full description of your psychological states entails neither q nor \simq, you cannot know whether q know non-inferentially.<br />
(5) If you cannot know whether q non-inferentially, q cannot make a difference to the justificatory status of your beliefs.<br />
(6) Thus, if a full description of your psychological states entails neither q nor \simq, q cannot make a difference to the justificatory status of your beliefs.</p>
<p>Does this compel us to accept Disjunctivism?<br />
McDowell is probably right that if something is beyond your ken, it cannot confer any epistemic benefit upon you. However, I think it is a mistake to say that your epistemic standing cannot be determined, in part, by features that are beyond your ken. In fact, McDowell should say as much. On his view, there can be matters beyond your ken that can partially determine the justificatory standing of your beliefs&#8211;that you are in the bad case, for example, is not blankly external to your subjectivity but it is, nevertheless, something that partially determines your epistemic standing. It does if Disjunctivism is true and either Better Reasons or Good Enough is true. Better Reasons and Good Enough say that there is a justificatory difference between the good and bad cases and Disjunctivism says that this corresponds to a difference in the psychological states and events by virtue of which it looks to you the way it does in these cases. Thus, we should restate (5) and (6) as follows: </p>
<p>(5&#8242;) If you cannot know whether q non-inferentially, q cannot make a difference to the justificatory status of your beliefs by conferring any sort of epistemic benefit upon you.<br />
(6&#8242;) If a full description of your psychological states entails neither q nor ~q cannot make a difference to the justificatory status of your beliefs by conferring any sort of epistemic benefit upon you.</p>
<p>With this fix in place, we have our argument for Disjunctivism. </p>
<p>McDowell is right to deny that something inaccessible to you can confer upon you an epistemic benefit. Consider some examples. Suppose someone does something there is reason not to do. Suppose that there happens also to be reason to do it. Bernie shoots a kid carrying a weapon (that is something there is a pro tanto reason not to do), but doesn’t know that the kid is carrying a weapon. Maybe the kid was going to use that weapon to attack a bunch of people (perhaps that’s a pro tanto reason to shoot the kid). Since this has nothing to do with Bernie’s reasons for shooting, it is hard to see how facts about what the kid was carrying and what the kid planned to do with his weapon could be cited to justify his deeds. Even if Bernie were made aware of the kid’s weapon, if Bernie is shooting the kid just because he hates kids it is hard to see how these facts could justify his conduct. To justifiably act against a reason, it seems that it is not enough that there is overriding reason that happens to be out there somewhere. It seems that this reason to act has to be the reason for which the subject acts if that reason is going to be the reason in virtue of which some other agent’s deeds are going to have a moral standing superior to the standing of Bernie’s deeds. The reasons that count in favor of acting seem to contribute positively to moral standing only if they play some motivational role. They cannot play that motivational role, however, if they are beyond the subject’s ken. Indeed, one argument for the claim that considerations beyond your ken cannot confer any justification is predicated on the assumption that considerations can only justify when they play some motivational role. If Bernie&#8217;s reasons for shooting were not the reasons for which he shot, those reasons seem to do nothing to justify his action even if he is aware of them but is motivated instead wholly by malice. We do not need practical examples to make the point. One lesson you might take from BonJour&#8217;s clairvoyant examples is precisely that considerations that are inaccessible to you cannot be reasons that justify forming beliefs. </p>
<p>This much seems right. It seems to be the sort of thing that might lead McDowell to say that there is something a subject in the good case is cognizant of that explains why a subject in this case ends up with beliefs better justified than beliefs formed in the bad case. The reasons that count against acting, however, can contribute negatively to the normative standing of an action without playing any motivational role. Moreover, the reasons that count against acting can contribute to normative standing of an action even if the agent is non-culpably ignorant of them. Think about cases where someone is imprisoned for a crime that we later discover that they did not commit. In the wake of this discovery, we discover that we have a duty of reparation and must compensate the victim. Such reparative duties are, however, not mere duties of beneficence. Such reparative duties should leave the victim better off than they were, but unlike duties of beneficence the duty is one that arises between the victim and the subject(s) that harmed the victim. These duties can exist when the parties responsible for imprisoning the victim were non-culpably ignorant of the fact that the accused was innocent. (Just think about cases where reliable eyewitnesses came forward to suggest that the victim was guilty and it was only later developments in forensic science that exonerated the person imprisoned.) These duties only exist when the agent acted against some genuine reason that contributed negatively to the normative standing of the original act. (Otherwise, helping the wrongly accused would not be a response to some past wrong and would be a mere duty of beneficence.) If this is right, the act of putting the innocent victim away and forcing them to suffer the hardships of prison was wrongful and wrongful for reasons that all relevant parties could have been non-culpably ignorant of. </p>
<p>Examples like these suggest that there is an important asymmetry between reasons for belief or action and reasons against. Even if reasons for believing or acting cannot contribute to normative standing unless the subject is cognizant of them, reasons <em>against</em> can contribute negatively to normative standing when the subject is not cognizant of them. (This line of thought is something I owe to John Gardner who might not be thrilled that I&#8217;m crediting/blaming him for the fact that I have thoughts like this.) McDowell himself seems to concede this much if he accepts Better Reasons and accepts that subjects in the bad case are in no position to realize that their reasons are defective. Since comparative normative standing is a function of both the reasons for and reasons against, there is a serious lacuna in McDowell’s argument for Disjunctivism. Why? Well, suppose there are reasons not to believe p on the basis of how things look when its looking as if p is due to hallucination. It could be that beliefs in the good case are comparatively better off even if there is not something internal to the subject’s experience that is distinctive of the good case. The disparity is due entirely to reasons not to believe that are present only in the bad case that make beliefs formed in that case defective. </p>
<p>Notice that there is a way of accomodating the internalist point about reasons to believe. None justify if they are beyond your ken. However, if he must concede that reasons not to believe can do their work by making it wrongful to believe even if they are beyond the subject&#8217;s ken, we can explain the difference in epistemic standing between the good case and bad in terms of this difference in the reasons not to believe. We could say, if we wanted, that there were the same reasons to believe in these cases. Thus, it seems that the right to believe does not depend upon the possession of reasons that entail that the belief in question is true. One might have such reasons on hand, say, in the case of non-inferentially justified belief, but there is no necessary connection between rightly held belief and entailing evidence.  </p>
<p>Why does this matter?  Because maybe we do not need factive reasons.  Even if we are rather radical externalists. </p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/an-epistemological-argument-for-disjunctivism/feed/</wfw:commentRss>
		<slash:comments>7</slash:comments>
		</item>
		<item>
		<title>Hey Internalists, Which Experiences Justify and Why?</title>
		<link>http://certaindoubts.com/hey-internalists-which-experiences-justify-and-why/</link>
		<comments>http://certaindoubts.com/hey-internalists-which-experiences-justify-and-why/#comments</comments>
		<pubDate>Tue, 11 May 2010 19:32:53 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[a priori knowledge]]></category>
		<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[memory]]></category>
		<category><![CDATA[perception]]></category>
		<category><![CDATA[internalism]]></category>
		<category><![CDATA[non-inferential justification]]></category>
		<category><![CDATA[phenomenal conservatism]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=1866</guid>
		<description><![CDATA[Here is my impression: it is very popular to allow certain kinds of experiences to provide (prima facie propositional) justification for certain propositions.  Which propositions might an experience justify?  The most straightforward thing to say is that certain experiences provide &#8230; <a class="more-link" href="http://certaindoubts.com/hey-internalists-which-experiences-justify-and-why/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p style="text-align: justify">Here is my impression: it is very popular to allow certain kinds of experiences to provide (prima facie propositional) justification for certain propositions.  Which propositions might an experience justify?  The most straightforward thing to say is that certain experiences provide justification for their propositional contents; but if experiences don’t have propositional contents, some more elaborate story will need to be told.  For the sake of simplicity, I’ll assume that an experience justifies a proposition only if it has a propositional content.</p>
<p style="text-align: justify">Which experiences provide justification for their propositional contents?  Here are some popular answers: perceptual experiences, memorial experiences, a priori intuitions, or some combination thereof.  (I am thinking of a priori intuitions as experiences.  Intuitions about morality, math, modality, and philosophy often count as a priori intuitions.)  It is not popular, however, to say that just any experience (or just any experience with a representational content) can justify its conclusion.  But this raises the following questions: if some experiences justify their contents, why don’t all experiences justify their contents?  What principled criterion is there for allowing only certain experiences (with contents) to justify their conclusions?</p>
<p style="text-align: justify"><span id="more-1866"></span></p>
<p style="text-align: justify">Reliabilists have a straightforward answer: only experiences that are caused in a reliable way can justify.  Other externalists will have similar stories to tell.  But what about the internalist?  What criterion can he use to distinguish between experiences that justify and those that don’t?</p>
<p style="text-align: justify">One answer is available to those who allow a priori intuitions to justify.  They can say something like this: an experience that P justifies P just in case it is the result of possessing, or understanding, the concepts involved in P.  The intuition that torture is wrong justifies because it results from possessing the concepts ‘torture’, ‘is’, ‘wrong’.  The experience that the Cubs will win the World Series does not justify because it does not result possessing the concepts involved.</p>
<p style="text-align: justify">I’ve never found this explanation very appealing for two reasons.  The first is essentially this argument: (i) perceptual experiences and a priori experiences justify; (ii) concept possession does not explain why perceptual experiences justify (at least not all of them); (iii) there is one explanation for why experiences justify (so if concept possession doesn’t explain why perceptual experiences justify, then it doesn’t explain why a priori intuitions justify); (iv) therefore, concept possession doesn’t explain why a priori intuitions justify.  The second reason is that if you are going to give concept possession such a prominent role in a priori justification, a priori intuition doesn’t seem to do any work—it just seems along for the ride.</p>
<p style="text-align: justify">My own view on the matter is phenomenal conservatism: necessarily, if it seems to S that P, then S has (prima facie propositional) justification that P.  A seeming that P is an experience with propositional content P and a special kind of phenomenal character.  The phenomenal character “assures” the subject that its content is true.  Perceptual experiences, memorial experiences, and a priori intuitions are all plausible candidates for seemings.  Phenomenal conservatism is unpopular because many find it implausible that <em>all </em>seemings provide justification.  Surely, some argue, a seeming produced by wishful thinking has no justificatory power.</p>
<p style="text-align: justify">Here is another way of pressing the question in which I’m interested: if some seemings justify, why don’t all seemings justify?  It seems that many internalists allow perceptual and a priori seemings to justify, but they don’t allow wishfully-produced seemings to justify.  What principled, internalist criterion can allow only some (and the right ones) to justify?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/hey-internalists-which-experiences-justify-and-why/feed/</wfw:commentRss>
		<slash:comments>17</slash:comments>
		</item>
		<item>
		<title>Reminder: Deadline for Submissions to 3FEF, End of the Month.</title>
		<link>http://certaindoubts.com/reminder-deadline-for-submissions-to-3fef-end-of-the-month/</link>
		<comments>http://certaindoubts.com/reminder-deadline-for-submissions-to-3fef-end-of-the-month/#respond</comments>
		<pubDate>Wed, 10 Feb 2010 19:59:48 +0000</pubDate>
		<dc:creator><![CDATA[Jonathan Weisberg]]></dc:creator>
				<category><![CDATA[formal epistemology]]></category>
		<category><![CDATA[general]]></category>
		<category><![CDATA[perception]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=1716</guid>
		<description><![CDATA[The deadline for submissions to the 3rd Formal Epistemology Festival is the end of this month, Feb. 28. This year&#8217;s festivities are in Toronto, May 11-13, and the topics are Learning from Experience and Defeasible Reasoning.  The invited speakers are &#8230; <a class="more-link" href="http://certaindoubts.com/reminder-deadline-for-submissions-to-3fef-end-of-the-month/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>The deadline for submissions to the 3rd Formal Epistemology Festival is the end of this month, Feb. 28.</p>
<p>This year&#8217;s festivities are in Toronto, May 11-13, and the topics are Learning from Experience and Defeasible Reasoning.  The invited speakers are Thony Gillies (Rutgers), John Horty (Maryland), Mohan Matthen (Toronto), Jim Pryor (NYU), Susanna Siegel (Harvard), and Scott Sturgeon (Oxford University).</p>
<p>The conference website is <a href="http://www.utm.utoronto.ca/~weisber3/3FEF/">here</a> and the CFP is <a href="http://www.utm.utoronto.ca/~weisber3/3FEF/CFP.pdf">here</a>.  Feel free to distribute the CFP and to encourage friends, colleagues, and students to submit papers.  To contact the organizers, email <a href="mailto:FEF3@utoronto.ca">FEF3@utoronto.ca</a>.</p>
<p style="text-align: left">We look forward to seeing you in Toronto!</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/reminder-deadline-for-submissions-to-3fef-end-of-the-month/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Unsafe perceptual knowledge?</title>
		<link>http://certaindoubts.com/unsafe-perceptual-knowledge/</link>
		<comments>http://certaindoubts.com/unsafe-perceptual-knowledge/#respond</comments>
		<pubDate>Tue, 07 Oct 2008 19:50:15 +0000</pubDate>
		<dc:creator><![CDATA[Ted Poston]]></dc:creator>
				<category><![CDATA[general]]></category>
		<category><![CDATA[knowledge]]></category>
		<category><![CDATA[perception]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=873</guid>
		<description><![CDATA[I just finished teaching on Sosa’s safety-based defense of Mooreanism. Here’s a counterexample to safety I made up for my class. (An informal survey, on a 7-point Likert-scale, suggests the intuition enjoys strong support.) BANNED ART EXHIBIT: The Art Institute &#8230; <a class="more-link" href="http://certaindoubts.com/unsafe-perceptual-knowledge/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I just finished teaching on Sosa’s safety-based defense of Mooreanism.  Here’s a counterexample to safety I made up for my class.  (An informal survey,  on a 7-point Likert-scale, suggests the intuition enjoys strong support.)</p>
<blockquote><p>BANNED ART EXHIBIT:  The Art Institute is hosting an exhibit on banned art.  There is one particular very valuable piece that incredibly irks you—it offends every one of your religious and moral instincts.  You dash off an angry letter to the Institute threatening to destroy this piece.  Your letter is so convincing that the officials would secret away that piece of art and replace it with a believable fake.  You send the letter but it gets lost in the mail.  Completely unaware of the intrigue, Sally goes to the Institute and sees the controversial piece of art.  Sally knows that this piece is at the Institute even though her belief is unsafe; in close worlds where the letter isn’t lost in the mail she forms the same belief (through the same method) even though it’s false.</p></blockquote>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/unsafe-perceptual-knowledge/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Undercutting Defeaters for Conditionalizers</title>
		<link>http://certaindoubts.com/843/</link>
		<comments>http://certaindoubts.com/843/#comments</comments>
		<pubDate>Wed, 09 Jul 2008 12:27:11 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[formal epistemology]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[perception]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=843</guid>
		<description><![CDATA[In a forthcoming paper in the British Journal for the Philosophy of Science, Jonathan Weisberg shows that enthusiasts for conditionalization cannot accommodate a certain strong kind of holism. Very interestingly, Weisberg shows that this result does not just hold for &#8230; <a class="more-link" href="http://certaindoubts.com/843/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>
In a forthcoming paper in the <i>British Journal for the Philosophy of Science</i>, Jonathan Weisberg shows that enthusiasts for <i>conditionalization</i> cannot accommodate a certain strong kind of <i>holism</i>. Very interestingly, Weisberg shows that this result does not just hold for classical Bayesian conditionalization &#8212; which is well known to have a strikingly foundationalist character, since Bayesian conditionalization makes the &#8220;evidence&#8221; completely indefeasible; he shows that this result also holds for <i>Jeffrey</i> conditionalization as well. He also suggests that since conditionalizers cannot accommodate this sort of holism, they will have trouble making room for <i>undercutting defeaters</i> (as opposing to <i>rebutting defeaters</i>).</p>
</p>
<p>
In this note, I shall argue that while Weisberg is right that conditionalizers cannot accommodate this strong kind of holism, but they have no problems accommodating undercutting defeaters. (This note owes a great deal  to some correspondence that I have recently had with Weisberg about this issue.)</p>
<p><span id="more-843"></span></p>
<p>
The crucial point is that whenever one updates one&#8217;s credences by conditionalization, the transition from the old credences to the new credences is <i>rigid</i> in the sense that certain conditional probabilities must remain constant throughout the updating process.</p>
<ol>
<li>
     Suppose that your old credences can be represented by the probability function  <i>p</i><sub>0</sub>(•), you acquire the new evidence <i>E</i>, and you update your credences by classical Bayesian conditionalization. Then your updated credences can be represented by the      probability function  <i>p</i><sub>1</sub>(•) = <i>p</i><sub>0</sub>(•|<i>E</i>). This transition from <i>p</i><sub>0</sub> to <i>p</i><sub>1</sub> is rigid with respect to <i>E</i> because for every proposition <i>H</i>, <i>p</i><sub>0</sub>(<i>H</i>|<i>E</i>) = <i>p</i><sub>1</sub>(<i>H</i>|<i>E</i>).</li>
<li>
     Suppose that you do not learn any new &#8220;evidence&#8221; with complete certainty, but your experience somehow changes your credences across a <i>partition {</i><i>E<sub>i</sub></i>} (a partition is a set of propositions such that you are certain that one and only one of those propositions  is true). Specifically, suppose that your experience changes your credences in the members of {<i>E<sub>i</sub></i>} from <i>p</i><sub>0</sub>(<i>E<sub>i</sub></i>) to <i>p</i><sub>1</sub>(<i>E<sub>i</sub></i>). Then if you update the rest of your credences by <i>Jeffrey conditionalization</i>, your updated credences can be represented by the probability function  <i>p</i><sub>1</sub>(•) = &#8721;<sub><i>i</i></sub><i>p</i><sub>0</sub>(•|<i>E<sub>i</sub></i>)<i>p</i><sub>1</sub>(<i>E<sub>i</sub></i>). This transition from <i>p</i><sub>0 </sub> to <i>p</i><sub>1</sub> is rigid with respect to {<i>E<sub>i</sub></i>} because for every proposition <i>H</i>, <i>p</i><sub>0</sub>(<i>H</i>|<i>E<sub>i</sub></i>) = <i>p</i><sub>1</sub>(<i>H</i>|<i>E<sub>i</sub></i>) for each <i>E<sub>i</sub></i>.</li>
</ol>
<p>
From now on, I shall concentrate on Jeffrey conditionalization. Here is a quick sketch of Weisberg’s argument that Jeffrey conditionalization leaves no room for undercutting defeaters.</p>
</p>
<blockquote>
<p>
Suppose that your experience raises your credence in some proposition. E.g., you examine a jelly bean in dim light, and your experience raises your credence in the proposition <i>G</i>, &#8220;The jelly bean is green&#8221;, and lowers your credence in ¬<i>G</i>, &#8220;The jelly bean is not green&#8221;.</p>
</p>
<p>
Now consider the undercutting defeater <i>F</i>, &#8220;The lights are green-tinted&#8221;. If <i>F</i> is an undercutting defeater (as opposed to a  &#8220;rebutting defeater&#8221;), then in advance of your having the experience, <i>F</i> tells you nothing at all about the colour of the jelly bean; so according to the probability function that represents your earlier credences, the conditional probability <i>p</i><sub>0</sub>(<i>G</i>|<i>F</i>) is no different from the unconditional probability <i>p</i><sub>0</sub>(<i>G</i>).</p>
</p>
<p>
However, <i>after</i> you raise your credence in <i>G</i> in response to the experience, <i>F</i> <i>does</i> become relevant to how much credence you should have in <i>G</i>. So it seems that according to the probability function that represents your later credences,  <i>p</i><sub>1</sub>(<i>G</i>| <i>F</i>) must be <i>less</i> than <i>p</i><sub>1</sub>(<i>G</i>). As Weisberg shows, however, this cannot possibly happen if the transition from <i>p</i><sub>0</sub> to <i>p</i><sub>1</sub> is rigid with respect to {<i>G</i>, ¬<i>G</i>}.
</p>
</blockquote>
<p>
The obvious solution for a Jeffrey conditionalizer to go for is to deny that the updating of your credences resulting from your experience is rigid with respect to a simple pair of propositions like {<i>G</i>, ¬<i>G</i>}. The immediate effect of your experience is not just to raise your credence in <i>G</i> and lower your credence in ¬<i>G</i>. Instead the immediate effect of your experience must be more complex.</p>
</p>
<p>
Let <i>D</i> be what I shall call &#8220;the <i>generic</i> defeater&#8221; – let us take it to be the proposition &#8220;My colour experience is not a reliable guide to whether or not the jelly bean is green&#8221;. Then the relevant partition for the impact of your experience is: {<i>G</i>&nbsp;&amp;&nbsp;<i>D</i>, ¬<i>G</i>&nbsp;&amp;&nbsp;<i>D</i>, <i>G</i>&nbsp;&amp;&nbsp;¬<i>D</i>, ¬<i>G</i>&nbsp;&amp;&nbsp;¬<i>D</i>}. So long as your prior rational credence in <i>D</i> is sufficiently low, the main immediate effect of the experience will be that it will greatly increase your credence in <i>G</i>&nbsp;&amp;&nbsp;¬<i>D</i>. However, the experience will increase your credence in <i>G</i>&nbsp;&amp;&nbsp;¬<i>D</i> almost entirely at the expense of your credence in  ¬<i>G</i>&nbsp;&amp;&nbsp;¬<i>D</i>; the experience will barely change your credences in <i>G</i>&nbsp;&amp;&nbsp;<i>D</i> and in ¬<i>G</i>&nbsp;&amp;&nbsp;<i>D</i> at all – or at all events, if it does reduce your credence in either of those, it will do so in a way that leaves the ratio between your credence in <i>G</i>&nbsp;&amp;&nbsp;<i>D</i> and your credence in ¬<i>G</i>&nbsp;&amp;&nbsp;<i>D</i> more or less unchanged.</p>
</p>
<p>
So your experience <i>has</i> changed the conditional probabilities: <i>p</i><sub>1</sub>(<i>G</i>|<i>D</i>) is lower than <i>p</i><sub>1</sub>(<i>G</i>), even though according to the probability function that represented your earlier credences, <i>p</i><sub>0</sub>(<i>G</i>|<i>D</i>) is <i>not</i> lower than <i>p</i><sub>0</sub>(<i>G</i>). So we can now say that any proposition <i>H</i> that raises the probability of the generic defeater <i>D</i>, but did not tell against <i>G</i> according to the probability function that represents the earlier credences, counts as an undercutting defeater for <i>G</i>. I.e., if  <i>p</i><sub>0</sub>(<i>G</i>|<i>H</i>) is <i>not</i> lower than <i>p</i><sub>0</sub>(<i>G</i>), but <i>p</i><sub>1</sub>(<i>D</i>|<i>H</i>) is higher than <i>p</i><sub>1</sub>(<i>D</i>), then <i>H</i> is an undercutting defeater for <i>G</i>.</p>
</p>
<p>
Evidently, this solution involves making room for the possibility of defeaters in the <em>original partition that the experience immediately bears on</em>.  A radical holist would doubt that we can do this, because according to a truly radical holist there is a completely open-ended range of defeaters, and no simple &#8220;generic defeater&#8221; that can be expressed by any single proposition.  For example, the radical holist might insist that even you don’t acquire any evidence that your colour experience is  unreliable, there could be other undercutting defeaters as well. Perhaps you get extraordinary evidence that you are not having the experience at all! Or perhaps you acquire weird evidence that you don’t even possess the concept <i>green</i>, or that you are irrational to the point of total insanity.  Or perhaps …</p>
</p>
<p>
I am not at all convinced that we should be moved by these suggestions from the radical holist, however. It seems more plausible to me that there is a definite range of defeating propositions, which could at least in principle have been identified in advance of your having the particular experience.  So it seems perfectly possible to me that the original partition that the experience immediately bears on has already made room for the possibility of defeaters, in the way that I have sketched.</p>
</p>
<p>
For this reason then, I think that conditionalizers can make room for undercutting defeaters, on the most plausible way of understanding them. It is true that conditionalizers cannot  accommodate radical holism, but this sort of holism is not required in order to make sense of undercutting defeaters.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/843/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
		</item>
		<item>
		<title>Enablers and Conferrers</title>
		<link>http://certaindoubts.com/enablers-and-conferrers/</link>
		<comments>http://certaindoubts.com/enablers-and-conferrers/#comments</comments>
		<pubDate>Sat, 07 Jan 2006 14:28:11 +0000</pubDate>
		<dc:creator><![CDATA[Kvanvig Jon]]></dc:creator>
				<category><![CDATA[justification]]></category>
		<category><![CDATA[memory]]></category>
		<category><![CDATA[perception]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=503</guid>
		<description><![CDATA[I was talking with Matt McGrath yesterday about the following problem. If we consider ordinary epistemic principles such as &#8220;if you&#8217;re appeared to F-ly, without grounds for doubt, then it is reasonable to believe that something is F,&#8221; we can &#8230; <a class="more-link" href="http://certaindoubts.com/enablers-and-conferrers/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I was talking with Matt McGrath yesterday about the following problem.  If we consider ordinary epistemic principles such as &#8220;if you&#8217;re appeared to F-ly, without grounds for doubt, then it is reasonable to believe that something is F,&#8221; we can distinguish conferrers of justification (in this case, being appeared to F-ly) from enablers (in this case, lacking grounds for doubt).  (The question is important especially regarding memorial beliefs which are dispositional and regarding which one no longer possesses the original evidence for the beliefs.  It looks like about all that such beliefs having going for them, if one insists that justification must depend on <em>present</em> factors, is the idea that one has no reason to abandon them.)</p>
<p>Here&#8217;s one idea, though I think Matt was ultimately not satisfied with it.</p>
<p><span id="more-503"></span>Conferrers obey a principle connecting the state of being justified with the practice of justifying a belief.  A conferrer of justification is an item one could legitimately cite in defense of a belief.  The lack of grounds for doubt can&#8217;t be so cited, so it&#8217;s not a conferrer of justification.</p>
<p>One problem that worried Matt, and he&#8217;s right about this, is the question of how complete a cited defense might be.  So if asked, relative to the above principle, one might say, &#8220;I&#8217;m appeared to F-ly&#8221;.  But one might also say, &#8220;I&#8217;m appeared to F-ly and have no reason to doubt that my appearances are accurate in this case.&#8221;  Both answers are acceptable, and hence the latter conjunction would have to count as a conferrer as well.</p>
<p>This possibility would be a problem if, whenever A&#038;B is a conferrer of justification on p, then so is A and so is B.  But that problem can be resolved just by denying &#038;-Elim in this context.</p>
<p>Here&#8217;s a different and deeper worry, however.  If asked about continuing to believe the kind of memorial belief mentioned in the first paragraph, one likely response would be that you have no reason to abandon the belief.  We often defend our actions this way (&#8220;because I always eat oatmeal for breakfast&#8221;), and it is hard to see why such a defense isn&#8217;t legitimate.  It can, of course, be challenged, but so can the defense in terms of appearances (&#8220;you say you believe something is F because your appeared to F-ly, but that&#8217;s a lousy reason unless you supplement it with something else, such as a principle of self-trust&#8221;).</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/enablers-and-conferrers/feed/</wfw:commentRss>
		<slash:comments>11</slash:comments>
		</item>
		<item>
		<title>Experience and Propositional Content</title>
		<link>http://certaindoubts.com/experience-and-propositional-content/</link>
		<comments>http://certaindoubts.com/experience-and-propositional-content/#comments</comments>
		<pubDate>Wed, 04 Jan 2006 15:40:12 +0000</pubDate>
		<dc:creator><![CDATA[Kvanvig Jon]]></dc:creator>
				<category><![CDATA[foundationalism and coherentism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[knowledge]]></category>
		<category><![CDATA[perception]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=494</guid>
		<description><![CDATA[The restrictive view that collapses the distinction between epistemic permission and epistemic obligation is at odds with most versions of coherentism, and there&#8217;s an interesting reason why, I think. Suppose we begin with the assumption that knowledge and justification ultimately &#8230; <a class="more-link" href="http://certaindoubts.com/experience-and-propositional-content/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>The restrictive view that collapses the distinction between epistemic permission and epistemic obligation is at odds with most versions of coherentism, and there&#8217;s an interesting reason why, I think.  Suppose we begin with the assumption that knowledge and justification ultimately depend on experience (at least causally), and then consider what the relationship between experience and belief must be in order for the restrictive view to be correct.  In order for the restrictive view to be correct, there can&#8217;t be any kind of optionality about how to interpret experience, doxastically speaking.   Coherentists, and Lehrer is a paradigmatic example here, usually think of the relationship as involving some kind of looseness or play.  Lehrer puts the point something like this:  there is experience, but then there is always what we make of it.  It is this feature that leads to the &#8220;alternative systems&#8221; objection to coherentism, though it is hard to see why it is an objection unless you&#8217;ve already got a decisive argument for the restrictive view.</p>
<p>In any case, this slippage between experience and belief is harder to endorse if you think that experience justifies belief in virtue of some propositional content of the experience.</p>
<p><span id="more-494"></span>If, for example, your experience is correctly characterized as an experience as if p, then it is hard to see why this experience doesn&#8217;t justify just the belief that p.  Of course, an experience can be manifold in terms of propositional content:  it may be both an experience as if p and as if q.  In such a case, it looks like it will justify believing that p and believing that q.</p>
<p>What it won&#8217;t do is justify believing any competitors of p and q, and that is the point needed by coherentists to defend the kind of looseness or play that allows for a denial of the restrictive view based on the idea of a distinction between experience and its interpretation.  So it looks like (empiricistically inclined) coherentists who want to distinguish between epistemic permissions and epistemic obligations may need the view that the justificatory relationship between experience and belief does not depend on experience having propositional content.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/experience-and-propositional-content/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
		</item>
	</channel>
</rss>
