<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>knowledge &#8211; </title>
	<atom:link href="http://certaindoubts.com/category/knowledge/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 01:35:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>New empirical studies on epistemic contextualism</title>
		<link>http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/</link>
		<comments>http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/#comments</comments>
		<pubDate>Sun, 28 Feb 2016 18:26:42 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[contextualism]]></category>
		<category><![CDATA[general]]></category>
		<category><![CDATA[knowledge]]></category>
		<category><![CDATA[experimental epistemology]]></category>
		<category><![CDATA[methodology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4748</guid>
		<description><![CDATA[Epistemic contextualism is the view that the verb “know” is a context sensitive expression. As a first approximation, epistemic contextualism states that in order for us to truthfully say a person “knows” a proposition, that person must meet the standards &#8230; <a class="more-link" href="http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Epistemic contextualism is the view that the verb “know” is a context sensitive expression. As a first approximation, epistemic contextualism states that in order for us to truthfully say a person “knows” a proposition, that person must meet the standards set by our context and, critically, the standards change across contexts. The variation is thought to be theoretically important partly because it might indicate an ingredient of (the truth conditions of) &#8220;knowledge&#8221; statements beyond the traditional factors of belief, evidence, and truth.</p>
<p>Contextualists motivate their view based on a set of empirical claims about competent speakers’ linguistic behavior in certain situations. A famous way of illustrating the idea involves a pair of cases about a man who wants to deposit a check and is deciding whether to wait in a long line at the bank on a Friday afternoon, or come back on Saturday morning when the line would be short. But the question arises: is this bank actually open Saturday morning? The man visited this bank two Saturdays ago and it was open then, but banks do sometimes change their hours. In the “low stakes” version of the case, nothing serious hinges on whether he deposits the check before the weekend is over, and the man says, “I know that the bank is open tomorrow.” In the “high stakes” version of the case, something very serious hinges on whether he deposits the check before the weekend is over, and the man says, “I don’t know that the bank is open tomorrow.”</p>
<p>Contextualists claim that competent speakers will judge that the man truthfully says he “knows” in the low stakes version, and that the man truthfully says he “doesn’t know” in the high stakes version.</p>
<p>Do people behave as contextualists predict? Prior research on this empirical question has yielded mixed results. Taking into account methodological objections raised by contextualists,* I ran another series of studies to investigate the issue.** I found that, <strong><span style="color: #0000ff">just as contextualists predicted</span></strong>, people judged that the man truthfully says he “knows” in the low stakes case, and that the man truthfully says he “doesn’t know” in the high-stakes case.<span id="more-4748"></span></p>
<p>&nbsp;</p>
<p>However, I also found two other things that make it very difficult to interpret this as evidence for contextualism.</p>
<p>On the one hand, there is <span style="color: #0000ff"><strong>the general shifting problem</strong></span>: switching from low to high stakes also significantly decreased belief attributions, the evaluation of the agent’s evidence, and people’s confidence that the bank was open tomorrow. Thus, the contextualist hypothesis is not needed to explain the observed pattern in knowledge judgments: it could easily be explained by changes in underlying judgments about belief, evidence, and truth. This confirms some suspicions voiced by some philosophers over the years (e.g. Kent Bach and Jennifer Nagel).</p>
<p>On the other hand, there is <strong><span style="color: #0000ff">the deferral confound</span></strong>. Even if nothing about stakes or error possibilities is mentioned, people tend to agree that the agent speaks truthfully when he says “I know,” and they also tend to agree when he says “I don’t know.” In short, people tend to defer to another person’s self-regarding knowledge statement. (Some evidence for this might also be gleaned from earlier work by Wesley Buckwalter and Nat Hansen &amp; Emmanuel Chemla.)*** Unfortunately, this low-level agreement bias has been obscured because contextualist test cases are multiply confounded.</p>
<p>To illustrate the deferral confound, consider a pair of cases I tested, which involve not a low/high manipulation but rather a yes/no manipulation:</p>
<p style="padding-left: 30px">(Yes/No) Keith and his wife Jane are driving home from work on Friday afternoon. They just received a check from a client, which Keith plans to deposit in their bank account. As they drive past the bank, they see that the lines inside are very long. Keith says, “I hate waiting in line. I’ll just come back tomorrow morning instead.” Jane asks, “Do you know that our bank is open tomorrow?” Keith answers, “It was two Saturdays ago that I went to our bank, and it was open. So, [yes, I do/no, I don’t] know that our bank is open tomorrow.”</p>
<p>People tended to agree with the agent in both cases. Thus manipulating stakes (low/high) is not needed to produce the basic pattern in knowledge judgments that contextualists have focused on. Moreover, a follow-up study revealed that when the deferral confound is removed, manipulating stakes does not produce the relevant pattern in knowledge judgments: instead, people tend to (meta-linguistically) attribute knowledge in both low and high stakes cases (i.e. they say that the man should say “I know” in order to speak truthfully).</p>
<p>Based on these findings — all of which were replicated across multiple cover stories — I conclude that the principal extant motivation for contextualism fails. Contextualists still owe us a distinguishing prediction of their view, something we would confidently expect only if contextualism were true, or which contextualism seems uniquely suited to explain. Absent that, contextualism is an idle hypothesis and we should not accept it.</p>
<p>Of course, it is consistent with these findings that such a prediction will be made and vindicated. That would be an interesting development! But, moving forward, hopefully the theoretical debate will not get too far out ahead of available evidence. The fact that experimental epistemology is now a firmly established and growing interdisciplinary field will likely help in this regard.</p>
<p>* DeRose, K. (2011). <a href="http://link.springer.com/article/10.1007%2Fs11098-011-9799-x?LI=true" target="_blank">Contextualism, contrastivism, and X-Phi surveys</a>. <em>Philosophical Studies</em>, 156(1), 81–110.</p>
<p>** Turri, J. (in press). <a href="http://john.turri.org/research/idle.pdf" target="_blank">Epistemic contextualism: an idle hypothesis</a>. <em>Australasian Journal of Philosophy</em>.</p>
<p>*** For discussion, see Buckwalter, W. (in press). Epistemic contextualism and linguistic behavior. In Ichikawa, J. J. (Ed.), <em>Handbook of Epistemic Contextualism</em>. Routledge.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
		</item>
		<item>
		<title>What philosophers think might not be what you think they think</title>
		<link>http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/</link>
		<comments>http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/#comments</comments>
		<pubDate>Sun, 14 Feb 2016 04:13:24 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4738</guid>
		<description><![CDATA[Professional philosophers often appeal to patterns in ordinary thought and talk — “commonsense” — in order to support theories or assumptions. In recent years, the emerging interdisciplinary field of experimental epistemology has revealed many instances where commonsense epistemology has been &#8230; <a class="more-link" href="http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Professional philosophers often appeal to patterns in ordinary thought and talk — “commonsense” — in order to support theories or assumptions. In recent years, the emerging interdisciplinary field of experimental epistemology has revealed many instances where commonsense epistemology has been seriously mischaracterized. But even if professional philosophers misidentify what the folk think about knowledge, certainly they know what they themselves think about knowledge. Right?</p>
<p>Wrong.</p>
<p>In a fascinating <a href="http://link.springer.com/article/10.1007/s11098-016-0627-1">paper</a> forthcoming in <em>Philosophical Studies</em>, a pair of researchers tested ordinary people and professional philosophers (“experts”) on a range of cases.* A principal finding concerns knowledge attributions in cases where an agent sees an object that is surrounded by visually indistinguishable fakes.<span id="more-4738"></span></p>
<p>Here is one case they tested:</p>
<p style="padding-left: 30px">(Sculpture) The director of a sculpture museum is so impressed with recent improvements of hologram images that she decides to perform a secret test on the visitors of her museum. To this end, she orders hologram images that even art experts cannot visually distinguish from the real sculptures in her museum, and she replaces all but one of the sculptures by their hologram image. As the director had expected, no one realizes any difference between the hologram images and the real sculptures. One day, the world’s greatest Rodin expert is visiting her museum. The expert is standing in front of a famous marble sculpture by Rodin, which is the only real sculpture that is presently on display in the museum, and she thinks to herself: “I’m facing one of Rodin’s famous marble sculptures now.”</p>
<p>Participants rated their agreement with whether &#8220;the Rodin expert knows that the sculpture in front of her is one of Rodin’s famous marble sculptures.”</p>
<p>The case is structurally similar to the famous “fake barn” case. Textbooks and review articles tell us that there is “broad agreement” among experts that these aren’t cases of knowledge. And this verdict is often treated as a litmus test for theories of knowledge: if your view implies that there is knowledge in a “fake barn&#8221; case, this is often treated as a decisive refutation of your view. Accordingly, we would expect that most experts will deny that Sculpture is a case of knowledge.</p>
<p>But that’s not what the researchers found. Instead, a majority of experts <em>attributed</em> knowledge. Surprised, the researchers tested the case again on another group of experts. And, just for good measure, they tested another case with a “fake barn” structure too. Perhaps the initial result was a fluke?</p>
<p>It wasn’t.</p>
<p>Again and again, most experts attributed knowledge. Ongoing work by another team of researchers has returned broadly similar results.**</p>
<p>The researchers also found that in a case structurally similar to a “lottery case,” the majority of experts attributed knowledge, which again contradicts “the textbook consensus.”</p>
<p>Based on these findings, the researchers concluded that “the discipline of epistemology is dysfunctional insofar” as it is “deluded about” its practitioners&#8217; verdicts about cases.</p>
<p>I’ve only covered some of the paper&#8217;s interesting findings. Check it out!</p>
<p>*Horvath, J., &amp; Wiegmann, A. (2016). Intuitive expertise and intuitions about knowledge. Philosophical Studies, 1–26. http://doi.org/10.1007/s11098-016-0627-1</p>
<p>**Carter, J. A., Pritchard, D., &amp; Sheperd, J. (ms). Knowledge-how, understanding-why and epistemic luck: an experimental study.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/feed/</wfw:commentRss>
		<slash:comments>37</slash:comments>
		</item>
		<item>
		<title>Proto-reliabilism followup</title>
		<link>http://certaindoubts.com/proto-reliabilism-followup/</link>
		<comments>http://certaindoubts.com/proto-reliabilism-followup/#comments</comments>
		<pubDate>Sun, 24 Jan 2016 04:09:59 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[memory]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4722</guid>
		<description><![CDATA[Following up on some thoughtful suggestions in the comments to my previous post, I ran a couple follow-up studies with modified stimuli. One main question was whether people understood an &#8220;unreliable memory&#8221; to mean (1) most of the agent&#8217;s apparent memories contain false &#8230; <a class="more-link" href="http://certaindoubts.com/proto-reliabilism-followup/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Following up on some thoughtful suggestions in the comments to my <a href="http://certaindoubts.com/the-proto-reliabilist-hypothesis/">previous post</a>, I ran a couple follow-up studies with modified stimuli.<span id="more-4722"></span></p>
<p>One main question was whether people understood an &#8220;unreliable memory&#8221; to mean (1) most of the agent&#8217;s apparent memories contain false information, as opposed to (2) most of the agent apparent memories contain true information, even though the agent fails to retain information most of the time. If people understand &#8220;unreliable memory&#8221; in sense 2, then it could complicate the interpretation of one of the findings that undermine the proto-reliabilist hypothesis. Will we observe similar results if it&#8217;s made clearer that sense 1 is at issue?</p>
<p>To emphasize sense 1, I tested the following pair of cases (the reliability manipulation is bracketed):</p>
<p style="padding-left: 30px">Alvin is [unreliable/reliable] at remembering driving directions. Usually when it seems to him that he should make a particular turn, he’s [incorrect/correct]. Today Alvin is visiting a friend in an unfamiliar town. Alvin needs to pick up a prescription while he is there, so his friend gives him directions to the pharmacy. On the way, Alvin needs to turn right at Main Street. Alvin gets to Main Street and turns right, which is the correct turn.</p>
<p>People rated whether Alvin &#8220;knew&#8221; or &#8220;only thought&#8221; that &#8220;he needed to turn right at Main Street.&#8221; The rate of knowledge attribution was very high in both conditions: 83% in the unreliable condition and 97% in the reliable condition. This numerical difference did not reach statistical significance at the conventional .05 level  (N = 60, p = .098, v = .07). I then conducted a second follow-up with the same cases but a more sensitive 7-point scaled knowledge attribution. Mean knowledge attribution was again very high in both conditions: 6.13 in the unreliable condition and 5.71 in the reliable condition and the difference was not significant (N = 61, p = .290).</p>
<p>I believe that these results should make us more confident that knowledge ordinarily understood does not require reliability in sense 1. Of course, these results cannot show that there is no conceptual connection between reliability and knowledge, but the relationship does not appear to be (in the ballpark of) a necessary condition.</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilism-followups.png" rel="attachment wp-att-4723"><img class="alignnone wp-image-4723 size-full" src="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilism-followups-e1453607364487.png" alt="protoreliabilism-followups" width="500" height="360" /></a></p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/proto-reliabilism-followup/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>The proto-reliabilist hypothesis</title>
		<link>http://certaindoubts.com/the-proto-reliabilist-hypothesis/</link>
		<comments>http://certaindoubts.com/the-proto-reliabilist-hypothesis/#comments</comments>
		<pubDate>Thu, 21 Jan 2016 19:09:33 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4713</guid>
		<description><![CDATA[I conducted a simple study to determine whether knowledge, ordinarily understood, requires reliability.]]></description>
				<content:encoded><![CDATA[<p>In contemporary Anglo-American epistemology, it is very widely assumed that knowledge must be reliably produced. On this view, knowledge must be produced by abilities (processes, faculties, powers, etc.) that “will or would yield mostly true beliefs,” as William Alston put it. Call this consensus view “knowledge reliabilism.”</p>
<p>One thing I’ve always been surprised by is how little explicit, direct argumentation there is for knowledge reliabilism in the literature. An old paper by Goldman contains a weak explanatory argument, which gets cited sometimes. Aside from that, the main consideration offered in support of knowledge reliabilism is that it’s just commonsense. For instance, Edward Craig claims that reliabilism “matches our everyday practice with the concept of knowledge as actually found,” that it is “a good fit to the intuitive extension of ‘know’.” And Ernest Sosa claims that reliabilism is the theoretical “correlate” of “commonsense” epistemology. Call this “the proto-reliabilist hypothesis” about folk epistemology.</p>
<p>The proto-reliabilist hypothesis makes at least a couple straightforward predictions. First, people will tend to deny knowledge in cases of unreliably formed belief. Second, clear and explicit differences in reliability should produce large differences in people’s willingness to attribute knowledge. These predictions can be tested with some very simple experiments. Below I briefly describe one I ran.<span id="more-4713"></span></p>
<p>Participants read a brief story about Alvin. While visiting a friend in an unfamiliar town, Alvin needs to pick up a prescription. He’s on his way to the pharmacy and approaches an intersection where he needs to turn right. Some crucial details of the story differed across conditions. I manipulated whether Alvin was very unreliable or very reliable at remembering driving directions. I also manipulated whether he made the incorrect or correct turn at the intersection. Here is the text participants read, with the two manipulations noted in brackets:</p>
<p style="padding-left: 30px">Alvin is very [unreliable/reliable] at remembering driving directions. Today he is visiting a friend in an unfamiliar town. Alvin needs to pick up a prescription while he is there, so his friend gives him directions to the pharmacy. On the way, Alvin needs to make a [left/right] turn at an intersection. Alvin gets to the intersection and turns right.</p>
<p>Participants then responded to an open knowledge probe:</p>
<p style="padding-left: 30px">When he got to the intersection, Alvin _____ that he should turn right to get to the pharmacy.</p>
<p>The options were “knew” and “only thought.” Here are the results:</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm.jpg" rel="attachment wp-att-4717"><img class="alignnone size-full wp-image-4717" src="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm.jpg" alt="protoreliabilsm" width="1004" height="710" srcset="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm.jpg 1004w, http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm-300x212.jpg 300w, http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm-768x543.jpg 768w, http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm-424x300.jpg 424w" sizes="(max-width: 1004px) 100vw, 1004px" /></a></p>
<p>&nbsp;</p>
<p>The results from the two conditions where Alvin makes the incorrect turn (the &#8220;false&#8221; conditions) were exactly as you would expect: he thinks he should turn left, so people overwhelmingly denied that he knows he should turn right. But the results from the two conditions where Alvin makes the correct turn (the &#8220;true&#8221; conditions) were very different from what the proto-reliabilist hypothesis predicts. When Alvin made the correct turn, people attributed knowledge at similarly high rates, regardless of whether he was very reliable or very unreliable at remembering driving directions (80% vs. 77%).</p>
<p>This same basic pair of findings — high rates of knowledge attribution for beliefs produced by unreliable abilities, and little to no effect of reliability/unreliability on knowledge attributions — replicates across different narrative contexts, cognitive abilities, and ways of measuring knowledge attributions.</p>
<p>Overall, this leads me to conclude that the proto-reliabilist hypothesis is false. Knowledge ordinarily understood does not require reliability.</p>
<p>(A fuller description of these findings and other studies can be found in a <a href="http://john.turri.org/research/paradigm.pdf" target="_blank">paper</a> forthcoming in Ergo.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/the-proto-reliabilist-hypothesis/feed/</wfw:commentRss>
		<slash:comments>15</slash:comments>
		</item>
		<item>
		<title>New Study: No Difference in Gettier Intuition Across Cultures</title>
		<link>http://certaindoubts.com/new-study-no-difference-in-gettier-intuition-across-cultures/</link>
		<comments>http://certaindoubts.com/new-study-no-difference-in-gettier-intuition-across-cultures/#comments</comments>
		<pubDate>Wed, 19 Aug 2015 18:11:42 +0000</pubDate>
		<dc:creator><![CDATA[Joshua Knobe]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[experimental philosophy]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4650</guid>
		<description><![CDATA[Within the more metaphilosophically-oriented literature on experimental philosophy, there has been a great deal of discussion of the philosophical implications of cross-cultural differences in intuitions about Gettier cases. This work has been extremely impressive from a purely philosophical perspective, but &#8230; <a class="more-link" href="http://certaindoubts.com/new-study-no-difference-in-gettier-intuition-across-cultures/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Within the more metaphilosophically-oriented literature on experimental philosophy, there has been a great deal of discussion of the philosophical implications of cross-cultural differences in intuitions about Gettier cases. This work has been extremely impressive from a purely philosophical perspective, but at times, I worry that it has not been sufficiently closely connected to the actual empirical work in this area. In particular, much of it starts off from the assumption that people of different cultures differ in their intuitions about Gettier cases, but it turns out that the majority of the empirical studies actually find that Gettier intuitions do not depend on culture in this way (see <a href="http://philpapers.org/rec/KIMNCD" target="_blank">here</a>, <a href="http://philpapers.org/rec/SEYONA-2" target="_blank">here</a> and <a href="http://www.yorku.ca/mar/Nagel%20et%20al%20in%20press_Cog_Lay%20denial%20of%20knowledge%20for%20justified%20true%20beliefs.pdf" target="_blank">here</a>). So it sometimes seems that people are investigating the philosophical implications of an effect that doesn&#8217;t actually exist.</p>
<p>Happily, <em>Noûs</em> has just published a truly amazing <a href="http://onlinelibrary.wiley.com/doi/10.1111/nous.12110/abstract" target="_blank">study</a> on this topic by a team of experimental philosophers (Machery, Stich, Rose, Chatterjee, Karasawa, Struchiner, Sirker, Usui &amp; Hashimoto), and I think this new study gives us a much better understanding of the relevant empirical facts. The researchers presented two different Gettier cases to participants in the United States, Brazil, India and Japan, yielding a total sample size of 521 participants. The study is extraordinarily impressive from a methodological perspective and very much worth reading in full, but the basic result can be expressed pretty simply in the following figure:</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2015/08/Slide2.jpg"><img class="  wp-image-4651 aligncenter" src="http://certaindoubts.com/wp-content/uploads/2015/08/Slide2-300x225.jpg" alt="Slide2" width="410" height="313" /></a></p>
<p>Overall, the study finds no significant cross-cultural difference but instead a robust tendency, found across all four cultures, to conclude that people do not have knowledge in Gettier cases.</p>
<p>Of course, this finding does not mean that philosophers were mistaken to think that there was something of deep metaphilosophical importance about looking at Gettier intuitions in different cultures. On the contrary, the result obtained here is a truly fascinating one, which surely has rich metaphilosophical implications. The key point is just that the metaphilosophical question we need to be asking is the opposite one from the one people have been discussing thus far. The question worth asking is not &#8216;What are the metaphilosophical implications of cross-cultural differences in Gettier intuitions?&#8217; but rather &#8216;What are the metaphilosophical implications of the extraordinary cross-cultural similarity in Gettier intuitions?&#8217; This latter question has not yet been sufficiently explored, but it opens up a whole new range of exciting issues that I hope philosophers will begin exploring over these next few years.</p>
<p>[Cross-posted at <a href="http://philosophycommons.typepad.com/xphi/2015/08/new-study-no-difference-in-gettier-intuition-across-cultures.html" target="_blank">Experimental Philosophy</a>. The <a href="http://onlinelibrary.wiley.com/doi/10.1111/nous.12110/abstract" target="_blank">full paper </a>is available to subscribers at <em>Noûs</em>, but please do feel free to write in with comments even if you have not yet read the paper itself.]</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/new-study-no-difference-in-gettier-intuition-across-cultures/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>Contextualism and Skepticism &#8212; draft of chapter</title>
		<link>http://certaindoubts.com/contextualism-and-skepticism-draft-of-chapter/</link>
		<comments>http://certaindoubts.com/contextualism-and-skepticism-draft-of-chapter/#respond</comments>
		<pubDate>Wed, 13 May 2015 18:09:05 +0000</pubDate>
		<dc:creator><![CDATA[DeRose]]></dc:creator>
				<category><![CDATA[contextualism]]></category>
		<category><![CDATA[knowledge]]></category>
		<category><![CDATA[skepticism]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4608</guid>
		<description><![CDATA[link pdf Does the contextualist seek to dissolve disputes over skepticism? And does she use a &#8220;perfectly general strategy&#8221; for doing so? Is she not interested in, or not addressing, the traditional topic of whether we really know things, instead &#8230; <a class="more-link" href="http://certaindoubts.com/contextualism-and-skepticism-draft-of-chapter/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>link <a href="http://pantheon.yale.edu/~kd47/Contextualism%20and%20Skepticism--5-13-15.pdf">pdf</a></p>
<p>Does the contextualist seek to dissolve disputes over skepticism? And does she use a &#8220;perfectly general strategy&#8221; for doing so? Is she not interested in, or not addressing, the traditional topic of whether we really know things, instead addressing how the word &#8220;know&#8221; should be used? Is she engaged in philosophy of language instead of epistemology? Is she addressing the more important types of skeptic? And what are those? Are key aspects of her position inexpressible, by her o<span class="text_exposed_show">wn lights? Is she subject to a &#8220;factivity problem&#8221;? These and other questions are answered in this draft of my 4th chapter of the book I&#8217;ve been working on. Please let me know if there are other pressing worries I don&#8217;t address, or if there&#8217;s some problem with some of my answers.<br />
For my part, I&#8217;ll be happy if I just never again have to hear anything like &#8220;The contextualist only answers the high standards skeptic.&#8221;<br />
Oh, I forgot: <img src="https://s.w.org/images/core/emoji/11/72x72/1f642.png" alt="🙂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></span></p>
<p>I suppose one question I don&#8217;t explicitly address here is whether I construe myself as<br />
doing &#8220;ordinary language philosophy.&#8221; I&#8217;m not sure what that would be, or if I&#8217;m doing<br />
it, but at and around the top of p. 24, I am explaining/defending one aspect of my<br />
approach that I suppose could be construed as a way that I have at least partly taken<br />
some &#8220;linguistic turn.&#8221;</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/contextualism-and-skepticism-draft-of-chapter/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Trouble for E=K?</title>
		<link>http://certaindoubts.com/trouble-for-ek/</link>
		<comments>http://certaindoubts.com/trouble-for-ek/#comments</comments>
		<pubDate>Thu, 11 Dec 2014 13:11:27 +0000</pubDate>
		<dc:creator><![CDATA[Clayton Littlejohn]]></dc:creator>
				<category><![CDATA[foundationalism and coherentism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[knowledge]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4543</guid>
		<description><![CDATA[Here&#8217;s a view that I think some people are attracted to, a tripartite view of how positive epistemic standing is attained: Tripartite View: For a belief to constitute knowledge, three elements have to be in place: (a) There&#8217;s the belief &#8230; <a class="more-link" href="http://certaindoubts.com/trouble-for-ek/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Here&#8217;s a view that I think some people are attracted to, a tripartite view of how positive epistemic standing is attained: </p>
<blockquote><p>Tripartite View: For a belief to constitute knowledge, three elements have to be in place:<br />
(a) There&#8217;s the belief about such and such;<br />
(b) Independent representational state of mind that represents some such and such;<br />
(c) The matter that the belief mentioned in (a) concerns that&#8217;s made rational by some state of mind mentioned in (b).</p></blockquote>
<p>When it comes to rationality or justification, only the first two terms are supposed to matter. This seems harmless enough, but it looks like this view might be in tension with a view I know you all love: </p>
<blockquote><p>E=K: Your evidence includes all and only what you know. </p></blockquote>
<p>1. To know p, you have to have a reason to believe p where this reason is your reason for believing p, a reason that’s provided by a representational state of mind that’s independent from the belief that p.<br />
2. This representational state either has p as its content or something distinct from p.<br />
3. If the former, the state would (under suitable conditions) enable the subject to believe things for the reason that p.<br />
4. The subject’s reason for believing p cannot be p.<br />
5. Thus, if there is a representational state that provides you with a reason that enables you to know p perceptually, it must have a content that’s distinct from p.<br />
6. Suppose that the representational state’s content is some distinct content, p’ and that (under suitable conditions), this representational state would enable the subject to believe things for the reason that p’.<br />
7. To know p perceptually as a result of believing p for the reason that p’, you have to know p’.<br />
8. To know p’, you have to have a reason to believe p’ where this reason is your reason for believing p’, a reason that’s provided by a representational state of mind that’s independent from the belief that p’.</p>
<p>Now, once you get to (8), it looks like we have the start of a vicious regress. The argument makes knowing p conditional on knowing p&#8217; on the basis of p&#8221; and I think it&#8217;s clear that p&#8221; has to be distinct from both p and p&#8217;.  If you think of your reasons for believing something as what convinced you that something was so, it&#8217;s hard to see how p could convince you that p&#8217; and p convince you that p&#8217;.  </p>
<p>What&#8217;s the best solution? (I have a favorite, but I&#8217;m not going to share it for a while.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/trouble-for-ek/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
		</item>
		<item>
		<title>Epistemic closure and folk epistemology</title>
		<link>http://certaindoubts.com/closure-and/</link>
		<comments>http://certaindoubts.com/closure-and/#comments</comments>
		<pubDate>Sat, 06 Sep 2014 23:05:40 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[experimental philosophy]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4475</guid>
		<description><![CDATA[Consider this case: When Maxwell arrives at work in the morning, he always parks in one of two spots: C8 or D8. Half the time he parks in C8, and half the time he parks in D8. Today Maxwell parked &#8230; <a class="more-link" href="http://certaindoubts.com/closure-and/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Consider this case:</p>
<p style="padding-left: 30px">When Maxwell arrives at work in the morning, he always parks in one of two spots: C8 or D8. Half the time he parks in C8, and half the time he parks in D8. Today Maxwell parked in C8. It’s lunchtime at work. Maxwell and his assistant are up in the archives room searching for a particular document. Maxwell says, “I might have left the document in my car.” The assistant asks, “Mr. Maxwell, is your car parked in space C8? It’s not unheard of for cars to be stolen.” Maxwell thinks carefully for a moment and then responds, “No, my car has not been stolen. It is parked in C8.”</p>
<p>Which of the following options best describes Maxwell?</p>
<ol>
<li>He knows that his car is parked in C8. And he knows that his car has not been stolen.</li>
<li>He does not know that his car is parked in C8. But he does know that his car has not been stolen.</li>
<li>He knows that his car is parked in C8. But he does not know that his car has not been stolen.</li>
<li>He does not know that his car is parked in C8. And he does not know that his car has not been stolen.</li>
</ol>
<p>The epistemic closure principle says, roughly, that if one knows that P, and one knows that if P then Q, and one infers Q, then one knows Q. Some philosophers, most notably Robert Nozick and Fred Dretske, reject the closure principle. However, many epistemologists have claimed that rejecting closure is extremely counterintuitive and radically revisionary. Related to these claims, philosophers have also claimed that conjunctive assertions suggesting a violation of closure are &#8220;abominable&#8221; and &#8220;repugnant.&#8221;</p>
<p>So if conventional wisdom in epistemology is correct, then when people consider the question about Maxwell above, the intuitively best answer will not be option 3. Instead, option 3 should seem absurd.</p>
<p>However, as reported in a <span style="text-decoration: underline"><strong><a href="http://john.turri.org/research/open_shut.pdf" target="_blank">paper</a></strong></span> forthcoming in <em>Philosophers&#8217; Imprint</em>, when I tested this case, it turned out that option 3 was viewed as <em>the best option</em>: nearly two-thirds of participants selected it.</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2014/09/best-option.png"><img class="alignnone  wp-image-4480" src="http://certaindoubts.com/wp-content/uploads/2014/09/best-option.png" alt="best option" width="488" height="311" /></a></p>
<p>&nbsp;</p>
<p>We see a similar pattern if we just ask people whether (A) Maxwell knows that his car is parked in the lot, and (B) Maxwell knows that his car has not been stolen. Roughly 80% of people agree with A, while only about 35% of people agree with B.</p>
<p>In light of these results, it seems that closure-denying conjunctions don&#8217;t actually strike people as absurd. Moreover, it is highly doubtful that rejecting the epistemic closure principle actually is revisionary.</p>
<p>&nbsp;</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/closure-and/feed/</wfw:commentRss>
		<slash:comments>36</slash:comments>
		</item>
		<item>
		<title>In defence of adherence</title>
		<link>http://certaindoubts.com/in-defence-of-adherence/</link>
		<comments>http://certaindoubts.com/in-defence-of-adherence/#comments</comments>
		<pubDate>Thu, 29 May 2014 10:27:59 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[knowledge]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4399</guid>
		<description><![CDATA[What more is required of a belief, besides being justified and true (JTB), if the belief is to count as knowledge? In my view, at least two further conditions are required: the belief must meet the conditions of safety and &#8230; <a class="more-link" href="http://certaindoubts.com/in-defence-of-adherence/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>What more is required of a belief, besides being <em>justified</em> and <em>true</em> (JTB), if the belief is to count as <em>knowledge</em>? In my view, at least two further conditions are required: the belief must meet the conditions of <em>safety</em> and <em>adherence</em>.</p>
<p>Safety is popular these days: it has been defended by many distinguished epistemologists,&nbsp;such as&nbsp;Duncan Pritchard and Timothy Williamson, among others. But adherence – the fourth condition that Robert Nozick imposed on knowledge – has few defenders. Most of the philosophers who have discussed adherence have rejected it. In this post, I defend adherence against its detractors.</p>
<p><span id="more-4399"></span></p>
<p>First, let me explain how I understand adherence. Let us focus on a case <em>C</em><sub>1</sub> in which a believer believes a true proposition <em>p</em><sub>1</sub> in a doxastically justified or rational manner. Then this belief “adheres to the truth” if and only if every <em>normal</em> case <em>C</em><sub>2</sub> that is <em>sufficiently similar</em> to <em>C</em><sub>1</sub> with respect to what makes the belief rationally held in <em>C</em><sub>1</sub>, and with respect to the case’s target proposition <em>p</em><sub>2</sub>’s being true, is also similar in that the believer believes <em>p</em><sub>2</sub> in <em>C</em><sub>2</sub>.</p>
<p>Adherence explains why knowledge is lacking in cases in which the believer’s environment is full of misleading defeating evidence, which by a fluke the believer never encounters. In a case of this sort, the belief does not adhere to the truth – because there are normal cases sufficiently similar to the actual case, both with respect to what makes the belief rational in the actual case, and with respect to the target proposition’s being true, in which the believer encounters this misleading defeating evidence and so does not believe the proposition.</p>
<p>For example, in Gilbert Harman’s “assassination” case (<em>Thought</em>, p. 143), what justifies the believer in believing that <em>the political leader has been assassinated</em> is the belief’s being based on an experience of hearing the original radio broadcast. So, cases in which the believer hears the radio broadcast, but then also encounters the denials of the original broadcast that are printed everywhere, and so ceases to be believe that the leader has been assassinated, will count (in at least some contexts) as “sufficiently similar”.</p>
<p>To take another example, Timothy Williamson (<em>Knowledge and its Limits</em>, p. 62)&nbsp;considers a&nbsp;burglar who ransacks a house all&nbsp;night, risking&nbsp;discovery, because he <em>knows</em> that the house contains a diamond.&nbsp;If the&nbsp;burglar&nbsp;had merely <em>safely believed</em> that the house contained a diamond, the house could have been full of misleading defeating evidence, which would have led the&nbsp;burglar to&nbsp;become agnostic about whether the house contained a diamond. It is only because the burglar&#8217;s belief adheres robustly to the truth that it&nbsp;is so unlikely that the&nbsp;burglar&nbsp;will abandon the belief that the house contains a diamond.</p>
<p>(In fact, I would defend a <em>contextualist</em> interpretation of adherence, according to which the <em>context</em> in which the term ‘knowledge’ is used may make a difference to <em>how similar</em> to the actual case these other cases have to be in order to count as “sufficiently similar” in the context; but we may bracket these complexities for present purposes.)</p>
<p>Some philosophers have tried to give direct counterexamples to adherence. Here is an attempted counterexample due to Ernest Sosa (“Tracking, competence, and knowledge”, p. 274):</p>
<blockquote><p>One can know that one faces a bird when one sees a large pelican on the lawn in plain daylight even if there might easily have been a solitary bird before one unseen, a small robin perched in the shade, in which case it is false that one would have believed that one faced a bird. Prima facie, then, it seems unnecessary that one’s belief be [adherent]; one might perhaps know through believing safely even if one does not believe [adherently].</p></blockquote>
<p>A second attempted counterexample is due to Saul Kripke (<em>Philosophical Troubles</em>, p. 178):</p>
<blockquote><p>Suppose that Mary is a physicist who places a detector plate so that it detects any photon that happens to go to the right. If the photon goes to the left, she will have no idea whether a photon has been emitted or not. Suppose a photon is emitted, that it does hit the detector plate (which is at the right), and that Mary concludes that a photon has been emitted. Intuitively, it seems clear that her conclusion indeed does constitute knowledge. But is Nozick’s fourth condition satisfied? No, for it is not true, according to Nozick’s conception of such counterfactuals, that if a photon had been emitted, Mary would have believed that a photon was emitted. The photon might well have gone to the left, in which case Mary would have had no beliefs about the matter.</p></blockquote>
<p>These cases may be counterexamples to rough and imprecise statements of adherence, but it seems clear that they are not counterexamples to the formulation that I have given.</p>
<p>Consider the case in which I see a large pelican on the lawn in daylight in front of me. What makes my belief that there is a bird in front of me rational? Presumably, it is the fact that I have an <em>experience</em> of a certain sort, an experience that inclines me to deploy my concept of a bird. So the only cases that count as “sufficiently similar” are other cases in which I have an experience of this sort. Clearly, cases in which I have no such experience – even if in fact there is a bird in front of me, a small robin concealed in the shade – are just not “sufficiently similar”.</p>
<p>Kripke’s case suffers from a similar defect – even though Kripke claims about his case “Here the method is held fixed.” As I shall argue here, this is a mistake: the method is not “held fixed”. In the actual case, Mary’s belief is rationally held because it is based on an experience of observing the detector plate’s responding to the presence of a photon. Cases in which Mary has no such experience are just not sufficiently similar.</p>
<p>In fact, Nozick himself made a similar mistake, assuming that each of the relevant “methods” could be used to answer the question of “whether or not” the target proposition <em>p</em> is true. It is clear, however, that in many cases, the methods that could be used to come to know a proposition are very different from any methods that could be used to come to know the proposition’s negation.</p>
<p>For instance, to know that an existentially quantified proposition is true, one needs only to observe one true instance; but  to know the negation of such an existentially quantified proposition, one would have to survey the entire domain of quantification. (E.g. to know that there is a spider in the room, one needs only to observe a single spider; to know that there is no spider in the room, one would have to search the whole room to make sure that no spider is hiding anywhere.) As they say, “proving a negative” is harder than proving the corresponding positive statement.</p>
<p>It seems to me, then, that adherence is not vulnerable to these counterexamples. But Kieran Setiya (<em>Knowing Right from Wrong</em>, pp. 91f.) has suggested a more general kind of objection:</p>
<blockquote><p>I can know the truth by a method whose threshold for delivering a verdict is extremely high, so high that it virtually always leaves me agnostic. A method of this kind may be epistemically poor in other respects; but it can be a source of knowledge.</p></blockquote>
<p>This may sound like a single objection, but in fact there are two very different kinds of case that are suggested by what Setiya says here.</p>
<p>In some cases, I may believe a true proposition by a “method” that is the same as an ordinary rational method except that it is arbitrarily restricted in some way. E.g. I believe a proposition that I have proved through rigorous mathematical reasoning, but only on the condition that I also believe that today is a Thursday (suppose that if I had not believed that today is a Thursday, I would have responded to this mathematical reasoning with agnosticism). Or I believe what I seem to see before my eyes, but only so long as there is nothing apparently orange in my field of vision (if there had been anything apparently orange in my field of vision, I would have been totally agnostic about the scene before my eyes).</p>
<p>In these cases, the belief in question seems not to be doxastically justified or rationally held. The believer is basing her belief in crucial part on utterly irrelevant considerations, and so the dispositions that the believer is manifesting do not count as rational dispositions. This sort of irrationality seems to me to be incompatible with genuine knowledge.</p>
<p>In some other cases, it is rational for one to use a high-standards method, or a method that can only be used in a narrow range of cases. Perhaps a physician is trying to diagnose whether a patient has a certain illness, and the only available test is one that yields a verdict only in a very narrow range of cases; but luckily, in the actual case at hand, this test does indeed yield a verdict.</p>
<p>In this case, as with Sosa’s and Kripke’s examples, it seems to me that cases in which the test yields no verdict are not just sufficiently similar to the actual case. So cases of this sort are not counterexamples to adherence.</p>
<p>In short, the only cases of justified true beliefs that fail to satisfy adherence are cases where&nbsp;the thinker&#8217;s environment is&nbsp;rife with&nbsp;misleading defeating evidence, which by a fluke the thinker never encounters. Unless it is wrong to deny knowledge in such cases, adherence is not vulnerable to the objections that have been raised against it.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/in-defence-of-adherence/feed/</wfw:commentRss>
		<slash:comments>15</slash:comments>
		</item>
		<item>
		<title>Where the action is</title>
		<link>http://certaindoubts.com/where-the-action-is/</link>
		<comments>http://certaindoubts.com/where-the-action-is/#comments</comments>
		<pubDate>Sat, 10 May 2014 17:41:56 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4378</guid>
		<description><![CDATA[I heard through the grapevine that Jason Stanley is claiming on Facebook that there is an emerging consensus in the experimental literature. The consensus is that there is a robust stakes-effect on knowledge attributions, and the real debate is whether &#8230; <a class="more-link" href="http://certaindoubts.com/where-the-action-is/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p style="color: #000000">I heard through the grapevine that Jason Stanley is claiming on Facebook that there is an emerging consensus in the experimental literature. The consensus is that there is a robust stakes-effect on knowledge attributions, and the real debate is whether to explain it in terms of semantic contextualism or interest-relative invariantism. I&#8217;m not on Facebook and have no plans to ever be, so apologies to Jason if this is not an accurate portrayal of what he wrote. But since it&#8217;s generating enough buzz for me to hear about it second- and third-hand, I figured I&#8217;d take to the air here and help to correct any misimpression, even if the misimpression is due to people mischaracterizing Jason&#8217;s post.</p>
<p style="color: #000000">There is no such consensus. How much is at stake, or how important people judge the situation to be, has an anemic and entirely indirect effect on knowledge attributions. Moreover, the stakes/importance-effect on knowledge attributions is entirely mediated by people&#8217;s estimation of whether the proposition in question is true and their estimation of the quality of evidence. Consequently, there is very little if anything for contextualism or interest-relative invariantism to explain.</p>
<p style="color: #000000">By contrast, people&#8217;s judgment about <em>whether an agent should act</em> on a proposition has a direct and robust effect on knowledge attributions. The effect of actionability on knowledge attributions is as large and direct as the effect of truth and evidence.</p>
<p style="color: #000000">In short, a practical factor definitely plays a large role in ordinary knowledge attributions and might even be part of the ordinary concept of knowledge. But that factor is not stakes. It is actionability.</p>
<p style="color: #000000">For those that are interested, I&#8217;ll be presenting some joint work with Wesley Buckwalter at <a href="http://philosophycommons.typepad.com/xphi/2014/03/symposium-at-the-2014-canadian-annual-congress-on-experimental-philosophy.html">the CPA in St. Catharines, Ontario later this month</a>, where I&#8217;ll walk through the relevant findings from some recent, very large behavioral experiments.</p>
<p style="color: #000000">(<a href="http://philosophycommons.typepad.com/xphi/2014/05/where-the-action-is.html">Cross-posted at the x-phi blog</a>.)</p>
<p> </p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/where-the-action-is/feed/</wfw:commentRss>
		<slash:comments>96</slash:comments>
		</item>
	</channel>
</rss>
