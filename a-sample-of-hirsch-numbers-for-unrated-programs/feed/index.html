<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: A Sample of Hirsch Numbers for Unrated Programs</title>
	<atom:link href="http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: ISI Web of Science &#124; chris alen sula</title>
		<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/#comment-7799</link>
		<dc:creator><![CDATA[ISI Web of Science &#124; chris alen sula]]></dc:creator>
		<pubDate>Wed, 04 Feb 2009 04:07:43 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=772#comment-7799</guid>
		<description><![CDATA[[...]  the past few months, so I’ll simply refer you to discussions on 29 Nov, 13 Dec, 15 Dec,  [...]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;]  the past few months, so I’ll simply refer you to discussions on 29 Nov, 13 Dec, 15 Dec,  [&#8230;]</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: ISI Web of Science &#124; the phylosophy project blog</title>
		<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/#comment-7802</link>
		<dc:creator><![CDATA[ISI Web of Science &#124; the phylosophy project blog]]></dc:creator>
		<pubDate>Thu, 10 Apr 2008 19:06:52 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=772#comment-7802</guid>
		<description><![CDATA[[...]  past few months, so I&#8217;ll simply refer you to discussions on 29 Nov, 13 Dec, 15 Dec, 17 De [...]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;]  past few months, so I&#8217;ll simply refer you to discussions on 29 Nov, 13 Dec, 15 Dec, 17 De [&#8230;]</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/#comment-7782</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Sat, 22 Dec 2007 21:02:11 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=772#comment-7782</guid>
		<description><![CDATA[The idea is great, Keith, and maybe someday...  What you describe, however, is very much what ISI does, except that it doesn&#039;t include books.  Scopus does include books, however, though none of these sources includes everything that needs to be included.  Most graduate deans I know already pay a lot of attention to the numbers generated from these sources.  What&#039;s interesting is, to repeat, that these sources generate lists that don&#039;t correlate well with each other, but rankings based on any of the sources correlate very well with each other (including GS), when they&#039;ve been tested (which of course doesn&#039;t include philosophy!).  But I&#039;m with you:  I&#039;d be happier about the whole thing if we started with a decent data source.]]></description>
		<content:encoded><![CDATA[<p>The idea is great, Keith, and maybe someday&#8230;  What you describe, however, is very much what ISI does, except that it doesn&#8217;t include books.  Scopus does include books, however, though none of these sources includes everything that needs to be included.  Most graduate deans I know already pay a lot of attention to the numbers generated from these sources.  What&#8217;s interesting is, to repeat, that these sources generate lists that don&#8217;t correlate well with each other, but rankings based on any of the sources correlate very well with each other (including GS), when they&#8217;ve been tested (which of course doesn&#8217;t include philosophy!).  But I&#8217;m with you:  I&#8217;d be happier about the whole thing if we started with a decent data source.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Keith DeRose</title>
		<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/#comment-7783</link>
		<dc:creator><![CDATA[Keith DeRose]]></dc:creator>
		<pubDate>Sat, 22 Dec 2007 17:24:30 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=772#comment-7783</guid>
		<description><![CDATA[I agree that a good measure of scholarly impact would be very helpful, for the reasons you give, Jon.  What I&#039;m most skeptical of is that Google Scholar can be a good source of citation counts for such a purpose.  That&#039;s especially true of Google Scholar as it presently works.  I don&#039;t want to underestimate the ability of the Google folks to improve GS.  But I&#039;m skeptical about GS becoming a good source for this purpose, because it seems to me to be headed in the wrong direction for this purpose.  I use GS frequently.  I find it an extremely useful tool for finding papers on topics I&#039;m working on.  Part of what&#039;s good about it is that I often find these papers before they are published.  So, for the purpose I use it for, it&#039;s good that GS picks up papers off of people&#039;s web pages, etc.  As it improves, I expect it to pick up even more of that.  But as long as it&#039;s doing that, it won&#039;t be distinguishing published from unpublished papers.  And I think we really should try to limit the source of citations to papers published in professional journals.  We don&#039;t want to end up with any measure that would encourage departments to hire the likes of Ayn Rand, for instance.  (Rand isn&#039;t a GS champ; her Hirsch-index based on on GS, seems to be 12.  Still, that&#039;s good enough, by Jon&#039;s measures to be better than the average h-index for even the #1 dept. in the country.  And it&#039;s  quite good for someone who&#039;s been dead for a quarter of a century.  [GS seems best at picking up recent references.])

I suspect GS would be a worse source for philosophy than for some other disciples, because we tend to publish fewer works, and cite less in the works we do publish (as compared, with, say, a lot of the sciences).  In an environment in which, say, even the very top departments only have faculty with average hirsch numbers around 10, little bits of junk (self-citation in unpublished papers) that might be relatively harmless in other, more prolific environments, are a real problem.

Here&#039;s how I would see something very useful coming from this.  We (and the exact extension of this &quot;we&quot; can be left open) draw up a list of professional philosophy journals that will count.  I&#039;m not thinking of this as being limited to prestigious journals; that would seem to go against the spirit of the effort: Journals too should distinguish themselves by having papers that get cited often.  If someone wants to figure out ways to give bonus points for being cited in journals that distinguish themselves in that way, OK, perhaps.  But none should start off on top.  But I do think we should limit it to real professional philosophy journals (edited by professional philosophers, publishing mostly papers by professional philosophers, etc., and with fairly open submission policies: nothing that might be limited, say, to submissions from philosophers in a certain dept.).  Books could be added, too, if we could find a way to limit that to professional philosophy books: perhaps certain presses philosophy series?  Then we need a way to count all and only citations made in those journals.  Even if this had to be done by hand by some human, it could be worth it: it would take just a few minutes per article (as compared with the countless hours of person-power it takes to produce a paper, and put it through the refereeing process).  If it came to it, a number of us could, for instance, each take responsibility for collecting the citations from a journal.  But there might be a more automatic way available.  (Warning: I&#039;m not very computer savvy!)  I&#039;ve noticed some journals already put on-line lists of the papers cited by their articles; see for instance, &lt;a href=&quot;http://www.informaworld.com/smpp/content~content=a788337404~db=all~order=page?tab=references&quot; rel=&quot;nofollow&quot;&gt;this&lt;/a&gt; example from AJP.  If a few good* journals have such listings, maybe some semi-automatic system could be set up for searching and gathering those citations as they&#039;re posted.  (It would have to, for example, recognize when two papers are both citing the same further paper, even though they employ somewhat different citation formats.  GS seems to try to do this, I think, but with *very* limited success.  Perhaps some human help would be needed here; yielding only a semi-automatic process.)  If the journals initially included were good*, and there were enough of them, the results could be helpful.  If they catch on, that could motivate further journals to posts lists of citations on-line.  The measure could get more &#038; more valid....  (Then I could wake up from this dream?)

[* OK, here I&#039;m imagining some element of elitism as playing a role.  I&#039;m thinking that getting good journals in the initial set will help get the process going.  But the goal would be to then let in all professional journals that list their citations in an easy-to-gather way.]

This would only measure impact *within the discipline of philosophy*.  We&#039;d probably also want a measure of the impact of philosophical writings on other fields.  Maybe other fields might do (or maybe even have already done: I&#039;m pretty oblivious to what goes on in other fields, I fear) something like this.  (It might be interesting to citation counts of philosophy works based on citations made in &lt;a href=&quot;http://www.jstor.org/browse&quot; rel=&quot;nofollow&quot;&gt;JSTOR journals [subscriber only link, I&#039;m afraid]&lt;/a&gt; from all listed disciplines.)]]></description>
		<content:encoded><![CDATA[<p>I agree that a good measure of scholarly impact would be very helpful, for the reasons you give, Jon.  What I&#8217;m most skeptical of is that Google Scholar can be a good source of citation counts for such a purpose.  That&#8217;s especially true of Google Scholar as it presently works.  I don&#8217;t want to underestimate the ability of the Google folks to improve GS.  But I&#8217;m skeptical about GS becoming a good source for this purpose, because it seems to me to be headed in the wrong direction for this purpose.  I use GS frequently.  I find it an extremely useful tool for finding papers on topics I&#8217;m working on.  Part of what&#8217;s good about it is that I often find these papers before they are published.  So, for the purpose I use it for, it&#8217;s good that GS picks up papers off of people&#8217;s web pages, etc.  As it improves, I expect it to pick up even more of that.  But as long as it&#8217;s doing that, it won&#8217;t be distinguishing published from unpublished papers.  And I think we really should try to limit the source of citations to papers published in professional journals.  We don&#8217;t want to end up with any measure that would encourage departments to hire the likes of Ayn Rand, for instance.  (Rand isn&#8217;t a GS champ; her Hirsch-index based on on GS, seems to be 12.  Still, that&#8217;s good enough, by Jon&#8217;s measures to be better than the average h-index for even the #1 dept. in the country.  And it&#8217;s  quite good for someone who&#8217;s been dead for a quarter of a century.  [GS seems best at picking up recent references.])</p>
<p>I suspect GS would be a worse source for philosophy than for some other disciples, because we tend to publish fewer works, and cite less in the works we do publish (as compared, with, say, a lot of the sciences).  In an environment in which, say, even the very top departments only have faculty with average hirsch numbers around 10, little bits of junk (self-citation in unpublished papers) that might be relatively harmless in other, more prolific environments, are a real problem.</p>
<p>Here&#8217;s how I would see something very useful coming from this.  We (and the exact extension of this &#8220;we&#8221; can be left open) draw up a list of professional philosophy journals that will count.  I&#8217;m not thinking of this as being limited to prestigious journals; that would seem to go against the spirit of the effort: Journals too should distinguish themselves by having papers that get cited often.  If someone wants to figure out ways to give bonus points for being cited in journals that distinguish themselves in that way, OK, perhaps.  But none should start off on top.  But I do think we should limit it to real professional philosophy journals (edited by professional philosophers, publishing mostly papers by professional philosophers, etc., and with fairly open submission policies: nothing that might be limited, say, to submissions from philosophers in a certain dept.).  Books could be added, too, if we could find a way to limit that to professional philosophy books: perhaps certain presses philosophy series?  Then we need a way to count all and only citations made in those journals.  Even if this had to be done by hand by some human, it could be worth it: it would take just a few minutes per article (as compared with the countless hours of person-power it takes to produce a paper, and put it through the refereeing process).  If it came to it, a number of us could, for instance, each take responsibility for collecting the citations from a journal.  But there might be a more automatic way available.  (Warning: I&#8217;m not very computer savvy!)  I&#8217;ve noticed some journals already put on-line lists of the papers cited by their articles; see for instance, <a href="http://www.informaworld.com/smpp/content~content=a788337404~db=all~order=page?tab=references" rel="nofollow">this</a> example from AJP.  If a few good* journals have such listings, maybe some semi-automatic system could be set up for searching and gathering those citations as they&#8217;re posted.  (It would have to, for example, recognize when two papers are both citing the same further paper, even though they employ somewhat different citation formats.  GS seems to try to do this, I think, but with *very* limited success.  Perhaps some human help would be needed here; yielding only a semi-automatic process.)  If the journals initially included were good*, and there were enough of them, the results could be helpful.  If they catch on, that could motivate further journals to posts lists of citations on-line.  The measure could get more &amp; more valid&#8230;.  (Then I could wake up from this dream?)</p>
<p>[* OK, here I&#8217;m imagining some element of elitism as playing a role.  I&#8217;m thinking that getting good journals in the initial set will help get the process going.  But the goal would be to then let in all professional journals that list their citations in an easy-to-gather way.]</p>
<p>This would only measure impact *within the discipline of philosophy*.  We&#8217;d probably also want a measure of the impact of philosophical writings on other fields.  Maybe other fields might do (or maybe even have already done: I&#8217;m pretty oblivious to what goes on in other fields, I fear) something like this.  (It might be interesting to citation counts of philosophy works based on citations made in <a href="http://www.jstor.org/browse" rel="nofollow">JSTOR journals [subscriber only link, I&#8217;m afraid]</a> from all listed disciplines.)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/#comment-7784</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Sat, 22 Dec 2007 13:21:44 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=772#comment-7784</guid>
		<description><![CDATA[Keith, that surely right, and it is worth noting that a department would be *crazy* to build in a way that favors average anything over superlative history.  So, no measure of scholarly impact, no matter how good, has any hope of being the Grand Unified Metric to replace all others.  At the same, however, a good measure of scholarly impact can help correct for the halo effect that some departments enjoy on reputational surveys and the lack of exposure other departments suffer from, given the way in which face-to-face events play a role in such surveys that is disproportionate to their significance (in much the same way that short interviews swamp more useful information in hiring decisions).  I&#039;m not saying the exercise here provides such a good measure, but it would be nice to have one.]]></description>
		<content:encoded><![CDATA[<p>Keith, that surely right, and it is worth noting that a department would be *crazy* to build in a way that favors average anything over superlative history.  So, no measure of scholarly impact, no matter how good, has any hope of being the Grand Unified Metric to replace all others.  At the same, however, a good measure of scholarly impact can help correct for the halo effect that some departments enjoy on reputational surveys and the lack of exposure other departments suffer from, given the way in which face-to-face events play a role in such surveys that is disproportionate to their significance (in much the same way that short interviews swamp more useful information in hiring decisions).  I&#8217;m not saying the exercise here provides such a good measure, but it would be nice to have one.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Keith DeRose</title>
		<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/#comment-7785</link>
		<dc:creator><![CDATA[Keith DeRose]]></dc:creator>
		<pubDate>Fri, 21 Dec 2007 22:46:47 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=772#comment-7785</guid>
		<description><![CDATA[There are many different aspects of the sociology of the profession, and on many (most?) of them, top-notch historians of philosophy seem to be treated by the profession as if they outrank average philosophers of language.  For example, glowing letters from the former are worth much more on the job market than are equally glowing letters from the latter, the former are much more likely than the latter to be awarded important professional honors, etc.  Rankings that reflect the supposed elevated sociological position of even average philosophers of language will be badly aimed for at least many purposes.]]></description>
		<content:encoded><![CDATA[<p>There are many different aspects of the sociology of the profession, and on many (most?) of them, top-notch historians of philosophy seem to be treated by the profession as if they outrank average philosophers of language.  For example, glowing letters from the former are worth much more on the job market than are equally glowing letters from the latter, the former are much more likely than the latter to be awarded important professional honors, etc.  Rankings that reflect the supposed elevated sociological position of even average philosophers of language will be badly aimed for at least many purposes.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/#comment-7798</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Fri, 21 Dec 2007 00:38:54 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=772#comment-7798</guid>
		<description><![CDATA[The measure here does favor avg. language over terrific history, and I was merely pointing that that a measure of *scholarly impact* is going to do just that, because language has a place in the profession that history doesn&#039;t.  I wasn&#039;t defending that this is the way it should be, just that this is the way it is.  So on that comparison, a measure of scholarly impact has to give such a result to be faithful to the sociology of the profession.  But the same isn&#039;t true for other areas that get high citations, such as business ethics or medical ethics.  Even from a purely sociological point of view, those areas aren&#039;t discipline-makers, and so a measure of scholarly impact that is built off of citations alone is going to get this wrong.  So Keith is right to point out the differential citation rates between subfields, and to worry about the bias it introduces.]]></description>
		<content:encoded><![CDATA[<p>The measure here does favor avg. language over terrific history, and I was merely pointing that that a measure of *scholarly impact* is going to do just that, because language has a place in the profession that history doesn&#8217;t.  I wasn&#8217;t defending that this is the way it should be, just that this is the way it is.  So on that comparison, a measure of scholarly impact has to give such a result to be faithful to the sociology of the profession.  But the same isn&#8217;t true for other areas that get high citations, such as business ethics or medical ethics.  Even from a purely sociological point of view, those areas aren&#8217;t discipline-makers, and so a measure of scholarly impact that is built off of citations alone is going to get this wrong.  So Keith is right to point out the differential citation rates between subfields, and to worry about the bias it introduces.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike</title>
		<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/#comment-7797</link>
		<dc:creator><![CDATA[Mike]]></dc:creator>
		<pubDate>Fri, 21 Dec 2007 00:12:56 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=772#comment-7797</guid>
		<description><![CDATA[I missed that entirely. I thought you were expressing reservations about Keith D&#039;R&#039;s reservations about the skewed h-values favoring ave. language over terrific history.]]></description>
		<content:encoded><![CDATA[<p>I missed that entirely. I thought you were expressing reservations about Keith D&#8217;R&#8217;s reservations about the skewed h-values favoring ave. language over terrific history.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/#comment-7796</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Thu, 20 Dec 2007 22:52:14 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=772#comment-7796</guid>
		<description><![CDATA[No, Mike, that&#039;s explicitly what I was disavowing in the comment.  I wasn&#039;t making any claims about what is important or matters most, but rather about the sociology of the profession.  And here the evidence is overwhelming.  Just go look at the AOS&#039;s at the top 50 departments and notice how many people claim AOS&#039;s in mind/language compared to history, and look at what gets published in the major journals in the field.]]></description>
		<content:encoded><![CDATA[<p>No, Mike, that&#8217;s explicitly what I was disavowing in the comment.  I wasn&#8217;t making any claims about what is important or matters most, but rather about the sociology of the profession.  And here the evidence is overwhelming.  Just go look at the AOS&#8217;s at the top 50 departments and notice how many people claim AOS&#8217;s in mind/language compared to history, and look at what gets published in the major journals in the field.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike</title>
		<link>http://certaindoubts.com/a-sample-of-hirsch-numbers-for-unrated-programs/#comment-7795</link>
		<dc:creator><![CDATA[Mike]]></dc:creator>
		<pubDate>Thu, 20 Dec 2007 21:20:27 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=772#comment-7795</guid>
		<description><![CDATA[&lt;i&gt; . . .you are right that h-values for the former are significantly higher than the latter. There is a good objection here to take into account in assessing these rankings, but the language/history comparison makes me balk. Philosophy of mind and language are clearly discipline-makers in contrast to the history of philosophy . . .&lt;/i&gt;

That is not easy to follow, probably because I have no sense of &quot;discipline-maker&quot; on which it comes out true that the avergage philosopher of language is more of one than major historians of philosophy. To me, this sounds like an &quot;everyone knows that X matters and Y doesn&#039;t&quot; observation that I&#039;d be sorry to see get any traction in this discussion.]]></description>
		<content:encoded><![CDATA[<p><i> . . .you are right that h-values for the former are significantly higher than the latter. There is a good objection here to take into account in assessing these rankings, but the language/history comparison makes me balk. Philosophy of mind and language are clearly discipline-makers in contrast to the history of philosophy . . .</i></p>
<p>That is not easy to follow, probably because I have no sense of &#8220;discipline-maker&#8221; on which it comes out true that the avergage philosopher of language is more of one than major historians of philosophy. To me, this sounds like an &#8220;everyone knows that X matters and Y doesn&#8217;t&#8221; observation that I&#8217;d be sorry to see get any traction in this discussion.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
