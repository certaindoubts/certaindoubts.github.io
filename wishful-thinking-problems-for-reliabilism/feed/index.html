<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Wishful Thinking Problems for Reliabilism</title>
	<atom:link href="http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Pozycjonowanie gdansk</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comment-29226</link>
		<dc:creator><![CDATA[Pozycjonowanie gdansk]]></dc:creator>
		<pubDate>Thu, 03 May 2012 10:30:11 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369#comment-29226</guid>
		<description><![CDATA[Hi Chris,

Suppose a reliabilist states that only cognitive processes can produce understanding, and desires possess the wrong direction of fit to become a port to some cognitive process, no matter if the process under consideration is reliable. Cognitive processes as well as their inputs have mind-to-world direction of fit, but wishes and desires have world-to-mind direction of fit.

This really is in line with wishes impacting on the smoothness of inputs which have the best direction of fit. Wishes just can’t function as the inputs themselves.]]></description>
		<content:encoded><![CDATA[<p>Hi Chris,</p>
<p>Suppose a reliabilist states that only cognitive processes can produce understanding, and desires possess the wrong direction of fit to become a port to some cognitive process, no matter if the process under consideration is reliable. Cognitive processes as well as their inputs have mind-to-world direction of fit, but wishes and desires have world-to-mind direction of fit.</p>
<p>This really is in line with wishes impacting on the smoothness of inputs which have the best direction of fit. Wishes just can’t function as the inputs themselves.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Stephen Harris</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comment-28139</link>
		<dc:creator><![CDATA[Stephen Harris]]></dc:creator>
		<pubDate>Mon, 09 Apr 2012 10:05:41 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369#comment-28139</guid>
		<description><![CDATA[&quot;I said the reliabilist might sensibly deny that the priming effect get built into the process that gets evaluated for reliability. Are you disagreeing with that claim?&quot;

The following quote appears to disagree with you claim?! I think what I wrote in the last post agrees with the quote below, although my post is more specific in example and less technically termed. 
I meant by an Angel or Demon example or usage, one that was also tied into invoking Godel&#039;s Incompleteness Theorems in that context.

Internalism and Externalism in Semantics and Epistemology
By Sanford Goldberg

f. A Reﬁnement: Suitable Modulational Control
&quot;An important general point emerges from these considerations: cognitive agents like humans deploy various belief-forming processes in ways that are holistically integrated within the agent’s overall cognitive architecture. Very frequently, such processes are employed not in isolation, but rather under the modulating inﬂuence of various other or wider cognitive processes that are coupled to them and are poised to modulate them if and when certain forms of information become available to those wider processes. As we will put it, the given belief-forming process is under the modulational control of these associated processes. Such control can make for a selective application of the process or a selective inhibition, or can otherwise tailor its application to aspects of those local environments about which information is had—and thereby can enhance its reliability as so tailored. In principle, a whole host of different conditioning or modulating relations might be epistemically important. The wider processes might give rise to a narrower process — designing it or otherwise selecting or spawning it. They might trigger the conditioned process in ways that are ﬁtting, or thought to be appropriate.&quot;

But I think they might also generate distortions as well.

Regards,
Stephen]]></description>
		<content:encoded><![CDATA[<p>&#8220;I said the reliabilist might sensibly deny that the priming effect get built into the process that gets evaluated for reliability. Are you disagreeing with that claim?&#8221;</p>
<p>The following quote appears to disagree with you claim?! I think what I wrote in the last post agrees with the quote below, although my post is more specific in example and less technically termed.<br />
I meant by an Angel or Demon example or usage, one that was also tied into invoking Godel&#8217;s Incompleteness Theorems in that context.</p>
<p>Internalism and Externalism in Semantics and Epistemology<br />
By Sanford Goldberg</p>
<p>f. A Reﬁnement: Suitable Modulational Control<br />
&#8220;An important general point emerges from these considerations: cognitive agents like humans deploy various belief-forming processes in ways that are holistically integrated within the agent’s overall cognitive architecture. Very frequently, such processes are employed not in isolation, but rather under the modulating inﬂuence of various other or wider cognitive processes that are coupled to them and are poised to modulate them if and when certain forms of information become available to those wider processes. As we will put it, the given belief-forming process is under the modulational control of these associated processes. Such control can make for a selective application of the process or a selective inhibition, or can otherwise tailor its application to aspects of those local environments about which information is had—and thereby can enhance its reliability as so tailored. In principle, a whole host of different conditioning or modulating relations might be epistemically important. The wider processes might give rise to a narrower process — designing it or otherwise selecting or spawning it. They might trigger the conditioned process in ways that are ﬁtting, or thought to be appropriate.&#8221;</p>
<p>But I think they might also generate distortions as well.</p>
<p>Regards,<br />
Stephen</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Stephen Harris</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comment-28135</link>
		<dc:creator><![CDATA[Stephen Harris]]></dc:creator>
		<pubDate>Mon, 09 Apr 2012 08:37:08 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369#comment-28135</guid>
		<description><![CDATA[Hi Chris,

Yes, I agreed with you interesting original post for the most part, with the exception of how you supported your argument within one paragraph.

&quot;Epistemic angels can bring about the required reliability by organizing the world to ensure that desires (within a certain domain) regularly come to pass.  The modal profile of P can ensure that any basis of P, including a desire for P, is a trivially reliable indicator for P.  Since Goedel’s first incompleteness theorem is necessarily true, there’s never a case in which you will be led astray by believing the theorem on the basis of desiring or wishing it to be true.&quot;

I haven&#039;t encountered this -- I&#039;ll call it a thought experiment. Godel&#039;s Inc. Theorems require the conditions of a formal system. I think this Angel would need to be omniscient to reliably and consistently sort and organize into the correct domains, beliefs or desires included within beliefs.  IOW, the Angel isn&#039;t a hyper-computational device and so still subject to a higher-level halting problem, as I understand your description of the capabilities of the angel. So your example doesn&#039;t fall under the purview of a formal system so it doesn&#039;t have a bearing on Godel Incompleteness because the Angel&#039;s powers include all three: Completeness, Consistency and Soundness (meta-theoretic); sufficiently rich formal systems can&#039;t be all three, so no Godel Inc. traction. I think your Angel example transcends the scope of a formal system... Did you read your Angel example/usage in the literature?

Yes, I disagree that &quot;the reliabilist might sensibly deny that the priming effect get built into the process that gets evaluated for reliability.&quot; Of course this hinges on the word &quot;sensibly&quot;.  I&#039;m mostly a Physicalist which I think supports a view close to Fallibilism. 

A primitive ancestor sees motion in the grasses of the Savannah. Is it a predator or the wind? Most of our ancestors played it safe rather than being sorry, and their genes dominate the gene pool, even though the result of their particular -lion or wind- decisions were probably not confirmed. Our thinking is more optimized for survival than rational objective judgments. But since our survival depends on responses to cause and effect events in the world, our cognition still approximates reality well enough to generate highly predictive physical theories. Natural selection does not perfectly optimize the gene pool, it&#039;s probabilistic. The gene pool contains fixed benevolent, neutral and deleterious random mutations. Genes provide the instructions for building our brains, and so constrains how our minds perceive and prioritize and it includes large numbers of instinctual drives which act as judgment molders, curtailing the range of available choices. 

Our cognition is good enough but not optimized to rational decision making and evaluations, so there is always going to be a bias due to the genes selected to blueprint the building of our brain structures. Fidelity or reliability to a standard will eventually fail to randomness. 
I think this process undermines a sensible defense by a reliabilist, but I suppose it could be argued that evolutionary constraints are too primitive or too distant in time to be thought of as priming-&#062;or a factor in reaching an action potential which triggers neural network firings.
I don&#039;t seem to be very capable of writing a perspicuous post.

&quot;The best reaction to a paradox is to invent a genuinely new and deep idea.” Ian Hacking            Regards, Stephen]]></description>
		<content:encoded><![CDATA[<p>Hi Chris,</p>
<p>Yes, I agreed with you interesting original post for the most part, with the exception of how you supported your argument within one paragraph.</p>
<p>&#8220;Epistemic angels can bring about the required reliability by organizing the world to ensure that desires (within a certain domain) regularly come to pass.  The modal profile of P can ensure that any basis of P, including a desire for P, is a trivially reliable indicator for P.  Since Goedel’s first incompleteness theorem is necessarily true, there’s never a case in which you will be led astray by believing the theorem on the basis of desiring or wishing it to be true.&#8221;</p>
<p>I haven&#8217;t encountered this &#8212; I&#8217;ll call it a thought experiment. Godel&#8217;s Inc. Theorems require the conditions of a formal system. I think this Angel would need to be omniscient to reliably and consistently sort and organize into the correct domains, beliefs or desires included within beliefs.  IOW, the Angel isn&#8217;t a hyper-computational device and so still subject to a higher-level halting problem, as I understand your description of the capabilities of the angel. So your example doesn&#8217;t fall under the purview of a formal system so it doesn&#8217;t have a bearing on Godel Incompleteness because the Angel&#8217;s powers include all three: Completeness, Consistency and Soundness (meta-theoretic); sufficiently rich formal systems can&#8217;t be all three, so no Godel Inc. traction. I think your Angel example transcends the scope of a formal system&#8230; Did you read your Angel example/usage in the literature?</p>
<p>Yes, I disagree that &#8220;the reliabilist might sensibly deny that the priming effect get built into the process that gets evaluated for reliability.&#8221; Of course this hinges on the word &#8220;sensibly&#8221;.  I&#8217;m mostly a Physicalist which I think supports a view close to Fallibilism. </p>
<p>A primitive ancestor sees motion in the grasses of the Savannah. Is it a predator or the wind? Most of our ancestors played it safe rather than being sorry, and their genes dominate the gene pool, even though the result of their particular -lion or wind- decisions were probably not confirmed. Our thinking is more optimized for survival than rational objective judgments. But since our survival depends on responses to cause and effect events in the world, our cognition still approximates reality well enough to generate highly predictive physical theories. Natural selection does not perfectly optimize the gene pool, it&#8217;s probabilistic. The gene pool contains fixed benevolent, neutral and deleterious random mutations. Genes provide the instructions for building our brains, and so constrains how our minds perceive and prioritize and it includes large numbers of instinctual drives which act as judgment molders, curtailing the range of available choices. </p>
<p>Our cognition is good enough but not optimized to rational decision making and evaluations, so there is always going to be a bias due to the genes selected to blueprint the building of our brain structures. Fidelity or reliability to a standard will eventually fail to randomness.<br />
I think this process undermines a sensible defense by a reliabilist, but I suppose it could be argued that evolutionary constraints are too primitive or too distant in time to be thought of as priming-&gt;or a factor in reaching an action potential which triggers neural network firings.<br />
I don&#8217;t seem to be very capable of writing a perspicuous post.</p>
<p>&#8220;The best reaction to a paradox is to invent a genuinely new and deep idea.” Ian Hacking            Regards, Stephen</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Chris Tucker</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comment-28126</link>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
		<pubDate>Mon, 09 Apr 2012 03:29:25 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369#comment-28126</guid>
		<description><![CDATA[Hi Stephen, 

Thanks for your comment.  As I understand it, you are not objecting to my original post but my defense of Turri&#039;s comment.  I said the reliabilist might sensibly deny that the priming effect get built into the process that gets evaluated for reliability.  Are you disagreeing with that claim?  

If I understand you, and I&#039;m not sure I do, your point is that priming makes a big difference to what one actually believes or perhaps what is perceptually represented to one.  I agree, but it doesn&#039;t follow that the reliabilist must say that the priming stuff gets built into the process to be evaluated for reliability.  Visual conditions, such as lighting, make a big difference to what one ends up believing, but most reliabilists don&#039;t want to include lighting conditions as a part of the relevant process.  I also doubt that some of the information that you appeal to, such as hyper agency detection, is best cashed out in terms of priming.]]></description>
		<content:encoded><![CDATA[<p>Hi Stephen, </p>
<p>Thanks for your comment.  As I understand it, you are not objecting to my original post but my defense of Turri&#8217;s comment.  I said the reliabilist might sensibly deny that the priming effect get built into the process that gets evaluated for reliability.  Are you disagreeing with that claim?  </p>
<p>If I understand you, and I&#8217;m not sure I do, your point is that priming makes a big difference to what one actually believes or perhaps what is perceptually represented to one.  I agree, but it doesn&#8217;t follow that the reliabilist must say that the priming stuff gets built into the process to be evaluated for reliability.  Visual conditions, such as lighting, make a big difference to what one ends up believing, but most reliabilists don&#8217;t want to include lighting conditions as a part of the relevant process.  I also doubt that some of the information that you appeal to, such as hyper agency detection, is best cashed out in terms of priming.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Stephen Harris</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comment-28061</link>
		<dc:creator><![CDATA[Stephen Harris]]></dc:creator>
		<pubDate>Sat, 07 Apr 2012 02:40:41 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369#comment-28061</guid>
		<description><![CDATA[&quot;Much of the good that desires can do has to do with priming, and it is at least open to the reliabilist to deny that the priming stuff gets built into the cognitive process that is evaluated for reliability.&quot;

I don&#039;t think this option is available to the reliabilist. Fundamentally, the cognitive process attempts to recognize patterns and JTB is one such patttern. Pattern recognition is skewed by evolution. Two terms, Apophenia, and Patternicity: The tendency to find meaningful patterns in meaningless noise, describe innate cognitive constraints.

&quot;Why do people see faces in nature, interpret window stains as human figures, hear voices in random sounds generated by electronic devices or find conspiracies in the daily news? A proximate cause is the priming effect, in which our brain and senses are prepared to interpret stimuli according to an expected model.&quot;

SH: I think this includes wishful thinking and even magical thinking.

...&quot;evolutionary modeling demonstrates that whenever the cost of believing a false pattern is real is less than the cost of not believing a real pattern, natural selection will favor patternicity.&quot;

So I think natural selection has a bias in constructing our cognition and this will impact any theories our cognition devises to recognize patterns -&#062; jtbs -&#062; reliabilism. I&#039;m not so sure that Godelian Inc. nor Tarski Undefinability of Truth capture this biased origin. Godel and Tarski apply to formalized processes and their resistance to being captured and their inexhaustibility. I think this biased basis precludes a formal system from being devised, so that there is no prior structure for Godel Inc. or Tarski Undefinability to bear application upon - come to grips with.]]></description>
		<content:encoded><![CDATA[<p>&#8220;Much of the good that desires can do has to do with priming, and it is at least open to the reliabilist to deny that the priming stuff gets built into the cognitive process that is evaluated for reliability.&#8221;</p>
<p>I don&#8217;t think this option is available to the reliabilist. Fundamentally, the cognitive process attempts to recognize patterns and JTB is one such patttern. Pattern recognition is skewed by evolution. Two terms, Apophenia, and Patternicity: The tendency to find meaningful patterns in meaningless noise, describe innate cognitive constraints.</p>
<p>&#8220;Why do people see faces in nature, interpret window stains as human figures, hear voices in random sounds generated by electronic devices or find conspiracies in the daily news? A proximate cause is the priming effect, in which our brain and senses are prepared to interpret stimuli according to an expected model.&#8221;</p>
<p>SH: I think this includes wishful thinking and even magical thinking.</p>
<p>&#8230;&#8221;evolutionary modeling demonstrates that whenever the cost of believing a false pattern is real is less than the cost of not believing a real pattern, natural selection will favor patternicity.&#8221;</p>
<p>So I think natural selection has a bias in constructing our cognition and this will impact any theories our cognition devises to recognize patterns -&gt; jtbs -&gt; reliabilism. I&#8217;m not so sure that Godelian Inc. nor Tarski Undefinability of Truth capture this biased origin. Godel and Tarski apply to formalized processes and their resistance to being captured and their inexhaustibility. I think this biased basis precludes a formal system from being devised, so that there is no prior structure for Godel Inc. or Tarski Undefinability to bear application upon &#8211; come to grips with.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Chris Tucker</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comment-27521</link>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
		<pubDate>Tue, 27 Mar 2012 19:53:04 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369#comment-27521</guid>
		<description><![CDATA[Hi Jack,

I take no stand on whether desires lead to different processes.  I don&#039;t really have clear intuitions about the sort of process individuation that would be required for epistemic evaluation--it&#039;s just such a thorny topic.  So my goal in this post and the previous one (http://el-prod.baylor.edu/certain_doubts/?p=3325) was just to indicate what I think the options are for the reliabilist and hopefully to indicate some reason for being pessimistic about its prospects for resolving the various issues.

Based on our personal correspondence (which I may have misinterpreted), I&#039;m a bit surprised by what you say in this comment here.  It sounds like you are allowing inputs and outputs to do more of the individuating work and that you are after narrower processes than I had previously assumed. I think your remarks in this comment at least gesture to a very narrow way of individuating processes.  As you know better than I do, there are all sorts of things going on in perception besides what&#039;s the direct result of retinal stimulation.  If all that stuff leads to a different process (rather than constituting additional inputs to the same process), individuation would be very narrow.  Of course, there may be good reasons to treat desires differently than all that other stuff, but I imagine it will be tricky to find a good reason for making such a sharp difference.  

In any event, it&#039;s not clear how what you say in this comment can help save the reliabilist.   To whatever extent desires-as-inputs leads to a different process, it will be easy for epistemic angels to be stable features of the environment (across close possible worlds) that guarantee the reliability of those processes.  Also, generally speaking, the narrower the processes, the easier it is for the modal profile of propositions to lead to trivial reliability of the relevant process.

As far as your response to John goes, I&#039;m not sure it&#039;s decisive.  Again, it all comes down to process individuation.  Much of the good that desires can do has to do with priming, and it is at least open to the reliabilist to deny that the priming stuff gets built into the cognitive process that is evaluated for reliability.]]></description>
		<content:encoded><![CDATA[<p>Hi Jack,</p>
<p>I take no stand on whether desires lead to different processes.  I don&#8217;t really have clear intuitions about the sort of process individuation that would be required for epistemic evaluation&#8211;it&#8217;s just such a thorny topic.  So my goal in this post and the previous one (<a href="http://el-prod.baylor.edu/certain_doubts/?p=3325" rel="nofollow">http://el-prod.baylor.edu/certain_doubts/?p=3325</a>) was just to indicate what I think the options are for the reliabilist and hopefully to indicate some reason for being pessimistic about its prospects for resolving the various issues.</p>
<p>Based on our personal correspondence (which I may have misinterpreted), I&#8217;m a bit surprised by what you say in this comment here.  It sounds like you are allowing inputs and outputs to do more of the individuating work and that you are after narrower processes than I had previously assumed. I think your remarks in this comment at least gesture to a very narrow way of individuating processes.  As you know better than I do, there are all sorts of things going on in perception besides what&#8217;s the direct result of retinal stimulation.  If all that stuff leads to a different process (rather than constituting additional inputs to the same process), individuation would be very narrow.  Of course, there may be good reasons to treat desires differently than all that other stuff, but I imagine it will be tricky to find a good reason for making such a sharp difference.  </p>
<p>In any event, it&#8217;s not clear how what you say in this comment can help save the reliabilist.   To whatever extent desires-as-inputs leads to a different process, it will be easy for epistemic angels to be stable features of the environment (across close possible worlds) that guarantee the reliability of those processes.  Also, generally speaking, the narrower the processes, the easier it is for the modal profile of propositions to lead to trivial reliability of the relevant process.</p>
<p>As far as your response to John goes, I&#8217;m not sure it&#8217;s decisive.  Again, it all comes down to process individuation.  Much of the good that desires can do has to do with priming, and it is at least open to the reliabilist to deny that the priming stuff gets built into the cognitive process that is evaluated for reliability.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jack Lyons</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comment-27468</link>
		<dc:creator><![CDATA[Jack Lyons]]></dc:creator>
		<pubDate>Tue, 27 Mar 2012 02:23:05 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369#comment-27468</guid>
		<description><![CDATA[Hi Chris,

Maybe a detailed example would convince me otherwise, but it seems to me that cases where desires serve as inputs involve different processes than in cases where they don&#039;t. (This relates to your previous post on this topic, too.) Suppose a perceptual process P takes retinal stimulation (and things like eye position and motion, etc.) as inputs and returns object identifications as outputs, and this process is highly reliable. If P* is just like P but also takes desires as inputs, I&#039;d say that P* is a different process, and if on this occasion I&#039;m using P*, and it&#039;s unreliable, then I&#039;m not prima facie justified. 


I don&#039;t know about other reliabilists, but I wouldn&#039;t want to take John&#039;s suggested route, because I think there are cases where desires and other motivational states can actually contribute to justification, as I mention in the paper you&#039;re citing. If being afraid of snakes makes me &lt;i&gt;better&lt;/i&gt; at spotting snakes (not just more &quot;powerful&quot;, but more reliable), then that&#039;s a factor our epistemology should take into account, so I wouldn&#039;t want a blanket prohibition on such states figuring into cognitive processes. For this sort of reason, I don&#039;t think that every influence of desires on perception/belief is a problem in principle. I take it that wishful thinking is one particular &lt;i&gt;species&lt;/i&gt; of desire-influenced belief.


Obviously, all this would be more convincing in the presence of detailed theory of process individuation. But even without it, it seems intuitively clear enough that the desire-mediated process is a different process than the other, more reliable one.]]></description>
		<content:encoded><![CDATA[<p>Hi Chris,</p>
<p>Maybe a detailed example would convince me otherwise, but it seems to me that cases where desires serve as inputs involve different processes than in cases where they don&#8217;t. (This relates to your previous post on this topic, too.) Suppose a perceptual process P takes retinal stimulation (and things like eye position and motion, etc.) as inputs and returns object identifications as outputs, and this process is highly reliable. If P* is just like P but also takes desires as inputs, I&#8217;d say that P* is a different process, and if on this occasion I&#8217;m using P*, and it&#8217;s unreliable, then I&#8217;m not prima facie justified. </p>
<p>I don&#8217;t know about other reliabilists, but I wouldn&#8217;t want to take John&#8217;s suggested route, because I think there are cases where desires and other motivational states can actually contribute to justification, as I mention in the paper you&#8217;re citing. If being afraid of snakes makes me <i>better</i> at spotting snakes (not just more &#8220;powerful&#8221;, but more reliable), then that&#8217;s a factor our epistemology should take into account, so I wouldn&#8217;t want a blanket prohibition on such states figuring into cognitive processes. For this sort of reason, I don&#8217;t think that every influence of desires on perception/belief is a problem in principle. I take it that wishful thinking is one particular <i>species</i> of desire-influenced belief.</p>
<p>Obviously, all this would be more convincing in the presence of detailed theory of process individuation. But even without it, it seems intuitively clear enough that the desire-mediated process is a different process than the other, more reliable one.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Chris Tucker</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comment-27448</link>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
		<pubDate>Mon, 26 Mar 2012 21:37:28 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369#comment-27448</guid>
		<description><![CDATA[I&#039;m a proponent of dogmatism, and I still find it a bit counterintuitive to allow indirect wishful thinking to produce prima facie J.  I think it&#039;s interesting and, as a dogmatist, nice that you don&#039;t get the intuition that would be problematic for me.

Regarding your proposal, I worry that it would put restrictions on reliabilism that reliabilists normally wouldn&#039;t want.  Most reliabilists want to leave it open that a process produces justification even if its inputs aren&#039;t mental items or aren&#039;t the sort of mental items that have a fit to the world (e.g. if experiences don&#039;t have content at all).  I think your proposal rules out those possibilities and pushes the reliabilist toward an evidentialist point of view.  I&#039;m not necessarily saying that&#039;s a bad thing; I&#039;m just reporting what I take to be the implications of the view.

Also, what is it for a process to have a mind-to-world fit?  Is it just for the output to have a mind to world fit?]]></description>
		<content:encoded><![CDATA[<p>I&#8217;m a proponent of dogmatism, and I still find it a bit counterintuitive to allow indirect wishful thinking to produce prima facie J.  I think it&#8217;s interesting and, as a dogmatist, nice that you don&#8217;t get the intuition that would be problematic for me.</p>
<p>Regarding your proposal, I worry that it would put restrictions on reliabilism that reliabilists normally wouldn&#8217;t want.  Most reliabilists want to leave it open that a process produces justification even if its inputs aren&#8217;t mental items or aren&#8217;t the sort of mental items that have a fit to the world (e.g. if experiences don&#8217;t have content at all).  I think your proposal rules out those possibilities and pushes the reliabilist toward an evidentialist point of view.  I&#8217;m not necessarily saying that&#8217;s a bad thing; I&#8217;m just reporting what I take to be the implications of the view.</p>
<p>Also, what is it for a process to have a mind-to-world fit?  Is it just for the output to have a mind to world fit?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: John Turri</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comment-27445</link>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
		<pubDate>Mon, 26 Mar 2012 20:30:48 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369#comment-27445</guid>
		<description><![CDATA[Hi Chris,

Yes, I was offering a principled explanation on behalf of the reliabilist.

On the envisioned proposal, cognitive processes take as direct inputs only states with mind-to-world direction of fit. The quality of a cognitive process is determined by reliability. Call any mental process that produces a belief &quot;doxastic.&quot; Non-cognitive processes that are also doxastic processes, such as wishful thinking, are not bad cognitive processes. But they are still epistemically bad, in the sense that they can&#039;t result in knowledge.

The envisioned proposal is consistent with wishes influencing experience, which then serve as inputs to cognitive processes. In contrast to the Lyons quote, I see no reason why anyone, reliabilist or dogmatist or otherwise, should think that this is a problem in principle. Indeed, I suspect that it would be a serious problem to rule it out as improper, necessarily, in advance.]]></description>
		<content:encoded><![CDATA[<p>Hi Chris,</p>
<p>Yes, I was offering a principled explanation on behalf of the reliabilist.</p>
<p>On the envisioned proposal, cognitive processes take as direct inputs only states with mind-to-world direction of fit. The quality of a cognitive process is determined by reliability. Call any mental process that produces a belief &#8220;doxastic.&#8221; Non-cognitive processes that are also doxastic processes, such as wishful thinking, are not bad cognitive processes. But they are still epistemically bad, in the sense that they can&#8217;t result in knowledge.</p>
<p>The envisioned proposal is consistent with wishes influencing experience, which then serve as inputs to cognitive processes. In contrast to the Lyons quote, I see no reason why anyone, reliabilist or dogmatist or otherwise, should think that this is a problem in principle. Indeed, I suspect that it would be a serious problem to rule it out as improper, necessarily, in advance.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Chris Tucker</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comment-27442</link>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
		<pubDate>Mon, 26 Mar 2012 19:08:06 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369#comment-27442</guid>
		<description><![CDATA[Hi John,

Let me make sure I understand where you are going with your comment.  I say reliabilism, as currently formulated, looks committed to approving of direct wishful thinking.  One way to respond is to provide a non-ad hoc explanation for why desires can&#039;t be inputs for cognitive processes.  You are attempting to provide such an explanation.  Is that what you are up to?

In any event, I&#039;m not sure I see why a cognitive process can&#039;t take something with the wrong fit as an input.  If a cognitive process took a desire as an input, that might make it a bad cognitive process.  But I don&#039;t see why taking a bad input should prevent a process from counting as cognitive.

Suppose you are correct.  You still allow that desires could cognitively penetrate experience, which could be appropriate inputs.  Then the reliabilist will still be committed to approving of indirect wishful thinking, which means it&#039;s not clear that the reliabilist is any better with respect to wishful thinking than is the dogmatist.]]></description>
		<content:encoded><![CDATA[<p>Hi John,</p>
<p>Let me make sure I understand where you are going with your comment.  I say reliabilism, as currently formulated, looks committed to approving of direct wishful thinking.  One way to respond is to provide a non-ad hoc explanation for why desires can&#8217;t be inputs for cognitive processes.  You are attempting to provide such an explanation.  Is that what you are up to?</p>
<p>In any event, I&#8217;m not sure I see why a cognitive process can&#8217;t take something with the wrong fit as an input.  If a cognitive process took a desire as an input, that might make it a bad cognitive process.  But I don&#8217;t see why taking a bad input should prevent a process from counting as cognitive.</p>
<p>Suppose you are correct.  You still allow that desires could cognitively penetrate experience, which could be appropriate inputs.  Then the reliabilist will still be committed to approving of indirect wishful thinking, which means it&#8217;s not clear that the reliabilist is any better with respect to wishful thinking than is the dogmatist.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
