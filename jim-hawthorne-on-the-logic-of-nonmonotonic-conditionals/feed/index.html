<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Jim Hawthorne on the logic of nonmonotonic conditionals</title>
	<atom:link href="http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Certain Doubts &#187; Stats for May</title>
		<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/#comment-1366</link>
		<dc:creator><![CDATA[Certain Doubts &#187; Stats for May]]></dc:creator>
		<pubDate>Thu, 01 Jun 2006 11:54:33 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=255#comment-1366</guid>
		<description><![CDATA[[...] views for last month: 53,378, another new record.   	Top-read posts for the month were: 	1  Jim Hawthorne on the logic of nonmonotonic conditionals 1,674 	2  Norms o [...]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;] views for last month: 53,378, another new record.   	Top-read posts for the month were: 	1  Jim Hawthorne on the logic of nonmonotonic conditionals 1,674 	2  Norms o [&#8230;]</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Certain Doubts &#187; April Stats</title>
		<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/#comment-1365</link>
		<dc:creator><![CDATA[Certain Doubts &#187; April Stats]]></dc:creator>
		<pubDate>Mon, 01 May 2006 13:56:02 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=255#comment-1365</guid>
		<description><![CDATA[[...] pressivism about the value of truth 397 8  Norms of Assertion and Constitutive Rules 267 9  Jim Hawthorne on the logic of nonmonotonic conditionals 253 10  Epistemol [...]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;] pressivism about the value of truth 397 8  Norms of Assertion and Constitutive Rules 267 9  Jim Hawthorne on the logic of nonmonotonic conditionals 253 10  Epistemol [&#8230;]</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Postmodernist</title>
		<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/#comment-1364</link>
		<dc:creator><![CDATA[Postmodernist]]></dc:creator>
		<pubDate>Fri, 27 May 2005 01:33:10 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=255#comment-1364</guid>
		<description><![CDATA[Is the notion of a nonmonotonic intuitionist logic coherent?  Are such logics studied?  I&#039;ve never seen one.]]></description>
		<content:encoded><![CDATA[<p>Is the notion of a nonmonotonic intuitionist logic coherent?  Are such logics studied?  I&#8217;ve never seen one.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jim Hawthorne</title>
		<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/#comment-1363</link>
		<dc:creator><![CDATA[Jim Hawthorne]]></dc:creator>
		<pubDate>Sat, 12 Feb 2005 23:17:18 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=255#comment-1363</guid>
		<description><![CDATA[Horacio,

I received the copy of your forthcoming JPL paper. Thanks for sending it!!! I gave it a fairly quick read in order to be able to reply intelligently (I hope) to your posting. (Itâ??s really interesting, and Iâ??ll take the time to go through more carefully in the next few days.) Anyway, I think I get it now. Let me try to characterize what I think is going on in the result you described in your post. This will take several pages to describe, Iâ??m afraid. [Sorry this is going to be so long, Jon!!!] Please tell me if you think Iâ??m getting it right or wrong.

Letâ??s put the consequence relations (the nonmonotonic conditionals) completely to the side for now, and just talk about probability. And let us distinguish between what Iâ??ll call â??van Fraassen Functionsâ?? (vF functions) and â??Popper functionsâ?? (Pop functions). One big difference is that Pop functions are defined on sentences, whereas vF functions are defined on sets, which can be thought of as propositions -- i.e. sets of possible worlds. But they are similar in that both take conditional probability as primitive (not defined in terms of unconditional probability), and logically they work in exactly the same way -- with one exception.

The vF functions are defined on a probability space [U,F,P], where U is a set (think â??set of all possible worldsâ??), F is a field of subsets of U (think â??propositionsâ??) and P is a conditional probability function defined on pairs of â??propositionsâ??. To say that F is a field of subsets of U just means that:(1) if A is in F, its complement, U-A, is in F; (2) if A and B are in F, their union is in F (and thus, so is their intersection, which is definable in terms of union and complement). Think of each member of F as a proposition, and F is a Boolean algebra of propositions. [Iâ??m going into this kind of  detail for readers who may not be up on this stuff.] Given this, the function P in a vF probability space [U,F,P] assigns numbers between 0 and 1 such that, holding A from F fixed, P[  &#124;A] &lt;i&gt;either&lt;/i&gt; satisfies the usual axioms for a one-place probability functions (defined on sets) &lt;i&gt;or else&lt;/i&gt; P[ &#124;A] is degenerate in that P[X&#124;A] has value 1 for all X in F. Letâ??s call such functions (on such probability spaces) â??finitely additive vF functions.â??

However, it is also common to define â??countably additive vF functionsâ??. Such functions are defined on a probability space [U,F,P], just like before, except that F is a sigma-field of subsets of U. That means that F is a field, as before, and in addition, for each countable collection of members of F, {A1, A2, ...}, F must also contain â??union{A1, A2, ...}â??, the union of the whole collection (and it follows that F also contains the intersections of each countable collection of its members).  Furthermore, when F is a sigma-field, P is taken to be a â??countably additive probability measureâ??, which means it satisfies the usual rules for probabilities described above, and in addition: if {B1, B2, ...} a countable set of disjoint sets, then P[union{B1, B2, ...}&#124;A] = (P[B1&#124;A] + P[B2&#124;A] + ...+ P[Bn&#124;A]+ ...).

All of this makes the â??finitely additive vF functionsâ?? just like the Pop functions, except that the Pop functions are defined on sentences of a formal language L for sentential logic (with a countable set of sentence letters), rather than on sets (rather than on propositions-as-sets-of-worlds). The probabilistic logic of finitely additive vF functions is precisely the same as that of the usual Pop functions -- lets us call them the â??finitely additive Pop functionsâ?? to mark this.

One might extend the usual definition of finitely additive Pop function to â??countably additive Pop functionsâ?? by doing something analogous to what one does to get countably additive vF functions. To do so one must first introduce a way to represent infinite disjunctions (or conjunctions--either one will do) of sentences: i.e., for any set of sentences {b1, b2, ...}, let â??v(b1, b2, ...)â?? (where the bi are in some specific order) be the disjunction of those sentences. The propositional logic of languages with such a connective has been worked out, and is pretty well known. Then a â??countably additive Pop functionâ?? would say: if each distinct pair in {b1, b2, ...} is inconsistent, then p[v(b1, b2, ...) &#124; a] = p[b1&#124;a] + p[b2&#124;a] + ... . One usually doesnâ??t introduce infinite disjunction into the Pop functions, and so does not have countably additive Pop functions -- but there is no technical problem in doing so. (Horacio&#039;s and Rohitâ??s paper uses lower case letters for sentences and upper case letters for sets, and Iâ??m following suit here.)

Horacio&#039;s and Rohitâ??s paper assumes, for their main results, that the set U (of worlds) is countable. That means that the set F of propositions might be as large as 2^aleph-null (e.g. if F is the set of all subsets of U). But F is only â??requiredâ?? to be some Boolean algebra of sets -- so it may be countable (even finite, for some given case of a probability space). However, the set of sentences (atomic and larger) of the formal language L (for sentential logic) is only countable. Nevertheless, given any specific part of a probability space [U,F], one can use it as an â??interpretationâ?? of sentences of L by specifying an assignment function I such that for each atomic sentence b in L, I[b] is in F (I[b] is the proposition B in F that sentence b represents). There are a few obvious rules that interpretations I must follow, though: for all sentences c, I[~c] = U-I[c]; for all b, c, I[(bvc)] = (I[b] union I[c]). Also, if F is a sigma field &lt;i&gt;and if&lt;/i&gt; L &lt;i&gt;permits infinite disjunctions&lt;/i&gt;, then we should have I[v(b1, b2, ...)] = (union{I[b1], I[b2], ...}). However, although Horacio and Rohit have models where F is a sigma-field, they do not employ a language L that contains infinite disjunctions. I think this is important to understanding the result in their paper that Horacio described in his post.

Now, clearly, each finitely additive vF function is mimicked by a finitely additive Pop functions, and vice versa. Given a finitely additive [U,F,P] and an interpretation I that maps sentences of L to sets in F, define a corresponding function p on L such that p[b&#124;a] = P[I[a] &#124; I[b]]. It is easy to show that p is a Pop function. Conversely, given any finitely additive Pop function p, we can define a finitely additive probability space that mimics it.

 The same goes for the countably additive vF and countably additive Pop functions.

Now, what if the language L has no way of representing infinite disjunctions, but one starts with a countably additive vF function [U,F,P]. Is there a Pop function that â??agrees with Pâ?? on an interpretation I of the language? Sure!!! Just extend the language to a new language L+ that also accommodates infinite disjunctions, extent I to map sentences in L+ to the corresponding countable unions of F (there is one and only one way to do this, since the way I makes assignments to complex sentences is fixed uniquely by how it makes assignments to atomic sentences), then find the Pop function p+ that corresponds to P (as above). So we have a Pop function p+ on L+ that behaves just like P on F. Now just throw out all of p+ that applies to sentences involving infinite disjunctions, and call the resulting function p. p is a Pop function that agrees with the vF function on the Boolean sub-algebra of F picked out by interpretation I restricted to the language L.

However, the converse of this process wonâ??t work in general, and that is â??effectivelyâ?? (i.e. for my purposes) what the result that Horacio describes in his post is about. That is, start with an arbitrary finitely additive Pop function p on a usual language L for sentential logic (with countably many sentence letters). Is there &lt;i&gt;always&lt;/i&gt; (i.e. for each given p) a way to construct a probability space [U,F,P] with U countable, F a sigma-field, and P a countably additive vF function, such that there is an interpretation I that makes p agree with P (i.e. such that, for some I, p[b&#124;a] = P[I[a] &#124; I[b]] for each a and b in L)? The answer is NO!

So, about the conditionals in R:

They are just the probability 1 parts of finitely additive Pop functions. I.e.,

(1)for each conditional --&gt; satisfying the rules of R, there is a finitely additive Pop function p that has
p[a&#124;b] = 1 iff b--&gt;a.

and

(2) for each finitely additive Pop function p, there is a conditional --&gt; satisfying the rules of R such that, b--&gt;a iff p[a&#124;b] = 1.

However if we define Pop functions on a language L+ with countable disjunction (which L doesnâ??t have) we get frm Horacioâ??s and Rohitâ??s result:

(1*) there are conditionals --&gt; satisfying the rules of R (on L) such that no countably additive Pop function p on L+ agrees with --&gt; on L (i.e. no p gives â??p[a&#124;b] = 1 iff b--&gt;aâ?? for all sentences a, b in L).

But, of course, the alteration for (2) to countably additive Pop functions still works:

(2*) for each countably additive Pop function P (on L+), there is a conditional --&gt; satisfying the rules of R (on L) such that (for sentences of L), b--&gt;a iff P[A&#124;B] = 1.

The obvious question is, â??what if we extend R to the language L+ ?â?? That is Define R+ to include all conditionals (all pairs of sentences of L+) that satisfy the rules of R (where the notion of logical entailment &#124;= in these rules is replaced by the entailment relation &#124;=+ appropriate to logic with countable disjunctions)?

Clearly the claim corresponding to (2) still holds:

(2+) for each countably additive Pop function p, there is a conditional --&gt; satisfying the rules of R+ such that, b--&gt;a iff p[a&#124;b] = 1. (One can show quite easily that a well-known way to axiomatize the Pop functions yield (2+) when altered to handle L+.)

What about the claim corresponding to (1)?

(1+) for each conditional --&gt; satisfying the rules of R+, there is a countably additive Pop function P that has p[a&#124;b] = 1 iff b--&gt;a.

If looks to me like this should hold as well, and can be proved in the same way that (1) is usually proved.

Does this all look right?]]></description>
		<content:encoded><![CDATA[<p>Horacio,</p>
<p>I received the copy of your forthcoming JPL paper. Thanks for sending it!!! I gave it a fairly quick read in order to be able to reply intelligently (I hope) to your posting. (Itâ??s really interesting, and Iâ??ll take the time to go through more carefully in the next few days.) Anyway, I think I get it now. Let me try to characterize what I think is going on in the result you described in your post. This will take several pages to describe, Iâ??m afraid. [Sorry this is going to be so long, Jon!!!] Please tell me if you think Iâ??m getting it right or wrong.</p>
<p>Letâ??s put the consequence relations (the nonmonotonic conditionals) completely to the side for now, and just talk about probability. And let us distinguish between what Iâ??ll call â??van Fraassen Functionsâ?? (vF functions) and â??Popper functionsâ?? (Pop functions). One big difference is that Pop functions are defined on sentences, whereas vF functions are defined on sets, which can be thought of as propositions &#8212; i.e. sets of possible worlds. But they are similar in that both take conditional probability as primitive (not defined in terms of unconditional probability), and logically they work in exactly the same way &#8212; with one exception.</p>
<p>The vF functions are defined on a probability space [U,F,P], where U is a set (think â??set of all possible worldsâ??), F is a field of subsets of U (think â??propositionsâ??) and P is a conditional probability function defined on pairs of â??propositionsâ??. To say that F is a field of subsets of U just means that:(1) if A is in F, its complement, U-A, is in F; (2) if A and B are in F, their union is in F (and thus, so is their intersection, which is definable in terms of union and complement). Think of each member of F as a proposition, and F is a Boolean algebra of propositions. [Iâ??m going into this kind of  detail for readers who may not be up on this stuff.] Given this, the function P in a vF probability space [U,F,P] assigns numbers between 0 and 1 such that, holding A from F fixed, P[  |A] <i>either</i> satisfies the usual axioms for a one-place probability functions (defined on sets) <i>or else</i> P[ |A] is degenerate in that P[X|A] has value 1 for all X in F. Letâ??s call such functions (on such probability spaces) â??finitely additive vF functions.â??</p>
<p>However, it is also common to define â??countably additive vF functionsâ??. Such functions are defined on a probability space [U,F,P], just like before, except that F is a sigma-field of subsets of U. That means that F is a field, as before, and in addition, for each countable collection of members of F, {A1, A2, &#8230;}, F must also contain â??union{A1, A2, &#8230;}â??, the union of the whole collection (and it follows that F also contains the intersections of each countable collection of its members).  Furthermore, when F is a sigma-field, P is taken to be a â??countably additive probability measureâ??, which means it satisfies the usual rules for probabilities described above, and in addition: if {B1, B2, &#8230;} a countable set of disjoint sets, then P[union{B1, B2, &#8230;}|A] = (P[B1|A] + P[B2|A] + &#8230;+ P[Bn|A]+ &#8230;).</p>
<p>All of this makes the â??finitely additive vF functionsâ?? just like the Pop functions, except that the Pop functions are defined on sentences of a formal language L for sentential logic (with a countable set of sentence letters), rather than on sets (rather than on propositions-as-sets-of-worlds). The probabilistic logic of finitely additive vF functions is precisely the same as that of the usual Pop functions &#8212; lets us call them the â??finitely additive Pop functionsâ?? to mark this.</p>
<p>One might extend the usual definition of finitely additive Pop function to â??countably additive Pop functionsâ?? by doing something analogous to what one does to get countably additive vF functions. To do so one must first introduce a way to represent infinite disjunctions (or conjunctions&#8211;either one will do) of sentences: i.e., for any set of sentences {b1, b2, &#8230;}, let â??v(b1, b2, &#8230;)â?? (where the bi are in some specific order) be the disjunction of those sentences. The propositional logic of languages with such a connective has been worked out, and is pretty well known. Then a â??countably additive Pop functionâ?? would say: if each distinct pair in {b1, b2, &#8230;} is inconsistent, then p[v(b1, b2, &#8230;) | a] = p[b1|a] + p[b2|a] + &#8230; . One usually doesnâ??t introduce infinite disjunction into the Pop functions, and so does not have countably additive Pop functions &#8212; but there is no technical problem in doing so. (Horacio&#8217;s and Rohitâ??s paper uses lower case letters for sentences and upper case letters for sets, and Iâ??m following suit here.)</p>
<p>Horacio&#8217;s and Rohitâ??s paper assumes, for their main results, that the set U (of worlds) is countable. That means that the set F of propositions might be as large as 2^aleph-null (e.g. if F is the set of all subsets of U). But F is only â??requiredâ?? to be some Boolean algebra of sets &#8212; so it may be countable (even finite, for some given case of a probability space). However, the set of sentences (atomic and larger) of the formal language L (for sentential logic) is only countable. Nevertheless, given any specific part of a probability space [U,F], one can use it as an â??interpretationâ?? of sentences of L by specifying an assignment function I such that for each atomic sentence b in L, I[b] is in F (I[b] is the proposition B in F that sentence b represents). There are a few obvious rules that interpretations I must follow, though: for all sentences c, I[~c] = U-I[c]; for all b, c, I[(bvc)] = (I[b] union I[c]). Also, if F is a sigma field <i>and if</i> L <i>permits infinite disjunctions</i>, then we should have I[v(b1, b2, &#8230;)] = (union{I[b1], I[b2], &#8230;}). However, although Horacio and Rohit have models where F is a sigma-field, they do not employ a language L that contains infinite disjunctions. I think this is important to understanding the result in their paper that Horacio described in his post.</p>
<p>Now, clearly, each finitely additive vF function is mimicked by a finitely additive Pop functions, and vice versa. Given a finitely additive [U,F,P] and an interpretation I that maps sentences of L to sets in F, define a corresponding function p on L such that p[b|a] = P[I[a] | I[b]]. It is easy to show that p is a Pop function. Conversely, given any finitely additive Pop function p, we can define a finitely additive probability space that mimics it.</p>
<p> The same goes for the countably additive vF and countably additive Pop functions.</p>
<p>Now, what if the language L has no way of representing infinite disjunctions, but one starts with a countably additive vF function [U,F,P]. Is there a Pop function that â??agrees with Pâ?? on an interpretation I of the language? Sure!!! Just extend the language to a new language L+ that also accommodates infinite disjunctions, extent I to map sentences in L+ to the corresponding countable unions of F (there is one and only one way to do this, since the way I makes assignments to complex sentences is fixed uniquely by how it makes assignments to atomic sentences), then find the Pop function p+ that corresponds to P (as above). So we have a Pop function p+ on L+ that behaves just like P on F. Now just throw out all of p+ that applies to sentences involving infinite disjunctions, and call the resulting function p. p is a Pop function that agrees with the vF function on the Boolean sub-algebra of F picked out by interpretation I restricted to the language L.</p>
<p>However, the converse of this process wonâ??t work in general, and that is â??effectivelyâ?? (i.e. for my purposes) what the result that Horacio describes in his post is about. That is, start with an arbitrary finitely additive Pop function p on a usual language L for sentential logic (with countably many sentence letters). Is there <i>always</i> (i.e. for each given p) a way to construct a probability space [U,F,P] with U countable, F a sigma-field, and P a countably additive vF function, such that there is an interpretation I that makes p agree with P (i.e. such that, for some I, p[b|a] = P[I[a] | I[b]] for each a and b in L)? The answer is NO!</p>
<p>So, about the conditionals in R:</p>
<p>They are just the probability 1 parts of finitely additive Pop functions. I.e.,</p>
<p>(1)for each conditional &#8211;> satisfying the rules of R, there is a finitely additive Pop function p that has<br />
p[a|b] = 1 iff b&#8211;>a.</p>
<p>and</p>
<p>(2) for each finitely additive Pop function p, there is a conditional &#8211;> satisfying the rules of R such that, b&#8211;>a iff p[a|b] = 1.</p>
<p>However if we define Pop functions on a language L+ with countable disjunction (which L doesnâ??t have) we get frm Horacioâ??s and Rohitâ??s result:</p>
<p>(1*) there are conditionals &#8211;> satisfying the rules of R (on L) such that no countably additive Pop function p on L+ agrees with &#8211;> on L (i.e. no p gives â??p[a|b] = 1 iff b&#8211;>aâ?? for all sentences a, b in L).</p>
<p>But, of course, the alteration for (2) to countably additive Pop functions still works:</p>
<p>(2*) for each countably additive Pop function P (on L+), there is a conditional &#8211;> satisfying the rules of R (on L) such that (for sentences of L), b&#8211;>a iff P[A|B] = 1.</p>
<p>The obvious question is, â??what if we extend R to the language L+ ?â?? That is Define R+ to include all conditionals (all pairs of sentences of L+) that satisfy the rules of R (where the notion of logical entailment |= in these rules is replaced by the entailment relation |=+ appropriate to logic with countable disjunctions)?</p>
<p>Clearly the claim corresponding to (2) still holds:</p>
<p>(2+) for each countably additive Pop function p, there is a conditional &#8211;> satisfying the rules of R+ such that, b&#8211;>a iff p[a|b] = 1. (One can show quite easily that a well-known way to axiomatize the Pop functions yield (2+) when altered to handle L+.)</p>
<p>What about the claim corresponding to (1)?</p>
<p>(1+) for each conditional &#8211;> satisfying the rules of R+, there is a countably additive Pop function P that has p[a|b] = 1 iff b&#8211;>a.</p>
<p>If looks to me like this should hold as well, and can be proved in the same way that (1) is usually proved.</p>
<p>Does this all look right?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jim Hawthorne</title>
		<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/#comment-1362</link>
		<dc:creator><![CDATA[Jim Hawthorne]]></dc:creator>
		<pubDate>Fri, 11 Feb 2005 04:31:34 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=255#comment-1362</guid>
		<description><![CDATA[Horacio,

Where is your paper coming out? It sounds really interesting to me -- I definitely need to read it!!!

It can be shown that the system R is a complete characterization of the probability 1 parts of Popper functions on a language for propositional logic with a &lt;i&gt;countably infinite number of atomic sentences&lt;/i&gt;. But this language has no way (no symbol) for representing infinite conjunctions or disjunctions of sentences -- so is only finitely additive, not sigma additive. R is also a complete charaterization of the probability 1 parts of Popper functions when applied to the (the usual countably infinite) language of first-order predicate logic (with identity). Again, this language has no general way to represent infinite conjunctions or disjunctions &lt;i&gt;of arbitray collections of sentences&lt;/i&gt;. However, the quantifiers (in the object language) let one represent &quot;infinite conjunctions&quot; and &quot;infinite disjunctions&quot; of some sentences (those gotten by plugging names into open formulas in place of free variables) -- e.g. (x)Fx can represent (Fc1 &amp; Fc2 &amp; ...), and (Ex)Fx can represent (Fc1 v Fc2 v ...), for arbitrarily complex formulas Fx.

Indeed, like the Popper functions themselves, there is a set of rules for R (on infinite languages) that doesn&#039;t draw on an already defined notion of logical entailment. The propositional logic version of these rules is as follows:

1) for some D and E, it is not the case that E--&gt;D;
2) A --&gt; A;
3) if (C&amp;B) --&gt; A, then (B&amp;C) --&gt;A;
4.1) if C --&gt; (B&amp;A), then C --&gt; (A&amp;B);
4.2) if C --&gt; ~(B&amp;A), then C --&gt; ~(A&amp;B);
5.1) if B --&gt; ~~A, then B --&gt; A;
5.2) if B --&gt; A and B --&gt; ~A, then B --&gt; C (for all C);
6.1) C --&gt; B and (C&amp;B) --&gt; A iff C --&gt; (B&amp;A);
6.2) C --&gt; ~B or (C&amp;B) --&gt; ~A iff C --&gt; ~(B&amp;A).

It turns out that one can derive all of the usual rules for the rational consequence relations R from these, and vice versa.
Notice that these rules don&#039;t presuppose the classical notion (or any other notion) of logical entailment. There is no assumption here that &#039;B--&gt;T&#039; holds for tautologies T, and no assumption that one can substitute logically equivalent sentence in. Rather, one can &quot;define&quot; a notion of logical entailment in terms of these conditionals, then show that it is equivalent to the classical notion. And then one can &lt;i&gt;prove&lt;/i&gt; that &#039;B--&gt;T&#039; holds for tautologies T, and that substitute logically equivalent sentences can be substituted into conditional statements.

Definition: B R-entails A iff for every conditional &#039;--&gt;&#039; satisfying these rules, B--&gt;A.

Theorem: B R-entails A iff B logically entails A (in the usual classical sense).

etc.

One can do a similar thing for predicate logic (with identity) -- but the quantifier rule is a bit complicated, so I won&#039;t repeat it here. All of this is on infinite languages, but without countable conjunctions or disjunctions(except for quantified sentences, insofar as they are like infinite conjunctions and disjunctions).

Anyway, please tell me where I will find your paper!!!

Jim]]></description>
		<content:encoded><![CDATA[<p>Horacio,</p>
<p>Where is your paper coming out? It sounds really interesting to me &#8212; I definitely need to read it!!!</p>
<p>It can be shown that the system R is a complete characterization of the probability 1 parts of Popper functions on a language for propositional logic with a <i>countably infinite number of atomic sentences</i>. But this language has no way (no symbol) for representing infinite conjunctions or disjunctions of sentences &#8212; so is only finitely additive, not sigma additive. R is also a complete charaterization of the probability 1 parts of Popper functions when applied to the (the usual countably infinite) language of first-order predicate logic (with identity). Again, this language has no general way to represent infinite conjunctions or disjunctions <i>of arbitray collections of sentences</i>. However, the quantifiers (in the object language) let one represent &#8220;infinite conjunctions&#8221; and &#8220;infinite disjunctions&#8221; of some sentences (those gotten by plugging names into open formulas in place of free variables) &#8212; e.g. (x)Fx can represent (Fc1 &#038; Fc2 &#038; &#8230;), and (Ex)Fx can represent (Fc1 v Fc2 v &#8230;), for arbitrarily complex formulas Fx.</p>
<p>Indeed, like the Popper functions themselves, there is a set of rules for R (on infinite languages) that doesn&#8217;t draw on an already defined notion of logical entailment. The propositional logic version of these rules is as follows:</p>
<p>1) for some D and E, it is not the case that E&#8211;>D;<br />
2) A &#8211;> A;<br />
3) if (C&#038;B) &#8211;> A, then (B&#038;C) &#8211;>A;<br />
4.1) if C &#8211;> (B&#038;A), then C &#8211;> (A&#038;B);<br />
4.2) if C &#8211;> ~(B&#038;A), then C &#8211;> ~(A&#038;B);<br />
5.1) if B &#8211;> ~~A, then B &#8211;> A;<br />
5.2) if B &#8211;> A and B &#8211;> ~A, then B &#8211;> C (for all C);<br />
6.1) C &#8211;> B and (C&#038;B) &#8211;> A iff C &#8211;> (B&#038;A);<br />
6.2) C &#8211;> ~B or (C&#038;B) &#8211;> ~A iff C &#8211;> ~(B&#038;A).</p>
<p>It turns out that one can derive all of the usual rules for the rational consequence relations R from these, and vice versa.<br />
Notice that these rules don&#8217;t presuppose the classical notion (or any other notion) of logical entailment. There is no assumption here that &#8216;B&#8211;>T&#8217; holds for tautologies T, and no assumption that one can substitute logically equivalent sentence in. Rather, one can &#8220;define&#8221; a notion of logical entailment in terms of these conditionals, then show that it is equivalent to the classical notion. And then one can <i>prove</i> that &#8216;B&#8211;>T&#8217; holds for tautologies T, and that substitute logically equivalent sentences can be substituted into conditional statements.</p>
<p>Definition: B R-entails A iff for every conditional &#8216;&#8211;>&#8217; satisfying these rules, B&#8211;>A.</p>
<p>Theorem: B R-entails A iff B logically entails A (in the usual classical sense).</p>
<p>etc.</p>
<p>One can do a similar thing for predicate logic (with identity) &#8212; but the quantifier rule is a bit complicated, so I won&#8217;t repeat it here. All of this is on infinite languages, but without countable conjunctions or disjunctions(except for quantified sentences, insofar as they are like infinite conjunctions and disjunctions).</p>
<p>Anyway, please tell me where I will find your paper!!!</p>
<p>Jim</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Branden Fitelson</title>
		<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/#comment-1361</link>
		<dc:creator><![CDATA[Branden Fitelson]]></dc:creator>
		<pubDate>Thu, 10 Feb 2005 07:35:15 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=255#comment-1361</guid>
		<description><![CDATA[Dear Greg,

The algorithm is fully general.  I just discuss 3-event examples to illustrate.  Canny showed (in 1992) that the (pure) existential quantifier elimination problem in the theory of real closed fields is PSPACE.  This entails that the present problems are PSPACE, since we can translate them into that fragment of the TRCF.  The paper describes that translation, and demonstrates how Mathematica&#039;s built-in TRCF QE algorithm (which is double exponential) can be used to solve problems.  My graduate student is implementing Canny&#039;s PSPACE algorithm, which will hopefull be a bit faster in practice, and which will also be public domain (rather than being tied to Mathematica).  I hope that helps.

-B]]></description>
		<content:encoded><![CDATA[<p>Dear Greg,</p>
<p>The algorithm is fully general.  I just discuss 3-event examples to illustrate.  Canny showed (in 1992) that the (pure) existential quantifier elimination problem in the theory of real closed fields is PSPACE.  This entails that the present problems are PSPACE, since we can translate them into that fragment of the TRCF.  The paper describes that translation, and demonstrates how Mathematica&#8217;s built-in TRCF QE algorithm (which is double exponential) can be used to solve problems.  My graduate student is implementing Canny&#8217;s PSPACE algorithm, which will hopefull be a bit faster in practice, and which will also be public domain (rather than being tied to Mathematica).  I hope that helps.</p>
<p>-B</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/#comment-1360</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Wed, 09 Feb 2005 19:17:11 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=255#comment-1360</guid>
		<description><![CDATA[Thanks for the links, Branden. So, it is polynomial space. I didn&#039;t know whether this result was generalized, since I&#039;ve only seen it for one language. I glanced at the slides, which are very interesting. A question: is the idea to reduce nearly all problems to 3 terms to make the algorithm tractable? What type of confirmation problems resist this reduction strategy---or, why the qualification of &#039;nearly all&#039; on slide 9?  Or have I misunderstood how the program works?

You can get down to NP-complete with a weaker language (namely one that won&#039;t allow you to express independence within the language, nor to compare likelihood ratios); I&#039;m sure you know this, I&#039;m just mentioning it for casual readers.]]></description>
		<content:encoded><![CDATA[<p>Thanks for the links, Branden. So, it is polynomial space. I didn&#8217;t know whether this result was generalized, since I&#8217;ve only seen it for one language. I glanced at the slides, which are very interesting. A question: is the idea to reduce nearly all problems to 3 terms to make the algorithm tractable? What type of confirmation problems resist this reduction strategy&#8212;or, why the qualification of &#8216;nearly all&#8217; on slide 9?  Or have I misunderstood how the program works?</p>
<p>You can get down to NP-complete with a weaker language (namely one that won&#8217;t allow you to express independence within the language, nor to compare likelihood ratios); I&#8217;m sure you know this, I&#8217;m just mentioning it for casual readers.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Branden Fitelson</title>
		<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/#comment-1359</link>
		<dc:creator><![CDATA[Branden Fitelson]]></dc:creator>
		<pubDate>Wed, 09 Feb 2005 16:36:26 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=255#comment-1359</guid>
		<description><![CDATA[Dear Greg,

I have a decision procedure for all of probability calculus that is double-exponential.  The best possible algorithm is PSPACE.  I have a student working on that for his thesis in the logic group at Berkeley.   See my talk:

http://fitelson.org/bristol_pr.pdf

for some details.  You can download a user-friendly version of my procedure as a Mathematica package (co-written with Jason Alexander). See

http://fitelson.org/PrSAT

-Branden]]></description>
		<content:encoded><![CDATA[<p>Dear Greg,</p>
<p>I have a decision procedure for all of probability calculus that is double-exponential.  The best possible algorithm is PSPACE.  I have a student working on that for his thesis in the logic group at Berkeley.   See my talk:</p>
<p><a href="http://fitelson.org/bristol_pr.pdf" rel="nofollow">http://fitelson.org/bristol_pr.pdf</a></p>
<p>for some details.  You can download a user-friendly version of my procedure as a Mathematica package (co-written with Jason Alexander). See</p>
<p><a href="http://fitelson.org/PrSAT" rel="nofollow">http://fitelson.org/PrSAT</a></p>
<p>-Branden</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/#comment-1358</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Wed, 09 Feb 2005 14:27:24 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=255#comment-1358</guid>
		<description><![CDATA[Jim, thanks very much for your reply. I need to think on this some more. I&#039;m very excited about your study of systems below system P. I agree with you that a system weaker than P is necessay if you take the notion of probabilistic acceptance seriously.

Branden &amp; Jim: a thought came to me about a logic for likelihood ratios on the train this morning. I think there may be a problem with complexity. Standard (propositional) probabilistic logics are NP-complete, which is no worse than propositional logic. But wouldn&#039;t a logic for likelihood ratios be decided in polynomial space? The thought is that you couldn&#039;t clear the denominators and solve the equations linearly for a language rich enough to express likelihood ratios. If this is right, then while you&#039;ll be able to give the semantics fairly straightforwardly, it would be harder to axiomatize and difficult to determine the validity of formulas within such a logic.]]></description>
		<content:encoded><![CDATA[<p>Jim, thanks very much for your reply. I need to think on this some more. I&#8217;m very excited about your study of systems below system P. I agree with you that a system weaker than P is necessay if you take the notion of probabilistic acceptance seriously.</p>
<p>Branden &#038; Jim: a thought came to me about a logic for likelihood ratios on the train this morning. I think there may be a problem with complexity. Standard (propositional) probabilistic logics are NP-complete, which is no worse than propositional logic. But wouldn&#8217;t a logic for likelihood ratios be decided in polynomial space? The thought is that you couldn&#8217;t clear the denominators and solve the equations linearly for a language rich enough to express likelihood ratios. If this is right, then while you&#8217;ll be able to give the semantics fairly straightforwardly, it would be harder to axiomatize and difficult to determine the validity of formulas within such a logic.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jim Hawthorne</title>
		<link>http://certaindoubts.com/jim-hawthorne-on-the-logic-of-nonmonotonic-conditionals/#comment-1354</link>
		<dc:creator><![CDATA[Jim Hawthorne]]></dc:creator>
		<pubDate>Wed, 09 Feb 2005 08:24:48 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=255#comment-1354</guid>
		<description><![CDATA[Greg,

Here are some partials answers to your questions -- partial because itâ??s the best I can do right now.

1. The logic containing only one Q[r] conditional (only one conditional satisfying the Q rules at threshold level r) doesnâ??t have the resources to also say â??B makes A almost certainâ?? for some degree of certainty higher than r. One might do something close to this, though, with a system containing two conditionals, one a Q[r] conditional (for some specific level r) and the second a conditional, =&gt;, for the system R (a so-called rational consequence relation). The R conditional =&gt; would satisfy rules 0-5, 11, and 12. The Q[r] conditional â??--&gt;â?? would satisfy rules 0-9, and a version of 10 with the antecedent consisting of conditionals of form â??B =&gt; (Ai v Aj)â?? and the consequent having (the disjunction of) conditionals of form â??B--&gt;Aiâ??. (Such a logic would also need a rule saying â??if B=&gt;A, then B--&gt;Aâ??.) This isnâ??t exactly what you wanted, but goes in that direction, since the antecedent of 10 would no longer involve the claims â??B&amp;~(Ai v Aj) --&gt; (Ai v Aj)â??, which require that B make (Ai v Aj) &lt;i&gt;absolutely&lt;/i&gt; (nonmonotonically) certain, but would instead employ the somewhat weaker claims â??B =&gt; (Ai v Aj)â?? that say that B makes (Ai v Aj) defeasibly certain.
Perhaps one could even use a similar two-conditional strategy employing two distinct Q conditionals, a Q[r] conditional â??--&gt;â?? and a Q[s] conditional â??=&gt;â?? with s &gt; r. In that case rule 10 would have to be replaced by a somewhat more complex two-conditional rule (more complex because of how the proof of rule 10 works), and itâ??s not exactly clear to me how that more complex rule should look.

2. The interpretations of rules 9 and 10 in terms of pages (for the preface) and in terms of lotteries was only illustrative. These rules hold regardless of what propositions the terms â??Aiâ?? and â??Bâ?? stand for, and regardless of their logical complexity (i.e. they need not be atomic statement letters). [I know this is obvious, but it helps set up what Iâ??m about to say in answer to your other questions.] To help the reader get the gist of rule 10, I suggested letting each â??Aiâ?? say â??ticket i wonâ??t winâ?? (in a given lottery). On this interpretation each conditional in the antecedent of rule 10 effectively says â??B makes it absolutely certain that either ticket i wonâ??t win or ticket j wonâ??t winâ??. Now, you ask, what if we add â??B makes it absolutely certain that more than one ticket will winâ??. This, of course, contradicts the antecedent of rule 10 (if we take the â??Ai v Ajâ?? to say â??ticket i wonâ??t win or ticket j wonâ??t winâ??) -- so it seems that rule 10 just doesnâ??t apply here. But not so fast!
Suppose we want to say â??B makes it absolutely certain that at least one ticket will winâ??. Here is how we can say that for an n ticket lottery: â??B&amp;~(~A1 v ... v ~An) --&gt; (~A1 v ... v ~An)â?? (where â??(~Ai v ... v ~An)â?? says â??one of the tickets doesnâ??t loseâ??). It follows from this that â??B --&gt; (~A1 v ... v ~An)â??; and it follows from rule 10 (supposing n &gt; or = (r/(1-r))+1, and supposing that B makes it certain that no two tickets will win) that â??B --&gt; A1 or B --&gt; A2 or ... or B --&gt;Anâ??. All of this is perfectly consistent and reasonable.
Suppose, instead, we want to say â??B makes it absolutely certain that at least two tickets will winâ??. Here is how to say that: B&amp;~[(~A1&amp;~A2) v ... v (~An-1&amp;~An)] --&gt; [(~A1&amp;~A2) v ... v (~An-1&amp;~An)]â??. Each term â??(~Ai &amp; ~Aj)â?? says â??ticket i doesnâ??t lose and ticket j doesnâ??t loseâ?? (i.e. â??ticket i wins and ticket j winsâ??); and the disjunction of these terms says that some pair of tickets wins -- at leaast two tickets win. Notice that this claim seems to violate the antecedent of 10. However, 10 is still useful. For we might also be certain that â??no more than k tickets will all winâ?? for some given k (e.g. we might be certain that no more than 10 tickets can win this lottery, given how the lottery is set up). Then we will have each of the conditionals of form â??B&amp;~(Ci v Cj) --&gt; (Ci v Cj)â?? to use in the antecedent of rule 10, where each â??Ciâ?? says that some specific block of p (not necessarily consecutive) tickets wonâ??t all win (e.g. (A1 v ... v Ap)), and each â??Cjâ?? says that some specific block of q tickets wonâ??t win (e.g. (A1 v ... v Aq)), and where p+q = k+1 (and where Ci and Cj share no tickets in common). For each way of dividing the tickets up into such non-overlapping blocks, and provided that the total number of the blocks (for a given way of dividing them) is at least (r/(1-r))+1, rule 10 give us that â??B --&gt; C1 or ... or B --&gt;Cnâ??.

3. One more point. Consider lotteries where, B makes it plausible that â??at least k tickets will winâ?? in the sense that â??B --&gt; [(~A1 &amp; .. &amp;~Ak) v ... v (~An-k &amp; .. &amp;~An)] (where each possible conjunction of k tickets â??not losingâ?? is represented by one of the disjuncts). [B may also make plausible lots of other things, such as, that â??no more than m tickets will win -- i.e. we are no supposing that B is limited to only implying the lower bound k.] For such â??lower bound conditionalsâ??, rule 10 tells us nothing much -- but rule 9 also applies, and may tell us something informative. That is, provided that B isnâ??t contradictory  (i.e. provided that it is not the case that B --&gt; ~ B), and provided that the number of such blocks of k tickets is less than (r/(1-r)), rule 9 says that one of the following &lt;i&gt;must not hold&lt;/i&gt;: B --&gt; (A1 v ... v Ak) or ... or B --&gt; (An-k v ... v An) (where each disjunction saying that â??one of k tickets will loseâ?? is represented). In other words, based on B, &lt;i&gt;it must not be the case&lt;/i&gt; that for each block of k tickets, you believe &lt;i&gt;one of the tickets in this block must lose&lt;/i&gt; (when the number of such blocks is small enough -- less than (r/(1-r)) -- and you believe â??at least k tickets will win).

Sorry this reply is so long, Greg. But I hope its helps answer your questions.]]></description>
		<content:encoded><![CDATA[<p>Greg,</p>
<p>Here are some partials answers to your questions &#8212; partial because itâ??s the best I can do right now.</p>
<p>1. The logic containing only one Q[r] conditional (only one conditional satisfying the Q rules at threshold level r) doesnâ??t have the resources to also say â??B makes A almost certainâ?? for some degree of certainty higher than r. One might do something close to this, though, with a system containing two conditionals, one a Q[r] conditional (for some specific level r) and the second a conditional, =>, for the system R (a so-called rational consequence relation). The R conditional => would satisfy rules 0-5, 11, and 12. The Q[r] conditional â??&#8211;>â?? would satisfy rules 0-9, and a version of 10 with the antecedent consisting of conditionals of form â??B => (Ai v Aj)â?? and the consequent having (the disjunction of) conditionals of form â??B&#8211;>Aiâ??. (Such a logic would also need a rule saying â??if B=>A, then B&#8211;>Aâ??.) This isnâ??t exactly what you wanted, but goes in that direction, since the antecedent of 10 would no longer involve the claims â??B&#038;~(Ai v Aj) &#8211;> (Ai v Aj)â??, which require that B make (Ai v Aj) <i>absolutely</i> (nonmonotonically) certain, but would instead employ the somewhat weaker claims â??B => (Ai v Aj)â?? that say that B makes (Ai v Aj) defeasibly certain.<br />
Perhaps one could even use a similar two-conditional strategy employing two distinct Q conditionals, a Q[r] conditional â??&#8211;>â?? and a Q[s] conditional â??=>â?? with s > r. In that case rule 10 would have to be replaced by a somewhat more complex two-conditional rule (more complex because of how the proof of rule 10 works), and itâ??s not exactly clear to me how that more complex rule should look.</p>
<p>2. The interpretations of rules 9 and 10 in terms of pages (for the preface) and in terms of lotteries was only illustrative. These rules hold regardless of what propositions the terms â??Aiâ?? and â??Bâ?? stand for, and regardless of their logical complexity (i.e. they need not be atomic statement letters). [I know this is obvious, but it helps set up what Iâ??m about to say in answer to your other questions.] To help the reader get the gist of rule 10, I suggested letting each â??Aiâ?? say â??ticket i wonâ??t winâ?? (in a given lottery). On this interpretation each conditional in the antecedent of rule 10 effectively says â??B makes it absolutely certain that either ticket i wonâ??t win or ticket j wonâ??t winâ??. Now, you ask, what if we add â??B makes it absolutely certain that more than one ticket will winâ??. This, of course, contradicts the antecedent of rule 10 (if we take the â??Ai v Ajâ?? to say â??ticket i wonâ??t win or ticket j wonâ??t winâ??) &#8212; so it seems that rule 10 just doesnâ??t apply here. But not so fast!<br />
Suppose we want to say â??B makes it absolutely certain that at least one ticket will winâ??. Here is how we can say that for an n ticket lottery: â??B&#038;~(~A1 v &#8230; v ~An) &#8211;> (~A1 v &#8230; v ~An)â?? (where â??(~Ai v &#8230; v ~An)â?? says â??one of the tickets doesnâ??t loseâ??). It follows from this that â??B &#8211;> (~A1 v &#8230; v ~An)â??; and it follows from rule 10 (supposing n > or = (r/(1-r))+1, and supposing that B makes it certain that no two tickets will win) that â??B &#8211;> A1 or B &#8211;> A2 or &#8230; or B &#8211;>Anâ??. All of this is perfectly consistent and reasonable.<br />
Suppose, instead, we want to say â??B makes it absolutely certain that at least two tickets will winâ??. Here is how to say that: B&#038;~[(~A1&#038;~A2) v &#8230; v (~An-1&#038;~An)] &#8211;> [(~A1&#038;~A2) v &#8230; v (~An-1&#038;~An)]â??. Each term â??(~Ai &#038; ~Aj)â?? says â??ticket i doesnâ??t lose and ticket j doesnâ??t loseâ?? (i.e. â??ticket i wins and ticket j winsâ??); and the disjunction of these terms says that some pair of tickets wins &#8212; at leaast two tickets win. Notice that this claim seems to violate the antecedent of 10. However, 10 is still useful. For we might also be certain that â??no more than k tickets will all winâ?? for some given k (e.g. we might be certain that no more than 10 tickets can win this lottery, given how the lottery is set up). Then we will have each of the conditionals of form â??B&#038;~(Ci v Cj) &#8211;> (Ci v Cj)â?? to use in the antecedent of rule 10, where each â??Ciâ?? says that some specific block of p (not necessarily consecutive) tickets wonâ??t all win (e.g. (A1 v &#8230; v Ap)), and each â??Cjâ?? says that some specific block of q tickets wonâ??t win (e.g. (A1 v &#8230; v Aq)), and where p+q = k+1 (and where Ci and Cj share no tickets in common). For each way of dividing the tickets up into such non-overlapping blocks, and provided that the total number of the blocks (for a given way of dividing them) is at least (r/(1-r))+1, rule 10 give us that â??B &#8211;> C1 or &#8230; or B &#8211;>Cnâ??.</p>
<p>3. One more point. Consider lotteries where, B makes it plausible that â??at least k tickets will winâ?? in the sense that â??B &#8211;> [(~A1 &#038; .. &#038;~Ak) v &#8230; v (~An-k &#038; .. &#038;~An)] (where each possible conjunction of k tickets â??not losingâ?? is represented by one of the disjuncts). [B may also make plausible lots of other things, such as, that â??no more than m tickets will win &#8212; i.e. we are no supposing that B is limited to only implying the lower bound k.] For such â??lower bound conditionalsâ??, rule 10 tells us nothing much &#8212; but rule 9 also applies, and may tell us something informative. That is, provided that B isnâ??t contradictory  (i.e. provided that it is not the case that B &#8211;> ~ B), and provided that the number of such blocks of k tickets is less than (r/(1-r)), rule 9 says that one of the following <i>must not hold</i>: B &#8211;> (A1 v &#8230; v Ak) or &#8230; or B &#8211;> (An-k v &#8230; v An) (where each disjunction saying that â??one of k tickets will loseâ?? is represented). In other words, based on B, <i>it must not be the case</i> that for each block of k tickets, you believe <i>one of the tickets in this block must lose</i> (when the number of such blocks is small enough &#8212; less than (r/(1-r)) &#8212; and you believe â??at least k tickets will win).</p>
<p>Sorry this reply is so long, Greg. But I hope its helps answer your questions.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
