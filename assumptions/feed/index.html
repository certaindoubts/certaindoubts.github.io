<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Assumptions</title>
	<atom:link href="http://certaindoubts.com/assumptions/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/assumptions/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/assumptions/#comment-3080</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Tue, 03 Jan 2006 17:52:01 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=498#comment-3080</guid>
		<description><![CDATA[Jonathan&#039;s observations are very helpful and mesh quite well with what one sees on the computational side of several analogous issues. I get excited by some of the methodological issues in play here, so I&#039;ll remark on that with a brief example.

Distribution properties are very important for a formal language to enjoy, but it is not always clear whether those assumptions are appropriate to project onto the problem domain itself. Believing falsum (p and not-p) is a good point to zero out, I suspect.  But believing p and believing ~p might not be such a bad thing for our toy language to allow. All we&#039;re doing here is denying Chellas&#039; ( C ) axiom for classical modal logics, where X is a modadic modality (e.g., box):

  ( C ) (Xp and Xq) only if X(p and q)

which corresponds to a class of non-normal modal logics that characterize non-monotonic inference. (See Horacio Arlo-Costa&#039;s 71(1) 2002, Studia Logica). And there are a variety of reasons to be interested in non-monotonic logics, reasons that extend outside the bounds of epistemology proper.

One reason for chasing these things down as they run outside of philosophy proper is that often see remarkably similar problems cropping up in other domains and practitioners there, sometimes, advancing the mathematics to isolate these features at a level of abstraction that affords us more understanding of what is going on.

In reply to Jon&#039;s question to evidentialists, I can imagine (without endorsing) a reply that would push the issue into the theory of assessibility. So an evidentialist might say that there is a mental action that the agent performs to &#039;access&#039; the assumed information upon which to evaluate the epistemic status of the belief. Do you think this has legs?]]></description>
		<content:encoded><![CDATA[<p>Jonathan&#8217;s observations are very helpful and mesh quite well with what one sees on the computational side of several analogous issues. I get excited by some of the methodological issues in play here, so I&#8217;ll remark on that with a brief example.</p>
<p>Distribution properties are very important for a formal language to enjoy, but it is not always clear whether those assumptions are appropriate to project onto the problem domain itself. Believing falsum (p and not-p) is a good point to zero out, I suspect.  But believing p and believing ~p might not be such a bad thing for our toy language to allow. All we&#8217;re doing here is denying Chellas&#8217; ( C ) axiom for classical modal logics, where X is a modadic modality (e.g., box):</p>
<p>  ( C ) (Xp and Xq) only if X(p and q)</p>
<p>which corresponds to a class of non-normal modal logics that characterize non-monotonic inference. (See Horacio Arlo-Costa&#8217;s 71(1) 2002, Studia Logica). And there are a variety of reasons to be interested in non-monotonic logics, reasons that extend outside the bounds of epistemology proper.</p>
<p>One reason for chasing these things down as they run outside of philosophy proper is that often see remarkably similar problems cropping up in other domains and practitioners there, sometimes, advancing the mathematics to isolate these features at a level of abstraction that affords us more understanding of what is going on.</p>
<p>In reply to Jon&#8217;s question to evidentialists, I can imagine (without endorsing) a reply that would push the issue into the theory of assessibility. So an evidentialist might say that there is a mental action that the agent performs to &#8216;access&#8217; the assumed information upon which to evaluate the epistemic status of the belief. Do you think this has legs?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jonathan Weinberg</title>
		<link>http://certaindoubts.com/assumptions/#comment-3079</link>
		<dc:creator><![CDATA[Jonathan Weinberg]]></dc:creator>
		<pubDate>Tue, 03 Jan 2006 16:50:20 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=498#comment-3079</guid>
		<description><![CDATA[My recommendation to evidentialists would be that they not focus too much on the formation of beliefs (which will, if they become serious naturalists (as everyone should, of course!), take them into unconscious &#038; non-beliefy terrain rather quickly), but that they focus instead on the rational defense of their beliefs.

That is, if S forms a belief p partly on the basis of the (non-belief) assumption that q, then basically what S needs is to have the epistemic resources such that _if q were challenged_, S&#039;s evidence is sufficient to justify q.  But those epistemic resources need not have played any role whatsoever in the production of the belief that p.]]></description>
		<content:encoded><![CDATA[<p>My recommendation to evidentialists would be that they not focus too much on the formation of beliefs (which will, if they become serious naturalists (as everyone should, of course!), take them into unconscious &amp; non-beliefy terrain rather quickly), but that they focus instead on the rational defense of their beliefs.</p>
<p>That is, if S forms a belief p partly on the basis of the (non-belief) assumption that q, then basically what S needs is to have the epistemic resources such that _if q were challenged_, S&#8217;s evidence is sufficient to justify q.  But those epistemic resources need not have played any role whatsoever in the production of the belief that p.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/assumptions/#comment-3078</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Tue, 03 Jan 2006 15:21:20 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=498#comment-3078</guid>
		<description><![CDATA[Jonathan, this is very nice and helpful.  It raises a hard question for evidentialists, however, if Greg is right (as I think he is) that assumptions play a role in belief formation, and hence by implication in a proper account of (doxastic) justification.  One would have thought that evidentialists understand justification in terms of evidence possessed, where this latter idea is characterized in terms of the contents of belief and experience.  But if assumptions play a role as well, then it is not as easy to see what an evidentialist needs to say here.]]></description>
		<content:encoded><![CDATA[<p>Jonathan, this is very nice and helpful.  It raises a hard question for evidentialists, however, if Greg is right (as I think he is) that assumptions play a role in belief formation, and hence by implication in a proper account of (doxastic) justification.  One would have thought that evidentialists understand justification in terms of evidence possessed, where this latter idea is characterized in terms of the contents of belief and experience.  But if assumptions play a role as well, then it is not as easy to see what an evidentialist needs to say here.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jonathan Weinberg</title>
		<link>http://certaindoubts.com/assumptions/#comment-3077</link>
		<dc:creator><![CDATA[Jonathan Weinberg]]></dc:creator>
		<pubDate>Tue, 03 Jan 2006 06:42:42 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=498#comment-3077</guid>
		<description><![CDATA[This strikes me as a case where it really helps to be a _practical_ (and not merely metaphysical) naturalist about the mind -- not just adhering to some sort of naturalist ontology on the whole, but accepting that science, in this case cognitive psychology, tells us what some of the different denizens of the mental are.  In this case, there are a number of different places where that vexing representing of ~p might be located, other than as a belief.  To just name two off the top of my head: in modular cognitive systems, and in the prototypes associated (but not, I think, identified) with our concepts.

Doing so eases both the epistemologist&#039;s problem of assumptions and the behaviorist&#039;s problem.  (The former is that the contraries have to be real enough to generate chagrin; the latter, that we can still see how each contrary connects up with behavior.)

How does it help with the epistemologist&#039;s problem?  By giving us, as noted, a stock of non-belief forms of representing.  It may be hard to see how one could both believe p and believe ~p (though I would note &#038; set aside cognitive dissonance as one mechanism to do so).  But it&#039;s not hard to see how we could believe p, but have ~p somehow represented in a different system.

To answer the behaviorist&#039;s problem, we have to say what behavioral evidence there might be for such behaviorally-active-but-non-belief representings.  But fortunately, there is a wealth of such evidence.  To use Jon&#039;s original example, the prototype of THREAT that feeds into your affective systems may represent features of African Americans, and hence that unfortunate but well-documented tendency of even good-meaning white folks to lock the doors when they drive by persons of color.  The prototypes are stored away in our fast, reflex-like, primarily unconscious layers of cognition, and that&#039;s where we&#039;ll find behavioral evidence for them.  Beliefs tend to have less direct effecton such systems, but can drive conscious, deliberative activity (like assertion).]]></description>
		<content:encoded><![CDATA[<p>This strikes me as a case where it really helps to be a _practical_ (and not merely metaphysical) naturalist about the mind &#8212; not just adhering to some sort of naturalist ontology on the whole, but accepting that science, in this case cognitive psychology, tells us what some of the different denizens of the mental are.  In this case, there are a number of different places where that vexing representing of ~p might be located, other than as a belief.  To just name two off the top of my head: in modular cognitive systems, and in the prototypes associated (but not, I think, identified) with our concepts.</p>
<p>Doing so eases both the epistemologist&#8217;s problem of assumptions and the behaviorist&#8217;s problem.  (The former is that the contraries have to be real enough to generate chagrin; the latter, that we can still see how each contrary connects up with behavior.)</p>
<p>How does it help with the epistemologist&#8217;s problem?  By giving us, as noted, a stock of non-belief forms of representing.  It may be hard to see how one could both believe p and believe ~p (though I would note &amp; set aside cognitive dissonance as one mechanism to do so).  But it&#8217;s not hard to see how we could believe p, but have ~p somehow represented in a different system.</p>
<p>To answer the behaviorist&#8217;s problem, we have to say what behavioral evidence there might be for such behaviorally-active-but-non-belief representings.  But fortunately, there is a wealth of such evidence.  To use Jon&#8217;s original example, the prototype of THREAT that feeds into your affective systems may represent features of African Americans, and hence that unfortunate but well-documented tendency of even good-meaning white folks to lock the doors when they drive by persons of color.  The prototypes are stored away in our fast, reflex-like, primarily unconscious layers of cognition, and that&#8217;s where we&#8217;ll find behavioral evidence for them.  Beliefs tend to have less direct effecton such systems, but can drive conscious, deliberative activity (like assertion).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/assumptions/#comment-3076</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Mon, 02 Jan 2006 15:10:06 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=498#comment-3076</guid>
		<description><![CDATA[Mike, I didn&#039;t mean anything substantive by my description, so I don&#039;t think we disagree here.  I say beliefs are inconsistent when we can derive a contradiction from their contents; contradictory when the contents instance p and ~p.  So beliefs can be contradictory even when the person has no contradictory belief (i.e., an instance of believing p&#038;~p).]]></description>
		<content:encoded><![CDATA[<p>Mike, I didn&#8217;t mean anything substantive by my description, so I don&#8217;t think we disagree here.  I say beliefs are inconsistent when we can derive a contradiction from their contents; contradictory when the contents instance p and ~p.  So beliefs can be contradictory even when the person has no contradictory belief (i.e., an instance of believing p&amp;~p).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike</title>
		<link>http://certaindoubts.com/assumptions/#comment-3075</link>
		<dc:creator><![CDATA[Mike]]></dc:creator>
		<pubDate>Mon, 02 Jan 2006 13:39:00 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=498#comment-3075</guid>
		<description><![CDATA[Jon, I must be misunderstanding you on this.

&quot;On the second issue, the beliefs are contradictory independent of closure issues&quot;.

The contents of those beliefs are inconsistent, since
the set {p, ~p} is not satisfiable. But the beliefs certainly seem consistent since {Bp, B~p} is satisfiable (or rather is satisfiable assuming the set is closed under some sufficiently weak logic for belief).]]></description>
		<content:encoded><![CDATA[<p>Jon, I must be misunderstanding you on this.</p>
<p>&#8220;On the second issue, the beliefs are contradictory independent of closure issues&#8221;.</p>
<p>The contents of those beliefs are inconsistent, since<br />
the set {p, ~p} is not satisfiable. But the beliefs certainly seem consistent since {Bp, B~p} is satisfiable (or rather is satisfiable assuming the set is closed under some sufficiently weak logic for belief).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/assumptions/#comment-3074</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Sun, 01 Jan 2006 23:57:04 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=498#comment-3074</guid>
		<description><![CDATA[Mike, in the example using names, I&#039;m assuming that the proposition expressed is a Russellian one, and that a Millian account of names is correct.  So the content of each belief is a structured entity involving the property of being tired plus you.

On the second issue, the beliefs are contradictory independent of closure issues, though as you note, depending on what one thinks about closure for belief, contradictory contents may or may not imply the existence of contradictory beliefs.

The primary worry about contradictory beliefs requires assuming something that behaviorists will exult about:  that there is a connection between action and belief.  Needless to say, however, I don&#039;t think you have to be a behaviorist to worry here.  Functionalism of a very weak variety is strong enough to cause worries.]]></description>
		<content:encoded><![CDATA[<p>Mike, in the example using names, I&#8217;m assuming that the proposition expressed is a Russellian one, and that a Millian account of names is correct.  So the content of each belief is a structured entity involving the property of being tired plus you.</p>
<p>On the second issue, the beliefs are contradictory independent of closure issues, though as you note, depending on what one thinks about closure for belief, contradictory contents may or may not imply the existence of contradictory beliefs.</p>
<p>The primary worry about contradictory beliefs requires assuming something that behaviorists will exult about:  that there is a connection between action and belief.  Needless to say, however, I don&#8217;t think you have to be a behaviorist to worry here.  Functionalism of a very weak variety is strong enough to cause worries.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike</title>
		<link>http://certaindoubts.com/assumptions/#comment-8592</link>
		<dc:creator><![CDATA[Mike]]></dc:creator>
		<pubDate>Sun, 01 Jan 2006 23:08:35 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=498#comment-8592</guid>
		<description><![CDATA[Jon, you say,

&quot;One can have contradictory beliefs by accessing the content under two different modes of presentation (&quot;I am tired&quot;, &quot;JK is tired&quot;, etc.).&quot;

I am not sure these beliefs are contradictory (using my own case for simplicity),

1.  I believe M.A. is not tired.
2.  I believe I am tired.

Can&#039;t get a contradiction from (1) and (2) since substitutivity fails. So your beliefs are not inconsistent.

But then,

&quot;But if we fix the mode of presentation, I don&#039;t see how one can believe both p and ~p at the same time&quot;

This is much more interesting, since Bp and B~p might not (depending on your views about closure) entail B(p &#038; ~p). So these beliefs needn&#039;t entail believing anything inconsistent. It&#039;s strange since, even under the assumption that (Bp &#038; B~p) does not entail B(p &#038; ~p), there remains some sense in which you *can&#039;t* have the beliefs Bp and B~p.]]></description>
		<content:encoded><![CDATA[<p>Jon, you say,</p>
<p>&#8220;One can have contradictory beliefs by accessing the content under two different modes of presentation (&#8220;I am tired&#8221;, &#8220;JK is tired&#8221;, etc.).&#8221;</p>
<p>I am not sure these beliefs are contradictory (using my own case for simplicity),</p>
<p>1.  I believe M.A. is not tired.<br />
2.  I believe I am tired.</p>
<p>Can&#8217;t get a contradiction from (1) and (2) since substitutivity fails. So your beliefs are not inconsistent.</p>
<p>But then,</p>
<p>&#8220;But if we fix the mode of presentation, I don&#8217;t see how one can believe both p and ~p at the same time&#8221;</p>
<p>This is much more interesting, since Bp and B~p might not (depending on your views about closure) entail B(p &amp; ~p). So these beliefs needn&#8217;t entail believing anything inconsistent. It&#8217;s strange since, even under the assumption that (Bp &amp; B~p) does not entail B(p &amp; ~p), there remains some sense in which you *can&#8217;t* have the beliefs Bp and B~p.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/assumptions/#comment-3073</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Sun, 01 Jan 2006 21:06:49 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=498#comment-3073</guid>
		<description><![CDATA[It&#039;s not the irrationality of contradictory beliefs that is the issue, but rather the possibility.  One can have contradictory beliefs by accessing the content under two different modes of presentation (&quot;I am tired&quot;, &quot;JK is tired&quot;, etc.).  But if we fix the mode of presentation, I don&#039;t see how one can believe both p and ~p at the same time.  To do so, such beliefs would have to be completely severed from explanations of action, including the act of asserting what one takes to be true.

Since I think inconsistent beliefs can be justified, I don&#039;t think there is any special reason to think contradictory beliefs could be justified as well, if such were possible.  So it seems to me that the key issue is possibility itself.]]></description>
		<content:encoded><![CDATA[<p>It&#8217;s not the irrationality of contradictory beliefs that is the issue, but rather the possibility.  One can have contradictory beliefs by accessing the content under two different modes of presentation (&#8220;I am tired&#8221;, &#8220;JK is tired&#8221;, etc.).  But if we fix the mode of presentation, I don&#8217;t see how one can believe both p and ~p at the same time.  To do so, such beliefs would have to be completely severed from explanations of action, including the act of asserting what one takes to be true.</p>
<p>Since I think inconsistent beliefs can be justified, I don&#8217;t think there is any special reason to think contradictory beliefs could be justified as well, if such were possible.  So it seems to me that the key issue is possibility itself.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/assumptions/#comment-3072</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Sat, 31 Dec 2005 23:43:48 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=498#comment-3072</guid>
		<description><![CDATA[Hi Jon; Happy New Year! There seems to be a trade-off in setting up this problem that might be worth probing. It seems that the introduction of a collection of distinct items (beliefs, dispositions to believe, or dispositions to have some other mental state) is motivated to get around the apparent problem of ascribing (A): both the belief that &lt;i&gt;p&lt;/i&gt; and belief that not-&lt;i&gt;p&lt;/i&gt;.

But I wonder about this. First, by slicing up belief into thinner concepts from the start, we might miss some of common features of general cases of question and answer situations. Second, one worry that might motivate an aversion to (A) is that it licenses irrationality. But this is a harder case to make than one might otherwise suppose, and turns on questionable assumptions about the fit between logic and rational belief. For instance, I think the algebriac properties of combining beliefs are not isomorphic to the properties of boolean combination of propositions.

You might be able to get to the same point by slicing up the domain and then explaining it all at the level of a boolean algebra. Similarly, you can read the bit code of this sentence, if you prefer. But maybe some information that is important to us is lost by doing it this way, never mind the task of keeping straight what is going on.

The thought is this: After working with a toy-model with very crude elements (beliefs, same, in a simple, monadic modal language) we might &lt;i&gt;then&lt;/i&gt; be in a position to introduce these thinner notions in a gradual and (somewhat) controlled way. Our intuitions about what is needed would be guided by the framework we are working with and particular observations about the failure of the framework to fit the data. The suggestion then is that sticking to a framework that avoids (A), from the start, might not be the best first step.]]></description>
		<content:encoded><![CDATA[<p>Hi Jon; Happy New Year! There seems to be a trade-off in setting up this problem that might be worth probing. It seems that the introduction of a collection of distinct items (beliefs, dispositions to believe, or dispositions to have some other mental state) is motivated to get around the apparent problem of ascribing (A): both the belief that <i>p</i> and belief that not-<i>p</i>.</p>
<p>But I wonder about this. First, by slicing up belief into thinner concepts from the start, we might miss some of common features of general cases of question and answer situations. Second, one worry that might motivate an aversion to (A) is that it licenses irrationality. But this is a harder case to make than one might otherwise suppose, and turns on questionable assumptions about the fit between logic and rational belief. For instance, I think the algebriac properties of combining beliefs are not isomorphic to the properties of boolean combination of propositions.</p>
<p>You might be able to get to the same point by slicing up the domain and then explaining it all at the level of a boolean algebra. Similarly, you can read the bit code of this sentence, if you prefer. But maybe some information that is important to us is lost by doing it this way, never mind the task of keeping straight what is going on.</p>
<p>The thought is this: After working with a toy-model with very crude elements (beliefs, same, in a simple, monadic modal language) we might <i>then</i> be in a position to introduce these thinner notions in a gradual and (somewhat) controlled way. Our intuitions about what is needed would be guided by the framework we are working with and particular observations about the failure of the framework to fit the data. The suggestion then is that sticking to a framework that avoids (A), from the start, might not be the best first step.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
