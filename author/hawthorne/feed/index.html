<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>hawthorne &#8211; </title>
	<atom:link href="http://certaindoubts.com/author/hawthorne/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 01:35:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>How useful is a logic for Defeasible / Nonmonotonic Conditionals for Epistemology?</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/</link>
		<comments>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comments</comments>
		<pubDate>Tue, 15 Feb 2005 00:54:51 +0000</pubDate>
		<dc:creator><![CDATA[hawthorne]]></dc:creator>
				<category><![CDATA[general]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259</guid>
		<description><![CDATA[The posting &#8220;Jim Hawthorne on the Logic of Nonmonotonic Conditionals&#8221; took a rather technical turn (which was my fault&#8211;sorry!!!). This posting is addressed to readers of the blog more generally. In it I will describe much about defeasible conditionals that &#8230; <a class="more-link" href="http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>The posting &#8220;Jim Hawthorne on the Logic of Nonmonotonic Conditionals&#8221; took a rather technical turn (which was my fault&#8211;sorry!!!). This posting is addressed to readers of the blog more generally. In it I will describe much about defeasible conditionals that experts already know, though they may disagree with the interpretative spin I&#8217;ll give. This posting is intended to provide one take (my take) on what certain kinds of defeasible conditionals represent that may be of interest to epistemologists. I&#8217;d be interested in whatever anyone thinks of this.</p>
<p>With regard to the logic of defeasible conditionals, I think that the most central issues for epistemologists are:</p>
<p>1. What &#8220;exactly&#8221; are defeasible or nonmonotonic conditionals such as those in system R (the rational consequence relations) supposed to represent?  and how precisely are they supposed to be relevant to knowledge or belief?   and</p>
<p>2. How does each particular semantic basis or model theory (e.g. Popper functions, Popper measures (which I&#8217;ve been calling &#8220;vF functions&#8221;), preferential models, etc.) <i>illuminate</i> whatever it is that these conditionals are supposed to represent (in a way that is useful to epistemology)?  Skip the technicalities &#8212; what is it supposed to represent, intuitively? And does it succeed?</p>
<p>I&#8217;ll take a stab at part of this. I&#8217;ll focus on the R conditionals.</p>
<p><span id="more-259"></span></p>
<p>Consider a conditional &#8211;> that satisfies the rules of R. Each &#8220;conditional statement&#8221; of form B&#8211;>A,  may be interpreted as saying, &#8220;among the possible worlds where B is true, A is almost certainly true&#8221;. (In this posting the capital letters all represent statements.) Here the &#8220;almost certainly&#8221; may be understood in the mathematicians  sense &#8212; e.g. among the worlds where B is true, those that make ~A true have &#8220;measure 0&#8221;. There may be such ~A worlds, but they are so unlikely that we need not concern ourselves with them at all, unless we learn something else, C, that makes them loom much larger. We may indeed learn something new, C, that brings the ~A worlds to be worth considering. That is, although B&#8211;>A, it may be that (B&#038;C)-/->A (i.e., (B&#038;C) does not make A almost certain), and it may even happen that (B&#038;C)&#8211;>~A. That is, the B&#038;C worlds, which is a subset of the B worlds, may not give A measure 1, and may even give ~A measure 1. But, as the rule called &#8220;Rational Monotony&#8221; says, when B&#8211;>A holds, learning that C is true can interrupt that support (i.e. (B&#038;C)-/->A) <i>only when</i> C itself has measure 0 among the worlds where B is true &#8212; i.e. only when B&#8211;>~C. And this process can iterate. That is, suppose that (B&#038;C)&#8211;> ~A. Then learning anything new, D, will continue to make ~A almost certain, unless (B&#038;C)&#8211;>~D, in which case we might have (B&#038;C&#038;D)&#8211;>A again (or we might still have (B&#038;C&#038;D)&#8211;>~A, or it might be that (B&#038;C&#038;D)-/->A and (B&#038;C&#038;D)-/->~A &#8212; the logic itself doesn&#8217;t force any one of these on us &#8212; it only requires that each given conditional &#8211;> in R does one of these three things).</p>
<p>So, on this reading, &#8220;B&#8211;>A&#8221; says that that among the worlds in which B is true, A is true in almost all (measure 1) of them. And, in general, more information C will leave this strong support of A by B intact, unless C itself is almost certainly false in the B worlds, in which case learning C can &#8220;re-invigorate&#8221; a subset of the possibilities that were considered &#8220;almost certainly impossible&#8221; on the basis of B alone.</p>
<p>However, there may be statements A that, according to a particular conditional, &#8211;>, are considered &#8220;absolutely certain&#8221; among the B worlds (not just &#8220;almost certain&#8221;), and that cannot be undermined, no matter what is learned. So, even if we &#8220;learn&#8221; ~A, statement A is still considered certain on B. That is, B&#8211;>A, and for every possible C, (B&#038;C)&#8211;>A, and even (B&#038;~A)&#8211;>A. This last conditional, (B&#038;~A)&#8211;>A, is the mark of B making A absolutely certain. The idea is that among the B worlds, absolutely none of them make ~A true, so (B&#038;~A) is a &#8220;conceptual contradiction&#8221; &#8212; no worlds make (B&#038;~A) true. So, A is true among &#8220;all of the worlds&#8221; that make (B&#038;~A) true. Thus, whereas &#8216;B&#8211;>A&#8217; says that B makes A &#8220;almost certain&#8221;, &#8216;(B&#038;~A)&#8211;>A&#8217; makes the stronger claim that B makes A &#8220;absolutely certain&#8221;.</p>
<p>What a conditional statement B&#8211;>A in R says about belief is this: if the agent is &#8220;certain of B&#8221;, then she should be &#8220;almost certain of A&#8221;. So suppose a particular conditional &#8211;> in R represents a particular agent&#8217;s &#8220;belief supporting conditional&#8221;. And suppose that she is certain (for now) that C, and suppose that C&#8211;>B holds for her. Should she then be &#8220;almost certain that B&#8221;? Yes, provided that there is no additional claim D of which she is certain and such that C&#8211;>~D. So, C need not consist of &#8220;everything she is certain of&#8221;. C suffices to support &#8220;almost certainty&#8221; in B provided that she is not also certain of some claim D that C implies (according to &#8211;>) is almost certainly false.</p>
<p>Notice, we must keep claims like C that the agent is &#8220;certain of&#8221; distinct from claims like B that the agent is (only) &#8220;almost certain of&#8221;. That is, after B is inferred on the basis of C, one cannot then just throw B into the same pot with C. If one did so, then one would lose track of what to retract when one learns some new information D that (together with C) should undermine B.</p>
<p>Thus, the way to think about these conditionals is this. One needs to keep two &#8220;lists of statements&#8221;, which I call &#8220;the <i>given</i> list&#8221; and &#8220;the <i>inferred</i> list&#8221;. The &#8220;given list&#8221; is the &#8220;certain list&#8221;, the list of claims on which the agent is certain. The &#8220;inferred list&#8221; for conditionals in R is the &#8220;almost certain list&#8221;. The given list contains everything the agent &#8220;believes with certainty&#8221; (at a given time, anyway &#8212; she may later change the given list, but that is not part of the defeasible logic that the conditionals &#8211;> are about). The inferred list contains every statement B such that C&#8211;>B holds, provided that C is presently on the given list and provided that there is no claim D presently on the given list such that C&#8211;>~D. (If there is such a D, then B can only be on the inferred list if (C&#038;D)&#8211;>B.) That is, B&#8217;s support from members of the given list must be undefeated. The inferred list represents the claims of which the agent is &#8220;almost certain&#8221;, given her certainty in whats on the given list. (Notice that C&#8211;>C always holds &#8212; so the inferred list contains everything on the given list as well &#8212; if C is &#8220;certain&#8221;, then it is &#8220;almost certain&#8221;, too.)</p>
<p>Notice what this does to transitivity in belief updating. In R we don&#8217;t in general have that &#8220;if C&#8211;>B and B&#8211;>A, then C&#8211;>A&#8221;. What we have instead is this: if C&#8211;>B and B&#8211;>A, then C&#8211;>A, provided that B-/-> ~C. That is, if C is on the given list (i.e., the &#8220;certain&#8221; list), and if by virtue of that, B is on the inferred list, then any statement A that B would support (were B to be placed on the given list) can be placed on the inferred list as well, <i>provided that</i> B itself doesn&#8217;t imply that C is almost certainly false. This kind of transitivity permits the inferred list to be updated with whatever its members defeasibly imply, provided those member of the inferred list don&#8217;t &#8220;bit the hand&#8221; of the member of the given list that put them there. Notice, too, that if B&#8211;>~C does hold, then we can still update the inferred list, but only based on (C&#038;B) &#8212; because if the given list has C and the inferred list has B (because of inference from C), then the inferred list has both B and C, and so has (B&#038;C). So although B on its own may give measure 0 to C, we are now reasoning &#8220;within the set of worlds&#8221; (B&#038;C) (that had measure 0 on B alone).</p>
<p>One more point. What about cases where C supports neither B nor ~B &#8212; i.e. where C-/->B and C-/-> ~B. That is, neither B nor ~B has measure 0 or 1 among C worlds &#8212; that is, when the agent is certain of C, she is neither &#8220;almost certain&#8221; of B nor is she &#8220;almost certain&#8221; of ~B. Does the agent have to simply leave it at that? It is rather natural for an agent to take C to support some such statements B more strongly than other such statements. If we model the agent as having &#8220;belief strengths&#8221; on such statements, scaled between 0 and 1, and if these belief strengths follow some very simple, obvious rules that are compatible with how the logic of &#8220;almost certainty&#8221;, R, works, we get the Popper functions!!!</p>
<p>For a Popper function P, P[A|B] = r may be read as &#8220;among the worlds where B is true, A is true in proportion r of them (according the way that P measures worlds). Thus, if a particular Popper function P represents an agents belief strengths, then when she is certain of B (and B represents everything she is certain of that is relevant to A), her belief strength for A should be r. But Popper functions also have R embedded in them. That is, although P[~C|B] may be 1, P[A | B&#038;C] is still perfectly well defined. That is, although among B worlds C has measure 0, if C were learned, the (B&#038;C) worlds may still provide a perfectly coherent measure of the plausibility of A. Indeed, each conditional &#8211;> in R is the probability 1 part of a Popper function, and the probability 1 part of each Popper function is a conditional in R. That is, if we define a conditional &#8211;} such that B&#8211;} A iff P[A|B]= 1, then &#8211;} must satisfy the rules of R. And, conversely, each conditional &#8211;> that satisfies the rules of R can be expanded into a Popper function P by assigning P[A|B]= 1 whenever B&#8211;>A and assigning some number less that 1 (but greater than or equal to 0) to all other pairs of sentence (in accord with certain restrictions). For any given &#8211;> satisfying R, there is always a way to do this (and generally many different ways) &#8212; different ways to expand the conditionals in R to incorporate &#8220;belief strengths&#8221;.</p>
<p>This naturally gives rise to the question, are there other interesting conditionals for which C&#8211;>B represents, for example, &#8220;among worlds where C is true, B is true in at least proportion r of them&#8221;, or where the conditional may be read as &#8220;when the agent is certain that C, and C is the strongest claim of which she is certain that is relevant to A, then her degree of confidence in A is (or should be) at least r&#8221;? The systems Q in the posting that started this discussion (i.e. &#8220;Jim Hawthorne on the Logic of Nonmonotonic Conditionals&#8221;) are an attempt to investigate the qualitative rules for such a logic of &#8220;uncertain&#8221; (not even &#8220;almost certain&#8221;) belief at various levels r.</p>
<p>So, for those of you who know about such logics, what is your reading of these logics? Does it differ from mine?</p>
<p>For the epistemologists more generally: Does such a <i>logic</i> for Defeasible / Nonmonotonic Conditionals seem helpful/useful to Epistemology? Your thoughts about how! &#8212; or about why not!</p>
<p>Your comments and reactions, please!</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/feed/</wfw:commentRss>
		<slash:comments>33</slash:comments>
		</item>
	</channel>
</rss>
