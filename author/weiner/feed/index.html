<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>weiner &#8211; </title>
	<atom:link href="http://certaindoubts.com/author/weiner/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 01:35:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>Is the Problem of Grue the Problem of Old Evidence?</title>
		<link>http://certaindoubts.com/is-the-problem-of-grue-the-problem-of-old-evidence/</link>
		<comments>http://certaindoubts.com/is-the-problem-of-grue-the-problem-of-old-evidence/#comments</comments>
		<pubDate>Thu, 22 Feb 2007 13:12:01 +0000</pubDate>
		<dc:creator><![CDATA[weiner]]></dc:creator>
				<category><![CDATA[confirmation theory]]></category>
		<category><![CDATA[epistemic paradoxes]]></category>
		<category><![CDATA[formal epistemology]]></category>
		<category><![CDATA[general]]></category>
		<category><![CDATA[justification]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=662</guid>
		<description><![CDATA[via Jon&#8217;s post below and Gillian Russell at TAR, Greg Restall summarizes and links to Branden Fitelson&#8217;s very interesting talk (pdf of Branden&#8217;s slides) at the Banff Mathematical Methods in Philosophy workshop. I&#8217;ve only seen the slides, but I have &#8230; <a class="more-link" href="http://certaindoubts.com/is-the-problem-of-grue-the-problem-of-old-evidence/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>via <a href="http://fleetwood.baylor.edu/certain_doubts/?p=661">Jon&#8217;s post below</a> and <a href="http://tar.weatherson.org/2007/02/19/the-lark-of-a-definite-precisely-formulated-formal-system/">Gillian Russell at TAR</a>, <a href="http://consequently.org/news/2007/02/20/in_banff_branden_fitelson_on_formal_epistemology/">Greg Restall</a> summarizes and links to Branden Fitelson&#8217;s very interesting talk (<a href="http://fitelson.org/banff_handout.pdf">pdf of Branden&#8217;s slides</a>) at the Banff Mathematical Methods in Philosophy workshop. I&#8217;ve only seen the slides, but I have some questions about Branden&#8217;s argument; I hope Branden or some Banffer will be able to say more about how it works.<br />
<span id="more-662"></span><br />
Branden starts by discussing the new developments in formal epistemology that Jon mentioned below. But his main argument is an analogy between the problem of &#8216;grue&#8217; and, on the one hand, the relevantist critique of classical logic, and on the other, the problem of old evidence.</p>
<p>Branden quickly summarizes the relevantist critique thus:</p>
<blockquote><p>(1) On classical logic, if a set X of beliefs is inconsistent, then any p is a consequence of X.<br />
(2) If your total set of beliefs entails p (and you know this), then you are justified in believing p.<br />
(3) But even if you know that your beliefs are inconsistent, there are some things you aren&#8217;t justified in believing.<br />
Conclusion: We should reject classical logic, on which an inconsistent set entails anything.</p></blockquote>
<p>Branden points out that Harman acknowledges the inconsistency but rejects the bridge principle (2) linking entailment and inference. We can preserve the classical entailment relation by denying that we are entitled to infer whatever our beliefs entailed. When our beliefs are inconsistent the proper response is often to reject one of our beliefs rather than to infer all their consequences.</p>
<p>Branden argues that the grue argument against a Carnapian conception of confirmation uses the Requirement of Total Evidence as a similar bridge principle. Carnap sees confirmation as an <i>a priori</i> logical relation between sentences. But this relation alone doesn&#8217;t tell us how to apply itself in forming new beliefs. That requires the bridge principle of the Requirement of Total Evidence:</p>
<blockquote><p>(RTE) E evidentially supports H for S in C iff E confirms H relative to K, where K is S&#8217;s total evidence in C. </p></blockquote>
<p>(E confirms H relative to K means Pr(H|E&#038;K) &gt; Pr(H|K), for a suitable probability function Pr; Carnap thought &#8216;suitable&#8217; meant &#8216;logical&#8217;, but Branden points out that the grue argument he canvasses doesn&#8217;t depend on which probability function is used.) The grue argument&mdash;if I&#8217;m reading Branden aright&mdash;works because we admit &#8216;the emerald is observed before time t&#8217; into the total background evidence, and once we do this our new evidence confirms &#8220;This emerald is green&#8221; and thus &#8220;All emeralds are green&#8221; just in case it confirms &#8220;This emerald is grue&#8221; and thus &#8220;All emeralds are grue.&#8221; [See step (iii) in the lower right hand slide on Branden&#8217;s p. 3.]</p>
<p>But, as Branden points out, (RTE) has to be rejected anyway because of the Problem of Old Evidence, that hypotheses can be evidentially supported by evidence that is already in K. Bayesians and Carnapians are much better off defining evidential support in terms of confirmation relative to an empty set of background knowledge.</p>
<p>Branden concludes, &#8220;So, many Bayesians <i>already</i> reject (RTE). They shouldn&#8217;t be <i>too</i> worried about &#8220;Grue&#8221;. It&#8217;s a new twist on &#8220;Old Evidence&#8221;.</p>
<p>Here&#8217;s my main question: If &#8220;grue&#8221; is just a new twist on old evidence, then presumably the solution to old evidence is meant to work for grue. That solution is to replace (RTE) with the idea that evidential support depends on confirmation relative to an empty background. But I don&#8217;t see how that helps with the grue problem.</p>
<p>Consider the choice between two hypotheses, that all emeralds are green and that all emeralds are grue with respect to Jan. 1, 2150. Against an empty background, does the observation of a green emerald now support one hypothesis more than the other? I don&#8217;t see how; and answering the question why it should just is solving the problem of grue, it seems to me. Similarly, we&#8217;d need to solve the problem of grue to  explain why, on an empty background, we might assign a higher probability to &#8220;All emeralds are green&#8221; than to &#8220;All emeralds are grue<sub>2150</sub>.&#8221; If we can&#8217;t do either of those things, the move from (RTE) to confirmation against an empty background just doesn&#8217;t seem to give us any progress in explaining why the observation of a green emerald now supports &#8220;All emeralds are green&#8221; rather than &#8220;All emeralds are grue.&#8221; Any thoughts?</p>
<p>[I have another question about a more minor point of Branden&#8217;s presentation. In the lower left slide on p. 3, he presents a counterexample to the hypothesis that the examination of a green emerald before t confirms &#8220;All emeralds are green&#8221; iff it confirms &#8220;All emeralds are grue.&#8221; This is based on I.J. Gold&#8217;s counterexample to the idea that a black raven always confirms &#8220;All ravens are black&#8221;; in Branden&#8217;s example are background knowledge is that either there are 1000 green emeralds 900 of which have been examined before t, no non-green emeralds, and 1 million other things, or there are 100 green emeralds all of which have been examined before time t, 900 non-green emeralds that have not been examined before time t, and 1 million other things. Then, if you randomly select an object and it turns out to be an examined green emerald, against this background knowledge this confirms that all emeralds are green but not that all emeralds are grue. My question is: Can we set up the background knowledge this way? Shouldn&#8217;t the observations that have already been carried out be part of the background knowledge? This problem, however, could be easily taken care of by changing the second hypothesis so that there are nine times as many of each kind of emerald, and in both cases we&#8217;ve examined 900 green emeralds; we might also have to add an unexamined green emerald to the second case, because on my view we should see the next examined object as drawn from the ones that haven&#8217;t been examined already.]</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/is-the-problem-of-grue-the-problem-of-old-evidence/feed/</wfw:commentRss>
		<slash:comments>19</slash:comments>
		</item>
		<item>
		<title>The (Mostly Harmless) Inconsistency of Knowledge Attributions</title>
		<link>http://certaindoubts.com/the-mostly-harmless-inconsistency-of-knowledge-attributions/</link>
		<comments>http://certaindoubts.com/the-mostly-harmless-inconsistency-of-knowledge-attributions/#comments</comments>
		<pubDate>Fri, 12 May 2006 22:09:20 +0000</pubDate>
		<dc:creator><![CDATA[weiner]]></dc:creator>
				<category><![CDATA[contextualism]]></category>
		<category><![CDATA[epistemic paradoxes]]></category>
		<category><![CDATA[knowledge]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=587</guid>
		<description><![CDATA[I&#8217;ve posted a long paper, &#8220;The (Mostly Harmless) Inconsistency of Knowledge Attributions.&#8221; It argues for a fourth alternative to contextualism, invariantism, and relativism: that knowledge-talk is governed by inconsistent inference-principles, but that these principles rarely lead us into contradiction. In &#8230; <a class="more-link" href="http://certaindoubts.com/the-mostly-harmless-inconsistency-of-knowledge-attributions/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I&#8217;ve posted a long <a href="http://mattweiner.net/papers/inconsistency%205-06.pdf">paper</a>,  &#8220;The (Mostly Harmless) Inconsistency of Knowledge Attributions.&#8221; It argues for a fourth alternative to contextualism, invariantism, and relativism: that knowledge-talk is governed by inconsistent inference-principles, but that these principles rarely lead us into contradiction. In fact, we can almost always assign an effective content to knowledge attributions even if their absolute content is self-contradictory. (The &#8220;effective content&#8221;/&#8221;absolute content&#8221; distinction is borrowed from Anil Gupta&#8217;s work on inconsistent discourses, which I draw on heavily.) So there is no reason to abandon knowledge-talk, even if it is inconsistent.</p>
<p>Pretty much the first thing I did after putting the paper up was to surf on over here and see <a href="http://fleetwood.baylor.edu/certain_doubts/?p=586">Keith&#8217;s post</a>, which seems quite relevant, since my paper compares and contrasts the inconsistency view with a version of contextualism on which an attribution of standards is always implicit (if often unvoiced).</p>
<p>Anyway, comments are of course welcome.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/the-mostly-harmless-inconsistency-of-knowledge-attributions/feed/</wfw:commentRss>
		<slash:comments>11</slash:comments>
		</item>
		<item>
		<title>Another Surprise Examination</title>
		<link>http://certaindoubts.com/another-surpise-examination/</link>
		<comments>http://certaindoubts.com/another-surpise-examination/#comments</comments>
		<pubDate>Sat, 21 May 2005 18:09:24 +0000</pubDate>
		<dc:creator><![CDATA[weiner]]></dc:creator>
				<category><![CDATA[epistemic paradoxes]]></category>
		<category><![CDATA[knowledge]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=335</guid>
		<description><![CDATA[I&#8217;d like to see what you think about one (and a half) versions of the surprise examination paradox. I&#8217;m not actually sure this case is paradoxical; it&#8217;s a variant of one of the variants Williamson considers in Knowledge and Its &#8230; <a class="more-link" href="http://certaindoubts.com/another-surpise-examination/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I&#8217;d like to see what you think about one (and a half) versions of the surprise examination paradox.  I&#8217;m not actually sure this case is paradoxical; it&#8217;s a variant of one of the variants Williamson considers in <i>Knowledge and Its Limits</i>.</p>
<p>It goes like this:</p>
<p>Mr. Chips is teaching a class that meets Monday through Friday for the whole semester (which is, let&#8217;s say, ten weeks long).  On the first day of class, he announces, &#8220;There will be a test one day during the semester; I&#8217;ve scheduled it already, but I won&#8217;t tell you when it is yet.&#8221;</p>
<p>On the second day of class, he announces, &#8220;About that test: It&#8217;s not on the last day; and if it is on a certain day, you can&#8217;t come to know now that it&#8217;s on the next day&#8211;<i>unless</i> yesterday you already knew that it wasn&#8217;t on the next day.  And when I say &#8216;next day&#8217;, I&#8217;m counting weekends.&#8221;</p>
<p>Mr. Chips is extraordinarily reliable, such that it would be reasonable to take any ordinary assertion of his as conferring knowledge.  <span id="more-335"></span></p>
<p>The students reason as follows:</p>
<p>Yesterday, we knew only that the exam would be on some weekday.</p>
<p>Today, we know that the exam won&#8217;t be on the last Friday, because Mr. Chips told us so.</p>
<p>The exam can&#8217;t be on the last Thursday, either.  Because if it were on the last Thursday, we wouldn&#8217;t have come to know that the exam wasn&#8217;t on the next day.  But we have come to know that the exam isn&#8217;t on the next day (the last Friday); and we didn&#8217;t know that yesterday.</p>
<p>Nor can the exam be on the last Wednesday.  Because we have come to know (in the previous paragraph) that the exam isn&#8217;t on the last Thursday, we didn&#8217;t know that yesterday, and according to what Mr. Chips said we couldn&#8217;t have come to know that if the exam was on the last Wednesday.</p>
<p>Similary, the exam can&#8217;t be on the last Monday or Tuesday.</p>
<p>But the exam <i>might</i> be on the next-to-last Friday.  Because we <i>already</i> knew yesterday that the exam wouldn&#8217;t be on the next day, since class doesn&#8217;t meet Saturday.  So what Mr. Chips said doesn&#8217;t rule out that the exam isn&#8217;t on the last Friday, or any earlier day.</p>
<p>So we know that the exam doesn&#8217;t take place in the last week, but it might take place any other time.</p>
<p><b>My questions</b>:  Suppose the exam is in fact scheduled for the next-to-last Wednesday.  Do the students come to know that the exam isn&#8217;t any day during the last week?</p>
<p>Suppose the exam is in fact scheduled for the last Wednesday.  Do the students have the right to be annoyed at Mr. Chips?  (They&#8217;d have the right to be annoyed at him if he told them a falsehood; but that might not be the only possible grounds for annoyance.  I&#8217;m deliberately leaving this vague.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/another-surpise-examination/feed/</wfw:commentRss>
		<slash:comments>12</slash:comments>
		</item>
		<item>
		<title>Gettier Cases and Internalism</title>
		<link>http://certaindoubts.com/gettier-cases-and-internalism/</link>
		<comments>http://certaindoubts.com/gettier-cases-and-internalism/#comments</comments>
		<pubDate>Thu, 14 Apr 2005 16:21:33 +0000</pubDate>
		<dc:creator><![CDATA[weiner]]></dc:creator>
				<category><![CDATA[general]]></category>
		<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[knowledge]]></category>
		<category><![CDATA[major figures]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=306</guid>
		<description><![CDATA[Brian Weatherson had a couple of posts critical of Williamson last week at his blog. While I&#8217;m sympathetic to what I think Brian&#8217;s general point is, I&#8217;m not sure I agree with the claims in this post. The dispute is &#8230; <a class="more-link" href="http://certaindoubts.com/gettier-cases-and-internalism/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Brian Weatherson had a couple of posts critical of Williamson last week at <a href="http://tar.weatherson.net">his blog</a>.  While I&#8217;m sympathetic to what I think Brian&#8217;s general point is, I&#8217;m not sure I agree with the claims in <a href="http://tar.weatherson.net/archives/004302.html">this post</a>.  The dispute is a question more of what&#8217;s accepted than what&#8217;s right, so I&#8217;d like to canvas your opinions on the question.</p>
<p>Brian notes that Williamson argues that Gettier refuted the justified true belief analysis of knowledge, and that he also claims that &#8220;a flat-out belief is fully justified if and only if it constitutes knowledge.&#8221;  But if the second is true, justified true belief is knowledge (and vice versa).  Brian continues:</p>
<blockquote><p>From the article it looks like the way to resolve the apparent contradiction is that Williamson thinks that the Gettier cases only work if we interpret ‘justified’ as ‘justified by the best version of internalist epistemology’. He doesn’t think that there are counterexamples to an <em>externalist</em> version of JTB. I don’t think this is particularly plausible. <strong>The intuitions supporting Gettier cases don’t turn on whether we’re internalists or externalists about justification</strong>.</p></blockquote>
<p>I ask: Do you agree with the last sentence?  I don&#8217;t, because of these historical points:</p>
<p>(1) Gettier&#8217;s own cases were, I take it, directed at internalist versions of JTB&#8211;is this generally accepted?<br />
(2) Gettier cases have been used to support externalist versions of JTB; for instance, as I read Goldman, he uses the Ginet fake barn cases to support reliabilist JTB (the theory of knowledge he puts forth in &#8220;Discrimination and Perceptual Knowledge&#8221; is a JTB theory on the theory of justification he puts forth in &#8220;What is Justified Belief?&#8221;&#8211;if I&#8217;m remembering correctly.)</p>
<p>Some  externalist versions of JTB are vulnerable to Gettier counterexamples, but it&#8217;s not clear to me that every externalist version of JTB is vulnerable.  But I&#8217;m curious if others share my sense that Gettier cases are particularly suited to internalist theories.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/gettier-cases-and-internalism/feed/</wfw:commentRss>
		<slash:comments>14</slash:comments>
		</item>
		<item>
		<title>What Defeats Testimony?</title>
		<link>http://certaindoubts.com/what-defeats-testimony/</link>
		<comments>http://certaindoubts.com/what-defeats-testimony/#comments</comments>
		<pubDate>Tue, 29 Mar 2005 22:14:43 +0000</pubDate>
		<dc:creator><![CDATA[weiner]]></dc:creator>
				<category><![CDATA[justification]]></category>
		<category><![CDATA[testimony and social epistemology]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=285</guid>
		<description><![CDATA[In the previous post Jon writes: I’m thinking of the following kinds of cases: empirical disputes, political disputes, moral disputes, etc. There are two, er, bizarre views here: the first is that unanimity of testimony is required for rational acceptance &#8230; <a class="more-link" href="http://certaindoubts.com/what-defeats-testimony/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>In the previous post Jon writes:</p>
<blockquote><p>I’m thinking of the following kinds of cases: empirical disputes, political disputes, moral disputes, etc. There are two, er, bizarre views here: the first is that unanimity of testimony is required for rational acceptance of the content of the testimony, and the other is the position&#8230; that no amount of disagreement matters.</p>
<p>How about this viewpoint? Testimony creates a presumption in its favor that requires defeating information to block rational acceptance, and the defeating information must itself be something more than that there is contrary testimony. What else? I can’t say, but I can list some things: some sketch of an explanation of why the testifier is mistaken or unreliable; the existence of contrary testimony plus a claim to the effect that there are no rational grounds on which to prefer one piece of testimony to another; etc. Central to the position is that testimony is a generative source of justification (or rationality or (non-Plantingian) warrant). Many here have worked on testimony much more than I, so I ask: does this position withstand scrutiny (or better: is there is precisified version of it that withstands scrutiny)?</p></blockquote>
<p>My view is that a precisified version will withstand scrutiny, but that we need to distinguish a whole bunch of distinctions first.  The question seems to me very sensitive to what exactly we mean by justification and rational acceptance.  Maybe the best way to explain is to start with the Thesis</p>
<blockquote><p>(T1) Testimony creates a presumption in its favor that requires defeating information to block rational acceptance, and the defeating information must itself be something more than that there is contrary testimony</p></blockquote>
<p>and then precisify in stages.<span id="more-285"></span></p>
<p>First stage: What do we mean by &#8216;rational acceptance&#8217;?  If we mean that it is rational for the hearer to act on the assumption that what she is told is true, then I don&#8217;t think T1 can hold, because there will be cases in which it isn&#8217;t rational to act on the basis of unsupported testimony.  Consider Fantl and McGrath&#8217;s example in their Phil Review paper: If it is absolutely vital that you make it to Foxboro soon, the unsupported testimony of a stranger won&#8217;t be enough to make it rational to act on the assumption that this train stops in Foxboro; you should double-check.</p>
<p>But that doesn&#8217;t mean that the stranger&#8217;s unsupported testimony is epistemically worthless; it just doesn&#8217;t have enough worth to make acceptance rational given the high stakes involved.  So in this case (perhaps) the testimony provides <em>some</em> evidential support. First precisification: talk about evidential support rather than &#8216;rational acceptance:</p>
<blockquote><p>(T2) Testimony that p provides some evidential support for p unless there is some defeating information, and the defeating information must itself be something more than that there is contrary testimony</p></blockquote>
<p>[What I&#8217;m invoking here is a bit like the distinction between pro tanto and on balance justification that Peter Graham cites in his paper <a href="http://www.philosophy.ucr.edu/people/graham/Liberal_Fundamentalism.pdf">Liberal Fundamentalism and Its Rivals</a>, forthcoming in the Lackey and Sosa volume on the Epistemology of Testimony.  And maybe it will console Jon a bit about the pragmatic encroachment on epistemology&#8211;even if pragmatics encroaches on rational acceptance, evidential support might remain free of pragmatic encroachment.]</p>
<p>The second question is what we mean by evidential support.  If evidential support is viewed externalistically, then (T2) will fail.  Take a view on which whether something provides evidential support is a matter of whether it brings the believer closer to knowledge (with lots of qualifications about Gettier cases, true belief, etc.)  On this view the testimony of a stranger will not provide evidential support if the stranger happens to be a habitual liar, or incompetent about the subject matter on which he is testifying, even if he was right in this case.  The testimony does not bring us closer to knowledge.  On such a view perhaps testimony at best passes a warrant along from speaker to hearer&#8211;though the hearer might be blameless for believing the speaker, if the speaker had no evidential support for the testimony the hearer doesn&#8217;t have any either.</p>
<p>But we can view evidential support internalistically.  Then the question is, given the fact that I have just been told that p (and whatever other information I may have on the subject), what degree of credence should I give to p?  Here it is plausible that testimony from someone who is in fact incompetent or a chronic liar still provides evidential support, so long as you don&#8217;t know of your informant&#8217;s flaws.  So precisification 2 is to specify that we&#8217;re taking things internalistically:</p>
<blockquote><p>(T2) Testimony that p provides some evidential support for p (viewed internalistically) unless there is some defeating information, and the defeating information must itself be something more than that there is contrary testimony</p></blockquote>
<p>Now the question is what kind of information can defeat the testimony?  The fact that there is <em>some</em> contrary testimony won&#8217;t in general defeat the testimony, or all testimony will be defeated.  On the other hand, two equal opposing testimonies must defeat each other if there are no grounds for breaking the symmetry between them.  In at least one <a href="http://fleetwood.baylor.edu/certain_doubts/index.php?p=284#comment-2347">comment</a> below Jon suggested that one difference might be that one piece of testimony has been received and the other not.  That is, if I&#8217;ve been told that p (and have no reason to doubt this testimony) and know that someone else is saying that not-p but haven&#8217;t heard it myself, in general I&#8217;ll have evidential support for p.  As I read Jon, this is because I haven&#8217;t been able to monitor the testimony that not-p to see if <em>it</em> betrays any signs of untrustworthiness.</p>
<p>I think that there will be cases in which this won&#8217;t hold.  Take this case:</p>
<blockquote><p>JUROR.  I am a juror at a trial concerning some arcane technical issue on which I have no expertise.  The plaintiff calls an expert witness who testifies that p.  Though I cannot make head or tail of the witness&#8217;s testimony, the witness seems as calm and credible as I would expect an expert witness to be.  However, I know that the next day the defendant will call a different expert witness, who will testify that not-p.</p></blockquote>
<p>Evaluating the juror&#8217;s beliefs in the time between the testimony of the two witnesses, I don&#8217;t think the juror has any evidence in favor of p as opposed to not-p.  The first witness was no more and no less credible than the juror expects a witness to be; so the juror should expect the second witness to be exactly as credible.  Given that the juror expects to find himself in a situation in which the symmetry between the testimonies is not broken, and so there is no evidence in favor of p or not-p, he (it seems to me) has no evidence in favor of p or not-p now.</p>
<p>The case would be very different if the first witness were an expert who had been selected at random and the second witness were called by the defendant.  In that case, the juror would have the following information:<br />
(1) A randomly selected expert says that p.<br />
(2) An expert selected by the defense will say that not-p.<br />
And (2) more or less amounts to: There is some expert who will say that not-p.  For the defense is naturally going to pick whatever expert will say that not-p.  So (1) and (2) together provide more evidence that p than that not-p; assuming, always, that there isn&#8217;t some other reason to believe the second expert rather than the first.</p>
<p>In the original Juror case we have one of the defeaters Jon cites: The existence of contrary testimony plus a claim to the effect that there&#8217;s no reason to prefer one piece of testimony over the other.  In the second case we just have the existence of contrary testimony.  And in the second case the contrary testimony doesn&#8217;t defeat the original justification.</p>
<p>Furthermore, the existence of contrary testimony requires at least justification for the claim that there&#8217;s no reason to prefer one piece of testimony over the other.  On the internalist point of view, if we&#8217;re not justified in believing that claim, then we will be justified in preferring one piece of testimony, and so that testimony will yield undefeated epistemic strength.  Of course other things besides contrary testimony can defeat the original testimony, such as the explanation why the teller is mistaken or unreliable (as Jon mentioned).</p>
<p>I&#8217;ve already alluded to an interesting question here: Is actually received testimony in general to be preferred over testimony that hasn&#8217;t been received?  If we&#8217;re good at detecting insincere or unreliable testimony, then the very fact that we haven&#8217;t detected this in the testimony we have received gives us reason to prefer it over the testimony we haven&#8217;t received; we don&#8217;t know whether, if we were to hear the other testimony, we would detect something wrong with it.   What goes on in the JUROR case is that the hearer isn&#8217;t good at detecting unreliable testimony in these cases, and so has no reason to prefer the already received testimony to the tesitmony that hasn&#8217;t been received yet.  I myself am a bit skeptical about how good we are at monitoring the reliability of testimony, so I necessarily think that JUROR-like cases might be more common than we&#8217;d think.</p>
<p>But I do think that, precisified as I&#8217;ve specified, Jon&#8217;s thesis is plausible.</p>
<p>I should say, however, that I&#8217;ve simply assumed and not argued for the idea that testimony does have some default evidential strength.  Lots of people working on testimony criticize that.  In <a href="http://www.niu.edu/phil/~lackey/Two%20to%20Tango.pdf">It Takes Two To Tango</a> (in Lackey and Sosa) Jennifer Lackey criticizes this idea.  I think that the criticisms depend in part on her externalist notion of justification, but this post has already gone on far too long&#8230;.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/what-defeats-testimony/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
		</item>
		<item>
		<title>Paper on DeRose on Gaps</title>
		<link>http://certaindoubts.com/paper-on-derose-on-gaps/</link>
		<comments>http://certaindoubts.com/paper-on-derose-on-gaps/#comments</comments>
		<pubDate>Tue, 01 Mar 2005 23:01:36 +0000</pubDate>
		<dc:creator><![CDATA[weiner]]></dc:creator>
				<category><![CDATA[contextualism]]></category>
		<category><![CDATA[general]]></category>
		<category><![CDATA[knowledge]]></category>
		<category><![CDATA[major figures]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=269</guid>
		<description><![CDATA[I&#8217;ve just posted a shortish paper entitled &#8220;DeRose on Truth-Value Gaps for &#8216;Knows.'&#8221; The title is a bit misleading&#8211;I&#8217;m not so much discussing Keith&#8217;s actual view as a view that Keith might have. Keith holds that the standards for &#8216;know&#8217; &#8230; <a class="more-link" href="http://certaindoubts.com/paper-on-derose-on-gaps/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I&#8217;ve just posted a shortish <a href="http://mattweiner.net/papers/deroseongaps.pdf">paper</a> entitled &#8220;DeRose on Truth-Value Gaps for &#8216;Knows.'&#8221;  The title is a bit misleading&#8211;I&#8217;m not so much discussing Keith&#8217;s actual view as a view that Keith might have.  Keith holds that the standards for &#8216;know&#8217; in a certain context are the standards that the speaker chooses to use, rather than the ones that would be reasonable for her to use.  If two participants in a conversation insist on different standards, then knowledge ascriptions that meet only one of the standards have no truth-value.  I argue that, even if Keith held that the standards in a context were the standards that are reasonable to use, there&#8217;d still be truth value gaps in a lot of situations; and that even given his actual views, there are truth-value gaps in more situations than you might think.</p>
<p>Anyway, I&#8217;d greatly appreciate any comments anyone has.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/paper-on-derose-on-gaps/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>Intuitions on a Painted Mule Case</title>
		<link>http://certaindoubts.com/intuitions-on-a-painted-mule-case/</link>
		<comments>http://certaindoubts.com/intuitions-on-a-painted-mule-case/#comments</comments>
		<pubDate>Mon, 18 Oct 2004 18:37:39 +0000</pubDate>
		<dc:creator><![CDATA[weiner]]></dc:creator>
				<category><![CDATA[contextualism]]></category>
		<category><![CDATA[general]]></category>
		<category><![CDATA[knowledge]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=165</guid>
		<description><![CDATA[I&#8217;m curious about what your intuitions are in this variation of the painted mule case. Apologies if it&#8217;s already been gone over in the literature or elsewhere. As usual, I&#8217;ll stipulate that a painted mule really would look like a &#8230; <a class="more-link" href="http://certaindoubts.com/intuitions-on-a-painted-mule-case/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I&#8217;m curious about what your intuitions are in this variation of the painted mule case.  Apologies if it&#8217;s already been gone over in the literature or elsewhere.  As usual, I&#8217;ll stipulate that a painted mule really would look like a zebra.</p>
<blockquote><p>Jordan the zookeeper has just fed the zebra, and seen that it is the same zebra that he has cared for for years.  Jordan hears someone ask Jackie, a small child looking into the cage, &#8220;Do you <i>know</i> what that animal is?&#8221;  Jackie says, &#8220;I <i>know</i> that it&#8217;s a zebra.&#8221;  It crosses Jordan&#8217;s mind that zebras look much like mules except for the coloring, and that if an appropriately painted mule were in the cage Jackie would still think it was a zebra.  Jordan also knows that no one has ever pulled such a prank in this zoo, and in fact thinks that nobody has ever even thought of substituting a painted mule for a zebra in any zoo anywhere.</p>
<p>Should Jordan evaluate Jackie&#8217;s knowledge claim, &#8220;I <i>know</i> that it&#8217;s a zebra,&#8221; as true or false?  If Jordan said, &#8220;Jackie <i>knows</i> that it&#8217;s a zebra,&#8221; would it be true or false?  Is your answer affected at all by the fact that Jordan can rule out (in the way that Jackie can&#8217;t) that the zebra is a painted mule?</p></blockquote>
<p>My answers are likely as theoretically laden as anyone&#8217;s here, but I&#8217;ll put them in the comments so you can formulate your answers without looking at mine.</p>
<p>An irrelevant question:  Wouldn&#8217;t The Painted Mule be a great name for a nightclub?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/intuitions-on-a-painted-mule-case/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>Can Justification Just Fall Short of Knowledge?</title>
		<link>http://certaindoubts.com/can-justification-just-fall-short-of-knowledge/</link>
		<comments>http://certaindoubts.com/can-justification-just-fall-short-of-knowledge/#comments</comments>
		<pubDate>Sat, 26 Jun 2004 18:51:23 +0000</pubDate>
		<dc:creator><![CDATA[weiner]]></dc:creator>
				<category><![CDATA[justification]]></category>
		<category><![CDATA[knowledge]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=37</guid>
		<description><![CDATA[We all know that justified true belief can fail to be knowledge when funny stuff happens (or at least most of us think this). What I want to ask is whether a JTB can fail to be knowledge for a &#8230; <a class="more-link" href="http://certaindoubts.com/can-justification-just-fall-short-of-knowledge/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>We all know that justified true belief can fail to be knowledge when funny stuff happens (or at least most of us think this).  What I want to ask is whether a JTB can fail to be knowledge for a more mundane reason&#8211;because the belief is justified, but it isn&#8217;t justified enough to count as knowledge.</p>
<p>Another way, perhaps, to put this is to question a line from section 6 of Ralph&#8217;s paper <a href="http://users.ox.ac.uk/~mert1230/aim.htm">&#8220;The Aim of Belief&#8221;</a>: &#8220;[T]here is no way for a rational thinker to pursue the truth except in a way that, if it succeeds, will result in knowledge.&#8221; Is this so?</p>
<p>Here&#8217;s a case I&#8217;d like to survey you on. Charlie Brown, a baseball general manager, is trying to decide who to pick in the amateur draft. He looks at the prospects and comes to believe, based on his high school performance, that Joe Shlabotnik will be a good major league player someday. Indeed, Joe does turn out to be a good major leaguer. So Charlie had a true belief; it also seems as though it may have been justified, because it was based on performance. Yet I would think that it falls short of knowledge, because predicting someone&#8217;s eventual major league performance on the basis of his high school performance is too uncertain.</p>
<p>(Apologies to non-baseball fans; the argument probably transfers to any sport, though baseball performance is notoriously difficult to predict.)</p>
<p>Indeed, I&#8217;d argue that Charlie is much better off knowing that his pursuit of the truth about Joe&#8217;s future performance will not result in knowledge.  I&#8217;m convinced by Tim Williamson&#8217;s argument that one of the advantages of knowledge over JTB is that it is less likely to be abandoned in the face of counterevidence. Yet Charlie should be ready to abandon his belief in Joe&#8217;s future in the face of counterevidence. Given the chancy nature of baseball prospects, a general manager has to be prepared to abandon someone who looked promising but who isn&#8217;t panning out, or he may damage his team by keeping on an underperforming player. Players who you know to be good will be kept in the lineup after a poor start (I remember Barry Bonds batting under .200 one May when he was in Pittsburgh and going on to win the MVP&#8211;er, sorry again to non-baseball fans); players who you think to be good won&#8217;t.</p>
<p>Does this case convince you?  Do you think Charlie is only justified in believing that Joe will probably be good?  Do you think it casts any sort of light on the kind of justification that&#8217;s necessary for knowledge?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/can-justification-just-fall-short-of-knowledge/feed/</wfw:commentRss>
		<slash:comments>15</slash:comments>
		</item>
		<item>
		<title>More on Degrees</title>
		<link>http://certaindoubts.com/more-on-degrees/</link>
		<comments>http://certaindoubts.com/more-on-degrees/#comments</comments>
		<pubDate>Fri, 18 Jun 2004 21:44:02 +0000</pubDate>
		<dc:creator><![CDATA[weiner]]></dc:creator>
				<category><![CDATA[justification]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=25</guid>
		<description><![CDATA[Below Ralph asks whether the concept of &#8220;degrees of justification&#8221; is best measured by a probability function. This worries him because it would mean that all logical truths are maximally justified, and it seems that you may be more justified &#8230; <a class="more-link" href="http://certaindoubts.com/more-on-degrees/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Below <a href="http://bengal.missouri.edu/~kvanvigj/certain_doubts/index.php?p=21">Ralph</a> asks whether the concept of &#8220;degrees of justification&#8221; is best measured by a probability function. This worries him because it would mean that all logical truths are maximally justified, and it seems that you may be more justified in believing some than others. (Contrast ~(p&#038;~p) with a page-long tautology.)</p>
<p>I&#8217;d like to suggest&#8211;or really, fool around with the idea that&#8211;if you think that you should be  more justified in believing some logical truths than others, then that tells you how to avoid treating degrees of justification as a probability function.</p>
<p>First let me say why you might not think that. Suppose that your conception of degrees of justification is: The more likely that your evidence makes a proposition, the more justified you are in believing it. Any cognitive limitations you may have that block you from figuring out how likely your evidence makes a proposition are your own problem. Then it&#8217;s no problem to say that all logical truths are maximally justified. They&#8217;re all certain, no matter what experiences you&#8217;ve had&#8211;because they&#8217;re independent of experience&#8211;and the only difference between ~(p&#038;~p) and the page-long tautology is that your cognitive limitations may keep you from seeing that the latter is certain. But on this view, that&#8217;s your problem.</p>
<p>OK, so most of us will probably say that there&#8217;s at least a sense of justification that that view doesn&#8217;t capture. Maybe it&#8217;s something like this: How justified you are in believing a proposition depends on how confident you should feel about it, given the thought processes you&#8217;ve just gone through (including gathering evidence). So even after working out the 100-column truth table for the page-long tautology, we should be pretty unsure that it&#8217;s actually true&#8211;reflecting on that process, we can see that we might easily have made a mistake.</p>
<p>Now, how do we work out that the page-long tautology has to have maximum probability? By going through the probability axioms&#8211;pr(~p) has to be 1 &#8211; pr(p), pr(p v q) has to be pr(p)+pr(q)-pr(p&#038;q), etc. As we work out each step, we can see that the probability of the tautology must be 1.</p>
<p>Except&#8211;in calculating that probability, we are going through a long, mistake-prone thought process. So on this conception of justification, we aren&#8217;t absolutely justified in thinking that the probability of the tautology is 1. We have some reason to believe that the probability is 1, but we can&#8217;t be absolutely sure. If you conceive of justification as degree of confidence appropriate to your thought process, then justification will be more like a distribution of probabilities rather than a single probability. And some tautologies will indeed come out less justified than others. (This also looks like it makes justification into a partial rather than a complete ordering, which Ralph seemed to think might be desirable.)</p>
<p>The ironic result, if this works, is that it may undercut a certain style of argument for Bayesianism. This is the argument based on which bets it&#8217;s practically rational to accept. Practical rationality seems to be tied to how confident it&#8217;s appropriate for you to feel about your beliefs rather than to how likely those beliefs are on your evidence.  If I&#8217;m faced with a bet on p, I&#8217;ll think about whether <i>I&#8217;ve</i> worked out that p must be true, rather than on whether p is likely on my evidence.  (The former is my best shot at getting the truth of the latter, and the latter isn&#8217;t as important as how likely p is, period.) So I should not assign degrees of justification that are like probabilities&#8211;I shouldn&#8217;t be willing to stake my life against a penny on some complicated logical tautology. Hence focusing on what is practically rational won&#8217;t lead me to Bayesianism.</p>
<p>This argument depends crucially on our cognitive limitations. It&#8217;s because we have reason not to be 100% confident in our thought processes that we wind up with degrees of justification that don&#8217;t match the probability laws. So it may be that we would assign probability-like degrees of justification if we didn&#8217;t have these cognitive limits&#8211;and then we would assign maximum justification to all logical truths. (Or it may not be!)</p>
<p>One of the questions this raises is whether the purely epistemic standpoint should take account of our cognitive limitations. Often I think not, but it also seems to me as though a lot of our cognitive architecture is dependent on those very limitations. If we could keep track of degrees of justification for all our beliefs, would we have any categorical beliefs at all?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/more-on-degrees/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
		</item>
	</channel>
</rss>
