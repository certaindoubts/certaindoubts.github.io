<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Chris Tucker &#8211; </title>
	<atom:link href="http://certaindoubts.com/author/tucker/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 01:35:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>Book Announcement: Seemings and Justification</title>
		<link>http://certaindoubts.com/book-announcement-seemings-and-justification/</link>
		<comments>http://certaindoubts.com/book-announcement-seemings-and-justification/#comments</comments>
		<pubDate>Tue, 06 Nov 2012 12:34:42 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=3737</guid>
		<description><![CDATA[I&#8217;m pleased to announce the forthcoming edited collection Seemings and Justification: New Essays on Dogmatism and Phenomenal Conservatism (OUP).  All the essays are finalized (or in penultimate form), but the book won&#8217;t be out until late 2013 or early 2014.  &#8230; <a class="more-link" href="http://certaindoubts.com/book-announcement-seemings-and-justification/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I&#8217;m pleased to announce the forthcoming edited collection <em>Seemings and Justification: New Essays on Dogmatism and Phenomenal Conservatism</em> (OUP).  All the essays are finalized (or in penultimate form), but the book won&#8217;t be out until late 2013 or early 2014.  The exact timeline is largely out of my hands at this point.  Below the fold, I&#8217;ve included the table of contents and links to the introduction and to the few papers I have permission to link here.  Several other papers are available on the website of the relevant author.  In the comments of this post, I&#8217;m happy to respond to questions about the book or to objections to my introduction.</p>
<p>Before listing the contents of the book, I thought I&#8217;d point out a few features of the book.  In no particular order:</p>
<ul>I believe my introduction to the volume will be the only standalone introduction to the issues surrounding dogmatism and phenomenal conservatism.  (Please let me know if I&#8217;m wrong about that.)</ul>
<ul>This book will be of interest to philosophers of mind, as well as epistemologists.  In particular, the entries of Cullison (ch 2) and Brogaard (ch 12) contain substantial discussions of the phil mind literature on perceptual content.  More broadly, the book has numerous discussions of seemings which go well beyond what is presently in the literature.</ul>
<ul>This volume will include the latest work on the two most prominent objections to dogmatism and phenomenal conservatism, which appeal to cognitive penetration and Bayesianism, respectively.  Regarding cognitive penetration, Part V of the book contains three essays which try to restrict dogmatism so that it avoids these objections.</ul>
<ul>This book addresses a wide variety of issues.  In addition to the issues mentioned above, the book address perceptual, memorial, a priori justification (including moral epistemology), and testimonial justification, as well as the internalism/externalism debate and the epistemology of disagreement.</ul>
<p><span id="more-3737"></span></p>
<p style="text-align: center"><strong>Table of Contents</strong></p>
<p>1. <a href="http://sandbox.arts.auckland.ac.nz/~christucker/papers/Seemings%20and%20Justification-Intro.pdf" target="_blank"><em>Seemings and Justification: An Introduction</em></a><br />
Chris Tucker</p>
<p><strong>Part I: Seemings and Seeming Reports</strong><br />
2. <em>Seemings and Semantics</em><br />
Andrew Cullison<br />
3. <em>Seeming Evidence</em><br />
Earl Conee</p>
<p><strong>Part II: Foundations of Dogmatism</strong><br />
4. <em>Immediate Justification, Perception, and Intuition</em><br />
Jessica Brown<br />
5. <a href="http://www.jimpryor.net/research/index.html#Credulism" target="_blank"><em>Problems for Credulism</em></a><br />
James Pryor</p>
<p><strong>Part III: Seemings and Epistemic Internalism</strong><br />
6. <em>Does Phenomenal Conservatism Solve Internalism’s Dilemma?</em><br />
Matthias Steup<br />
7. <em>Phenomenal Conservatism and the Dilemma for Internalism</em><br />
Michael Bergmann</p>
<p><strong>Part IV: The Significance of Seemings within Specific Domains</strong><br />
8. <em>Doxastic Innocence: Phenomenal Conservatism and Grounds of Justification</em><br />
Robert Audi<br />
9. <em>Agent Centeredness, Agent Neutrality, Disagreement, and Truth Conduciveness</em><br />
Michael DePaul<br />
<strong><br />
Part V: Dealing with Cognitive Penetration</strong><br />
10. <em>Phenomenal Conservatism and Cognitive Penetration: the “Bad Basis” Counterexamples</em><br />
Matthew McGrath<br />
11. <em>Searching for True Dogmatism</em><br />
Peter Markie<br />
12. <em>Phenomenal Seemings and Sensible Dogmatism</em><br />
Berit Brogaard</p>
<p><strong>Part VI: Phenomenal Conservatism</strong><br />
13. <a href="http://www.unc.edu/~ujanel/PCPC.pdf" target="_blank"><em>Phenomenal Conservatism and the Principle of Credulity</em></a><br />
William Lycan<br />
14. <em>Michael Huemer and the Principle of Phenomenal Conservatism</em><br />
Michael Tooley<br />
15. <em>Phenomenal Conservatism Über Alles</em><br />
Michael Huemer</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/book-announcement-seemings-and-justification/feed/</wfw:commentRss>
		<slash:comments>9</slash:comments>
		</item>
		<item>
		<title>Defeating Defeaters</title>
		<link>http://certaindoubts.com/defeating-defeaters/</link>
		<comments>http://certaindoubts.com/defeating-defeaters/#comments</comments>
		<pubDate>Wed, 09 May 2012 19:25:39 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3441</guid>
		<description><![CDATA[I gain evidence that this used car salesman is unreliable.  He tells me he’s the most honest person I’ll ever know.  It would be ridiculous, on that basis, to think “Well, gee, I guess he’s reliable after all.”  We need &#8230; <a class="more-link" href="http://certaindoubts.com/defeating-defeaters/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p><strong></strong>I gain evidence that this used car salesman is unreliable.  He tells me he’s the most honest person I’ll ever know.  It would be ridiculous, on that basis, to think “Well, gee, I guess he’s reliable after all.”  We need <em>independent</em> confirmation that his testimony is reliable.  Here are two more controversial examples.  I gain evidence that my moral intuitions are unreliable.  Can my moral intuitions defeat that evidence?   It seems not: to defeat that undercutting evidence, you would need to appeal to something <em>independent</em> of the intuitions undercut.  You’re smart, but we disagree about P, which gives me some reason to think that my relevant arguments and intuitions aren’t reliable.  Can I rely on those intuitions and arguments to defeat the evidence of my unreliability?  It seems not: again, we seem to think we need something independent of those arguments and intuitions.</p>
<p>Our intuitions suggest that, to defeat undercutting evidence, we need to appeal to something independent of what’s undercut.  I think those intuitions are wrong.  Suppose I receive testimony from a reliable source that all my belief-forming methods are unreliable.  Given our “independence intuitions”, this undercutting evidence is impervious to defeat.  Since it undercuts everything, there is nothing to which I can appeal.  Yet the mere generality of the defeater should not make it invincible.</p>
<p>When we realize that the intuitions are wrong, we have some explaining to do.  If <em>undercut</em> evidence can defeat the <em>undercutting</em> evidence, then what’s the problem with trusting the testimony of the car salesman?  And what’s the problem with relying on the wall’s appearing red to give me evidence of my reliability in the context where the wall is lit by red lights?  If our “independence intuitions” don’t explain what’s going on in these cases, why can’t we appeal to the undercut evidence to defeat the undercutting evidence?</p>
<p>Feel free to comment on the above quick and dirty argument without consulting the material below the fold.  For those who want to see the argument against our independence intuitions laid out more carefully, see below. <span id="more-3441"></span></p>
<p>I’ve just completed a mathematics test.  My belief in each answer is highly justified.  But then I’m told by a reliable source that my coffee was laced with a drug that makes mathematical reasoning highly unreliable for at least four hours (it only took 1 to complete the test).  It seems that I should now lower my confidence that my answers are correct.  More generally, when our beliefs are highly justified (but not certain), and we acquire some undefeated evidence that they were formed in an unreliable way, it seems that our beliefs are less justified and, perhaps, no longer justified at all.  More formally, we can appeal to the:</p>
<p><strong>Undercutting Evidence Principle (UEP): </strong>If my beliefs in domain D are highly justified (but not certain) at t1 and if, at t2, I acquire evidence that my judgments within D were formed using method M and that M is unreliable, then, unless this evidence is defeated, my beliefs in D are less justified at t2 than they were at t1.</p>
<p>Once I’m informed of the drug, I begin to check my answers.  I consider first question.  I check my calculations and they seem flawless.  I then realize that there are other ways of calculating the answer to the question.  For example, instead of multiplying <em>4 x 4</em>, I add <em>4 + 4 + 4 + 4</em>.  I consider an additional five ways of calculating the results to the answer and each time I confirm my original answer.  I undertake a similar investigation for each of the other 9 answers. My new calculations confirm my old ones again and again.  Presumably, these confirmations, when taken together, count as evidence <em>for</em> the reliability of my mathematical reasoning.  Can this evidence raise my justification that my answers are correct (at least partially) back to their original level? Or perhaps even higher than their original level?  Intuitively, many think the answer is clearly no.  These “confirmations” appealed solely to mathematical reasoning.  But that is the very sort of reasoning that my evidence suggests is unreliable.  How can further investigation defeat the undercutting evidence by relying on the very sort of reasoning that is undercut?  At first glance at least, that’s just plain foolish.  Hence, the following principle may seem undeniable:</p>
<p><strong>Independence:</strong> A body of evidence E* can defeat undercutting evidence that M is unreliable only if E* was, at least in part, was not obtained via M.</p>
<p><strong></strong>Unfortunately, things aren’t so simple.  We are faced with a contradiction when we consider two other very plausible claims.  Consider first:</p>
<p><strong>Possibility of Global Undercutting</strong><strong> (PGU):</strong> it is possible to have beliefs that are highly justified at t1 and then acquire evidence at t2 that all of your belief forming methods are unreliable, so all your judgments are/were formed using methods.</p>
<p>PGU is a very weak claim.  It says that it is <em>possible</em> to have beliefs that are highly justified and then acquire evidence that all your beliefs are formed via some unreliable method.  Suppose, for example, that I receive reliable testimony that all my belief-forming methods are unreliable.  This testimony is confirmed by the world’s leading experts.  The most reliable news outlets testify that my beliefs are unreliable, an unfortunate result of an insidious science experiment.  I would say that I have now acquired evidence that all my beliefs are formed by some unreliable method.  Indeed, one might think that this is fairly strong evidence that all my belief forming faculties are unreliable.  I usually confidently believe things on far less impressive testimony.</p>
<p>But when you put UEP and PGU together, it follows that I should reduce confidence in <em>all</em> my beliefs.  Is there any way that I can regain the lost degree of justification?  Not given Independence.  Since it disallows me from appealing to anything undercut and every way I have of forming beliefs is undercut, there is nothing to which I can appeal.  I’m stuck where I am—at least until I gain even more evidence of my unreliability, at which point my justification might decrease even further.  Hence,  invincible counterevidence would be possible.  Yet the mere fact that undercutting evidence is completely general should not make that evidence invincible, as would be the case were Independence true.  In other words:</p>
<p><strong>Anti-Invincibility:</strong> A body of undercutting evidence E can’t be invincible, i.e. there must be some possible circumstances in which E is defeated.  Or at the very least, the generality of the undercutting evidence shouldn’t ensure that the defeater is invincible.</p>
<p>Setting aside the possibility that one can acquire new belief forming methods, UEP, Independence, PGU, and Anti-Invincibility form an incompatible tetrad.  UEP, Independence, and PGU guarantee that invincible defeaters are possible, and Anti-Invincibility guarantees that there aren’t any.</p>
<p>I take it that the two least plausible claims are Independence and Anti-Invincibility.  Which one should we give up?  Which one is the least plausible?  I don’t have a super strong argument for Anti-Invincibility, but I do want to put a little pressure on Independence.  In the case described above, I have all sorts of testimonial evidence that suggests all my belief forming methods are unreliable.  Independence entails that, even if I were to acquire rather convincing evidence that the whole thing is an elaborate gag, this evidence still could not restore me to my original level of justification.  And that seems rather counterintuitive, and it reinforces the intuition that the mere generality of undercutting evidence should not make it invincible.  I think, therefore, that we should reject Independence.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/defeating-defeaters/feed/</wfw:commentRss>
		<slash:comments>7</slash:comments>
		</item>
		<item>
		<title>Dogmatism vs Bayesianism: Why Should Bayesianism Win?</title>
		<link>http://certaindoubts.com/dogmatism-vs-bayesianism-why-should-bayesianism-win/</link>
		<comments>http://certaindoubts.com/dogmatism-vs-bayesianism-why-should-bayesianism-win/#comments</comments>
		<pubDate>Tue, 17 Apr 2012 21:52:31 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3409</guid>
		<description><![CDATA[Perceptual dogmatism is the view that a perceptual seeming that P prima facie justifies P.  Classical Bayesianism (CB), as I am using the term, is the idea that justification is accurately modelled by classical probability theory, which includes Bayes’ Theorem.  &#8230; <a class="more-link" href="http://certaindoubts.com/dogmatism-vs-bayesianism-why-should-bayesianism-win/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Perceptual dogmatism is the view that a perceptual seeming that P prima facie justifies P.  Classical Bayesianism (CB), as I am using the term, is the idea that justification is accurately modelled by classical probability theory, which includes Bayes’ Theorem.  A popular way of objecting to dogmatism goes something like this: dogmatism is incompatible with CB, so dogmatism is false.  I’ll assume that you have some familiarity with this sort of objection, which can be found in White’s “Problems for Dogmatism”, Schiffer’s “Skepticism and the Vagaries of Justified Belief” (pgs 175-6), and Wright’s “The Perils of Dogmatism” (pg 42).</p>
<p>Suppose we grant the premise that dogmatism is incompatible with CB.  Why in the world should we conclude that the CB wins?  Why shouldn’t we reject CB instead?  The latter view does have a number of virtues, but it is not as though dogmatism has <em>nothing </em>going for it.  And CB has a number of well-known problems.  So I repeat: if dogmatism and CB are incompatible, why should the Classical Bayesian win?</p>
<p>Here is a way of approaching the question: if the incompatibility between CB and dogmatism depends on the most controversial features of Classical Bayesianism, then dogmatism should win.  For example, I find it implausible that a rational human being should assign a credence to every proposition or a credence of 1 to every necessary truth.  I take it that these implausible claims are entailed by CB.  To whatever extent the incompatibility arises because of CB’s commitment to either of those two claims, dogmatism should win and we should rework CB.  If, however, the incompatibility relies only on the least controversial features of CB, then CB should win.  Perhaps an example of something uncontroversial would be: <em>if</em> S assigns a credence to both P and P or Q, S is irrational for assigning P or Q a lower credence than P.<span id="more-3409"></span></p>
<p>My suspicion is that you can only derive the incompatibility by relying on the most controversial features of dogmatism, such as the claim that I suffer a rational failing if I don&#8217;t assign every proposition a credence.  Suppose I might reasonably fail to assign a credence to the proposition (~D) that  I’m not being deceived into thinking there is a hand.  That is, suppose that, prior to having an experience as of my hand, ~D has no probability for me (perhaps because I have no information one way or the other, I’ve never considered ~D, etc.).  Now what’s the problem with the dogmatism allowing this: my experience provides me with justification to believe that I have a hand, and then, from my justified belief that I have a hand, I justifiably deduce ~D?</p>
<p>I admit that I’m worse than an idiot when it comes to formal epistemology, so this post is intended as a request for information as much as it is intended as a defense of dogmatism.  And let me also stress that I’m not against formal epistemology.  If dogmatism wins, then we shouldn’t give up on formal epistemology; rather, we should improve our formal modelling techniques.</p>
<p>(Btw: Peter Kung&#8217;s &#8220;<a href="http://www.springerlink.com/content/g56p153t02927161/">On Having No Reason: Dogmatism and Bayesian Confirmation</a>&#8221; provides a defense of dogmatism that may be a more intelligent way of pushing some of the points I make in this post.  But perhaps Peter wouldn&#8217;t like to be associated with ideas that may be worse than idiotic.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/dogmatism-vs-bayesianism-why-should-bayesianism-win/feed/</wfw:commentRss>
		<slash:comments>13</slash:comments>
		</item>
		<item>
		<title>Wishful Thinking Problems for Reliabilism</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/</link>
		<comments>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comments</comments>
		<pubDate>Mon, 26 Mar 2012 16:00:56 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[perception]]></category>
		<category><![CDATA[reliabilism]]></category>
		<category><![CDATA[wishful thinking]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369</guid>
		<description><![CDATA[Phenomenal conservatism and dogmatism get a bad rep for allowing some cases of wishful thinking to provide prima facie justification.  In this post, I argue that reliabilism has wishful thinking problems that are even worse. Contrast direct and indirect wishful &#8230; <a class="more-link" href="http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Phenomenal conservatism and dogmatism get a bad rep for allowing some cases of wishful thinking to provide prima facie justification.  In this post, I argue that reliabilism has wishful thinking problems that are even worse.</p>
<p>Contrast direct and indirect wishful thinking.  The former occurs when one bases a belief that P directly on one’s desire (wish, lust, etc.) that P.  The latter occurs in any other way.  For our purposes, we can assume all cases of indirect wishful thinking fit this pattern: a desire that P causally influences the way things seem, and then a belief that P is based directly on the seeming that is so influenced.  For example, I might base my belief that the nugget is gold on its seeming that the nugget is gold, where I have that seeming, not because of relevant expertise, but because I’m lusting for gold.  Lyons holds that, as a matter of fact, most wishful thinking is indirect in this way, which sounds plausible to me.  Seemings Internalism (SI) holds that seemings necessarily provide prima facie justification.  (SI is inclusive of dogmatism and phenomenal conservatism.)  Hence, SI seems committed to allowing indirect wishful thinking to provide prima facie justification.</p>
<p>Says Lyons: “For SI to bite the bullet here would be for it to hold that the epistemology of (typical) wishful thinking perfectly parallels the epistemology of (typical) perception: an agent has an appearance as of <em>p</em>, which <em>prima facie</em> justifies her in believing that <em>p</em>.  I myself would think that this bullet just can’t be bitten, that an epistemology that licences wishful thinking in this way simply can’t be taken seriously” (pg 299 of <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1533-6077.2011.00205.x/abstract">this paper</a>).  Note that Lyons doesn’t claim that, given SI, typical cases of wishful thinking result in <em>ultima facie</em> justification.  Since it’s plausible that typical wishful thinkers have defeaters for their wishful thinking, the latter claim is dubious.</p>
<p>I agree with Lyons that it is counterintuitive to allow indirect wishful thinking to prima facie justify its content; however, reliabilists suffer from wishful thinking problems that are <em>worse</em>.  I admit it’s bad to allow typical cases of <em>indirect </em>wishful thinking to provide <em>prima facie</em> justification.  It’s worse, in my mind, to allow possible cases of <em>direct </em>wishful thinking to provide <em>ultima facie</em> justification.  Proponents of SI can say that it is impossible for desires, by themselves, to be an acceptable basis for beliefs.  Reliabilists can’t say that.  (I think the same holds for externalism more generally and possibly also for some versions of internalism.)<span id="more-3369"></span></p>
<p>To see the basic point, start with a simple version of indicator reliabilism.  On such a view, a desire that P will justify a belief that P just in case that desire is a reliable indicator of P.  Epistemic angels can bring about the required reliability by organizing the world to ensure that desires (within a certain domain) regularly come to pass.  The modal profile of P can ensure that any basis of P, including a desire for P, is a trivially reliable indicator for P.  Since Goedel’s first incompleteness theorem is necessarily true, there’s never a case in which you will be led astray by believing the theorem on the basis of desiring or wishing it to be true.  The modal profile of certain contingent truths also can make desires trivially reliable indicators of P, but I won’t go into the details here.  More sophisticated indicator reliabilisms will give more subtle accounts of reliability, but give me an account and I’ll give you a possible case in which the view allows a belief to be ultima facie justified on the basis of a desire.</p>
<p>Depending on what they say about process individuation, process reliabilists may approve of actual cases of direct wishful thinking.  A process can be wrong every time it takes a desire as an input, but still be reliable overall if desires rarely get used as inputs.  For example, I might use process R 100 times.  It&#8217;s output might be mistaken both times it took a desire as an input, but be very reliable because it was correct in all 98 other uses.  Suppose that desires do sometimes causally influence the way things seem (which Lyons accepts) and that this happens in a very small number of times relative to the number of perceptual seemings we have (which seems plausible).  When desires do get involved, are those desires unusual inputs to the normal—and reliable—process of perception or do they always indicate that a different process is at work?  I don’t think reliabilists say enough about process individuation for us to say one way or another.  But if desires are unusual inputs to a normal reliable process, then process reliabilists are committed to allowing <em>direct</em> wishful thinking to provide <em>ultima facie </em>justification in the actual world.</p>
<p>So here’s a challenge, reliabilists.  Give me a proposed account of process individuation that doesn’t allow any actual wishful thinking to count as justified, and I’ll show you that there is a possible process that (i) takes at least one desire as an input and (ii) produces mostly true beliefs (or satisfies whatever account of reliability you put forward).</p>
<p>(I’ve assumed that the relevant sort of reliability is reliability in the world of the process being evaluated (what Lyons calls “in situ” reliability).  Alternative views hold that what matters is reliability in the actual world.  Such versions of reliabilism probably don’t have wishful thinking problems, unless their account of process individuation forces them to approve of some actual case of wishful thinking.  But they achieve this advantage by relying on the most implausible feature of their view, namely that processes that don’t exist can’t yield justified beliefs.  Possible processes that don’t exist can’t yield justified beliefs, because they aren’t reliable in the actual world.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/feed/</wfw:commentRss>
		<slash:comments>11</slash:comments>
		</item>
		<item>
		<title>Reliability and Cognitive Penetration</title>
		<link>http://certaindoubts.com/reliability-and-cognitive-penetration/</link>
		<comments>http://certaindoubts.com/reliability-and-cognitive-penetration/#respond</comments>
		<pubDate>Tue, 13 Mar 2012 22:42:46 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[memory]]></category>
		<category><![CDATA[perception]]></category>
		<category><![CDATA[cognitive penetration]]></category>
		<category><![CDATA[reliabilism]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3325</guid>
		<description><![CDATA[Can a subject’s beliefs, desires, fears, or goals causally influence the way things seem to her?  Suppose that the answer is yes.  That is, suppose that a subject’s mental states can penetrate the way things seem to her.  What are &#8230; <a class="more-link" href="http://certaindoubts.com/reliability-and-cognitive-penetration/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Can a subject’s beliefs, desires, fears, or goals causally influence the way things seem to her?  Suppose that the answer is yes.  That is, suppose that a subject’s mental states can <em>penetrate</em> the way things seem to her.  What are the epistemic implications of this cognitive penetration?  This question is becoming a ‘hot’ topic in epistemology these days, though it has been around in various forms for decades at least.  My tentative plan is to write two blog posts on this topic.  Both are responses to Jack Lyons&#8217; <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1533-6077.2011.00205.x/abstract">very helpful paper</a>, but I hope the wider significance of the posts will be apparent.  In this post, I will argue, contra Lyons, that we have no reason to think reliability explains which instances of cognitive penetration are benign and which are malignant.  In the next blog post, I’ll argue that reliabilism has cognitive penetration problems of its own.<span id="more-3325"></span></p>
<p>It’s clear that some instances of cognitive penetration are perfectly benign and, sometimes, even epistemically beneficial.  It seems to me that I ate cereal for breakfast now because this morning I (rationally) formed the belief that I ate cereal for breakfast.  The previous belief makes it seem to me that I ate cereal for breakfast now.  If this kind of penetration isn’t benign (or beneficial), then one wonders whether any of our memorial beliefs are justified.  On the other hand, some cases of cognitive penetration apparently pose a problem for anyone who, <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1520-8583.2010.00202.x/abstract">like me</a>, wants to hold that all (perceptual) seemings prima facie justify.  If my lust for gold causes it to seem that the yellow nugget is gold, then most of us feel some hesitancy in allowing that such a seeming provides even prima facie justification that the nugget is gold.</p>
<p>So there are good cases of cognitive penetration and there are (apparently) bad cases.  What explains this difference?  Jack holds that it is explained by reliability (see section 4).  In the “good cases”, such as ordinary memorial belief formation, the reliability of the relevant process is high.  In the bad cases, the reliability of the relevant process is low.  If Jack could make good on these claims, it would be a real win for reliabilism; however, Jack is writing checks that reliabilism can’t cash (yet).  The problem is that whether reliability can explain the difference between the good and bad cases depends almost entirely on how one individuates processes, and it is far from clear that there is a sensible way of individuating processes that allows reliability to track the goodness/badness of cognitive penetration.</p>
<p>To see the problem, consider this question: are cognitively penetrated processes different processes than the ones that aren’t cognitively penetrated?  Since I don’t think an “it depends” answer will help the reliabilist much, I’m going to ignore it.  Suppose that the reliabilist says &#8220;no&#8221;.  This means that cognitively penetrated processes are identical to the ones that aren’t penetrated.  Hence, the reliability of those processes also will be identical to the reliability of the processes that aren’t penetrated.  Presumably, those processes will be reliable.  But then the bad cases of penetration would yield justified beliefs because they are produced by reliable processes.  So if the reliabilist is trying to explain the difference between the good and bad penetration, he shouldn’t say “no” to this question.</p>
<p>Suppose the reliabilist says, “yes, cognitively penetrated processes are different processes than non-penetrated processes.”  Now we are faced with a different question: Do the good cases of cognitive penetration involve different processes than the bad cases?  Again, I ignore the “it depends” answer.  If the reliabilist says “no,” she is stuck with a similar problem to what she faced by saying “no” to the previous question.  If the good and bad cases involve the same process, then the good and bad cases will be equally reliable and either the good cases will involve unreliable processes or the bad cases will involve reliable processes.  Either way, reliability can’t explain the difference between the good and bad cases of cognitive penetration.  So if the reliabilist is trying to explain this difference, she shouldn’t say “no” to this question either.</p>
<p>If the reliabilist is trying to explain the relevant difference, she needs to hold that, “yes, the good cases of cognitive penetration involve different processes than the bad cases of cognitive penetration.”  For the sake of keeping this blog post less long, I’ll just declare three things I think are true: 1) The required account of process individuation would likely need to individuate processes fairly narrowly.  2) No one, Jack included, has identified a way of individuating processes (i) that meets the above requirements for explaining the relevant difference; (ii) that is not ad hoc; and (iii) that is empirically adequate.  3) We won’t be in position to affirm that reliability (of processes) explains the difference between good and bad penetration until we have discovered a way of individuating process that at least plausibly satisfies (i)-(iii).  I conclude that we have no reason to think that reliability really does explain the difference between the good and bad cases of cognitive penetration.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/reliability-and-cognitive-penetration/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Two Conferences</title>
		<link>http://certaindoubts.com/two-conferences-2/</link>
		<comments>http://certaindoubts.com/two-conferences-2/#respond</comments>
		<pubDate>Mon, 04 Apr 2011 20:58:52 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=2566</guid>
		<description><![CDATA[**DEADLINE FOR ABSTRACT SUBMISSION EXTENDED TO MAY 15th** I&#8217;m hosting a couple conferences at the University of Auckland in mid-July.  The first conference concerns ethical naturalism, broadly understood, and the second concerns the philosophy of religion.  I certainly hope that &#8230; <a class="more-link" href="http://certaindoubts.com/two-conferences-2/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p><strong>**DEADLINE FOR ABSTRACT SUBMISSION EXTENDED TO MAY 15th**</strong></p>
<p>I&#8217;m hosting a couple conferences at the University of Auckland in mid-July.  The first conference concerns ethical naturalism, broadly understood, and the second concerns the philosophy of religion.  I certainly hope that I get some more epistemologists involved in both conferences.  For example, I&#8217;m keen to get some discussion of the evolutionary debunking arguments against morality and religion.  I&#8217;m considering papers on the basis of short abstracts.  The deadline for submission is May <del>1st</del> 15th.  For more details, see:</p>
<p>Philosophy of Religion: <a href="http://www.apra.org.au/the-apra-conference/">http://www.apra.org.au/the-apra-conference/</a></p>
<p>Naturalism in Ethics: <a href="http://sandbox.arts.auckland.ac.nz/~christucker/NEC.html">http://sandbox.arts.auckland.ac.nz/~christucker/NEC.html</a></p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/two-conferences-2/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Fumerton on Doxastic Justification and the Role of Epistemologists</title>
		<link>http://certaindoubts.com/fumerton-on-doxastic-justification-and-the-role-of-epistemologists/</link>
		<comments>http://certaindoubts.com/fumerton-on-doxastic-justification-and-the-role-of-epistemologists/#comments</comments>
		<pubDate>Tue, 24 Aug 2010 08:00:45 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[justification]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=2126</guid>
		<description><![CDATA[In his Epistemology, Fumerton argues that propositional justification is more central to (applied) epistemology than is doxastic justification.  Here is one of his arguments: There is another reason that epistemologists interested in applied epistemology are probably well advised to focus &#8230; <a class="more-link" href="http://certaindoubts.com/fumerton-on-doxastic-justification-and-the-role-of-epistemologists/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>In his <em>Epistemology, </em>Fumerton argues that propositional justification is more central to (applied) epistemology than is doxastic justification.  Here is one of his arguments:</p>
<blockquote><p>There is another reason that epistemologists interested in applied epistemology are probably well advised to focus on what there is [propositional] justification for people to believe rather than which beliefs are actually [doxastically] justified.  If it is true that S’s belief is [doxastically] justified only if it is based on good reasons, and it is also true that basing is to be understood, even partially, in terms of causation, then it is not clear that philosophers, in their capacity as philosophers, are particularly well equipped to answer questions concerning which beliefs are [doxastically] justified.  The causes of a belief are a more appropriate subject for the psychologist.  Freud spent a great deal of time wondering what causes a belief in a God or in an afterlife.  The epistemologist, qua epistemologist, should find such speculation utterly uninteresting.  Whatever causes such beliefs, the epistemologist’s concern is with the question of whether we possess good reasons for believing the propositions in question.  To answer that question we need not concern ourselves with what is actually causing our beliefs. (36-7)</p></blockquote>
<p>I worry that this argument shows too much.  If it shows that epistemologists, qua epistemologists, shouldn’t be interested in what we are doxastically justified in believing, then a parallel line of reasoning shows that epistemologists, qua epistemologists, shouldn’t be interested in what we have propositional justification or good reasons for believing.  Here is the parallel argument:</p>
<p style="padding-left: 30px">Whether we have certain reasons to believe P largely depends on what beliefs or experiences we have.  But whether we have certain beliefs and experiences is the sort of question that epistemologists, qua epistemologists, are not suited to answer.  If you wanna know the answer to that question, go talk to our friends the psychologists and cognitive scientists.</p>
<p>The parallel certainly isn’t perfect, but it seems close enough to cast doubt on Fumerton’s argument. (The parallel is stronger if we assume (i) that one can be mistaken about which beliefs and experiences one has and (ii) that brain scans and/or psychological evaluation can provide information about what experiences or beliefs one is having.  Fumerton seems to endorse at least (i).)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/fumerton-on-doxastic-justification-and-the-role-of-epistemologists/feed/</wfw:commentRss>
		<slash:comments>6</slash:comments>
		</item>
		<item>
		<title>Organizing a Conference and Conference Management Freeware</title>
		<link>http://certaindoubts.com/organizing-a-conference-and-conference-management-freeware/</link>
		<comments>http://certaindoubts.com/organizing-a-conference-and-conference-management-freeware/#comments</comments>
		<pubDate>Mon, 16 Aug 2010 03:10:31 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=2105</guid>
		<description><![CDATA[I&#8217;ll be organizing somewhere between 1-3 conferences in 2011-2, and at least one of them will involve a call for abstracts.  Since I&#8217;ve never organized a conference before, does anyone have any useful advice?  I doubt I&#8217;m the only one &#8230; <a class="more-link" href="http://certaindoubts.com/organizing-a-conference-and-conference-management-freeware/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I&#8217;ll be organizing somewhere between 1-3 conferences in 2011-2, and at least one of them will involve a call for abstracts.  Since I&#8217;ve never organized a conference before, does anyone have any useful advice?  I doubt I&#8217;m the only one preparing to organize a conference for the first time, so others will also benefit from any advice.  I have especial interest in answers to the following questions:</p>
<p>1. Does anyone have any experience using<a href="http://www.easychair.org/easychair.cgi"> EasyChair</a>, <a href="http://www.openconf.com/">OpenConf</a>, <a href="http://myreview.sourceforge.net/">MyReview</a>, or some other conference management freeware?  If so, do you have any thoughts?</p>
<p>2. Is receiving submissions over email sufficiently straightforward that it doesn&#8217;t even make sense to invest the time to learn one of these programs?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/organizing-a-conference-and-conference-management-freeware/feed/</wfw:commentRss>
		<slash:comments>6</slash:comments>
		</item>
		<item>
		<title>Hey Internalists, Which Experiences Justify and Why?</title>
		<link>http://certaindoubts.com/hey-internalists-which-experiences-justify-and-why/</link>
		<comments>http://certaindoubts.com/hey-internalists-which-experiences-justify-and-why/#comments</comments>
		<pubDate>Tue, 11 May 2010 19:32:53 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[a priori knowledge]]></category>
		<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[memory]]></category>
		<category><![CDATA[perception]]></category>
		<category><![CDATA[internalism]]></category>
		<category><![CDATA[non-inferential justification]]></category>
		<category><![CDATA[phenomenal conservatism]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=1866</guid>
		<description><![CDATA[Here is my impression: it is very popular to allow certain kinds of experiences to provide (prima facie propositional) justification for certain propositions.  Which propositions might an experience justify?  The most straightforward thing to say is that certain experiences provide &#8230; <a class="more-link" href="http://certaindoubts.com/hey-internalists-which-experiences-justify-and-why/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p style="text-align: justify">Here is my impression: it is very popular to allow certain kinds of experiences to provide (prima facie propositional) justification for certain propositions.  Which propositions might an experience justify?  The most straightforward thing to say is that certain experiences provide justification for their propositional contents; but if experiences don’t have propositional contents, some more elaborate story will need to be told.  For the sake of simplicity, I’ll assume that an experience justifies a proposition only if it has a propositional content.</p>
<p style="text-align: justify">Which experiences provide justification for their propositional contents?  Here are some popular answers: perceptual experiences, memorial experiences, a priori intuitions, or some combination thereof.  (I am thinking of a priori intuitions as experiences.  Intuitions about morality, math, modality, and philosophy often count as a priori intuitions.)  It is not popular, however, to say that just any experience (or just any experience with a representational content) can justify its conclusion.  But this raises the following questions: if some experiences justify their contents, why don’t all experiences justify their contents?  What principled criterion is there for allowing only certain experiences (with contents) to justify their conclusions?</p>
<p style="text-align: justify"><span id="more-1866"></span></p>
<p style="text-align: justify">Reliabilists have a straightforward answer: only experiences that are caused in a reliable way can justify.  Other externalists will have similar stories to tell.  But what about the internalist?  What criterion can he use to distinguish between experiences that justify and those that don’t?</p>
<p style="text-align: justify">One answer is available to those who allow a priori intuitions to justify.  They can say something like this: an experience that P justifies P just in case it is the result of possessing, or understanding, the concepts involved in P.  The intuition that torture is wrong justifies because it results from possessing the concepts ‘torture’, ‘is’, ‘wrong’.  The experience that the Cubs will win the World Series does not justify because it does not result possessing the concepts involved.</p>
<p style="text-align: justify">I’ve never found this explanation very appealing for two reasons.  The first is essentially this argument: (i) perceptual experiences and a priori experiences justify; (ii) concept possession does not explain why perceptual experiences justify (at least not all of them); (iii) there is one explanation for why experiences justify (so if concept possession doesn’t explain why perceptual experiences justify, then it doesn’t explain why a priori intuitions justify); (iv) therefore, concept possession doesn’t explain why a priori intuitions justify.  The second reason is that if you are going to give concept possession such a prominent role in a priori justification, a priori intuition doesn’t seem to do any work—it just seems along for the ride.</p>
<p style="text-align: justify">My own view on the matter is phenomenal conservatism: necessarily, if it seems to S that P, then S has (prima facie propositional) justification that P.  A seeming that P is an experience with propositional content P and a special kind of phenomenal character.  The phenomenal character “assures” the subject that its content is true.  Perceptual experiences, memorial experiences, and a priori intuitions are all plausible candidates for seemings.  Phenomenal conservatism is unpopular because many find it implausible that <em>all </em>seemings provide justification.  Surely, some argue, a seeming produced by wishful thinking has no justificatory power.</p>
<p style="text-align: justify">Here is another way of pressing the question in which I’m interested: if some seemings justify, why don’t all seemings justify?  It seems that many internalists allow perceptual and a priori seemings to justify, but they don’t allow wishfully-produced seemings to justify.  What principled, internalist criterion can allow only some (and the right ones) to justify?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/hey-internalists-which-experiences-justify-and-why/feed/</wfw:commentRss>
		<slash:comments>17</slash:comments>
		</item>
		<item>
		<title>Closure vs. Transmission</title>
		<link>http://certaindoubts.com/closure-vs-transmission/</link>
		<comments>http://certaindoubts.com/closure-vs-transmission/#comments</comments>
		<pubDate>Sat, 01 May 2010 13:23:47 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[justification]]></category>
		<category><![CDATA[skepticism]]></category>
		<category><![CDATA[closure]]></category>
		<category><![CDATA[transmission]]></category>
		<category><![CDATA[Tucker]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=1846</guid>
		<description><![CDATA[Crispin Wright, Martin Davies (in some places but not others), and most explicitly Martin Smith seem sympathetic with the following diagnosis of Moore’s Proof (I have a hand therefore there is at least one material object): “Moore’s Proof (MP) seems &#8230; <a class="more-link" href="http://certaindoubts.com/closure-vs-transmission/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p style="text-align: justify">Crispin Wright, Martin Davies (in some places but not others), and most explicitly Martin Smith seem sympathetic with the following diagnosis of Moore’s Proof (I have a hand therefore there is at least one material object): “Moore’s Proof (MP) seems to be a bad argument, but intuitive closure principles seem too plausible to reject.  This tension can be resolved when MP is treated as an instance of transmission rather than closure failure.  MP seems to be a bad argument and <em>is </em>a bad argument because it fails to transmit justification to its conclusion; it is not, however, a counterexample to intuitive closure principles.”</p>
<p style="text-align: justify">The alleged virtue of this diagnosis is that it preserves intuitive closure principles while explaining why the inference is genuinely bad.  The explanation of badness is that the inference fails to transmit.  This diagnosis is no good because  Wright, etc. don’t salvage the closure principles that epistemologists find too plausible to reject.</p>
<p style="text-align: justify"><span id="more-1846"></span>An inference fails to transmit justification to belief in its conclusion when it doesn’t make belief in its conclusion justified.   A closure principle says if Pa and Rab, then Pb.  A transmission principle says if Pa and Rab, then Pb <em>in virtue of</em> Pa and Rab.  Let us say that a deduction is <strong>competent</strong> just in case the premises are well-justified; the premises provide deductive (so maximal) support for their conclusions; there are no relevant defeaters; and it is not premise circular (i.e. the premise of MP isn’t based on a chain of reasoning that uses the conclusion of MP as a premise).</p>
<p style="text-align: justify">The closure principle that people find attractive is something like this:</p>
<p style="text-align: justify"><strong>Strong Closure (SC):</strong> If S justifiably believes P and S <em>competently</em> deduces Q from P, then S justifiably believes Q.</p>
<p style="text-align: justify">There are various concerns with Strong Closure in the literature, but I get the impression that epistemologists often think something <em>like</em> Strong Closure will turn out to be true.  (Most discussions of closure focus on the closure of knowledge<em> </em>rather than doxastic justification, but I’m less optimistic about knowledge closure principles.)</p>
<p style="text-align: justify">The closure principle that Wright et al are able to endorse is:</p>
<p style="text-align: justify"><strong> </strong></p>
<p style="text-align: justify"><strong>Weak Closure (WC):</strong> If S justifiably believes P and S competently deduces Q from P, then S has some epistemic status for Q, no matter how weak.</p>
<p style="text-align: justify">Suppose S competently deduces Q from her justified belief that P.  SC holds that S must justifiably believe Q.  WC, on the other hand, says only that S must have some positive epistemic status for Q, no matter how weak.  Wright et al say that MP fails to make its conclusion justifiably believed, so it fails to transmit (doxastic) justification.  Yet Wright et al endorse a view of perceptual justification according to which one has, by default, some <strong>very</strong> weak epistemic status, entitlement, for the conclusion (that there is a material object) <em>and</em> this entitlement is an essential part of what justifies the person in believing the premise (that one has a hand).  So anytime one is justified in believing the premise, one has entitlement for the conclusion.  Thus, Weak Closure is true.  But Strong Closure is false because the conclusion is not justifiably believed (and on their view, the conclusion cannot be justifiably believed via MP).</p>
<p style="text-align: justify">I say it is no advantage to accommodate only WC, because epistemologists find something like SC too plausible to reject.  Hence, those who say that MP is an instance of transmission failure must say that it also is a counterexample to the closure principles epistemologists find too plausible to reject.</p>
<p style="text-align: justify">For further clarification of the above argument, see 4.C of my forthcoming IEP entry on transmission failure.  I defend a transmission principle that entails SC in my “When Transmission Fails,” esp. sec. 4 (forthcoming Phil Review).  Both papers are available on my website.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/closure-vs-transmission/feed/</wfw:commentRss>
		<slash:comments>18</slash:comments>
		</item>
	</channel>
</rss>
