<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Michael Huemer &#8211; </title>
	<atom:link href="http://certaindoubts.com/author/michael-huemer/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 01:35:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>Simplicity</title>
		<link>http://certaindoubts.com/simplicity/</link>
		<comments>http://certaindoubts.com/simplicity/#comments</comments>
		<pubDate>Sun, 29 Jan 2006 17:37:08 +0000</pubDate>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
				<category><![CDATA[general]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=512</guid>
		<description><![CDATA[Can someone tell me why it is said that &#8220;other things being equal, the simplest theory is the best&#8221;? I have some thoughts about it, but I&#8217;d like to hear what other people think. Extra credit question: Is simplicity in &#8230; <a class="more-link" href="http://certaindoubts.com/simplicity/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Can someone tell me why it is said that &#8220;other things being equal, the simplest theory is the best&#8221;?<br />
I have some thoughts about it, but I&#8217;d like to hear what other people think.</p>
<p>Extra credit question: Is simplicity in philosophical theories a virtue in the same way (or in any way) as simplicity in scientific theories?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/simplicity/feed/</wfw:commentRss>
		<slash:comments>43</slash:comments>
		</item>
		<item>
		<title>Is coherence truth-conducive?</title>
		<link>http://certaindoubts.com/is-coherence-truth-conducive/</link>
		<comments>http://certaindoubts.com/is-coherence-truth-conducive/#comments</comments>
		<pubDate>Sun, 22 Jan 2006 03:17:17 +0000</pubDate>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
				<category><![CDATA[foundationalism and coherentism]]></category>
		<category><![CDATA[general]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=509</guid>
		<description><![CDATA[Prompted partly by Olsson&#8217;s recent Against Coherence (OUP 2005), I&#8217;ve been thinking about the truth-conduciveness of coherence. There&#8217;ve been two recent claims to prove that coherence cannot be truth conducive (in Olsson, and Bovens &#038; Hartmann&#8217;s Bayesian Epistemology). I don&#8217;t &#8230; <a class="more-link" href="http://certaindoubts.com/is-coherence-truth-conducive/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Prompted partly by Olsson&#8217;s recent <em>Against Coherence</em> (OUP 2005), I&#8217;ve been thinking about the truth-conduciveness of coherence. There&#8217;ve been two recent claims to prove that coherence cannot be truth conducive (in Olsson, and Bovens &#038; Hartmann&#8217;s <em>Bayesian Epistemology</em>).</p>
<p>I don&#8217;t know how many people have looked at this literature. Briefly, the claim (theorem, in fact) is that if</p>
<blockquote><p>	a) the coherence of a set of beliefs is a function of the probability distribution over the believed propositions and</p>
<p>	b) the beliefs are formed independently of each other (i.e., when the truth-values of the relevant propositions are fixed, the occurrence of one belief doesn&#8217;t affect the probability of the other beliefs occurring),</p></blockquote>
<p>then</p>
<blockquote><p>c) there is no possible measure of the degree of coherence of a belief system on which more coherent beliefs are in general more likely to be true, <em>ceteris paribus</em>.</p></blockquote>
<p>So I wonder a few things about this:</p>
<p>1) Is (c) incompatible with coherentism? Perhaps some coherentists would like to weigh in.</p>
<p>2) Should the coherentist accept (a) and (b)?</p>
<p>3) Lastly, I&#8217;m wondering more generally about the interpretation of claims like &#8220;x is conducive to y, <em>ceteris paribus</em>.&#8221; Olsson says that means: As long as you hold fixed all factors that are independent of x, an increase in x always leads to an increase in y. But I don&#8217;t think that&#8217;s right. This actually makes a big difference to the impossibility theorem.</p>
<p>Has anyone else thought about this?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/is-coherence-truth-conducive/feed/</wfw:commentRss>
		<slash:comments>18</slash:comments>
		</item>
		<item>
		<title>Foundations &#038; Coherence</title>
		<link>http://certaindoubts.com/foundations-coherence/</link>
		<comments>http://certaindoubts.com/foundations-coherence/#comments</comments>
		<pubDate>Wed, 14 Sep 2005 21:23:26 +0000</pubDate>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
				<category><![CDATA[foundationalism and coherentism]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=434</guid>
		<description><![CDATA[Hey, here&#8217;s a draft of my article on foundationalism &#038; coherentism for the next Blackwell Companion: Foundations &#038; Coherence Comments are welcome, including comments about what important things I&#8217;ve omitted (especially if I&#8217;ve omitted reference to an important work of &#8230; <a class="more-link" href="http://certaindoubts.com/foundations-coherence/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Hey, here&#8217;s a draft of my article on foundationalism &#038; coherentism for the next Blackwell Companion:<br />
<a href="http://home.sprynet.com/~owl1/foundations%20and%20coherence2.pdf">Foundations &#038; Coherence</a><br />
Comments are welcome, including comments about what important things I&#8217;ve omitted (especially if I&#8217;ve omitted reference to an important work of yours!).</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/foundations-coherence/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
		</item>
		<item>
		<title>Holistic vs. Linear Coherentism</title>
		<link>http://certaindoubts.com/430/</link>
		<comments>http://certaindoubts.com/430/#comments</comments>
		<pubDate>Sun, 04 Sep 2005 00:59:38 +0000</pubDate>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
				<category><![CDATA[foundationalism and coherentism]]></category>
		<category><![CDATA[general]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=430</guid>
		<description><![CDATA[I don&#8217;t understand holistic coherentism. Here&#8217;s what I know: Linear coherentism is the form of coherentism that endorses circular reasoning (provided the circle is big enough). Holistic coherentism is supposed to be an alternative form of coherentism, which avoids foundations, &#8230; <a class="more-link" href="http://certaindoubts.com/430/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I don&#8217;t understand holistic coherentism. Here&#8217;s what I know: Linear coherentism is the form of coherentism that endorses circular reasoning (provided the circle is big enough). Holistic coherentism is supposed to be an alternative form of coherentism, which avoids foundations, circularity, infinite regress, and skepticism. It makes justification â€˜holistic&#8217;. (Sorry, I don&#8217;t know what that means.) I&#8217;ve heard that the holistic coherentist believes:</p>
<blockquote><p>A belief is justified iff it is part of a coherent system of beliefs.</p></blockquote>
<p>This view is obviously false, since it implies that either all one&#8217;s beliefs are justified, or none of them are. If one&#8217;s belief system is coherent, then all one&#8217;s beliefs are justified; if it isn&#8217;t, then none of them are. I&#8217;m sure that the above offset proposition is not what many coherentists genuinely believe.</p>
<p>Leave that aside. What I don&#8217;t see is what logically possible alternative there is to (a) foundations, (b) circularity, (c) infinite regress, and (d) skepticism. Stated more generally, suppose there is a relation R, and a thing X that something might stand in R to. Consider the set of things that stand in the ancestral of R to X. This set of things either</p>
<p>(a) contains at least one thing such that nothing stands in R to it;<br />
(b) contains at least one thing that stands in the ancestral of R to itself;<br />
(c) contains infinitely many things that something stands in R to; or<br />
(d) is the empty set.</p>
<p>I take it that what I just asserted is simply a truth of logic, independent of what R is. When we let R be the &#8220;is a reason for&#8221; relation (or something like it, maybe &#8220;is <em>the </em> reason for&#8221;, or &#8220;is a thing that _____ depends for its justification on&#8221;), (a) is the foundationalist structure, (b) is the linear coherentist structure, (c) is the infinitist structure, and (d) is the skeptical &#8220;structure.&#8221; I don&#8217;t see any logical space for the holistic coherentist to be another position. Can someone help explain this to me?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/430/feed/</wfw:commentRss>
		<slash:comments>25</slash:comments>
		</item>
		<item>
		<title>The Knowledge Norm for Belief</title>
		<link>http://certaindoubts.com/the-knowledge-norm-for-belief/</link>
		<comments>http://certaindoubts.com/the-knowledge-norm-for-belief/#comments</comments>
		<pubDate>Fri, 29 Jul 2005 16:01:37 +0000</pubDate>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
				<category><![CDATA[general]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=394</guid>
		<description><![CDATA[What do you all think of this claim; I call it the Knowledge Norm for Belief: If one believes that P, then one is committed to the view that one knows that P. This is the thesis of a paper &#8230; <a class="more-link" href="http://certaindoubts.com/the-knowledge-norm-for-belief/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>What do you all think of this claim; I call it the <em>Knowledge Norm for Belief</em>:</p>
<blockquote><p>If one believes that P, then one is committed to the view that one knows that P.</p></blockquote>
<p>This is the thesis of a paper I&#8217;m working on, <a href="http://home.sprynet.com/~owl1/moore1.pdf">here</a>. Brief argument:</p>
<p>One can&#8217;t rationally assert things like, &#8220;It is raining, but I don&#8217;t know that it is&#8221;; that generates Moore&#8217;s Paradox. But actually, Moore&#8217;s Paradox can be formulated equally well in terms of belief: it&#8217;s irrational to think things like that to oneself, even without saying anything. But this wouldn&#8217;t be the case, unless thinking the first half of that committed you to denying the second half. So thinking that it&#8217;s raining commits you to your knowing that it&#8217;s raining.</p>
<p>Amendment:<br />
Here&#8217;s some more to get you all excited to read the paper. The Knowledge Norm is explained by two further principles:</p>
<p><em>Metacoherence:</em></p>
<blockquote><p>Believing that P commits you to comprehensively endorsing (epistemically) your own belief.</p></blockquote>
<p><em>The Endorsement Theory of Knowledge:</em></p>
<blockquote><p>Knowledge attribution is the most comprehensive (epistemic) endorsement of belief.</p></blockquote>
<p>Roughly, then, if you hold a belief, you have to think your belief is generally epistemically acceptable; and attributing knowledge to someone is giving the most comprehensive endorsement of this kind, that is, saying that they have a belief that is acceptable in all epistemic respects. (This is not rendered trivial by the meaning of &#8220;epistemically acceptable&#8221;; it is non-trivial and interesting that there is a kind of evaluation, which applies distinctively to beliefs, such that knowledge attribution gives a kind of comprehensive positive evaluation of that kind, of a belief.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/the-knowledge-norm-for-belief/feed/</wfw:commentRss>
		<slash:comments>63</slash:comments>
		</item>
		<item>
		<title>Does Warrant Exist?</title>
		<link>http://certaindoubts.com/does-warrant-exist/</link>
		<comments>http://certaindoubts.com/does-warrant-exist/#comments</comments>
		<pubDate>Tue, 01 Feb 2005 06:36:26 +0000</pubDate>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
				<category><![CDATA[knowledge]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=252</guid>
		<description><![CDATA[In a paper that will someday appear in Phil Studies, if the sun doesn&#8217;t burn out first, I said something like that &#8220;warrant&#8221; doesn&#8217;t exist, because there is no unique property that, when conjoined with true belief, gives you knowledge. &#8230; <a class="more-link" href="http://certaindoubts.com/does-warrant-exist/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>In a paper that will someday appear in <em>Phil Studies</em>, if the sun doesn&#8217;t burn out first, I said something like that &#8220;warrant&#8221; doesn&#8217;t exist, because there is no unique property that, when conjoined with true belief, gives you knowledge. E. J. Coffman has responded to my argument, <a href="http://www.nd.edu/~ecoffman/elwej2draft.pdf">here</a>. Maybe some of you would be interested. Summary of my argument:</p>
<p>&#8220;Warrant&#8221; is supposed to be that which, when conjoined with true belief, yields knowledge. Suppose that Ksp = (S believes that p, p is true, and Wp). (&#8220;=&#8221; stands for logical equivalence.) Then consider another property, (True(x) -> Wx) (that&#8217;s a material conditional, so that&#8217;s the property of either being false or having W). It will also be true that Ksp = (S believes that p, p is true, and [True(p) -> Wp]). Therefore, if there is a property that when conjoined with true belief yields knowledge, then there is more than one such property. So there is no unique property that when conjoined with true belief yields knowledge. So warrant doesn&#8217;t exist. (Actually, in the paper, I said we should recognize the existence of &#8220;multiple warrant properties.&#8221;)</p>
<p>Coffman thinks this is wrong because warrant is not merely the property that when added to true belief yields knowledge; rather, warrant is the property such that (i) when you add it to true belief you get knowledge, <em>and</em> (ii) any belief that has it thereby has some positive epistemic status (&#8220;has moved toward constituting knowledge&#8221;). (See his pp. 9-15.) (True(x) -> Wx) doesn&#8217;t count, because every false belief has it automatically, but it&#8217;s not the case that every false belief has some positive epistemic status.</p>
<p>What do you all think about this debate?</p>
<p>My own view (we&#8217;ve just discussed this in email) is that the notion of positive epistemic status is unclear and that there may be no such thing as that either. (Details to follow.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/does-warrant-exist/feed/</wfw:commentRss>
		<slash:comments>14</slash:comments>
		</item>
		<item>
		<title>Epistemic Possibility</title>
		<link>http://certaindoubts.com/epistemic-possibility/</link>
		<comments>http://certaindoubts.com/epistemic-possibility/#comments</comments>
		<pubDate>Thu, 30 Sep 2004 07:13:39 +0000</pubDate>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
				<category><![CDATA[general]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=148</guid>
		<description><![CDATA[I&#8217;m working on a paper about epistemic possibility, and I need some help. Can someone tell me what epistemic possibility is? (This is a trick question.) To show why this is puzzling, here is a &#8216;problem case&#8217;: S, a person &#8230; <a class="more-link" href="http://certaindoubts.com/epistemic-possibility/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I&#8217;m working on a paper about epistemic possibility, and I need some help. Can someone tell me what epistemic possibility is? (This is a trick question.) To show why this is puzzling, here is a &#8216;problem case&#8217;:</p>
<p>S, a person of ordinary mathematical abilities, performs a complex mathematical calculation, which leads to a certain mathematical claim, P. S and I then have the following dialogue:</p>
<p>S: P.<br />
Me: That was a pretty difficult calculation, and you&#8217;ve made mistakes before. Could you be wrong about P?<br />
S: Yes. I could be wrong in thinking that P.</p>
<p>S speaks wisely here. But, if P is true, it is necessary in (what is usually called) the strongest sense: logical necessity. So in what sense <em>could</em> S be wrong? Well, it&#8217;s <em>epistemically</em> possible that S is wrong: yes, but how is that to be interpreted, such that it yields a kind of possibility broader than logical possibility?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/epistemic-possibility/feed/</wfw:commentRss>
		<slash:comments>49</slash:comments>
		</item>
	</channel>
</rss>
