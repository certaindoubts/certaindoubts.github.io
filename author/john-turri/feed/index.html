<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>John Turri &#8211; </title>
	<atom:link href="http://certaindoubts.com/author/john-turri/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 01:35:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>New empirical studies on epistemic contextualism</title>
		<link>http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/</link>
		<comments>http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/#comments</comments>
		<pubDate>Sun, 28 Feb 2016 18:26:42 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[contextualism]]></category>
		<category><![CDATA[general]]></category>
		<category><![CDATA[knowledge]]></category>
		<category><![CDATA[experimental epistemology]]></category>
		<category><![CDATA[methodology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4748</guid>
		<description><![CDATA[Epistemic contextualism is the view that the verb “know” is a context sensitive expression. As a first approximation, epistemic contextualism states that in order for us to truthfully say a person “knows” a proposition, that person must meet the standards &#8230; <a class="more-link" href="http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Epistemic contextualism is the view that the verb “know” is a context sensitive expression. As a first approximation, epistemic contextualism states that in order for us to truthfully say a person “knows” a proposition, that person must meet the standards set by our context and, critically, the standards change across contexts. The variation is thought to be theoretically important partly because it might indicate an ingredient of (the truth conditions of) &#8220;knowledge&#8221; statements beyond the traditional factors of belief, evidence, and truth.</p>
<p>Contextualists motivate their view based on a set of empirical claims about competent speakers’ linguistic behavior in certain situations. A famous way of illustrating the idea involves a pair of cases about a man who wants to deposit a check and is deciding whether to wait in a long line at the bank on a Friday afternoon, or come back on Saturday morning when the line would be short. But the question arises: is this bank actually open Saturday morning? The man visited this bank two Saturdays ago and it was open then, but banks do sometimes change their hours. In the “low stakes” version of the case, nothing serious hinges on whether he deposits the check before the weekend is over, and the man says, “I know that the bank is open tomorrow.” In the “high stakes” version of the case, something very serious hinges on whether he deposits the check before the weekend is over, and the man says, “I don’t know that the bank is open tomorrow.”</p>
<p>Contextualists claim that competent speakers will judge that the man truthfully says he “knows” in the low stakes version, and that the man truthfully says he “doesn’t know” in the high stakes version.</p>
<p>Do people behave as contextualists predict? Prior research on this empirical question has yielded mixed results. Taking into account methodological objections raised by contextualists,* I ran another series of studies to investigate the issue.** I found that, <strong><span style="color: #0000ff">just as contextualists predicted</span></strong>, people judged that the man truthfully says he “knows” in the low stakes case, and that the man truthfully says he “doesn’t know” in the high-stakes case.<span id="more-4748"></span></p>
<p>&nbsp;</p>
<p>However, I also found two other things that make it very difficult to interpret this as evidence for contextualism.</p>
<p>On the one hand, there is <span style="color: #0000ff"><strong>the general shifting problem</strong></span>: switching from low to high stakes also significantly decreased belief attributions, the evaluation of the agent’s evidence, and people’s confidence that the bank was open tomorrow. Thus, the contextualist hypothesis is not needed to explain the observed pattern in knowledge judgments: it could easily be explained by changes in underlying judgments about belief, evidence, and truth. This confirms some suspicions voiced by some philosophers over the years (e.g. Kent Bach and Jennifer Nagel).</p>
<p>On the other hand, there is <strong><span style="color: #0000ff">the deferral confound</span></strong>. Even if nothing about stakes or error possibilities is mentioned, people tend to agree that the agent speaks truthfully when he says “I know,” and they also tend to agree when he says “I don’t know.” In short, people tend to defer to another person’s self-regarding knowledge statement. (Some evidence for this might also be gleaned from earlier work by Wesley Buckwalter and Nat Hansen &amp; Emmanuel Chemla.)*** Unfortunately, this low-level agreement bias has been obscured because contextualist test cases are multiply confounded.</p>
<p>To illustrate the deferral confound, consider a pair of cases I tested, which involve not a low/high manipulation but rather a yes/no manipulation:</p>
<p style="padding-left: 30px">(Yes/No) Keith and his wife Jane are driving home from work on Friday afternoon. They just received a check from a client, which Keith plans to deposit in their bank account. As they drive past the bank, they see that the lines inside are very long. Keith says, “I hate waiting in line. I’ll just come back tomorrow morning instead.” Jane asks, “Do you know that our bank is open tomorrow?” Keith answers, “It was two Saturdays ago that I went to our bank, and it was open. So, [yes, I do/no, I don’t] know that our bank is open tomorrow.”</p>
<p>People tended to agree with the agent in both cases. Thus manipulating stakes (low/high) is not needed to produce the basic pattern in knowledge judgments that contextualists have focused on. Moreover, a follow-up study revealed that when the deferral confound is removed, manipulating stakes does not produce the relevant pattern in knowledge judgments: instead, people tend to (meta-linguistically) attribute knowledge in both low and high stakes cases (i.e. they say that the man should say “I know” in order to speak truthfully).</p>
<p>Based on these findings — all of which were replicated across multiple cover stories — I conclude that the principal extant motivation for contextualism fails. Contextualists still owe us a distinguishing prediction of their view, something we would confidently expect only if contextualism were true, or which contextualism seems uniquely suited to explain. Absent that, contextualism is an idle hypothesis and we should not accept it.</p>
<p>Of course, it is consistent with these findings that such a prediction will be made and vindicated. That would be an interesting development! But, moving forward, hopefully the theoretical debate will not get too far out ahead of available evidence. The fact that experimental epistemology is now a firmly established and growing interdisciplinary field will likely help in this regard.</p>
<p>* DeRose, K. (2011). <a href="http://link.springer.com/article/10.1007%2Fs11098-011-9799-x?LI=true" target="_blank">Contextualism, contrastivism, and X-Phi surveys</a>. <em>Philosophical Studies</em>, 156(1), 81–110.</p>
<p>** Turri, J. (in press). <a href="http://john.turri.org/research/idle.pdf" target="_blank">Epistemic contextualism: an idle hypothesis</a>. <em>Australasian Journal of Philosophy</em>.</p>
<p>*** For discussion, see Buckwalter, W. (in press). Epistemic contextualism and linguistic behavior. In Ichikawa, J. J. (Ed.), <em>Handbook of Epistemic Contextualism</em>. Routledge.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
		</item>
		<item>
		<title>What philosophers think might not be what you think they think</title>
		<link>http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/</link>
		<comments>http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/#comments</comments>
		<pubDate>Sun, 14 Feb 2016 04:13:24 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4738</guid>
		<description><![CDATA[Professional philosophers often appeal to patterns in ordinary thought and talk — “commonsense” — in order to support theories or assumptions. In recent years, the emerging interdisciplinary field of experimental epistemology has revealed many instances where commonsense epistemology has been &#8230; <a class="more-link" href="http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Professional philosophers often appeal to patterns in ordinary thought and talk — “commonsense” — in order to support theories or assumptions. In recent years, the emerging interdisciplinary field of experimental epistemology has revealed many instances where commonsense epistemology has been seriously mischaracterized. But even if professional philosophers misidentify what the folk think about knowledge, certainly they know what they themselves think about knowledge. Right?</p>
<p>Wrong.</p>
<p>In a fascinating <a href="http://link.springer.com/article/10.1007/s11098-016-0627-1">paper</a> forthcoming in <em>Philosophical Studies</em>, a pair of researchers tested ordinary people and professional philosophers (“experts”) on a range of cases.* A principal finding concerns knowledge attributions in cases where an agent sees an object that is surrounded by visually indistinguishable fakes.<span id="more-4738"></span></p>
<p>Here is one case they tested:</p>
<p style="padding-left: 30px">(Sculpture) The director of a sculpture museum is so impressed with recent improvements of hologram images that she decides to perform a secret test on the visitors of her museum. To this end, she orders hologram images that even art experts cannot visually distinguish from the real sculptures in her museum, and she replaces all but one of the sculptures by their hologram image. As the director had expected, no one realizes any difference between the hologram images and the real sculptures. One day, the world’s greatest Rodin expert is visiting her museum. The expert is standing in front of a famous marble sculpture by Rodin, which is the only real sculpture that is presently on display in the museum, and she thinks to herself: “I’m facing one of Rodin’s famous marble sculptures now.”</p>
<p>Participants rated their agreement with whether &#8220;the Rodin expert knows that the sculpture in front of her is one of Rodin’s famous marble sculptures.”</p>
<p>The case is structurally similar to the famous “fake barn” case. Textbooks and review articles tell us that there is “broad agreement” among experts that these aren’t cases of knowledge. And this verdict is often treated as a litmus test for theories of knowledge: if your view implies that there is knowledge in a “fake barn&#8221; case, this is often treated as a decisive refutation of your view. Accordingly, we would expect that most experts will deny that Sculpture is a case of knowledge.</p>
<p>But that’s not what the researchers found. Instead, a majority of experts <em>attributed</em> knowledge. Surprised, the researchers tested the case again on another group of experts. And, just for good measure, they tested another case with a “fake barn” structure too. Perhaps the initial result was a fluke?</p>
<p>It wasn’t.</p>
<p>Again and again, most experts attributed knowledge. Ongoing work by another team of researchers has returned broadly similar results.**</p>
<p>The researchers also found that in a case structurally similar to a “lottery case,” the majority of experts attributed knowledge, which again contradicts “the textbook consensus.”</p>
<p>Based on these findings, the researchers concluded that “the discipline of epistemology is dysfunctional insofar” as it is “deluded about” its practitioners&#8217; verdicts about cases.</p>
<p>I’ve only covered some of the paper&#8217;s interesting findings. Check it out!</p>
<p>*Horvath, J., &amp; Wiegmann, A. (2016). Intuitive expertise and intuitions about knowledge. Philosophical Studies, 1–26. http://doi.org/10.1007/s11098-016-0627-1</p>
<p>**Carter, J. A., Pritchard, D., &amp; Sheperd, J. (ms). Knowledge-how, understanding-why and epistemic luck: an experimental study.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/feed/</wfw:commentRss>
		<slash:comments>37</slash:comments>
		</item>
		<item>
		<title>Proto-reliabilism followup</title>
		<link>http://certaindoubts.com/proto-reliabilism-followup/</link>
		<comments>http://certaindoubts.com/proto-reliabilism-followup/#comments</comments>
		<pubDate>Sun, 24 Jan 2016 04:09:59 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[memory]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4722</guid>
		<description><![CDATA[Following up on some thoughtful suggestions in the comments to my previous post, I ran a couple follow-up studies with modified stimuli. One main question was whether people understood an &#8220;unreliable memory&#8221; to mean (1) most of the agent&#8217;s apparent memories contain false &#8230; <a class="more-link" href="http://certaindoubts.com/proto-reliabilism-followup/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Following up on some thoughtful suggestions in the comments to my <a href="http://certaindoubts.com/the-proto-reliabilist-hypothesis/">previous post</a>, I ran a couple follow-up studies with modified stimuli.<span id="more-4722"></span></p>
<p>One main question was whether people understood an &#8220;unreliable memory&#8221; to mean (1) most of the agent&#8217;s apparent memories contain false information, as opposed to (2) most of the agent apparent memories contain true information, even though the agent fails to retain information most of the time. If people understand &#8220;unreliable memory&#8221; in sense 2, then it could complicate the interpretation of one of the findings that undermine the proto-reliabilist hypothesis. Will we observe similar results if it&#8217;s made clearer that sense 1 is at issue?</p>
<p>To emphasize sense 1, I tested the following pair of cases (the reliability manipulation is bracketed):</p>
<p style="padding-left: 30px">Alvin is [unreliable/reliable] at remembering driving directions. Usually when it seems to him that he should make a particular turn, he’s [incorrect/correct]. Today Alvin is visiting a friend in an unfamiliar town. Alvin needs to pick up a prescription while he is there, so his friend gives him directions to the pharmacy. On the way, Alvin needs to turn right at Main Street. Alvin gets to Main Street and turns right, which is the correct turn.</p>
<p>People rated whether Alvin &#8220;knew&#8221; or &#8220;only thought&#8221; that &#8220;he needed to turn right at Main Street.&#8221; The rate of knowledge attribution was very high in both conditions: 83% in the unreliable condition and 97% in the reliable condition. This numerical difference did not reach statistical significance at the conventional .05 level  (N = 60, p = .098, v = .07). I then conducted a second follow-up with the same cases but a more sensitive 7-point scaled knowledge attribution. Mean knowledge attribution was again very high in both conditions: 6.13 in the unreliable condition and 5.71 in the reliable condition and the difference was not significant (N = 61, p = .290).</p>
<p>I believe that these results should make us more confident that knowledge ordinarily understood does not require reliability in sense 1. Of course, these results cannot show that there is no conceptual connection between reliability and knowledge, but the relationship does not appear to be (in the ballpark of) a necessary condition.</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilism-followups.png" rel="attachment wp-att-4723"><img class="alignnone wp-image-4723 size-full" src="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilism-followups-e1453607364487.png" alt="protoreliabilism-followups" width="500" height="360" /></a></p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/proto-reliabilism-followup/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>The proto-reliabilist hypothesis</title>
		<link>http://certaindoubts.com/the-proto-reliabilist-hypothesis/</link>
		<comments>http://certaindoubts.com/the-proto-reliabilist-hypothesis/#comments</comments>
		<pubDate>Thu, 21 Jan 2016 19:09:33 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4713</guid>
		<description><![CDATA[I conducted a simple study to determine whether knowledge, ordinarily understood, requires reliability.]]></description>
				<content:encoded><![CDATA[<p>In contemporary Anglo-American epistemology, it is very widely assumed that knowledge must be reliably produced. On this view, knowledge must be produced by abilities (processes, faculties, powers, etc.) that “will or would yield mostly true beliefs,” as William Alston put it. Call this consensus view “knowledge reliabilism.”</p>
<p>One thing I’ve always been surprised by is how little explicit, direct argumentation there is for knowledge reliabilism in the literature. An old paper by Goldman contains a weak explanatory argument, which gets cited sometimes. Aside from that, the main consideration offered in support of knowledge reliabilism is that it’s just commonsense. For instance, Edward Craig claims that reliabilism “matches our everyday practice with the concept of knowledge as actually found,” that it is “a good fit to the intuitive extension of ‘know’.” And Ernest Sosa claims that reliabilism is the theoretical “correlate” of “commonsense” epistemology. Call this “the proto-reliabilist hypothesis” about folk epistemology.</p>
<p>The proto-reliabilist hypothesis makes at least a couple straightforward predictions. First, people will tend to deny knowledge in cases of unreliably formed belief. Second, clear and explicit differences in reliability should produce large differences in people’s willingness to attribute knowledge. These predictions can be tested with some very simple experiments. Below I briefly describe one I ran.<span id="more-4713"></span></p>
<p>Participants read a brief story about Alvin. While visiting a friend in an unfamiliar town, Alvin needs to pick up a prescription. He’s on his way to the pharmacy and approaches an intersection where he needs to turn right. Some crucial details of the story differed across conditions. I manipulated whether Alvin was very unreliable or very reliable at remembering driving directions. I also manipulated whether he made the incorrect or correct turn at the intersection. Here is the text participants read, with the two manipulations noted in brackets:</p>
<p style="padding-left: 30px">Alvin is very [unreliable/reliable] at remembering driving directions. Today he is visiting a friend in an unfamiliar town. Alvin needs to pick up a prescription while he is there, so his friend gives him directions to the pharmacy. On the way, Alvin needs to make a [left/right] turn at an intersection. Alvin gets to the intersection and turns right.</p>
<p>Participants then responded to an open knowledge probe:</p>
<p style="padding-left: 30px">When he got to the intersection, Alvin _____ that he should turn right to get to the pharmacy.</p>
<p>The options were “knew” and “only thought.” Here are the results:</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm.jpg" rel="attachment wp-att-4717"><img class="alignnone size-full wp-image-4717" src="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm.jpg" alt="protoreliabilsm" width="1004" height="710" srcset="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm.jpg 1004w, http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm-300x212.jpg 300w, http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm-768x543.jpg 768w, http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm-424x300.jpg 424w" sizes="(max-width: 1004px) 100vw, 1004px" /></a></p>
<p>&nbsp;</p>
<p>The results from the two conditions where Alvin makes the incorrect turn (the &#8220;false&#8221; conditions) were exactly as you would expect: he thinks he should turn left, so people overwhelmingly denied that he knows he should turn right. But the results from the two conditions where Alvin makes the correct turn (the &#8220;true&#8221; conditions) were very different from what the proto-reliabilist hypothesis predicts. When Alvin made the correct turn, people attributed knowledge at similarly high rates, regardless of whether he was very reliable or very unreliable at remembering driving directions (80% vs. 77%).</p>
<p>This same basic pair of findings — high rates of knowledge attribution for beliefs produced by unreliable abilities, and little to no effect of reliability/unreliability on knowledge attributions — replicates across different narrative contexts, cognitive abilities, and ways of measuring knowledge attributions.</p>
<p>Overall, this leads me to conclude that the proto-reliabilist hypothesis is false. Knowledge ordinarily understood does not require reliability.</p>
<p>(A fuller description of these findings and other studies can be found in a <a href="http://john.turri.org/research/paradigm.pdf" target="_blank">paper</a> forthcoming in Ergo.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/the-proto-reliabilist-hypothesis/feed/</wfw:commentRss>
		<slash:comments>15</slash:comments>
		</item>
		<item>
		<title>Truth-insensitive epistemology: radical or commonsense?</title>
		<link>http://certaindoubts.com/truth-insensitive-epistemology-radical-or-commonsense/</link>
		<comments>http://certaindoubts.com/truth-insensitive-epistemology-radical-or-commonsense/#comments</comments>
		<pubDate>Sat, 13 Jun 2015 20:13:06 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[experimental epistemology]]></category>
		<category><![CDATA[experimental philosophy]]></category>
		<category><![CDATA[folk epistemology]]></category>
		<category><![CDATA[internalism]]></category>
		<category><![CDATA[issues in the profession]]></category>
		<category><![CDATA[thought experiments]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4625</guid>
		<description><![CDATA[Many philosophers endorse a truth-insensitivity hypothesis: certain core, philosophically important evaluative properties of a belief are insensitive to whether it is true. For example, if two possible agents believe the same proposition for the same reason, then either both are &#8230; <a class="more-link" href="http://certaindoubts.com/truth-insensitive-epistemology-radical-or-commonsense/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Many philosophers endorse a <em>truth-insensitivity hypothesis</em>: certain core, philosophically important evaluative properties of a belief are insensitive to whether it is true. For example, if two possible agents believe the same proposition for the same reason, then either both are justified or neither is. This does not change if it turns out that only one of the two agents has a true belief. Epitomizing this line of thought are thought experiments about radically deceived “brains in vats.”</p>
<p>Proponents claim that the truth-insensitivity hypothesis is extremely intuitive and appealing pre-theoretically — we have an “overpowering inclination” to think that it’s true (Richard Fumerton). To deny the truth-insensitivity hypothesis has been labelled “extraordinary” and “dissident” (Earl Conee). However, other philosophers claim that exactly the opposite is true: the truth-insensitivity hypothesis itself is counterintuitive and violates commonsense. The appeal of truth-insensitive epistemology, they claim, is limited to narrow circles within “the professional philosophical community” (Jonathan Sutton).</p>
<p>In a <a href="http://john.turri.org/research/radicalism.pdf" target="_blank">paper</a> forthcoming in <em>Philosophy and Phenomenological Research</em>, I investigated which side of this debate is correct. Proponents of the truth-insensitivity hypothesis illustrate their view’s plausibility with pairs of thought experiments. These pairs include mundane cases and fanciful “brain-in-a-vat” scenarios. I tested both sorts of cases.</p>
<p>Across three experiments (N = 1262), the results were absolutely clear:<span id="more-4625"></span></p>
<p>Ordinary evaluations of belief were <strong>deeply truth-sensitive</strong>. There was a consistent pattern whereby belief and evidence were judged much more favorably when the proposition in question was true rather than false. This was true across multiple narrative contexts and for evaluations elicited with a wide range of normative vocabulary (e.g. justification, evidence, rationality, reasonableness, responsibility, and what an agent should believe). It was true when people judged the pairs of cases separately (between-subjects) and when they judged the cases simultaneously (within-subjects). The basic finding appears to be very robust.</p>
<p>I find it fascinating that commonsense cuts so strongly against truth-insensitivity. I also find it somewhat disconcerting in light of the way introductory texts tend to treat the matter. For instance, how many epistemology students in recent decades have had their own judgments marginalized or contradicted by what “we” find intuitively compelling, and to what effect? That seems like a question researchers in the field should take seriously.</p>
<p>(<em>x-posted at the x-blog</em>)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/truth-insensitive-epistemology-radical-or-commonsense/feed/</wfw:commentRss>
		<slash:comments>19</slash:comments>
		</item>
		<item>
		<title>Epistemic closure and folk epistemology</title>
		<link>http://certaindoubts.com/closure-and/</link>
		<comments>http://certaindoubts.com/closure-and/#comments</comments>
		<pubDate>Sat, 06 Sep 2014 23:05:40 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[experimental philosophy]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4475</guid>
		<description><![CDATA[Consider this case: When Maxwell arrives at work in the morning, he always parks in one of two spots: C8 or D8. Half the time he parks in C8, and half the time he parks in D8. Today Maxwell parked &#8230; <a class="more-link" href="http://certaindoubts.com/closure-and/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Consider this case:</p>
<p style="padding-left: 30px">When Maxwell arrives at work in the morning, he always parks in one of two spots: C8 or D8. Half the time he parks in C8, and half the time he parks in D8. Today Maxwell parked in C8. It’s lunchtime at work. Maxwell and his assistant are up in the archives room searching for a particular document. Maxwell says, “I might have left the document in my car.” The assistant asks, “Mr. Maxwell, is your car parked in space C8? It’s not unheard of for cars to be stolen.” Maxwell thinks carefully for a moment and then responds, “No, my car has not been stolen. It is parked in C8.”</p>
<p>Which of the following options best describes Maxwell?</p>
<ol>
<li>He knows that his car is parked in C8. And he knows that his car has not been stolen.</li>
<li>He does not know that his car is parked in C8. But he does know that his car has not been stolen.</li>
<li>He knows that his car is parked in C8. But he does not know that his car has not been stolen.</li>
<li>He does not know that his car is parked in C8. And he does not know that his car has not been stolen.</li>
</ol>
<p>The epistemic closure principle says, roughly, that if one knows that P, and one knows that if P then Q, and one infers Q, then one knows Q. Some philosophers, most notably Robert Nozick and Fred Dretske, reject the closure principle. However, many epistemologists have claimed that rejecting closure is extremely counterintuitive and radically revisionary. Related to these claims, philosophers have also claimed that conjunctive assertions suggesting a violation of closure are &#8220;abominable&#8221; and &#8220;repugnant.&#8221;</p>
<p>So if conventional wisdom in epistemology is correct, then when people consider the question about Maxwell above, the intuitively best answer will not be option 3. Instead, option 3 should seem absurd.</p>
<p>However, as reported in a <span style="text-decoration: underline"><strong><a href="http://john.turri.org/research/open_shut.pdf" target="_blank">paper</a></strong></span> forthcoming in <em>Philosophers&#8217; Imprint</em>, when I tested this case, it turned out that option 3 was viewed as <em>the best option</em>: nearly two-thirds of participants selected it.</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2014/09/best-option.png"><img class="alignnone  wp-image-4480" src="http://certaindoubts.com/wp-content/uploads/2014/09/best-option.png" alt="best option" width="488" height="311" /></a></p>
<p>&nbsp;</p>
<p>We see a similar pattern if we just ask people whether (A) Maxwell knows that his car is parked in the lot, and (B) Maxwell knows that his car has not been stolen. Roughly 80% of people agree with A, while only about 35% of people agree with B.</p>
<p>In light of these results, it seems that closure-denying conjunctions don&#8217;t actually strike people as absurd. Moreover, it is highly doubtful that rejecting the epistemic closure principle actually is revisionary.</p>
<p>&nbsp;</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/closure-and/feed/</wfw:commentRss>
		<slash:comments>36</slash:comments>
		</item>
		<item>
		<title>Where the action is</title>
		<link>http://certaindoubts.com/where-the-action-is/</link>
		<comments>http://certaindoubts.com/where-the-action-is/#comments</comments>
		<pubDate>Sat, 10 May 2014 17:41:56 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4378</guid>
		<description><![CDATA[I heard through the grapevine that Jason Stanley is claiming on Facebook that there is an emerging consensus in the experimental literature. The consensus is that there is a robust stakes-effect on knowledge attributions, and the real debate is whether &#8230; <a class="more-link" href="http://certaindoubts.com/where-the-action-is/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p style="color: #000000">I heard through the grapevine that Jason Stanley is claiming on Facebook that there is an emerging consensus in the experimental literature. The consensus is that there is a robust stakes-effect on knowledge attributions, and the real debate is whether to explain it in terms of semantic contextualism or interest-relative invariantism. I&#8217;m not on Facebook and have no plans to ever be, so apologies to Jason if this is not an accurate portrayal of what he wrote. But since it&#8217;s generating enough buzz for me to hear about it second- and third-hand, I figured I&#8217;d take to the air here and help to correct any misimpression, even if the misimpression is due to people mischaracterizing Jason&#8217;s post.</p>
<p style="color: #000000">There is no such consensus. How much is at stake, or how important people judge the situation to be, has an anemic and entirely indirect effect on knowledge attributions. Moreover, the stakes/importance-effect on knowledge attributions is entirely mediated by people&#8217;s estimation of whether the proposition in question is true and their estimation of the quality of evidence. Consequently, there is very little if anything for contextualism or interest-relative invariantism to explain.</p>
<p style="color: #000000">By contrast, people&#8217;s judgment about <em>whether an agent should act</em> on a proposition has a direct and robust effect on knowledge attributions. The effect of actionability on knowledge attributions is as large and direct as the effect of truth and evidence.</p>
<p style="color: #000000">In short, a practical factor definitely plays a large role in ordinary knowledge attributions and might even be part of the ordinary concept of knowledge. But that factor is not stakes. It is actionability.</p>
<p style="color: #000000">For those that are interested, I&#8217;ll be presenting some joint work with Wesley Buckwalter at <a href="http://philosophycommons.typepad.com/xphi/2014/03/symposium-at-the-2014-canadian-annual-congress-on-experimental-philosophy.html">the CPA in St. Catharines, Ontario later this month</a>, where I&#8217;ll walk through the relevant findings from some recent, very large behavioral experiments.</p>
<p style="color: #000000">(<a href="http://philosophycommons.typepad.com/xphi/2014/05/where-the-action-is.html">Cross-posted at the x-phi blog</a>.)</p>
<p> </p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/where-the-action-is/feed/</wfw:commentRss>
		<slash:comments>96</slash:comments>
		</item>
		<item>
		<title>Out with the old &#8230;</title>
		<link>http://certaindoubts.com/out-with-the-old/</link>
		<comments>http://certaindoubts.com/out-with-the-old/#comments</comments>
		<pubDate>Tue, 31 Dec 2013 22:11:59 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[perception]]></category>
		<category><![CDATA[skepticism]]></category>
		<category><![CDATA[cognitive science]]></category>
		<category><![CDATA[experimental philosophy]]></category>
		<category><![CDATA[inference]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4222</guid>
		<description><![CDATA[&#8230; skeptical arguments. A new paper of mine, &#8220;Skeptical Appeal: The Source-Content Bias&#8221; (forthcoming in Cognitive Science), uncovers a subtle mechanism that triggers knowledge-denial and contributes to the appeal of classic skeptical arguments. The mechanism is an interaction between two factors. &#8230; <a class="more-link" href="http://certaindoubts.com/out-with-the-old/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>&#8230; skeptical arguments.</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2013/12/images.jpeg"><img class=" wp-image-4224     alignleft" alt="car_theft" src="http://certaindoubts.com/wp-content/uploads/2013/12/images.jpeg" width="179" height="118" /></a></p>
<p><a style="font-size: 16px;line-height: 1.4em" href="http://certaindoubts.com/wp-content/uploads/2013/12/images-2.jpeg"><img class="    alignnone" alt="big_cat" src="http://certaindoubts.com/wp-content/uploads/2013/12/images-2.jpeg" width="180" height="119" /></a></p>
<p>A new paper of mine, &#8220;<span style="color: #3366ff"><a title="Skeptical Appeal: The Source-Content Bias" href="http://john.turri.org/research/Appeal.pdf" target="_blank"><span style="color: #3366ff">Skeptical Appeal: The Source-Content Bias</span></a></span>&#8221; (forthcoming in <em>Cognitive Science</em>), uncovers a subtle mechanism that triggers knowledge-denial and contributes to the appeal of classic skeptical arguments.</p>
<p>The mechanism is an interaction between two factors. First, people evaluate inferential belief more harshly than perceptual belief. Second, people evaluate inferential belief more harshly when its content is negative (i.e. that something is not the case) than when it’s positive (i.e. that something is the case). That is, our cognitive evaluations are biased against this specific combination of source and content.</p>
<p>The skeptic exploits, perhaps unwittingly, the source-content bias. It just so happens that certain skeptical arguments tend to focus our attention on negative inferential beliefs, and we are especially prone to doubt that such beliefs count as knowledge.</p>
<p>Philosophers have long appreciated that research into features of language might help shed light on skeptical appeal (e.g. Cohen/DeRose/Lewis style contextualism, or invariantist proposals that invoke pragmatics). My New Year&#8217;s resolution: to keep firmly in mind that philosophically-informed research into features of our psychology can be equally helpful.</p>
<p>Who&#8217;ll join me?</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/out-with-the-old/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>The final nail</title>
		<link>http://certaindoubts.com/the-final-nail/</link>
		<comments>http://certaindoubts.com/the-final-nail/#comments</comments>
		<pubDate>Sat, 06 Jul 2013 19:16:48 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[testimony and social epistemology]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4077</guid>
		<description><![CDATA[Going back to at least G.E. Moore, philosophers have steadily built a strong case that the social practice of assertion is constituted by a knowledge norm: you should assert Q only if you know Q is true. As best I &#8230; <a class="more-link" href="http://certaindoubts.com/the-final-nail/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Going back to at least G.E. Moore, philosophers have steadily built a strong case that the social practice of assertion is constituted by a knowledge norm: you should assert Q only if you know Q is true. As best I can tell, this &#8220;knowledge account,&#8221; as it&#8217;s often called, is by now the best supported hypothesis in contemporary epistemology. It teaches us something deep and important about an absolutely central aspect of our lives as social beings. It&#8217;s a hard-won discovery that illustrates philosophy&#8217;s value, exemplifies genuine philosophical progress, and is something we as a discipline can be proud of.</p>
<p>Whenever I explain the knowledge account as part of a presentation or in conversation, the primary &#8212; indeed, pretty much the only &#8212; objection I hear is that it&#8217;s counterintuitive and, by way of illustration, purported counterexamples are adduced. The examples feature subjects who assert false but well justified beliefs. This is usually followed by the proposal that justified belief, not knowledge, is the norm of assertion. I&#8217;m also often told that this is the &#8220;ordinary&#8221; or &#8220;commonsense&#8221; view and that it&#8217;s a foible of epistemologists to place knowledge, or anything other factive state, into that role.</p>
<p>In a <span style="text-decoration: underline;color: #0000ff"><a href="http://john.turri.org/research/Truth_Test.pdf"><span style="color: #0000ff;text-decoration: underline">new paper to appear in <em>Cognition</em></span></a></span>, I report a series of experimental studies which strongly suggest that these objections and examples do not reflect the commonsense view. Instead, just the opposite seems to be true: the ordinary view is that we should <em>not</em> assert false claims, even ones extremely well supported by the evidence. By contrast, asserting well justified true claims is perfectly fine.</p>
<p>Interestingly, it turns out that resistance to a factive account of assertion&#8217;s norm is at least partly driven by a general psychological tendency that many people have to excuse blameless transgressions by (falsely) denying that any transgression has occurred.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/the-final-nail/feed/</wfw:commentRss>
		<slash:comments>29</slash:comments>
		</item>
		<item>
		<title>Tim Cook: Apple CEO and friend of the a priori</title>
		<link>http://certaindoubts.com/tim-cook-apple-ceo-and-friend-of-the-a-priori/</link>
		<comments>http://certaindoubts.com/tim-cook-apple-ceo-and-friend-of-the-a-priori/#respond</comments>
		<pubDate>Mon, 10 Dec 2012 02:15:57 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[a priori knowledge]]></category>
		<category><![CDATA[CEO epistemologists]]></category>
		<category><![CDATA[philosophy in the news]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=3830</guid>
		<description><![CDATA[Brian Williams: What’s the role of intuition in your job? Tim Cook: It’s critical. It’s extremely critical. The most important things in life, whether they’re personal or professional, are decided on intuition. I think you can have a lot of &#8230; <a class="more-link" href="http://certaindoubts.com/tim-cook-apple-ceo-and-friend-of-the-a-priori/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p><em>Brian Williams</em>: <strong>What’s the role of intuition in your job</strong>?<br />
<em></em></p>
<p><em>Tim Cook</em>: It’s critical. It’s extremely critical. The most important things in life, whether they’re personal or professional, are decided on intuition. I think you can have a lot of information and data feeding that intuition. You can do a lot of analysis. You can do lots of things that are quantitative in nature. But at the end of it, the things that are most important are always gut calls. And I think that’s just not true for me, but for many, many people. I don’t think it’s unique.</p>
<p><em>Brian Williams</em>: Fascinating. Absolutely fascinating.</p>
<p><em>Cook {reaches into his bag and hands Williams a worn out copy of <span style="text-decoration: underline"><span style="color: #3366ff;text-decoration: underline"><a href="http://books.google.ca/books/about/In_Defense_of_Pure_Reason.html?id=m1YsiiF0CrsC&amp;redir_esc=y"><span style="color: #3366ff;text-decoration: underline">some book</span></a></span></span>}: It&#8217;s all in here, man.</em></p>
<p><span style="text-decoration: underline;color: #3366ff"><a href="http://www.businessweek.com/printer/articles/85550-tim-cooks-freshman-year-the-apple-ceo-speaks"><span style="color: #3366ff;text-decoration: underline">Source</span></a></span>.</p>
<p><span id="more-3830"></span>Okay, okay, I made up the last exchange. But the rest is legit.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/tim-cook-apple-ceo-and-friend-of-the-a-priori/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
	</channel>
</rss>
