<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Ralph Wedgwood &#8211; </title>
	<atom:link href="http://certaindoubts.com/author/wedgwood/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 01:35:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>A simple problem for (unrestricted) Conditionalization</title>
		<link>http://certaindoubts.com/a-simple-problem-for-unrestricted-conditionalization/</link>
		<comments>http://certaindoubts.com/a-simple-problem-for-unrestricted-conditionalization/#comments</comments>
		<pubDate>Sun, 04 Nov 2018 15:38:33 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[epistemic paradoxes]]></category>
		<category><![CDATA[formal epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4890</guid>
		<description><![CDATA[Many formal epistemologists think that Conditionalization is always the uniquely rational way to update one’s credences. But this cannot be correct. In certain troublesome cases, Conditionalization would take the thinker to rationally forbidden destinations. Conditionalization has to be restricted somehow, &#8230; <a class="more-link" href="http://certaindoubts.com/a-simple-problem-for-unrestricted-conditionalization/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Many formal epistemologists think that Conditionalization is <i>always</i> the uniquely rational way to update one’s credences. But this cannot be correct. In certain troublesome cases, Conditionalization would take the thinker to rationally forbidden destinations. Conditionalization has to be restricted somehow, so that it does not apply in these troublesome cases.</p>
<p><span id="more-4890"></span></p>
<p>There is actually quite a range of such troublesome cases. But the simplest example is that of certain <i>Moore-paradoxical propositions</i> – propositions that the thinker could express by uttering something of the form ‘<i>P</i>, and there is no time <i>t</i> at which I assign a high credence to the proposition that <i>P</i>’.</p>
<p>(In contemplating this proposition, the thinker has to refer to <i>herself</i> in a distinctively first-personal way. However, to bracket worries about how to accommodate indexical references to <em>times</em> in our formal framework, I have chosen a Moore-paradoxical proposition that quantifies over times in its second conjunct – rather than a proposition that contains a distinctively indexical reference to the present time.)</p>
<p>Now, nothing prevents the thinker from rationally having a prior system of credences that assigns arbitrarily high probability to this Moore-paradoxical proposition, conditional on a certain possible body of evidence <i>E</i>.</p>
<p>Indeed, <i>E</i> might just be <i>P</i> itself. It might be obvious from the nature of <i>P</i> that <i>P</i> is the kind of proposition that one is extraordinarily unlikely to have a high credence in even if <i>P</i> is true. For example, suppose that <i>P</i> is the proposition that the number of flies in the world right now is exactly 17,000,000,000,000,000. Even conditional on the truth of <i>P</i>, it is unbelievably unlikely that one will ever have a high credence in <i>P</i>. So, conditional on the supposition of <i>P</i>, one rationally assigns an extremely high conditional credence to the proposition that one could express by uttering ‘<i>P</i>, and I never have a high credence in the proposition that <i>P</i>’.</p>
<p>However, one’s prior credence in <i>P</i> is still non-zero. So, it could still happen that one day one learns that <i>P</i> is true. But then, if one updates one’s credences by Conditionalization, one will end up assigning an extremely high credence to the proposition that one could express by uttering the relevant instance of ‘<i>P</i> and I never have a high credence in the proposition that <i>P</i>’.</p>
<p>This, surely, is an irrational place to end up in. It is <i>a priori</i> obvious that if one has a high credence in this proposition, the proposition cannot be true (given that it is also <i>a priori</i> obvious that if one has a high credence in a conjunction, one also has high credence in each of its conjuncts).</p>
<p>So, in these cases, it seems to me, it is irrational to update by Conditionalization. Conditionalization must be restricted so that it does not apply to these cases.</p>
<p>Indeed, this point seems so obvious to me that I feel sure that someone must have thought of this point before. I would be very grateful if someone could let me know who (if anyone) has made this point before!</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/a-simple-problem-for-unrestricted-conditionalization/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
		</item>
		<item>
		<title>Rationality is permissibility</title>
		<link>http://certaindoubts.com/rationality-is-permissibility/</link>
		<comments>http://certaindoubts.com/rationality-is-permissibility/#comments</comments>
		<pubDate>Sat, 25 Jul 2015 13:38:43 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[general]]></category>
		<category><![CDATA[justification]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4638</guid>
		<description><![CDATA[Many philosophers seem to think that – even if the notions of a belief’s being “justified” or “rational” are indeed normative notions, as is widely held to be the case – to say that a belief is “justified” is “rational” is to &#8230; <a class="more-link" href="http://certaindoubts.com/rationality-is-permissibility/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Many philosophers seem to think that – even if the notions of a belief’s being “justified” or “rational” are indeed normative notions, as is widely held to be the case – to say that a belief is “justified” is “rational” is to say something <em>stronger</em> than merely that the belief is <em>permissible</em>.</p>
<p>This is a mistake. It is easy to prove that if the notions of a belief’s being “justified” or “rational” are normative at all, then the permissibility of a belief is <em>sufficient</em> for the belief’s being justified or rational.<span id="more-4638"></span></p>
<hr class="at-page-break" />
<p>Here is the simplest version of the proof.</p>
<p style="padding-left: 30px"><strong>1.</strong> If it is not rational for you to believe <em>p</em>, you ought not to believe <em>p</em>.</p>
<p style="padding-left: 30px"><strong>2.</strong> If you ought not to believe <em>p</em>, it is not permissible for you to believe <em>p</em>.</p>
<p>Therefore (by the transitivity of these conditionals 1 and 2):</p>
<p style="padding-left: 30px"><strong>3.</strong> If it is not rational for you to believe <em>p</em>, it is not permissible for you to believe <em>p</em>.</p>
<p>Therefore (by contraposition and double-negation elimination from 3):</p>
<p style="padding-left: 30px"><strong>4.</strong> If it is permissible for you to believe <em>p</em>, it is rational for you to believe <em>p</em>.</p>
<p>That is, the permissibility of a belief is sufficient for the belief’s rationality.</p>
<p>Are the premises of this proof true? (2) seems obvious, given the intended interpretation of ‘ought’ and ‘permissible’; and it seems that (1) would surely be accepted by anyone who thinks that ‘rational’ is a normative concept.</p>
<p>Just in case anyone is tempted to doubt this, here is a supplementary argument for (1).</p>
<p style="padding-left: 30px"><strong>5.</strong> If it is not rational for you to believe <em>p</em>, it is irrational for you to believe <em>p</em>.</p>
<p style="padding-left: 30px"><strong>6.</strong> If it is irrational for you to believe <em>p</em>, you are rationally required not to believe <em>p</em>.</p>
<p style="padding-left: 30px"><strong>7.</strong> If you are rationally required not to believe <em>p</em>, you ought not to believe <em>p.</em></p>
<p>By the transitivity of these conditionals (5), (6), and (7) entail (1).</p>
<p>(5) seems obviously true given the intended interpretations of ‘rational’ and ‘irrational’; (6) seems obviously true given the intended interpretation of ‘rationally required’; and it is hard to see how anyone who thinks that ‘rational’ is a normative concept could possibly deny (7).</p>
<p><em>Mutatis mutandis</em>, the same argument seems to work for ‘justified’ as for ‘rational’. The permissibility of your believing <em>p</em> is sufficient for it to be rational or justified for you believe <em>p</em>.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/rationality-is-permissibility/feed/</wfw:commentRss>
		<slash:comments>10</slash:comments>
		</item>
		<item>
		<title>Internalism = coherentism</title>
		<link>http://certaindoubts.com/internalism-coherentism/</link>
		<comments>http://certaindoubts.com/internalism-coherentism/#comments</comments>
		<pubDate>Mon, 15 Dec 2014 20:21:39 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[foundationalism and coherentism]]></category>
		<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4546</guid>
		<description><![CDATA[Many epistemologists accept the mentalist version of internalism about rationality. In a slogan, this is the view that rationality supervenes on the mental states that the relevant thinker has at the relevant time. Coherentism, as I shall understand it here, &#8230; <a class="more-link" href="http://certaindoubts.com/internalism-coherentism/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Many epistemologists accept the <em>mentalist</em> version of <em>internalism about rationality</em>. In a slogan, this is the view that <em>rationality supervenes on the mental states</em> that the relevant thinker has at the relevant time.</p>
<p>Coherentism, as I shall understand it here, is the view that rationality requires nothing except that one’s mental states should <em>cohere</em> in certain ways: for it to be rational for you to have a certain belief (or other attitude) at a certain time is just for your having that belief (or attitude) at that time to be part of a system of mental states that meet all these rational requirements of coherence.</p>
<p>I shall argue here that given the right understanding of what “coherence” is, the only plausible form of internalism is equivalent to coherentism.<span id="more-4546"></span></p>
<p>First let me give a slightly more precise statement of this mentalist-internalist view. According to this view, whether or not a belief or attitude of some other kind counts as <em>rational</em> or as <em>irrational</em> depends, not on the attitude’s relation to the external world, but on how the attitude relates to the mental states that are present in the relevant thinker’s mind at that time, or just before that time. (Strictly, a complete account would have to take account of mental events, including events in which we form or revise our attitudes in various ways, as well as enduring mental states and attitudes; but for simplicity’s sake, I shall forget this complication here.)</p>
<p>I shall assume here that in addition to assessing the rationality or irrationality of <em>individual</em> beliefs or attitudes, we can also assess whole systems of beliefs and attitudes as rational or as irrational; and the assessment of individual beliefs or attitudes must harmonize with the assessment of systems of beliefs and attitudes – in the sense that every individual belief in any rational system of beliefs is itself a rational belief, and every individual rational belief is part of a possible rational system of beliefs.</p>
<p>What exactly is “coherence”? There are certainly narrow understandings of “coherence” on which coherentism is not plausible. For example, some forms of coherentism in epistemology imply that the only requirements of rational belief are that one’s <em>outright</em> or <em>full beliefs</em> should cohere with each other – where whether or not these beliefs count as “cohering” with each other is determined purely by the <em>propositional contents</em> of those beliefs.</p>
<p>This narrow notion of coherence would not even include what formal epistemologists call “probabilistic coherence”, which is a feature of systems of <em>partial degrees of belief</em>, not just of sets of outright or full beliefs. To determine whether a system of partial degrees of belief is probabilistically coherent, we need to look not just at the propositional contents, but also at the degree of belief that the believer attaches to each of these propositional contents.</p>
<p>Moreover, it seems clear that it is not just full and partial beliefs that can cohere or fail to cohere. Many philosophers have suggested that to be rational, one’s <em>choices</em> or <em>intentions</em> must cohere both with one’s other choices or intentions, and also with one’s beliefs, and perhaps with one’s desires and preferences as well. (For example, Michael Bratman argues that rational intentions must be “means-end coherent, relative to one’s beliefs”; and many forms of decision theory require that one’s preferences must cohere in a certain way both with each other and with one’s partial beliefs or credences.)</p>
<p>If the requirements of rational choice can include requirements about how one’s choices or intentions should cohere with one’s beliefs, why shouldn’t the requirements of rational belief include requirements that one’s beliefs should cohere with <em>other</em> mental states besides beliefs? For example, the “foundherentist” view of Susan Haack, according to which rational beliefs must cohere with one’s <em>experiences</em> as well as with each other, should also be counted as a form of coherentism.</p>
<p>Admittedly, as Haack in effect pointed out, forms of coherentism that include <em>experiences</em> among the mental states and events that must cohere, if one’s current beliefs and other attitudes are to be rational, will have an affinity with <em>foundationalism</em>. While we can in principle assess merely possible systems of mental states as rational or irrational, we are particularly interested in assessing the possible systems that are <em>available</em> to a particular thinker at a particular time. Since it is not up to the thinker what experiences she now has, all the systems of mental states that are now available to her will involve her <em>actual</em> experiences – which are thus in a way being “held fixed”, like a kind of “foundation” for the different systems of beliefs and other attitudes that count as coherent to a greater or lesser degree. (Similarly, it is not now up to the thinker what mental states she had in the past; and so all the systems of mental states that are now available to the thinker will be systems that succeed the system of mental states that the thinker had in the past; in this way, the facts about the thinker’s past mental states are also being “held fixed” in a similar way.)</p>
<p>Still, even if this “foundherentist” view has an affinity with foundationalism, it still seems to be a kind of coherentism – since its fundamental claim is that to be rational, the thinker’s mental states (including her beliefs and experiences) must cohere in a certain way, and for a belief to be rational is for it to be part of an optimally coherent system of mental states of this kind.</p>
<p>Some other philosophers might insist that coherence is a strictly <em>synchronic</em> relation, which can only hold between mental states that are present in the thinker’s mind at the same time. But on the face of it, it seems that we can also make sense of one’s present mental states’ “cohering with” some of one’s <em>past</em> mental states. Perhaps a radical conversion event, in which one makes a radical shift from one set of beliefs to another completely different set of beliefs, could count as a failure of <em>diachronic</em> coherence. Intuitively, one’s current set of beliefs does not “fit together” with one’s earlier beliefs. So it seems that we can make sense of diachronic coherence just as much as synchronic coherence.</p>
<p>So what is distinctive of coherence, then, if it is not defined as a relation that holds only among beliefs, or only synchronically among the mental states that the thinker has at a single time?</p>
<p>I propose then that we should interpret “coherence” as follows: coherence is a relation that holds between mental states purely in virtue of the content and nature of those mental states – specifically, a relation that helps to make that set of those mental states rational.</p>
<p>Suppose that this is all that it means for a system of mental states to cohere. Now internalism about rationality implies that whether or not a thinker’s system of beliefs and other attitudes is rational depends on the mental states that are present in the relevant thinker’s mind at that time, or just before that time. It seems clear then that internalism implies all the requirements of rationality are requirements of coherence in the large sense of the term that I have just explained.</p>
<p>If the requirements of rationality supervene on mental states, and coherence is just a rationality-enhancing relation among mental states, then all requirements of rationality are requirements of coherence.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/internalism-coherentism/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
		</item>
		<item>
		<title>In defence of adherence</title>
		<link>http://certaindoubts.com/in-defence-of-adherence/</link>
		<comments>http://certaindoubts.com/in-defence-of-adherence/#comments</comments>
		<pubDate>Thu, 29 May 2014 10:27:59 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[knowledge]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4399</guid>
		<description><![CDATA[What more is required of a belief, besides being justified and true (JTB), if the belief is to count as knowledge? In my view, at least two further conditions are required: the belief must meet the conditions of safety and &#8230; <a class="more-link" href="http://certaindoubts.com/in-defence-of-adherence/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>What more is required of a belief, besides being <em>justified</em> and <em>true</em> (JTB), if the belief is to count as <em>knowledge</em>? In my view, at least two further conditions are required: the belief must meet the conditions of <em>safety</em> and <em>adherence</em>.</p>
<p>Safety is popular these days: it has been defended by many distinguished epistemologists,&nbsp;such as&nbsp;Duncan Pritchard and Timothy Williamson, among others. But adherence – the fourth condition that Robert Nozick imposed on knowledge – has few defenders. Most of the philosophers who have discussed adherence have rejected it. In this post, I defend adherence against its detractors.</p>
<p><span id="more-4399"></span></p>
<p>First, let me explain how I understand adherence. Let us focus on a case <em>C</em><sub>1</sub> in which a believer believes a true proposition <em>p</em><sub>1</sub> in a doxastically justified or rational manner. Then this belief “adheres to the truth” if and only if every <em>normal</em> case <em>C</em><sub>2</sub> that is <em>sufficiently similar</em> to <em>C</em><sub>1</sub> with respect to what makes the belief rationally held in <em>C</em><sub>1</sub>, and with respect to the case’s target proposition <em>p</em><sub>2</sub>’s being true, is also similar in that the believer believes <em>p</em><sub>2</sub> in <em>C</em><sub>2</sub>.</p>
<p>Adherence explains why knowledge is lacking in cases in which the believer’s environment is full of misleading defeating evidence, which by a fluke the believer never encounters. In a case of this sort, the belief does not adhere to the truth – because there are normal cases sufficiently similar to the actual case, both with respect to what makes the belief rational in the actual case, and with respect to the target proposition’s being true, in which the believer encounters this misleading defeating evidence and so does not believe the proposition.</p>
<p>For example, in Gilbert Harman’s “assassination” case (<em>Thought</em>, p. 143), what justifies the believer in believing that <em>the political leader has been assassinated</em> is the belief’s being based on an experience of hearing the original radio broadcast. So, cases in which the believer hears the radio broadcast, but then also encounters the denials of the original broadcast that are printed everywhere, and so ceases to be believe that the leader has been assassinated, will count (in at least some contexts) as “sufficiently similar”.</p>
<p>To take another example, Timothy Williamson (<em>Knowledge and its Limits</em>, p. 62)&nbsp;considers a&nbsp;burglar who ransacks a house all&nbsp;night, risking&nbsp;discovery, because he <em>knows</em> that the house contains a diamond.&nbsp;If the&nbsp;burglar&nbsp;had merely <em>safely believed</em> that the house contained a diamond, the house could have been full of misleading defeating evidence, which would have led the&nbsp;burglar to&nbsp;become agnostic about whether the house contained a diamond. It is only because the burglar&#8217;s belief adheres robustly to the truth that it&nbsp;is so unlikely that the&nbsp;burglar&nbsp;will abandon the belief that the house contains a diamond.</p>
<p>(In fact, I would defend a <em>contextualist</em> interpretation of adherence, according to which the <em>context</em> in which the term ‘knowledge’ is used may make a difference to <em>how similar</em> to the actual case these other cases have to be in order to count as “sufficiently similar” in the context; but we may bracket these complexities for present purposes.)</p>
<p>Some philosophers have tried to give direct counterexamples to adherence. Here is an attempted counterexample due to Ernest Sosa (“Tracking, competence, and knowledge”, p. 274):</p>
<blockquote><p>One can know that one faces a bird when one sees a large pelican on the lawn in plain daylight even if there might easily have been a solitary bird before one unseen, a small robin perched in the shade, in which case it is false that one would have believed that one faced a bird. Prima facie, then, it seems unnecessary that one’s belief be [adherent]; one might perhaps know through believing safely even if one does not believe [adherently].</p></blockquote>
<p>A second attempted counterexample is due to Saul Kripke (<em>Philosophical Troubles</em>, p. 178):</p>
<blockquote><p>Suppose that Mary is a physicist who places a detector plate so that it detects any photon that happens to go to the right. If the photon goes to the left, she will have no idea whether a photon has been emitted or not. Suppose a photon is emitted, that it does hit the detector plate (which is at the right), and that Mary concludes that a photon has been emitted. Intuitively, it seems clear that her conclusion indeed does constitute knowledge. But is Nozick’s fourth condition satisfied? No, for it is not true, according to Nozick’s conception of such counterfactuals, that if a photon had been emitted, Mary would have believed that a photon was emitted. The photon might well have gone to the left, in which case Mary would have had no beliefs about the matter.</p></blockquote>
<p>These cases may be counterexamples to rough and imprecise statements of adherence, but it seems clear that they are not counterexamples to the formulation that I have given.</p>
<p>Consider the case in which I see a large pelican on the lawn in daylight in front of me. What makes my belief that there is a bird in front of me rational? Presumably, it is the fact that I have an <em>experience</em> of a certain sort, an experience that inclines me to deploy my concept of a bird. So the only cases that count as “sufficiently similar” are other cases in which I have an experience of this sort. Clearly, cases in which I have no such experience – even if in fact there is a bird in front of me, a small robin concealed in the shade – are just not “sufficiently similar”.</p>
<p>Kripke’s case suffers from a similar defect – even though Kripke claims about his case “Here the method is held fixed.” As I shall argue here, this is a mistake: the method is not “held fixed”. In the actual case, Mary’s belief is rationally held because it is based on an experience of observing the detector plate’s responding to the presence of a photon. Cases in which Mary has no such experience are just not sufficiently similar.</p>
<p>In fact, Nozick himself made a similar mistake, assuming that each of the relevant “methods” could be used to answer the question of “whether or not” the target proposition <em>p</em> is true. It is clear, however, that in many cases, the methods that could be used to come to know a proposition are very different from any methods that could be used to come to know the proposition’s negation.</p>
<p>For instance, to know that an existentially quantified proposition is true, one needs only to observe one true instance; but  to know the negation of such an existentially quantified proposition, one would have to survey the entire domain of quantification. (E.g. to know that there is a spider in the room, one needs only to observe a single spider; to know that there is no spider in the room, one would have to search the whole room to make sure that no spider is hiding anywhere.) As they say, “proving a negative” is harder than proving the corresponding positive statement.</p>
<p>It seems to me, then, that adherence is not vulnerable to these counterexamples. But Kieran Setiya (<em>Knowing Right from Wrong</em>, pp. 91f.) has suggested a more general kind of objection:</p>
<blockquote><p>I can know the truth by a method whose threshold for delivering a verdict is extremely high, so high that it virtually always leaves me agnostic. A method of this kind may be epistemically poor in other respects; but it can be a source of knowledge.</p></blockquote>
<p>This may sound like a single objection, but in fact there are two very different kinds of case that are suggested by what Setiya says here.</p>
<p>In some cases, I may believe a true proposition by a “method” that is the same as an ordinary rational method except that it is arbitrarily restricted in some way. E.g. I believe a proposition that I have proved through rigorous mathematical reasoning, but only on the condition that I also believe that today is a Thursday (suppose that if I had not believed that today is a Thursday, I would have responded to this mathematical reasoning with agnosticism). Or I believe what I seem to see before my eyes, but only so long as there is nothing apparently orange in my field of vision (if there had been anything apparently orange in my field of vision, I would have been totally agnostic about the scene before my eyes).</p>
<p>In these cases, the belief in question seems not to be doxastically justified or rationally held. The believer is basing her belief in crucial part on utterly irrelevant considerations, and so the dispositions that the believer is manifesting do not count as rational dispositions. This sort of irrationality seems to me to be incompatible with genuine knowledge.</p>
<p>In some other cases, it is rational for one to use a high-standards method, or a method that can only be used in a narrow range of cases. Perhaps a physician is trying to diagnose whether a patient has a certain illness, and the only available test is one that yields a verdict only in a very narrow range of cases; but luckily, in the actual case at hand, this test does indeed yield a verdict.</p>
<p>In this case, as with Sosa’s and Kripke’s examples, it seems to me that cases in which the test yields no verdict are not just sufficiently similar to the actual case. So cases of this sort are not counterexamples to adherence.</p>
<p>In short, the only cases of justified true beliefs that fail to satisfy adherence are cases where&nbsp;the thinker&#8217;s environment is&nbsp;rife with&nbsp;misleading defeating evidence, which by a fluke the thinker never encounters. Unless it is wrong to deny knowledge in such cases, adherence is not vulnerable to the objections that have been raised against it.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/in-defence-of-adherence/feed/</wfw:commentRss>
		<slash:comments>15</slash:comments>
		</item>
		<item>
		<title>Aptness entails safety</title>
		<link>http://certaindoubts.com/aptness-entails-safety/</link>
		<comments>http://certaindoubts.com/aptness-entails-safety/#comments</comments>
		<pubDate>Fri, 14 Feb 2014 05:36:08 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[virtue epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4283</guid>
		<description><![CDATA[Ernest Sosa had two big ideas about knowledge: In papers like “How to Defeat Opposition to Moore” (Philosophical Perspectives 1999), he argued that knowledge requires safety: for my belief in p to count as knowledge, it must be something that &#8230; <a class="more-link" href="http://certaindoubts.com/aptness-entails-safety/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Ernest Sosa had two big ideas about knowledge:</p>
<ol>
<li>In papers like “How to Defeat Opposition to Moore” (<i>Philosophical Perspectives</i> 1999), he argued that knowledge requires <i>safety</i>: for my belief in <i>p</i> to count as knowledge, it must be something that could not easily happen that I would have a belief on the kind of basis on which I in fact believe <i>p</i> in a proposition that is false.</li>
<li>In his 2007 book <i>A Virtue Epistemology</i> (<i>Apt Belief and Reflective Knowledge</i>, Vol. I), he argued that basic knowledge consists in a belief that is <i>apt</i> – a belief that is not merely competent and also correct, but a belief that is correct precisely <i>because</i><br />
it is competent.</li>
</ol>
<p>When he adopted the second idea, he simultaneously <i>abandoned</i> the first idea, arguing that there are cases in which a belief is apt but not safe, and in such cases the belief in question could still be knowledge (<i>A Virtue Epistemology</i>, pp. 29, 41).</p>
<p>It is only this last move that seems mistaken to me. Both of Sosa’s big ideas are fundamentally true. The two ideas are not in tension with each other, since – as I shall argue – no apt belief can be unsafe.<span id="more-4283"></span></p>
<p>What exactly does an “apt” belief amount to? To fix ideas, I shall assume that the only relevant sort of “competence” is <i>rationality</i>. So an apt belief is a belief that is <i>correct precisely because it is rational</i>. But what might it mean to say that a belief is correct “precisely because” it is rational?</p>
<p>“Because” is, of course, an explanatory term. The following features of explanations seem particularly relevant here:</p>
<ul>
<li>In every explanation, one fact – the <i>explanandum</i> – is explained on the basis of another fact – the <i>explanans</i>. For the explanation to be genuine, this connection between the <i>explanans</i> and the <i>explanandum</i> must be in some way an instance of a <i>more general pattern</i>.</li>
<li>Typically, this general pattern has to have some degree of <i>modal robustness</i>. That is, this pattern must hold, not just in other cases in the actual world, but also in cases in other <i>sufficiently nearby</i> possible worlds as well.</li>
<li>It seems that all normal explanations presuppose a background of <i>normal</i> conditions. So the relevant cases where this general pattern has to hold are cases where the background conditions are <i>normal</i> to the same degree, and in broadly the same way, as in the particular case in question.</li>
</ul>
<p>So, for you to have an apt belief in <i>p</i> in a given case <i>C</i><sub>1</sub>, it is not enough that in <i>C</i><sub>1</sub> your belief in <i>p</i> is both rational and correct. It is also necessary that in all the sufficiently nearby possible worlds, every case <i>C</i><sub>2</sub> that is similar to <i>C</i><sub>1</sub> with respect to what makes <i>C</i><sub>1</sub> a case of a rational belief (and also similar to <i>C</i><sub>1</sub> in the degree to which it is normal, and in the way in which it is normal to that degree) is also a case of a correct belief.</p>
<p>But this clearly implies is a kind of safety: it implies that it could not easily happen that a thinker would have a belief that was rational in a similar way to your belief in <i>p</i>, in conditions that are similar to your actual conditions in the degree to which they are normal (and in the way in which they are normal to that degree), while the belief in question was false. Just to give it a name, we could call this <i>rationality-and-normality-relative</i> safety, or RN-safety for short.</p>
<p>So, why does Sosa claim that apt beliefs can be unsafe? It is simply because he does not consider RN-safety; he only considers what he calls “outright safety” and “basis-relative safety” (<i>A Virtue Epistemology</i>, p. 26). Sosa is right to claim that outright safety and basis-relative safety are not necessary for knowledge; but RN-safety is much more plausibly necessary for knowledge.</p>
<p>Suppose that (i) you could easily have held a belief in a false proposition on the same kind of basis on which you actually believe <i>p</i>, but (ii) if that had happened, it would have been because either (a) your competence was impaired in a way in which it actually was not impaired, or else (b) your conditions were abnormal in a way in which they were actually not abnormal. Then, as Sosa correctly points out, your belief in <i>p</i> does not exhibit basis-relative safety (nor <i>a fortiori</i> outright safety); but since as things actually are, your conditions were quite normal, and your competence was not impaired, it surely could still be a case of knowledge.</p>
<p>However, even if cases of this sort could be cases of knowledge, they are not counterexamples to the claim that knowledge requires RN-safety, since in all these cases, the belief in question is RN-safe.</p>
<p>In short, Sosa was right both times. Both his first big idea – that knowledge requires safety – and his second big idea – that it requires apt belief – are fundamentally true. So far from being incompatible with each other, the first big idea actually follows<br />
from the second!</p>
<p>In a few days’ time, I shall produce a few more posts on this blog to explain how this approach can handle all of the Gettier cases, and to comment on some other features of this approach. But I hope that this argument for the conclusion that aptness entails safety will be sufficient for now.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/aptness-entails-safety/feed/</wfw:commentRss>
		<slash:comments>8</slash:comments>
		</item>
		<item>
		<title>Against &#8220;the norm of assertion&#8221;</title>
		<link>http://certaindoubts.com/against-the-norm-of-assertion/</link>
		<comments>http://certaindoubts.com/against-the-norm-of-assertion/#comments</comments>
		<pubDate>Sun, 17 Jul 2011 10:54:08 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[testimony and social epistemology]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=2869</guid>
		<description><![CDATA[Most of the literature on the “norm of assertion” assumes the following two controversial theses: Speech acts fall into various different natural kinds, one of which is assertion. Each of these natural kinds of speech act is subject to a &#8230; <a class="more-link" href="http://certaindoubts.com/against-the-norm-of-assertion/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Most of the literature on the “norm of assertion” assumes the following two controversial theses:</p>
<ol>
<li>Speech acts fall into various different <em>natural kinds</em>, one of which is assertion.</li>
<li>Each of these natural kinds of speech act is subject to a unique “<em>central</em>” or “<em>fundamental</em>” norm, which is especially intimately bound up with the nature of that kind of speech act.</li>
</ol>
<p>Typically, these controversial theses are assumed, rather than defended, in this literature. However, it is far from obvious that these theses are true. Indeed, I am strongly tempted to think that they are false.<span id="more-2869"></span></p>
<p><strong>1.</strong> According to one picture of discourse, understanding an utterance fundamentally involves <em>recognizing</em> the communicative <em>intentions</em> that lie behind the utterance. So every intelligible contribution to a conversation <em>presents itself</em> as being done with a certain intention (in the sense that the utterance allows the audience to see which intention the speaker means them to recognize as lying behind the utterance).</p>
<p>On this picture, the features of an utterance that are most relevant to the question of which type of speech act it belongs to are the intentions that the utterance presents itself as done with.</p>
<p>But there are many different possible intentions that an utterance might present itself as being done with. It is not clear which kind of intention is essential to the speech acts that we call “assertions”.</p>
<p>Certainly, the word ‘assertion’ in English can refer to acts of many different kinds. (E.g. one old meaning of the word was to <em>defend</em> or <em>vindicate</em> a cause against any hostile attack; it is in this sense that Milton announces at the beginning of <em>Paradise Lost</em> that he will “assert eternal Providence/ and justify the ways of God to men”.)</p>
<p>In some contexts, the word ‘assertion’ seems to be used for speech acts that present themselves as done with the intention of expressing a <em>true proposition</em> (by means of the very utterance in question). For example, the answers given by candidates in oral examinations, or by contestants on quiz shows, normally present themselves as done with this sort of intention. An early Christian martyr being interrogated by a Roman magistrate might in this sense “assert” the proposition that Jesus Christ came to save all human souls.</p>
<p>One very special subset of these speech acts are those that present themselves as done with the intention of <em>informing</em> the audience of the proposition that is expressed. To “inform” one’s audience of a proposition <em>p</em> is to bring it about that one’s audience <em>comes to know</em> this proposition <em>p</em>. But clearly not all acts that present themselves as done with the intention of expressing a truth also present themselves as done with the intention of informing one’s audience. The answers given by candidates in oral examinations do not present themselves as done with the intention of informing the examiner; and the Christian martyrs’ declaration of their faith need not present itself as done with the intention (as opposed to a mere hope) of informing the Roman magistrate of the proposition that is thereby expressed.</p>
<p>In other cases, a speaker – such as a trial lawyer or a politician – might make an utterance that presents itself as being done with the intention of <em>winning an argument</em>, but does not clearly present itself as done with the intention of expressing a truth, let alone with the intention of informing the audience.</p>
<p>So there are many different categories of speech acts here; and presumably, different theoretical projects will find it useful to focus on different categories. It seems clear that no word in ordinary English stably picks out just one of these categories; and so the theorist will just have to <em>stipulate</em> a semi-technical sense of the term ‘assertion’ to pick out one of these categories in the way that seems most useful to the theorist’s purposes. But there is surely no good question about what the true nature of “the speech act of assertion” is.</p>
<p><strong>2.</strong> Speech acts are acts, and acts are subject to lots of different norms. (E.g. there are moral norms, legal norms, prudential norms, technical norms, etc.) It is radically unclear what is meant by saying that a certain norm is the “central” or “fundamental” norm that applies to acts of a certain type. What is the central or fundamental norm that applies to acts of killing a human being, or to acts of scratching one’s head?</p>
<p>The best that I can do to make sense of the idea of the “central” norm of assertion is the following. In some cases, we identify an act-type by a certain <em>purpose</em>, and we talk about the “correct” or “proper” way to do an act that has that purpose. Thus, there is a correct way to tie a reef knot, or to play Bach’s first French Suite, etc.</p>
<p>If we can identify a kind of speech act by a certain purpose, then we might say that that kind of speech act is done correctly or properly on a given occasion if and only if it successfully accomplishes the relevant purpose on that occasion.</p>
<p>So, e.g. on this approach, one might say:</p>
<ul>
<li>An utterance is the correct performance of the speech act-type whose purpose is to <em>express a truth</em> if and only if the utterance does indeed express a truth.</li>
<li>An utterance is the correct performance of the speech act-type whose purpose is to <em>inform the audience</em> if and only if the utterance succeeds in informing the audience.</li>
<li>An utterance is the correct performance of the speech act-type whose purpose is to <em>win an argument</em> if and only if the utterance does indeed lead to the speaker’s winning the argument.</li>
</ul>
<p>Here, however, ‘correct’ effectively just means ‘achieves the relevant purpose’. So it is not clear what the introduction of normative terminology (like ‘correct’) adds to the basic element of this theory, which is just the identification of the relevant purpose.</p>
<p>So, it seems to me, the literature on the norm of assertion is in bad shape until it can make it clearer what exactly (if anything) it is supposed to be about&#8230;.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/against-the-norm-of-assertion/feed/</wfw:commentRss>
		<slash:comments>12</slash:comments>
		</item>
		<item>
		<title>Meno requires adherence, not safety</title>
		<link>http://certaindoubts.com/meno-requires-adherence-not-safety/</link>
		<comments>http://certaindoubts.com/meno-requires-adherence-not-safety/#comments</comments>
		<pubDate>Sun, 19 Jun 2011 17:14:05 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[major figures]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=2772</guid>
		<description><![CDATA[Many recent epistemologists have claimed to find inspiration in the discussion of knowledge and true belief in Plato’s Meno (97a-98a). At the same time, it has become common for philosophers to emphasize safety from error (or the like) as a &#8230; <a class="more-link" href="http://certaindoubts.com/meno-requires-adherence-not-safety/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Many recent epistemologists have claimed to find inspiration in the discussion of knowledge and true belief in Plato’s <em>Meno</em> (97a-98a).  At the same time, it has become common for philosophers to emphasize <em>safety from error</em> (or the like) as a necessary condition for knowledge – where (roughly) a belief is safe from error if and only if it held as a result of a process that could not easily yield a false belief.</p>
<p>Besides safety, another feature that a belief can have is what Robert Nozick called <em>adherence</em> to the truth – where (roughly) a belief adheres to the truth if and only if it is held as a result of a process that could not easily <em>fail to yield belief</em> if the proposition in question were true.  As I shall argue, Plato’s <em>Meno</em> suggests that knowledge requires adherence – <em>not</em> that knowledge requires safety.<br />
<span id="more-2772"></span><br />
According to <em>Meno</em> (98a), the difference between knowledge and true belief consists in the fact that a mere true belief is like a slave who is liable to “run away from the soul”, whereas knowledge has somehow been more securely  “tied down”. In effect, a mere true belief might too easily be <em>lost</em>, whereas knowledge is not so easily lost in this way. It is not suggested that if the true belief is lost it will be replaced by a <em>false</em> belief – the true belief might just simply disappear altogether, without being replaced by any belief on the relevant topic at all.</p>
<p>Plato’s suggestion here is presumably not that knowledge is less liable to be <em>forgotten</em> than a mere true belief. The suggestion is surely that knowledge is less liable to be <em>rationally undermined</em> by new evidence that comes to light. There are two ways in which new evidence might rationally undermine a true belief:</p>
<ol>
<li>The true belief might have been irrational or unjustified all along, and the new evidence might force the believer to realize that he never had any good reason for the belief in the first place.</li>
<li>The true belief might originally have been rational and justified, but the new evidence might <em>defeat</em> that original justification.</li>
</ol>
<p>Cases of this second kind (2) involve a JTB that falls short of knowledge. But they are not really like the original Gettier cases (or like Carl Ginet’s famous “barn façade” case). Instead, they are more like the “assassination case” that Gilbert Harman presented in <em>Thought</em> (1973, 143f.).</p>
<p>In Harman’s “assassination case”, there is a JTB that fails to count as knowledge, because there is a mass of (misleadingly) defeating evidence in the believer’s environment, and it is simply a fluke that the believer does not encounter this defeating evidence. But this defeating evidence – we may suppose – consists entirely of “<em>undercutting</em>” (rather than “rebutting”) defeaters. So if the thinker had encountered this defeating evidence, she would simply have <em>given up</em> on having any beliefs about the topic in question – she would not have come to believe the proposition’s negation. I.e., this belief fails to count as knowledge, not because it is unsafe, because it fails to adhere to the truth adequately.</p>
<p>In order to define ‘adherence to the truth’ more precisely, we need to factor the “process” that yields a belief into two components: the “positive conditions” (which require the <em>presence</em> of certain factors that normally yield the belief in question) and the “negative conditions” (which require the <em>absence</em> of certain factors that would <em>inhibit</em> the positive conditions from yielding the belief in question).</p>
<p>Then we can define the notion as follows:</p>
<blockquote><p>A belief adheres to the truth iff, for some process P, the belief is held as a result of P, and in all nearby cases in which the believer meets the positive conditions of P, and the corresponding proposition is true, P yields belief in that proposition.</p></blockquote>
<p>It is clear that a belief can be safe without adhering to the truth in this way. This will happen whenever there are no nearby cases in which the relevant process leads the believer to believe anything false, but there are nearby cases where the believer encounters undercutting defeaters (so that in those cases, the process fails to yield any belief at all).</p>
<p>In conversation, I have found that many fans of safety deny that knowledge requires this kind of adherence to the truth. In their view, the only way in which the “assassination case” can fail to be a case of knowledge is if it involves a failure of safety (as well as a failure of adherence).  As I have argued here, in denying that knowledge requires adherence as well as safety, these philosophers are disagreeing with Plato’s <em>Meno</em>.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/meno-requires-adherence-not-safety/feed/</wfw:commentRss>
		<slash:comments>30</slash:comments>
		</item>
		<item>
		<title>Against “Evidence”</title>
		<link>http://certaindoubts.com/against-%e2%80%9cevidence%e2%80%9d/</link>
		<comments>http://certaindoubts.com/against-%e2%80%9cevidence%e2%80%9d/#comments</comments>
		<pubDate>Sun, 01 Aug 2010 13:33:25 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[general]]></category>
		<category><![CDATA[justification]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=2036</guid>
		<description><![CDATA[There is no such thing as evidence – at least not if any genuine “evidence” would have to meet both of these conditions: It is your evidence that justifies all of your beliefs or credences that are justified at all. Evidence &#8230; <a class="more-link" href="http://certaindoubts.com/against-%e2%80%9cevidence%e2%80%9d/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>There is no such thing as evidence – at least not if any genuine “evidence” would have to meet both of these conditions:</p>
<ol>
<li>It is your evidence that justifies all of your beliefs or credences that are justified at all.</li>
<li>Evidence is at least roughly similar to what is called “evidence” in everyday English.</li>
</ol>
<p>As I shall argue, there is <em>nothing</em> that meets both these conditions. There is indeed something that justifies all of your beliefs or credences that are justified at all, but it is radically unlike what is called “evidence” in ordinary English. Philosophers who assume that your evidence is what justifies your beliefs are in constant peril of being led astray by their linguistic intuitions about the meaning of ‘evidence’ in everyday English.</p>
<p>My conclusion will be that the word ‘evidence’ should be banished from fundamental epistemology altogether.<span id="more-2036"></span></p>
<p><strong>A.</strong>  First, let me suggest an account of how the term ‘evidence’ is used in everyday English. (Incidentally, no other language known to me has any word that corresponds closely to ‘evidence’: the French word <em>évidence</em> means either <em>the property of being evident</em> or <em>an evident truth</em>; German also has no closely corresponding word. “Evidence” is a much less universal concept than some philosophers suppose!)</p>
<p>In English, we typically use the word ‘evidence’ in conversations that aim to reach an agreed answer to a question Q. (E.g., Q might be ‘Is theory T true?’ or ‘Did the defendant commit the crime?’ or the like.) We use the “evidence” as our basis for trying to answer this question Q – where every part of what we use as our basis for answering Q is something that we are (in that context) <em>presupposing</em> to be a <em>fact</em>. We accept the claim that <em>p</em> is part of the evidence only if it seems to make sense to presuppose <em>p</em> to be a fact, for the purposes of that particular conversation.</p>
<p>In short, I propose, in any context <em>C</em>, it is true in <em>C</em> to say that <em>p</em> is part of the “evidence” if and only if <em>p</em> is a proposition that it makes sense to presuppose in <em>C</em>, given the purpose of the conversation to try to reach an agreed answer to the relevant question.</p>
<p>According to this account, the term ‘evidence’ is acutely context-sensitive. It usually makes no sense to presuppose a proposition that is <em>controversial</em> among the participants in the conversation; so what counts as part of the “evidence” usually depends on who we are talking to. The proposition that the earth is over 4 billion years old may be part of the “evidence” when we are talking to our scientific colleagues, but not when we are talking to religious fundamentalists.</p>
<p><strong>B.</strong> Thus, our linguistic intuitions lead us to assume that our “evidence” consists of propositions that (i) we <em>presuppose</em> or <em>believe</em>, and (ii) are <em>uncontroversial</em> – part of a public “common ground”.</p>
<p>In my view, this explains why it seems plausible to so many Bayesian epistemologists that one’s “evidence” consists of propositions in which one has the <em>highest possible credence</em>, and why it seems plausible to Williamson that one’s “evidence” consists of the propositions that one <em>knows</em>. It also explains why so much of the literature on disagreement assumes that it is common for the parties to a disagreement to have <em>shared evidence</em>.</p>
<p>But in fact, most epistemologists do not accept that the only thing that can make your beliefs rational or justified are propositions that you believe. Most epistemologists would insist that a much wider range of mental states and mental events – including sensory experiences, sensations, memories, intuitions, intrinsically conditional beliefs, desires, emotions, plans, intentions, and the like. In general, your beliefs are not just based on your other beliefs. There are many complex and diverse processes that can lead you to form, revise, and maintain our beliefs.</p>
<p>It seems plausible that <i>all</i> of these mental states, events, and processes can be part of what makes your beliefs rational or justified. But these states, events and processes are not propositions that you believe, and they are also not public or uncontroversial or part of the shared common ground. It is in fact impossible for anyone else to share these mental states or events or processes.</p>
<p>So the claim that your “evidence” is what justifies your beliefs is grotesquely implausible, if the term ‘evidence’ is used in anything like its ordinary sense.</p>
<p>For this reason, the use of the term ‘evidence’ in much epistemology is a constant source of erroneous assumptions. We would be much better off if we eliminated the term ‘evidence’ from fundamental epistemology entirely.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/against-%e2%80%9cevidence%e2%80%9d/feed/</wfw:commentRss>
		<slash:comments>20</slash:comments>
		</item>
		<item>
		<title>A Refutation of the “JJ” Principle</title>
		<link>http://certaindoubts.com/a-refutation-of-the-%e2%80%9cjj%e2%80%9d-principle/</link>
		<comments>http://certaindoubts.com/a-refutation-of-the-%e2%80%9cjj%e2%80%9d-principle/#comments</comments>
		<pubDate>Mon, 02 Nov 2009 23:41:27 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[formal epistemology]]></category>
		<category><![CDATA[justification]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=1516</guid>
		<description><![CDATA[This blog post offers a refutation of the following “JJ” principle:

(1)	If you are justified in believing p, then you have highest possible degree of justification for believing that you’re justified in believing p (in other words, you can be certain that you’re justified in believing p).]]></description>
				<content:encoded><![CDATA[<p>This blog post offers a refutation of the following “JJ” principle:</p>
<blockquote><p>(1) If you are justified in believing <em>p</em>, then you have the <em>highest possible</em> degree of justification for believing that you’re justified in believing <em>p</em> (in other words, you can be <em>certain</em> that you’re justified in believing <em>p</em>).</p></blockquote>
<p>The refutation will be based on broadly Williamson-inspired considerations about “margins for error”. Nonetheless, the argument is also designed to be completely compatible with <em>internalism</em> about justification (or at least with the “mentalist” form of internalism).</p>
<p><span id="more-1516"></span></p>
<p>My refutation of (1) is based on the following “margins for error” principle for justified belief:</p>
<blockquote><p>(2)	If you’re justified to degree <em>d</em> in believing <em>p</em>, then in all relevantly <em>close</em> cases, you’re justified in believing <em>p</em> to at least degree <em>d</em> – ε (where ε is some small difference in degree of justification).</p></blockquote>
<p>(2) can be motivated by considering the same sorts of cases that Williamson considers in supporting his “margins for error” principle for knowledge (<em>Knowledge and Its Limits</em>, Chap. 5).</p>
<p>E.g., the degree of justification that you have for believing the proposition ‘That man is less than 6 feet tall’ varies smoothly over a spectrum of cases: the shorter the man looks to you, the more justification you have for believing the proposition. Among the cases where you at least have more justification for ‘He is less than 6 feet tall’ than for its negation ‘He is not less than 6 feet tall’, the <em>closer</em> you are to the tipping-point where you <em>cease</em> to have more justification for the proposition than for its negation, the <em>less</em> justification you have for that proposition.</p>
<p>Now let us use the phrase ‘a very high degree of justification for believing <em>q</em>’ to mean: a degree of justification for <em>q</em> that is at least 1 – ε (where 1 is total certainty, and ε as before is some small difference in degree of justification).</p>
<p>Then (1) and (2) entail:</p>
<blockquote><p>(3)	If you’re justified in believing <em>p</em>, then in all relevantly close cases, you have a <em>very high</em> degree of justification for believing that you’re justified in believing <em>p</em>.</p></blockquote>
<p>The second premise in my refutation of (1) is:</p>
<blockquote><p>(4)	If you have a <em>very high</em> degree of justification for the higher-order proposition that you’re justified in believing <em>p</em>, then your justification for that higher-order proposition must itself rest on (or incorporate) your justification for <em>p</em> – and so you must indeed be justified in believing <em>p</em>.</p></blockquote>
<p>In effect, (4) is a ‘J<sub>high</sub>J<em>p</em> → J<em>p</em>’ principle: if you’re highly justified in believing that you’re justified in believing <em>p</em>, then you are justified in believing <em>p</em>.</p>
<p>(4) should seem appealing to any philosopher who is attracted to anything like (1). After all, how could you have such a high degree of justification for the (higher-order) proposition that you’re justified in believing <em>p</em>, unless your justification for that higher-order proposition somehow rested on or incorporated your justification for the lower-order proposition <em>p</em>?</p>
<p>Taken together (3) and (4) entail:</p>
<blockquote><p>(5)	If you’re justified in believing <em>p</em>, then in all relevantly close cases, you’re justified in believing <em>p</em>.</p></blockquote>
<p>But if we iterate (5) sufficiently many times, we can infer from the obviously true premise that there are cases in which you are justified in believing ‘That man is less than 6 feet tall’ (when you are looking at someone who is clearly less than 5 feet tall) to the obviously false conclusion that you’re still justified in believing ‘That man is less than 6 feet tall’ when looking at someone who is clearly more than 7 feet tall!</p>
<p>The obvious conclusion to draw is that the ‘JJ’ principle is false and must be rejected – indeed, it must be rejected for fundamentally the same reasons as the better-known ‘KK’ principle.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/a-refutation-of-the-%e2%80%9cjj%e2%80%9d-principle/feed/</wfw:commentRss>
		<slash:comments>18</slash:comments>
		</item>
		<item>
		<title>Three Kinds of Justification &#8211; Three Kinds of Closure</title>
		<link>http://certaindoubts.com/three-kinds-of-justification/</link>
		<comments>http://certaindoubts.com/three-kinds-of-justification/#comments</comments>
		<pubDate>Mon, 08 Dec 2008 21:08:21 +0000</pubDate>
		<dc:creator><![CDATA[Ralph Wedgwood]]></dc:creator>
				<category><![CDATA[justification]]></category>

		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=886</guid>
		<description><![CDATA[There are three kinds of justification: (i) propositional justification, (ii) doxastic justification of mental events of judgment, and (iii) doxastic justification of enduring belief states. This distinction is relevant to the debates about the &#8220;closure&#8221; of justification under logical consequence. &#8230; <a class="more-link" href="http://certaindoubts.com/three-kinds-of-justification/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>There are three kinds of justification: (i) <em>propositional</em> justification, (ii) doxastic justification of <em>mental events of judgment</em>, and (iii) doxastic justification of <em>enduring belief states</em>. This distinction is relevant to the debates about the &#8220;closure&#8221; of justification under logical consequence.</p>
<p>In this post, I shall propose three different closure principles,  corresponding to these three kinds of justification; each of these closure principles is most plausible when applied only to the corresponding kind of justification. I suggest that this gives us a way to respond to the alleged counterexamples to closure.</p>
<p><span id="more-886"></span></p>
<p> 1. Let us start with the distinction between <i>propositional</i> and <i>doxastic</i> justification. In &#8220;What is Justified Belief?&#8221; Alvin Goldman uses the terminology of &#8220;<i>ex ante</i>&#8221; and &#8220;<i>ex post</i>&#8221; uses of the term ‘justified belief’, and explains the distinction as follows (p. 21):</p>
<blockquote>
<p>The <i>ex post</i> use occurs when there exists a belief, and we say <i>of that belief</i> that it is (or isn&#8217;t) justified. The <i>ex ante</i> use occurs when we … ignore … whether such a belief exists. Here we say of the <i>person</i> … that <i>p</i> is (or isn&#8217;t) suitable for him to believe.</p>
</blockquote>
<p>So, if <i>S</i>’s belief in <i>p</i> is <i>ex post</i> or doxastically justified, it follows that <i>S</i> believes <i>p</i>. On the other hand, even if <i>S</i> is <i>ex ante</i> or propositionally justified in believing <i>p</i>, it need not follow that <i>S</i> believes <i>p</i>.</p>
<p>I suggest that for propositional (or <i>ex ante</i>) justification, the most plausible principle is traditional SINGLE-PREMISE CLOSURE:</p>
<blockquote>
<p>For all propositions <i>p</i> and <i>q</i>,<i> </i>if you are propositionally justified (to degree <i>n</i>) in believing <i>p</i>, and <i>p</i> logically entails <i>q</i>, then you are also propositionally justified (to at least degree <i>n</i>) in believing <i>q</i>.</p>
</blockquote>
<p>SINGLE-PREMISE CLOSURE must obviously hold if the degrees to which you are propositionally justified in believing the relevant propositions can always be modelled by a <i>probability function</i>&nbsp;– since if <i>p</i> entails <i>q</i>, the probability of <i>q</i> must be <i>at least</i> as high as the probability of <i>p</i>.</p>
<p>To say that you are propositionally justified in believing <i>p</i> is to say that you are in a sense <i>in a position</i> to have a doxastically justified belief in <i>p</i>&nbsp;– that is, a doxastically justified in <i>p</i> is in some appropriate way <i>available</i> to you. This is not to say that it must be <i>easy</i> to acquire this doxastically justified belief. It might be very hard to acquire such a doxastically justified belief. All that is required is that there should be a possible process of reasoning (of an appropriate kind) that could take you to having such a doxastically justified belief in <i>p</i>.</p>
<p>If you are propositionally justified in believing <i>p</i>, and <i>p</i> entails <i>q</i>, then there is obviously one possible process of reasoning of the appropriate kind that will take you to having a doxastically justified belief in <i>q</i>&nbsp;– viz. a process that involves first coming to have a doxastically justified belief in <i>p</i>, and then competently deducing <i>q</i> from <i>p</i>. So SINGLE-PREMISE CLOSURE seems right for propositional justification.</p>
<p> 2.&nbsp;However, we can also draw a distinction <i>within</i> the sphere of doxastic (or <i>ex post</i>) justification. We can distinguish between <i>enduring belief states</i> and <i>conscious mental events of judgment</i>. I have believed for many years now that Hume was born in 1711, whereas a judgment cannot last for many years in this way. A judgment is a conscious event of <i>forming a belief</i>&nbsp;&#8209; although it may well be that the belief that is thereby formed does not really &#8220;stick&#8221;, and so never becomes the sort of enduring belief that lasts for many years. Clearly, both enduring belief states and conscious events of judgment can be described as &#8220;doxastically justified&#8221;.</p>
<p>For the doxastic justification of mental events of judgment, I suggest CLOSURE FOR JUDGMENTS:</p>
<blockquote>
<p>If you make a doxastically justified judgment that <i>p</i> is true, and you competently deduce <i>q</i> from <i>p</i> (and your judgment that <i>p</i> is true remains doxastically justified even as you reach the point of having completed this deduction), then your judgment that <i>q</i> is true is also doxastically justified.</p>
</blockquote>
<p>For the doxastic justification of enduring belief states, I suggest CLOSURE FOR ENDURING BELIEFS:</p>
<blockquote>
<p>If you have a doxastically justified enduring belief in <i>p</i>, and you also have an enduring belief in <i>q</i> that is stably sustained by your enduring belief in <i>p</i> and by your being appropriately sensitive to the fact that <i>p</i> logically entails <i>q</i>, then your enduring belief in <i>q</i> is also doxastically justified.</p>
</blockquote>
<p>Some philosophers will object to CLOSURE FOR JUDGMENTS, pointing out that you could competently deduce <i>q</i> from <i>p</i> even if you have compelling evidence that you are appallingly bad at making such deductions. (E.g., suppose that you are a novice mathematician, the deduction in question is exceptionally long and complicated, and you have a very mixed track record when it comes to long and complicated deductions of this sort.)</p>
<p>I suggest that this objection trades on confusing the doxastic justification of <i>mental events of judgments</i> with the justification of <i>enduring states of belief</i>. In all these cases, the mental event of judging that <i>q</i> is true really is doxastically justified; it only appears otherwise, because in many of these cases the belief that is formed in this mental event of judgment fails to become a doxastically justified enduring belief state.</p>
<p>Given CLOSURE FOR ENDURING BELIEFS, the mental event of judgment could only fail to lead to a doxastically justified enduring belief if the belief in <i>q</i> that you form by means of competently deducing <i>q</i> from <i>p</i> does not become an enduring belief that is stably sustained by your enduring belief in <i>p</i>, and by your appropriate sensitivity to the fact that <i>p</i> entails <i>q</i>. In these cases, your evidence that you are bad at deductions of this sort in some way <i>interferes</i> with this belief’s becoming an enduring belief that is stably sustained by your having an appropriate sensitivity to the logical relationship between <i>p</i> and <i>q</i>.</p>
<p>Your evidence could &#8220;interfere&#8221; in three ways. First, perhaps you really <i>are</i> appallingly bad at such deductions; then you presumably do not have the appropriate &#8220;sensitivity&#8221; to the logical relationship between <i>p</i> and <i>q</i>. Secondly, perhaps this evidence moves you to have doubts about your own deduction, with the result that (even though you still judge <i>q</i> as a result of performing the deduction) your belief in <i>q</i> never becomes a stably enduring belief at all. Thirdly, even if you do form an enduring belief in <i>q</i>, your doubts about your deduction may prevent your enduring belief in <i>q</i> from being sustained by your sensitivity to the logical relationship between <i>p</i> and <i>q</i>.</p>
<p>But what if you have such compelling evidence that you are appallingly bad at such deductions, but you simply ignore this evidence completely? Then this evidence presumably might not &#8220;interfere&#8221; with your belief in <i>q</i> becoming an enduring belief that is stably sustained by your doxastically justified belief in <i>p</i> and by your being appropriately sensitive to the fact that <i>p</i> entails <i>q</i>. But then I think we should say that your enduring belief in <i>q</i> really is doxastically justified after all. Perhaps your evidence prevents you having a high level of rational confidence in the <em>higher-order proposition</em> that you are justified in believing <i>q</i>. But I don’t see why that prevents you from being justified in believing <i>q</i> itself!</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/three-kinds-of-justification/feed/</wfw:commentRss>
		<slash:comments>8</slash:comments>
		</item>
	</channel>
</rss>
