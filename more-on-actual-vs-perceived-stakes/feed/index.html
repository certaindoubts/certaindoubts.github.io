<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: More on actual vs. perceived stakes</title>
	<atom:link href="http://certaindoubts.com/more-on-actual-vs-perceived-stakes/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/more-on-actual-vs-perceived-stakes/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Keith</title>
		<link>http://certaindoubts.com/more-on-actual-vs-perceived-stakes/#comment-143</link>
		<dc:creator><![CDATA[Keith]]></dc:creator>
		<pubDate>Fri, 25 Jun 2004 19:29:54 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=31#comment-143</guid>
		<description><![CDATA[(Sorry about the itallics in comment 4, above.  I meant for only the quotation from Matt to be in itallics.)

To relate comments 2 &amp; 4: What I&#039;m saying in 4, above, is that being misinformed about whether the subject has a ticket works like being Unaware of Fakes, as in comment 2, above.  This is misinformation about a fact relevant to whether the subject knows, not to what is meant by &quot;knows&quot;, at least by the tests I use to divide such factors.]]></description>
		<content:encoded><![CDATA[<p>(Sorry about the itallics in comment 4, above.  I meant for only the quotation from Matt to be in itallics.)</p>
<p>To relate comments 2 &#038; 4: What I&#8217;m saying in 4, above, is that being misinformed about whether the subject has a ticket works like being Unaware of Fakes, as in comment 2, above.  This is misinformation about a fact relevant to whether the subject knows, not to what is meant by &#8220;knows&#8221;, at least by the tests I use to divide such factors.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Keith</title>
		<link>http://certaindoubts.com/more-on-actual-vs-perceived-stakes/#comment-142</link>
		<dc:creator><![CDATA[Keith]]></dc:creator>
		<pubDate>Fri, 25 Jun 2004 19:18:02 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=31#comment-142</guid>
		<description><![CDATA[&lt;i&gt;Now, if misinformation can affect the content of ‘know’...&lt;i /&gt;

&lt;b&gt;Some&lt;/b&gt; types of misinformation that speaker has can easily affect, for me, the content of &quot;knows&quot;.  This is misinformation about factors that affect the standards that govern the speaker&#039;s use of &quot;knows&quot; -- how well-positioned a subject must be to count as &quot;knowing&quot; -- &lt;i&gt;not&lt;/i&gt; factors that affect how well-positioned the subject actually is.  What the speaker is wrong about in Matt&#039;s above lottery case is whether the subject has a ticket.  Given the intuitive tests I use for dividing such factors, that is misinformation about a factor that affects how well-positioned the subject actually is, not the standards that are being applied (how well-positioned he has to be to count as &quot;knowing&quot;).  And, wrt factors relevant to the subject&#039;s actual strength of position, it&#039;s the actual, and not the perceived, facts that matter.  So I wouldn&#039;t classify this as misinformation that affects the standards or content of the speaker&#039;s claim.&lt;/i&gt;&lt;/i&gt;]]></description>
		<content:encoded><![CDATA[<p><i>Now, if misinformation can affect the content of ‘know’&#8230;<i></i></p>
<p><b>Some</b> types of misinformation that speaker has can easily affect, for me, the content of &#8220;knows&#8221;.  This is misinformation about factors that affect the standards that govern the speaker&#8217;s use of &#8220;knows&#8221; &#8212; how well-positioned a subject must be to count as &#8220;knowing&#8221; &#8212; </i><i>not</i> factors that affect how well-positioned the subject actually is.  What the speaker is wrong about in Matt&#8217;s above lottery case is whether the subject has a ticket.  Given the intuitive tests I use for dividing such factors, that is misinformation about a factor that affects how well-positioned the subject actually is, not the standards that are being applied (how well-positioned he has to be to count as &#8220;knowing&#8221;).  And, wrt factors relevant to the subject&#8217;s actual strength of position, it&#8217;s the actual, and not the perceived, facts that matter.  So I wouldn&#8217;t classify this as misinformation that affects the standards or content of the speaker&#8217;s claim.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: mcgrath</title>
		<link>http://certaindoubts.com/more-on-actual-vs-perceived-stakes/#comment-8692</link>
		<dc:creator><![CDATA[mcgrath]]></dc:creator>
		<pubDate>Fri, 25 Jun 2004 17:09:25 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=31#comment-8692</guid>
		<description><![CDATA[I think Keith is right that contextualists should say that it&#039;s the speakers&#039; beliefs, thoughts, etc., (whether true or false) that shift the content of &#039;knows&#039; across conversational contexts.  This view has the consequence that misinformation about a third party&#039;s situation may shift the content of &#039;knows&#039; just as effectively as correct information.  If I&#039;m wrong about your stakes or wrong about whether you have a lottery ticket, it doesn&#039;t matter, the content of &#039;know&#039; may shift.

It seems to me that this consequence generates some unhappy results.

Suppose we&#039;re awaiting the announcement of the lottery winner on TV.  I have a ticket, but you don&#039;t.  However, I think you have a ticket.  I say to you, &quot;Hey, you might well win; you don&#039;t know you won&#039;t be rich tomorrow.&quot;  Now, if misinformation can affect the content of &#039;know&#039;, it seems that I will speak the truth in the second part of my claim.  (Reason:  the standards will be raised high enough to make it false for me to say of people with tickets that know they&#039;ll lose -- and this is high enough to make it false to say of people, with or without tickets, that they know lots of mundane facts).  So, I speak truly in saying &quot;You don&#039;t know you won&#039;t be rich tomorrow.&quot;  But in response to me, you&#039;ll laugh.  You&#039;ll say:  &quot;Um, no, I do know I won&#039;t be rich tomorrow; I&#039;m not going to win the lottery; I don&#039;t even have a ticket.&quot;  I will readily agree and admit my mistake.

I think it is very hard to swallow the claim that I spoke truly when I said you didn&#039;t know you wouldn&#039;t be rich tomorrow.

An invariantist can make better sense of what is going on here.  I had a false belief (that you had a lottery ticket), which led me to another false belief (that you didn&#039;t know you won&#039;t be rich tomorrow), and then when I was corrected on the former belief, I recognized the falsity of the latter and adjusted it.

Something similar seems to hold for cases in which a speaker is wrong about what&#039;s at stake for a subject.  If I learn that, contrary to what I had believed, Mary and John do have a lot at stake, I&#039;ll say:  &quot;Oh, I didn&#039;t realize that.  I was wrong; they don&#039;t really know.  They&#039;d better check further.&quot;

Here, too, the invariantist can make better sense of what is going on than the contextualist, it seems to me.]]></description>
		<content:encoded><![CDATA[<p>I think Keith is right that contextualists should say that it&#8217;s the speakers&#8217; beliefs, thoughts, etc., (whether true or false) that shift the content of &#8216;knows&#8217; across conversational contexts.  This view has the consequence that misinformation about a third party&#8217;s situation may shift the content of &#8216;knows&#8217; just as effectively as correct information.  If I&#8217;m wrong about your stakes or wrong about whether you have a lottery ticket, it doesn&#8217;t matter, the content of &#8216;know&#8217; may shift.</p>
<p>It seems to me that this consequence generates some unhappy results.</p>
<p>Suppose we&#8217;re awaiting the announcement of the lottery winner on TV.  I have a ticket, but you don&#8217;t.  However, I think you have a ticket.  I say to you, &#8220;Hey, you might well win; you don&#8217;t know you won&#8217;t be rich tomorrow.&#8221;  Now, if misinformation can affect the content of &#8216;know&#8217;, it seems that I will speak the truth in the second part of my claim.  (Reason:  the standards will be raised high enough to make it false for me to say of people with tickets that know they&#8217;ll lose &#8212; and this is high enough to make it false to say of people, with or without tickets, that they know lots of mundane facts).  So, I speak truly in saying &#8220;You don&#8217;t know you won&#8217;t be rich tomorrow.&#8221;  But in response to me, you&#8217;ll laugh.  You&#8217;ll say:  &#8220;Um, no, I do know I won&#8217;t be rich tomorrow; I&#8217;m not going to win the lottery; I don&#8217;t even have a ticket.&#8221;  I will readily agree and admit my mistake.</p>
<p>I think it is very hard to swallow the claim that I spoke truly when I said you didn&#8217;t know you wouldn&#8217;t be rich tomorrow.</p>
<p>An invariantist can make better sense of what is going on here.  I had a false belief (that you had a lottery ticket), which led me to another false belief (that you didn&#8217;t know you won&#8217;t be rich tomorrow), and then when I was corrected on the former belief, I recognized the falsity of the latter and adjusted it.</p>
<p>Something similar seems to hold for cases in which a speaker is wrong about what&#8217;s at stake for a subject.  If I learn that, contrary to what I had believed, Mary and John do have a lot at stake, I&#8217;ll say:  &#8220;Oh, I didn&#8217;t realize that.  I was wrong; they don&#8217;t really know.  They&#8217;d better check further.&#8221;</p>
<p>Here, too, the invariantist can make better sense of what is going on than the contextualist, it seems to me.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/more-on-actual-vs-perceived-stakes/#comment-141</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Wed, 23 Jun 2004 14:40:00 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=31#comment-141</guid>
		<description><![CDATA[Keith put the following comments at a different location, and they are a response to this post, which I lifted from elsewhere to foster further discussion of the points it contains.  So I&#039;m going to duplicate Keith&#039;s comments here:


Unaware of Fakes Vs. Unaware of Stakes

On Matt’s comment. I think there’s a huge difference between being wrong about stakes (or the like) vs. being wrong about whether the subject is in a Gettier situation.

So, start with a Gettier situation – I’ve always used Ginet’s fake barns case for this purpose. [Actually, I modify it somewhat, since some people have reported to me that they don’t have the no-knowledge intuition in the case as it’s best known (from Goldman). So, imagine that Henry is not only in a region filled with fake barns, but that he’s actually been fooled by *many* of those fakes. But the speaker is talking about the one incident where Henry was looking a real barn, and so is describing a true belief of Henry’s when she says, “Henry knew he was seeing a barn.&quot;] The speaker, we’ll suppose, doesn’t know about all the fakes.

Here, I’ve always supposed the speaker is just wrong about whether Henry knows. In fact, such cases have long been my reason for not going in for a simple relevant alternatives theory – by which I mean one according to which the content of a given knowledge attribution can be given by specifying what range of alternatives is relevant in context. For here, we must suppose that *it was a fake barn* is a relevant alternative to explain why the claim was false. But, on the *simple* RA, we’d need to suppose that that alternative is *not* relevant to explain why the claim is rationally made. Thus, I’ve thought that what context selects is not a range of rel alt’s, as on simple RA, but at most a standard for relevance. (This is in 1992 &amp; 1994 PPR papers.) But anyway, the key point here is that the subject just didn’t know, by any reasonable standards, and he or anybody else who says he knows is wrong, however reasonable they are in issuing the knowledge attribution if they’re unaware of the fakes.

But being unaware of what the stakes are is a completely different matter to me. If a speaker is unaware of the high stakes the subject faces, though the subject knows about them, I’m inclined to think the standards that govern this speaker’s claim are not driven up by the high stakes. In Matt’s case, where the speaker thinks the stakes are high for the subject, but they in fact are not, I think the standards that govern the speaker’s claim will typically be very high.

Why the difference in treatment? Well, the fakes vs. the stakes are falling on opposite sides of what for me (&amp; my intuitions) is a great divide. The fakes are affecting (by bringing down) how strong an epistemic position the subject is in. High stakes typically work (though a bit indirectly) by raising the standards for how well-positioned the subject must be for the speaker’s claim to be true. The standards in play are a matter of what the speaker means, and so are less plausibly affected by things the speaker is oblivious to. But how well positioned the subject actually is is something that anybody who is unaware of the fakes is likely to be very wrong about.]]></description>
		<content:encoded><![CDATA[<p>Keith put the following comments at a different location, and they are a response to this post, which I lifted from elsewhere to foster further discussion of the points it contains.  So I&#8217;m going to duplicate Keith&#8217;s comments here:</p>
<p>Unaware of Fakes Vs. Unaware of Stakes</p>
<p>On Matt’s comment. I think there’s a huge difference between being wrong about stakes (or the like) vs. being wrong about whether the subject is in a Gettier situation.</p>
<p>So, start with a Gettier situation – I’ve always used Ginet’s fake barns case for this purpose. [Actually, I modify it somewhat, since some people have reported to me that they don’t have the no-knowledge intuition in the case as it’s best known (from Goldman). So, imagine that Henry is not only in a region filled with fake barns, but that he’s actually been fooled by *many* of those fakes. But the speaker is talking about the one incident where Henry was looking a real barn, and so is describing a true belief of Henry’s when she says, “Henry knew he was seeing a barn.&#8221;] The speaker, we’ll suppose, doesn’t know about all the fakes.</p>
<p>Here, I’ve always supposed the speaker is just wrong about whether Henry knows. In fact, such cases have long been my reason for not going in for a simple relevant alternatives theory – by which I mean one according to which the content of a given knowledge attribution can be given by specifying what range of alternatives is relevant in context. For here, we must suppose that *it was a fake barn* is a relevant alternative to explain why the claim was false. But, on the *simple* RA, we’d need to suppose that that alternative is *not* relevant to explain why the claim is rationally made. Thus, I’ve thought that what context selects is not a range of rel alt’s, as on simple RA, but at most a standard for relevance. (This is in 1992 &#038; 1994 PPR papers.) But anyway, the key point here is that the subject just didn’t know, by any reasonable standards, and he or anybody else who says he knows is wrong, however reasonable they are in issuing the knowledge attribution if they’re unaware of the fakes.</p>
<p>But being unaware of what the stakes are is a completely different matter to me. If a speaker is unaware of the high stakes the subject faces, though the subject knows about them, I’m inclined to think the standards that govern this speaker’s claim are not driven up by the high stakes. In Matt’s case, where the speaker thinks the stakes are high for the subject, but they in fact are not, I think the standards that govern the speaker’s claim will typically be very high.</p>
<p>Why the difference in treatment? Well, the fakes vs. the stakes are falling on opposite sides of what for me (&#038; my intuitions) is a great divide. The fakes are affecting (by bringing down) how strong an epistemic position the subject is in. High stakes typically work (though a bit indirectly) by raising the standards for how well-positioned the subject must be for the speaker’s claim to be true. The standards in play are a matter of what the speaker means, and so are less plausibly affected by things the speaker is oblivious to. But how well positioned the subject actually is is something that anybody who is unaware of the fakes is likely to be very wrong about.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jason Stanley</title>
		<link>http://certaindoubts.com/more-on-actual-vs-perceived-stakes/#comment-140</link>
		<dc:creator><![CDATA[Jason Stanley]]></dc:creator>
		<pubDate>Wed, 23 Jun 2004 13:34:48 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=31#comment-140</guid>
		<description><![CDATA[Excellent cases, Jon -- those are exactly the ones that incline one to think that what is at issue are the stakes of the subject, and not the beliefs of the ascriber.

Just a geeky aside, though. Contextualism is a very flexible theory. The bare bones of it just say that one and the same knowledge ascription can express different propositions in different contexts of use, even when the values for all non-epistemically relevant indexicals are fixed across the contexts. So it would be open for a contextualist to mimic the subject-sensitive view, by claiming that the content for &quot;know&quot; shifts only when the attributor has *correct* beliefs about what is at stake for the subject. Of course, I think this would be a somewhat cheesy way to help the contextualist with these cases -- you&#039;d be packing SSI into the &#039;character&#039; (in Kaplan&#039;s sense) of the word &#039;know&#039;. But it&#039;s a possible maneuver.]]></description>
		<content:encoded><![CDATA[<p>Excellent cases, Jon &#8212; those are exactly the ones that incline one to think that what is at issue are the stakes of the subject, and not the beliefs of the ascriber.</p>
<p>Just a geeky aside, though. Contextualism is a very flexible theory. The bare bones of it just say that one and the same knowledge ascription can express different propositions in different contexts of use, even when the values for all non-epistemically relevant indexicals are fixed across the contexts. So it would be open for a contextualist to mimic the subject-sensitive view, by claiming that the content for &#8220;know&#8221; shifts only when the attributor has *correct* beliefs about what is at stake for the subject. Of course, I think this would be a somewhat cheesy way to help the contextualist with these cases &#8212; you&#8217;d be packing SSI into the &#8216;character&#8217; (in Kaplan&#8217;s sense) of the word &#8216;know&#8217;. But it&#8217;s a possible maneuver.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
