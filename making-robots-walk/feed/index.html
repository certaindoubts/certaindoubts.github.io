<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Making Robots Walk</title>
	<atom:link href="http://certaindoubts.com/making-robots-walk/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/making-robots-walk/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/making-robots-walk/#comment-7269</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Sat, 31 Mar 2007 11:03:29 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=676#comment-7269</guid>
		<description><![CDATA[Thanks for this, John. I think the problem of bridging traditional epistemology and formal epistemology is difficult for intellectual as well as sociological reasons.

From the beginning AI has been more receptive to philosophy than philosophy to AI, in part because of the seminal paper by Pat Haynes and John MacCarthy, &quot;Some Philosophical Problems from the Standpoint of Artificial Intelligence&quot; (1969). In that paper, which lays out the situation calculus and introduces the frame problem mentioned in the Dennett quote above, they argue that AI needs philosophy.

Philosophy hasn&#039;t had a similar argument that it needs AI, however. It has been admonished in the past to pay attention to the computational sciences, and to pay attention to cognitive psychology, but those scoldings have been made to advance particular theses about the mind, about language, about justification. In most cases the science was used as a bludgeon. Naturalists and armchairs, recall.

What&#039;s new about formal epistemology and, in my view, what needs to be made more explicit, is the observation that several problems that appear in various epistemological theories have analogues within the computational sciences. Formal epistemology is a field rather than a class of theories (cf. reliabilism) or a school (cf. Bayesianism), because it represents an attempt to marshal a treasure trove of methods to explicate epistemological notions and relations. As you noted, there are learning problems that have the very same structure that is described by various epistemic theories. Sometimes, &lt;i&gt;sometimes&lt;/i&gt;, there are genuine and deep philosophical insights that come from looking at the computational analogue.]]></description>
		<content:encoded><![CDATA[<p>Thanks for this, John. I think the problem of bridging traditional epistemology and formal epistemology is difficult for intellectual as well as sociological reasons.</p>
<p>From the beginning AI has been more receptive to philosophy than philosophy to AI, in part because of the seminal paper by Pat Haynes and John MacCarthy, &#8220;Some Philosophical Problems from the Standpoint of Artificial Intelligence&#8221; (1969). In that paper, which lays out the situation calculus and introduces the frame problem mentioned in the Dennett quote above, they argue that AI needs philosophy.</p>
<p>Philosophy hasn&#8217;t had a similar argument that it needs AI, however. It has been admonished in the past to pay attention to the computational sciences, and to pay attention to cognitive psychology, but those scoldings have been made to advance particular theses about the mind, about language, about justification. In most cases the science was used as a bludgeon. Naturalists and armchairs, recall.</p>
<p>What&#8217;s new about formal epistemology and, in my view, what needs to be made more explicit, is the observation that several problems that appear in various epistemological theories have analogues within the computational sciences. Formal epistemology is a field rather than a class of theories (cf. reliabilism) or a school (cf. Bayesianism), because it represents an attempt to marshal a treasure trove of methods to explicate epistemological notions and relations. As you noted, there are learning problems that have the very same structure that is described by various epistemic theories. Sometimes, <i>sometimes</i>, there are genuine and deep philosophical insights that come from looking at the computational analogue.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: John</title>
		<link>http://certaindoubts.com/making-robots-walk/#comment-7270</link>
		<dc:creator><![CDATA[John]]></dc:creator>
		<pubDate>Sat, 31 Mar 2007 00:07:16 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=676#comment-7270</guid>
		<description><![CDATA[Gregory,

Your post reminds me of Dennett&#039;s remarks about traditional philosophical methodology in &quot;Cognitive Wheels: The Frame Problem of AI&quot;:

&lt;blockquote&gt;Hume, like virtually all other philosophers and &quot;mentalistic&quot; psychologists, was unable to see the frame problem because he operated at what I call a purely semantic level, or a phenomenological level. At the phenomenological level, all the items in view are individuated by their meanings. Their meanings are, if you like, &quot;given&quot;—but this just means that the theorist helps himself to all the meanings he wants. In this way the semantic relation between one item and the next is typically plain to see, and one just assumes that the items behave as items with those meanings ought to behave.

....
That is the mechanical question the philosophers left to some dimly imagined future researcher. Such a division of labor might have been all right, but it is turning out that most of the truly difficult and deep puzzles of learning and intelligence get kicked downstairs by this move. It is rather as if philosophers were to proclaim themselves expert explainers of the methods of a stage magician, and then, when we ask them to explain how the magician does the sawing-the-lady-in-half trick, they explain that it is really quite obvious: the magician doesn&#039;t really saw her in half; he simply makes it appear that he does. &quot;But how does he do that?&quot; we ask. &quot;Not our department,&quot; say the philosophers—and some of them add, sonorously: &quot;Explanation has to stop somewhere.&quot; &lt;/blockquote&gt;

Personally, I have had a difficult time convincing certain epistemologists of the relevance of relatively primitive and abstract computability constraints, let alone computational complexity and other more basic implementation-level concerns.  It is my hope that the recent (seeming?) popularity of formal epistemology will catalyze dialogue between epistemologists and AI/machine learning researchers.]]></description>
		<content:encoded><![CDATA[<p>Gregory,</p>
<p>Your post reminds me of Dennett&#8217;s remarks about traditional philosophical methodology in &#8220;Cognitive Wheels: The Frame Problem of AI&#8221;:</p>
<blockquote><p>Hume, like virtually all other philosophers and &#8220;mentalistic&#8221; psychologists, was unable to see the frame problem because he operated at what I call a purely semantic level, or a phenomenological level. At the phenomenological level, all the items in view are individuated by their meanings. Their meanings are, if you like, &#8220;given&#8221;—but this just means that the theorist helps himself to all the meanings he wants. In this way the semantic relation between one item and the next is typically plain to see, and one just assumes that the items behave as items with those meanings ought to behave.</p>
<p>&#8230;.<br />
That is the mechanical question the philosophers left to some dimly imagined future researcher. Such a division of labor might have been all right, but it is turning out that most of the truly difficult and deep puzzles of learning and intelligence get kicked downstairs by this move. It is rather as if philosophers were to proclaim themselves expert explainers of the methods of a stage magician, and then, when we ask them to explain how the magician does the sawing-the-lady-in-half trick, they explain that it is really quite obvious: the magician doesn&#8217;t really saw her in half; he simply makes it appear that he does. &#8220;But how does he do that?&#8221; we ask. &#8220;Not our department,&#8221; say the philosophers—and some of them add, sonorously: &#8220;Explanation has to stop somewhere.&#8221; </p></blockquote>
<p>Personally, I have had a difficult time convincing certain epistemologists of the relevance of relatively primitive and abstract computability constraints, let alone computational complexity and other more basic implementation-level concerns.  It is my hope that the recent (seeming?) popularity of formal epistemology will catalyze dialogue between epistemologists and AI/machine learning researchers.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/making-robots-walk/#comment-7272</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Fri, 30 Mar 2007 11:07:59 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=676#comment-7272</guid>
		<description><![CDATA[Nice correction Kenny, thanks. A clarification: The foot itself is only in one of n3 positions, but the leg can be placed in 3n configurations, which is the problem. The leg is what has to be positioned to place the foot in one of these n3 positions. And foot placement is not independent of how the mass above it is distributed. (We fall over when we act otherwise.)]]></description>
		<content:encoded><![CDATA[<p>Nice correction Kenny, thanks. A clarification: The foot itself is only in one of n3 positions, but the leg can be placed in 3n configurations, which is the problem. The leg is what has to be positioned to place the foot in one of these n3 positions. And foot placement is not independent of how the mass above it is distributed. (We fall over when we act otherwise.)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Kenny Easwaran</title>
		<link>http://certaindoubts.com/making-robots-walk/#comment-7271</link>
		<dc:creator><![CDATA[Kenny Easwaran]]></dc:creator>
		<pubDate>Fri, 30 Mar 2007 01:11:01 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=676#comment-7271</guid>
		<description><![CDATA[Shouldn&#039;t that be n3 rather than 3n?]]></description>
		<content:encoded><![CDATA[<p>Shouldn&#8217;t that be n3 rather than 3n?</p>
]]></content:encoded>
	</item>
</channel>
</rss>
