<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Of Elections and Lotteries</title>
	<atom:link href="http://certaindoubts.com/3770/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/3770/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/3770/#comment-32514</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Tue, 13 Nov 2012 19:56:43 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=3770#comment-32514</guid>
		<description><![CDATA[In the case of the lottery, I take it that we are supposed to withhold claiming to know that the ticket is a loser because we&#039;ll find out in fact whether our ticket will win or lose. I am fine with this advice, so far as it goes. My point instead is that it is an uninteresting case and the advice one might take from it about so-called &#039;lottery propositions&#039; does not carry you very far. 

One doesn&#039;t have to get fancy with extensive measurement, although the epistemology literature would be better-served by measurement than by toy lotteries. The old carpenter&#039;s saying to &#039;measure twice, cut once&#039; is a detachment rule.  If we take ourselves to know extensive quantities of physical objects, such as a stick&#039;s length, we come by them through some finite set of measurements.  Our confidence that a stick so-measured is between .7532 and .7533 meters in length? Well, so long as no known errors occurred to confound our procedure (the default condition), such an undefeated procedure is such that it would be extremely unlikely that in fact the stick is either less than .7532 meters in length or greater than .7533. If one wished to print lottery tickets in some proportion to represent those odds, &lt;i&gt;that&lt;/i&gt; would be an interesting lottery; however, we mere mortals are not privy to the outcome of that draw.  Nevertheless, we detach!]]></description>
		<content:encoded><![CDATA[<p>In the case of the lottery, I take it that we are supposed to withhold claiming to know that the ticket is a loser because we&#8217;ll find out in fact whether our ticket will win or lose. I am fine with this advice, so far as it goes. My point instead is that it is an uninteresting case and the advice one might take from it about so-called &#8216;lottery propositions&#8217; does not carry you very far. </p>
<p>One doesn&#8217;t have to get fancy with extensive measurement, although the epistemology literature would be better-served by measurement than by toy lotteries. The old carpenter&#8217;s saying to &#8216;measure twice, cut once&#8217; is a detachment rule.  If we take ourselves to know extensive quantities of physical objects, such as a stick&#8217;s length, we come by them through some finite set of measurements.  Our confidence that a stick so-measured is between .7532 and .7533 meters in length? Well, so long as no known errors occurred to confound our procedure (the default condition), such an undefeated procedure is such that it would be extremely unlikely that in fact the stick is either less than .7532 meters in length or greater than .7533. If one wished to print lottery tickets in some proportion to represent those odds, <i>that</i> would be an interesting lottery; however, we mere mortals are not privy to the outcome of that draw.  Nevertheless, we detach!</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Trent Dougherty</title>
		<link>http://certaindoubts.com/3770/#comment-32509</link>
		<dc:creator><![CDATA[Trent Dougherty]]></dc:creator>
		<pubDate>Tue, 13 Nov 2012 17:25:41 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=3770#comment-32509</guid>
		<description><![CDATA[Greg, I take it we&#039;re on the same side here, right.  Are you thinking there is a species-genus relationship here between lotteries and measurements?  Or are you suggesting they are or are not structurally similar?

Is the suggestion that knowledge of an announcement throws people off in lottery cases?  I said something like that in my dissertation.  

Consider: I ask you to estimate the height of the child within reasonable parameters (an inch or an inch and a half, say.  You would probably take yourself to reasonably know the height.  But then I say that the exact hight of the child will be posted tomorrow, this might make you hesitate to say you knew the hight.  I attribute this in part to people being very risk averse to being called out as wrong.]]></description>
		<content:encoded><![CDATA[<p>Greg, I take it we&#8217;re on the same side here, right.  Are you thinking there is a species-genus relationship here between lotteries and measurements?  Or are you suggesting they are or are not structurally similar?</p>
<p>Is the suggestion that knowledge of an announcement throws people off in lottery cases?  I said something like that in my dissertation.  </p>
<p>Consider: I ask you to estimate the height of the child within reasonable parameters (an inch or an inch and a half, say.  You would probably take yourself to reasonably know the height.  But then I say that the exact hight of the child will be posted tomorrow, this might make you hesitate to say you knew the hight.  I attribute this in part to people being very risk averse to being called out as wrong.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/3770/#comment-32505</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Tue, 13 Nov 2012 15:29:05 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=3770#comment-32505</guid>
		<description><![CDATA[Trent,

Default logic is a non-monotonic logic, and detachment rules of the kind you&#039;re advocating are usually taken for examples of &#039;nonmonotonic reasoning&#039;. 

Detachment, as you put it here, however, is not just fine within default logic, however. There is a missing component to the argument: the default condition: if 99/100 (of observable r&#039;s) are p, it is not provable that (r is) not p, then (r is) p.

I think it would be more fruitful to look at extensive measurement examples rather than &#039;explicit lotteries&#039;. We routinely take ourselves to know (assert; act as if true) the height of our children, say, or the length of planks of wood; otherwise bookshelves wouldn&#039;t get built, children wouldn&#039;t be enrolled in school. The main difference between lotteries and measured quantities is that there isn&#039;t a public announcement to look forward to that will resolve the true height of a child, the true length of a plank. I fail to see this as very telling about detachment rules; it is an accidental feature of this thought experiment.]]></description>
		<content:encoded><![CDATA[<p>Trent,</p>
<p>Default logic is a non-monotonic logic, and detachment rules of the kind you&#8217;re advocating are usually taken for examples of &#8216;nonmonotonic reasoning&#8217;. </p>
<p>Detachment, as you put it here, however, is not just fine within default logic, however. There is a missing component to the argument: the default condition: if 99/100 (of observable r&#8217;s) are p, it is not provable that (r is) not p, then (r is) p.</p>
<p>I think it would be more fruitful to look at extensive measurement examples rather than &#8216;explicit lotteries&#8217;. We routinely take ourselves to know (assert; act as if true) the height of our children, say, or the length of planks of wood; otherwise bookshelves wouldn&#8217;t get built, children wouldn&#8217;t be enrolled in school. The main difference between lotteries and measured quantities is that there isn&#8217;t a public announcement to look forward to that will resolve the true height of a child, the true length of a plank. I fail to see this as very telling about detachment rules; it is an accidental feature of this thought experiment.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Trent Dougherty</title>
		<link>http://certaindoubts.com/3770/#comment-32484</link>
		<dc:creator><![CDATA[Trent Dougherty]]></dc:creator>
		<pubDate>Tue, 13 Nov 2012 05:06:11 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=3770#comment-32484</guid>
		<description><![CDATA[Jennifer, 

&quot;99% chance that p, therefore p&quot; is only fallacious in monotonic* reasoning.  In default logic it&#039;s just fine.  And I&#039;m inclined to think--and partly due to B&#038;H lit--that we are nonmonotonic reasoners who use default logic all the time.



Brian, why am I not surprised...  Please post something when you have it together.

*I typo&#039;d &quot;nonmonotonic&quot; because I was focusing on the next sentence, where default logic is a standard nonmonotonic logic.  Thanks to Greg for catching this typo.]]></description>
		<content:encoded><![CDATA[<p>Jennifer, </p>
<p>&#8220;99% chance that p, therefore p&#8221; is only fallacious in monotonic* reasoning.  In default logic it&#8217;s just fine.  And I&#8217;m inclined to think&#8211;and partly due to B&amp;H lit&#8211;that we are nonmonotonic reasoners who use default logic all the time.</p>
<p>Brian, why am I not surprised&#8230;  Please post something when you have it together.</p>
<p>*I typo&#8217;d &#8220;nonmonotonic&#8221; because I was focusing on the next sentence, where default logic is a standard nonmonotonic logic.  Thanks to Greg for catching this typo.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jennifer Nagel</title>
		<link>http://certaindoubts.com/3770/#comment-32412</link>
		<dc:creator><![CDATA[Jennifer Nagel]]></dc:creator>
		<pubDate>Fri, 09 Nov 2012 13:15:54 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=3770#comment-32412</guid>
		<description><![CDATA[Hi Trent,

OK, I&#039;m really glad you aren&#039;t resurrecting the availability heuristic explanation!  

But I&#039;m still not sure I like your reservations about our mathematical way of thinking about (say) future contingents.  You suggest that people are poor at intuitively approximating the difference between a million and a billion (OK), and then suggest that there is something wrong with &quot;the basis on which some people (not me!) feel apprehension about attributing knowledge in explicit lotteries&quot;.  I still don&#039;t see how the weakness you identify can be pinpointed as what is giving rise to the apprehension.  

Here&#039;s my take on the source of the apprehension: when we reason probabilistically about a prospect and come to the conclusion that its chance of occurring is (say) .99, it seems like a mistake in probabilistic reasoning to conclude categorically that it will happen.  &quot;There is a .99 chance of p, therefore p&quot; really is bad reasoning, and we&#039;re not wrong about it being bad reasoning, and we really wouldn&#039;t have categorical knowledge of the outcome if we attained a belief in it by reasoning in that (actually bad) manner.

When we think about things in the L-way, we reach the considered judgment that the relevant prospect is very likely (&quot;this lottery ticket is very likely to lose&quot;).  As long as we are reasoning in the L-way we would be making a mistake to claim categorical knowledge.  It may however in some cases be open to us to reason in other ways about the outcomes we are considering.  So for many mundane claims about future events (&quot;I&#039;m going to have lunch with my friend Melanie today&quot;) we do not reason probabilistically about the chance of the occurrence, compounding various risks, etc.  We simply take as a default the most likely outcome (let&#039;s call this the O-way of reasoning; psychologists might describe it as a heuristic way of thinking). In many cases the O-way of reasoning may be a perfectly good way of securing knowledge.  And we shouldn&#039;t rush to conclude that our positive intuitions about securing knowledge in the O-way really are in conflict with our negative intuitions about securing knowledge of the same propositions in the L-way.  There is no conflict in saying that someone can know something through testimony right now, even though she can&#039;t know it through perception; likewise, it may be possible for someone to know something through heuristic thinking that he can&#039;t know by probabilistic reasoning.

In short, I think we are right to feel apprehension about claiming to know in advance of the draw that lottery tickets will lose -- this apprehension comes from a precisely accurate deliverance of our probabilistic reasoning (like the recognition that .99 does not equal 1).  We would be wrong to think that this apprehension is a reason for skepticism about our ordinary ways of knowing.  

Class-O intuitions and class-K intuitions are (generally) both correct, and not really in conflict.]]></description>
		<content:encoded><![CDATA[<p>Hi Trent,</p>
<p>OK, I&#8217;m really glad you aren&#8217;t resurrecting the availability heuristic explanation!  </p>
<p>But I&#8217;m still not sure I like your reservations about our mathematical way of thinking about (say) future contingents.  You suggest that people are poor at intuitively approximating the difference between a million and a billion (OK), and then suggest that there is something wrong with &#8220;the basis on which some people (not me!) feel apprehension about attributing knowledge in explicit lotteries&#8221;.  I still don&#8217;t see how the weakness you identify can be pinpointed as what is giving rise to the apprehension.  </p>
<p>Here&#8217;s my take on the source of the apprehension: when we reason probabilistically about a prospect and come to the conclusion that its chance of occurring is (say) .99, it seems like a mistake in probabilistic reasoning to conclude categorically that it will happen.  &#8220;There is a .99 chance of p, therefore p&#8221; really is bad reasoning, and we&#8217;re not wrong about it being bad reasoning, and we really wouldn&#8217;t have categorical knowledge of the outcome if we attained a belief in it by reasoning in that (actually bad) manner.</p>
<p>When we think about things in the L-way, we reach the considered judgment that the relevant prospect is very likely (&#8220;this lottery ticket is very likely to lose&#8221;).  As long as we are reasoning in the L-way we would be making a mistake to claim categorical knowledge.  It may however in some cases be open to us to reason in other ways about the outcomes we are considering.  So for many mundane claims about future events (&#8220;I&#8217;m going to have lunch with my friend Melanie today&#8221;) we do not reason probabilistically about the chance of the occurrence, compounding various risks, etc.  We simply take as a default the most likely outcome (let&#8217;s call this the O-way of reasoning; psychologists might describe it as a heuristic way of thinking). In many cases the O-way of reasoning may be a perfectly good way of securing knowledge.  And we shouldn&#8217;t rush to conclude that our positive intuitions about securing knowledge in the O-way really are in conflict with our negative intuitions about securing knowledge of the same propositions in the L-way.  There is no conflict in saying that someone can know something through testimony right now, even though she can&#8217;t know it through perception; likewise, it may be possible for someone to know something through heuristic thinking that he can&#8217;t know by probabilistic reasoning.</p>
<p>In short, I think we are right to feel apprehension about claiming to know in advance of the draw that lottery tickets will lose &#8212; this apprehension comes from a precisely accurate deliverance of our probabilistic reasoning (like the recognition that .99 does not equal 1).  We would be wrong to think that this apprehension is a reason for skepticism about our ordinary ways of knowing.  </p>
<p>Class-O intuitions and class-K intuitions are (generally) both correct, and not really in conflict.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: John Turri</title>
		<link>http://certaindoubts.com/3770/#comment-32399</link>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
		<pubDate>Fri, 09 Nov 2012 03:50:45 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=3770#comment-32399</guid>
		<description><![CDATA[Hi, Trent. Great post! Just a quick note to say that Ori Friedman and I are in the midst of a series of studies on lotteries and knowledge and closure. Preliminary results are intriguing, and I will post a draft here when it is in good enough shape (might be a few months).]]></description>
		<content:encoded><![CDATA[<p>Hi, Trent. Great post! Just a quick note to say that Ori Friedman and I are in the midst of a series of studies on lotteries and knowledge and closure. Preliminary results are intriguing, and I will post a draft here when it is in good enough shape (might be a few months).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Luis Rosa</title>
		<link>http://certaindoubts.com/3770/#comment-32395</link>
		<dc:creator><![CDATA[Luis Rosa]]></dc:creator>
		<pubDate>Fri, 09 Nov 2012 00:03:50 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=3770#comment-32395</guid>
		<description><![CDATA[Just a question: given that Class-O intuitions are more &lt;i&gt;solid&lt;/i&gt; (I&#039;m not sure I understood what you mean by &#039;solid&#039; though) than Class-K intuitions with respect to some case c, why exactly do we have to favour the first ones? Any prospect of presenting evidence in favor of the thesis that, if O intuitions are more solid than K intuitions about a case c then, &lt;i&gt;probably&lt;/i&gt;, the judgment generated by an O intuition is true and the judgment generated by a K intuition is not?]]></description>
		<content:encoded><![CDATA[<p>Just a question: given that Class-O intuitions are more <i>solid</i> (I&#8217;m not sure I understood what you mean by &#8216;solid&#8217; though) than Class-K intuitions with respect to some case c, why exactly do we have to favour the first ones? Any prospect of presenting evidence in favor of the thesis that, if O intuitions are more solid than K intuitions about a case c then, <i>probably</i>, the judgment generated by an O intuition is true and the judgment generated by a K intuition is not?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Trent Dougherty</title>
		<link>http://certaindoubts.com/3770/#comment-32393</link>
		<dc:creator><![CDATA[Trent Dougherty]]></dc:creator>
		<pubDate>Thu, 08 Nov 2012 21:55:15 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=3770#comment-32393</guid>
		<description><![CDATA[Jennifer.

1. I never claimed originality for this.  It is too obvious to anyone familiar with the literature.  Indeed, I noted that John suggests it.  But I omitted reference to the availability heuristic precisely because I don&#039;t think it&#039;s the most promising version of the strategy.  

2. I don&#039;t think the kind of strategy I sketch an outline of requires *blanket* reasons to distrust our own math or prob reasoning.  I tried to be careful about two things:

a. I said there was an &quot;elevated risk&quot; of error when math/numbers/chance came into the picture.

b. I said that when two intuitions conflict, the fact in (a) can lead to a *favoring* of one vs. the other.  There is no need at all to refer to blanket distrust in such a strategy.  If I have to indicators, both highly reliable but one more so than the other, I go with the more reliable one.

3. I don&#039;t think we need any X-phi to ward off skeptical worries from structural similarity between ordinary knowledge and lottery situations because I&#039;m perfectly happy being a hard-headed Moorean and saying that if there is such a parallel structure then I&#039;m a far sight more confident in my ordinary knowledge attributions than in my lottery ones (or at least that&#039;s what I&#039;d say if I *had* skeptical intuitions about lotteries).

4a. There are a lot of other parts of the B&#038;H lit than the availability heuristic (though it&#039;s a nice broad one and pretty flexible and applicable), and I haven&#039;t seen it mined thoroughly to test some of the relevant skills.  For example, when I taught High School math, it was pretty common for syllabi resources to include stuff (kinda like this: http://serc.carleton.edu/quantskills/activities/UndBigNos.html and this: http://www.ucmp.berkeley.edu/education/lessons/billion/billion.html ) to try to get people to appreciate the largeness of large numbers.  It does not come naturally.  Whether it is the size of the national debt, the age of the univers, the size of the universe, the scale of the sub-atomic, what have you, educators must constantly overcome our inability to appreciate the vastness of numbers over relatively low thresholds.  

4b. The same goes for games of chance.  If people were naturally good at them, there&#039;d be no Vegas.  And there are other related factors plausibly involved in lottery intuitions and they all come together to make me pretty sure of the following:

TD1  Lottery intuitions are less reliable than ordinary intuitions

where that is interpreted in such a way as to have as an essence that the basis on which some people (not me!) feel apprehension about attributing knowledge in explicit lotteries is less secure than the basis upon which we judge that we know things in ordinary life under ordinary descriptions, even if those situations admit of L-descriptions due to relevantly similar structure.  

I wish I had the money to give you a huge grant to do this, because you rock at such things.  Otherwise, I repeat my recommend to folks what appears to me to be an interesting line of research.]]></description>
		<content:encoded><![CDATA[<p>Jennifer.</p>
<p>1. I never claimed originality for this.  It is too obvious to anyone familiar with the literature.  Indeed, I noted that John suggests it.  But I omitted reference to the availability heuristic precisely because I don&#8217;t think it&#8217;s the most promising version of the strategy.  </p>
<p>2. I don&#8217;t think the kind of strategy I sketch an outline of requires *blanket* reasons to distrust our own math or prob reasoning.  I tried to be careful about two things:</p>
<p>a. I said there was an &#8220;elevated risk&#8221; of error when math/numbers/chance came into the picture.</p>
<p>b. I said that when two intuitions conflict, the fact in (a) can lead to a *favoring* of one vs. the other.  There is no need at all to refer to blanket distrust in such a strategy.  If I have to indicators, both highly reliable but one more so than the other, I go with the more reliable one.</p>
<p>3. I don&#8217;t think we need any X-phi to ward off skeptical worries from structural similarity between ordinary knowledge and lottery situations because I&#8217;m perfectly happy being a hard-headed Moorean and saying that if there is such a parallel structure then I&#8217;m a far sight more confident in my ordinary knowledge attributions than in my lottery ones (or at least that&#8217;s what I&#8217;d say if I *had* skeptical intuitions about lotteries).</p>
<p>4a. There are a lot of other parts of the B&amp;H lit than the availability heuristic (though it&#8217;s a nice broad one and pretty flexible and applicable), and I haven&#8217;t seen it mined thoroughly to test some of the relevant skills.  For example, when I taught High School math, it was pretty common for syllabi resources to include stuff (kinda like this: <a href="http://serc.carleton.edu/quantskills/activities/UndBigNos.html" rel="nofollow">http://serc.carleton.edu/quantskills/activities/UndBigNos.html</a> and this: <a href="http://www.ucmp.berkeley.edu/education/lessons/billion/billion.html" rel="nofollow">http://www.ucmp.berkeley.edu/education/lessons/billion/billion.html</a> ) to try to get people to appreciate the largeness of large numbers.  It does not come naturally.  Whether it is the size of the national debt, the age of the univers, the size of the universe, the scale of the sub-atomic, what have you, educators must constantly overcome our inability to appreciate the vastness of numbers over relatively low thresholds.  </p>
<p>4b. The same goes for games of chance.  If people were naturally good at them, there&#8217;d be no Vegas.  And there are other related factors plausibly involved in lottery intuitions and they all come together to make me pretty sure of the following:</p>
<p>TD1  Lottery intuitions are less reliable than ordinary intuitions</p>
<p>where that is interpreted in such a way as to have as an essence that the basis on which some people (not me!) feel apprehension about attributing knowledge in explicit lotteries is less secure than the basis upon which we judge that we know things in ordinary life under ordinary descriptions, even if those situations admit of L-descriptions due to relevantly similar structure.  </p>
<p>I wish I had the money to give you a huge grant to do this, because you rock at such things.  Otherwise, I repeat my recommend to folks what appears to me to be an interesting line of research.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jennifer Nagel</title>
		<link>http://certaindoubts.com/3770/#comment-32383</link>
		<dc:creator><![CDATA[Jennifer Nagel]]></dc:creator>
		<pubDate>Thu, 08 Nov 2012 17:52:55 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=3770#comment-32383</guid>
		<description><![CDATA[Hi Trent,

You are not the only person to point to the biases and heuristics literature as a possible source of error in thinking about probabilities -- Hawthorne does exactly that himself, claiming that work on the availability heuristic suggests that we are liable to overestimate probabilities of error on hearing them mentioned.  I&#039;ve argued &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9213.2009.624.x/abstract&quot; rel=&quot;nofollow&quot;&gt; in a paper in PQ &lt;/a&gt; that this is a misreading of the relevant empirical literature.  The availability heuristic has the wrong activation and cancellation conditions, for starters.  So I don&#039;t think this is a good research project for xphi right now -- I think that it&#039;s a research project that has already been executed in the empirical literature on reasoning, and the existing empirical research tells pretty decisively against a Hawthorne-style explanation.  Unless you have a better story about what it is in the biases and heuristics literature that is problematic, I&#039;m not going there.  I don&#039;t think that body of literature gives us any *blanket* reasons to distrust our own mathematical or probabilistic reasoning (thank goodness).  I think that our judgments about mathematics and risk can be perfectly accurate, that there is absolutely nothing wrong with my appreciation of the odds of my ticket&#039;s losing a one-in-a-million fair lottery, for example.

But I agree with you &lt;a href=&quot;http://philpapers.org/rec/NAGTPB&quot; rel=&quot;nofollow&quot;&gt; for reasons explained here &lt;/a&gt; that we do not need to resort to fancy semantics to get out of the problem, or to save Closure.]]></description>
		<content:encoded><![CDATA[<p>Hi Trent,</p>
<p>You are not the only person to point to the biases and heuristics literature as a possible source of error in thinking about probabilities &#8212; Hawthorne does exactly that himself, claiming that work on the availability heuristic suggests that we are liable to overestimate probabilities of error on hearing them mentioned.  I&#8217;ve argued <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9213.2009.624.x/abstract" rel="nofollow"> in a paper in PQ </a> that this is a misreading of the relevant empirical literature.  The availability heuristic has the wrong activation and cancellation conditions, for starters.  So I don&#8217;t think this is a good research project for xphi right now &#8212; I think that it&#8217;s a research project that has already been executed in the empirical literature on reasoning, and the existing empirical research tells pretty decisively against a Hawthorne-style explanation.  Unless you have a better story about what it is in the biases and heuristics literature that is problematic, I&#8217;m not going there.  I don&#8217;t think that body of literature gives us any *blanket* reasons to distrust our own mathematical or probabilistic reasoning (thank goodness).  I think that our judgments about mathematics and risk can be perfectly accurate, that there is absolutely nothing wrong with my appreciation of the odds of my ticket&#8217;s losing a one-in-a-million fair lottery, for example.</p>
<p>But I agree with you <a href="http://philpapers.org/rec/NAGTPB" rel="nofollow"> for reasons explained here </a> that we do not need to resort to fancy semantics to get out of the problem, or to save Closure.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Trent Dougherty</title>
		<link>http://certaindoubts.com/3770/#comment-32377</link>
		<dc:creator><![CDATA[Trent Dougherty]]></dc:creator>
		<pubDate>Thu, 08 Nov 2012 15:52:02 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=3770#comment-32377</guid>
		<description><![CDATA[Jennifer, thanks for your questions.

1. Yes, I think that a sufficiently high (total) probability (relative to one’s evidence) that the ticket is a loser is a (logically) sufficient condition for propositional justification that that ticket is a loser.  And that when one properly basis their belief that that ticket is a loser on that evidence, then that is a (logically) sufficient condition for having knowledge-level doxastic justification.  And that when these conditions hold and the belief is true, one knows that the ticket is a loser. 

2. I have not suggested the precise mechanism whereby this is occurring, that’s what I think would make a great research project at the intersection of epistemology and X-phi.  But I take it that the lit on biases and heuristics supports the very general thesis that 

BH1  Subjects show an elevated risk of bamboozlement when thinking about probabilities.

That’s still vague and a short inference from, not the direct result of, the tests.  My admittedly casual but frequent and very interested reading of the B&#038;H lit leads me to believe that there are lots of theses similar to BH1 such as

BH2  ...when thinking about games of chance.

BH3  ...thinking about large numbers.

If my argument is valid then if my claim that the BHi are supported by the B&#038;H literature is substantiated by detailed application, we’ve got a pretty good argument that the pervasive skepticism discussed in Hawthorne 2004 can be avoided without any fancy new linguisticsy stuff.  I think that’s a good thing.  

I think the BHi are just a step above common sense in obviousness, and I don’t think the claims need much by way of particular empirical support for Premise 2 to be belief-worthy.  But it would be really nice to nail it down solidly by connecting it to particular studies in the literature or to gather some new data to test the hypothesis more directly.  Seems like a great research project to me.

3. As to the issue of whether there are cases that admit of both O- and L-descriptions without (relevant) loss, I guess I just think John gives some good examples in K&#038;L.  But it might not be as widespread as some have claimed.  My recollection is that he makes it seem quite broad. I put that in my data, becuause it’s generally accepted and I wanted to focus on what follows from it, but it is interesting that you question it.]]></description>
		<content:encoded><![CDATA[<p>Jennifer, thanks for your questions.</p>
<p>1. Yes, I think that a sufficiently high (total) probability (relative to one’s evidence) that the ticket is a loser is a (logically) sufficient condition for propositional justification that that ticket is a loser.  And that when one properly basis their belief that that ticket is a loser on that evidence, then that is a (logically) sufficient condition for having knowledge-level doxastic justification.  And that when these conditions hold and the belief is true, one knows that the ticket is a loser. </p>
<p>2. I have not suggested the precise mechanism whereby this is occurring, that’s what I think would make a great research project at the intersection of epistemology and X-phi.  But I take it that the lit on biases and heuristics supports the very general thesis that </p>
<p>BH1  Subjects show an elevated risk of bamboozlement when thinking about probabilities.</p>
<p>That’s still vague and a short inference from, not the direct result of, the tests.  My admittedly casual but frequent and very interested reading of the B&amp;H lit leads me to believe that there are lots of theses similar to BH1 such as</p>
<p>BH2  &#8230;when thinking about games of chance.</p>
<p>BH3  &#8230;thinking about large numbers.</p>
<p>If my argument is valid then if my claim that the BHi are supported by the B&amp;H literature is substantiated by detailed application, we’ve got a pretty good argument that the pervasive skepticism discussed in Hawthorne 2004 can be avoided without any fancy new linguisticsy stuff.  I think that’s a good thing.  </p>
<p>I think the BHi are just a step above common sense in obviousness, and I don’t think the claims need much by way of particular empirical support for Premise 2 to be belief-worthy.  But it would be really nice to nail it down solidly by connecting it to particular studies in the literature or to gather some new data to test the hypothesis more directly.  Seems like a great research project to me.</p>
<p>3. As to the issue of whether there are cases that admit of both O- and L-descriptions without (relevant) loss, I guess I just think John gives some good examples in K&amp;L.  But it might not be as widespread as some have claimed.  My recollection is that he makes it seem quite broad. I put that in my data, becuause it’s generally accepted and I wanted to focus on what follows from it, but it is interesting that you question it.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
