<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Justification and Explanation</title>
	<atom:link href="http://certaindoubts.com/507/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/507/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Michael Huemer</title>
		<link>http://certaindoubts.com/507/#comment-3155</link>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
		<pubDate>Thu, 02 Feb 2006 05:55:23 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=507#comment-3155</guid>
		<description><![CDATA[Hm, I think we have very different methodological assumptions. I think Foley&#039;s argument is compelling in the intuition-mooting forum, simply because the intuition he relies on is strong. When I first heard it, it convinced me that epistemic conservatism was false. I don&#039;t think the &lt;i&gt;frequency&lt;/i&gt; with which cases of the kind occur matters -- indeed, Foley&#039;s case may never have actually been realized; still, conservatism implies that &lt;i&gt;if such a case were to occur&lt;/i&gt;, the belief in question would be justified, and that counterfactual strikes me as clearly false.

Also, even though we have strong evidence that science is generally good at finding things out, I don&#039;t think we have strong empirical evidence for the conservatism norm. This is for two reasons: (1) Because the general reliability of science is compatible with some particular norm of scientific practice being dispensible (as we&#039;ve both agreed), and (2) because anyway, the norm of conservatism is an &lt;i&gt;interpretation&lt;/i&gt; of scientific practice that I think is open to question. Other interpretations are possible; e.g., perhaps the norm is really &quot;Prefer theories that are consistent with existing &lt;i&gt;justified&lt;/i&gt; theories&quot; or &quot;Prefer theories that are consistent with existing theories &lt;i&gt;that are not in question&lt;/i&gt;.&quot; And I think more interpretations may exist.]]></description>
		<content:encoded><![CDATA[<p>Hm, I think we have very different methodological assumptions. I think Foley&#8217;s argument is compelling in the intuition-mooting forum, simply because the intuition he relies on is strong. When I first heard it, it convinced me that epistemic conservatism was false. I don&#8217;t think the <i>frequency</i> with which cases of the kind occur matters &#8212; indeed, Foley&#8217;s case may never have actually been realized; still, conservatism implies that <i>if such a case were to occur</i>, the belief in question would be justified, and that counterfactual strikes me as clearly false.</p>
<p>Also, even though we have strong evidence that science is generally good at finding things out, I don&#8217;t think we have strong empirical evidence for the conservatism norm. This is for two reasons: (1) Because the general reliability of science is compatible with some particular norm of scientific practice being dispensible (as we&#8217;ve both agreed), and (2) because anyway, the norm of conservatism is an <i>interpretation</i> of scientific practice that I think is open to question. Other interpretations are possible; e.g., perhaps the norm is really &#8220;Prefer theories that are consistent with existing <i>justified</i> theories&#8221; or &#8220;Prefer theories that are consistent with existing theories <i>that are not in question</i>.&#8221; And I think more interpretations may exist.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jonathan weinberg</title>
		<link>http://certaindoubts.com/507/#comment-3154</link>
		<dc:creator><![CDATA[jonathan weinberg]]></dc:creator>
		<pubDate>Mon, 30 Jan 2006 06:22:29 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=507#comment-3154</guid>
		<description><![CDATA[A few responses: first, even if we were just sitting around with no particular reasons to suspect that we should adopt conservatism, and so just mooting about our intuitions about it, I don&#039;t see where this case would show very much.  I agree that we don&#039;t want it to be _generally_ the case that people could get their beliefs justified so easily; and that we don&#039;t want our norms to be easily _gameable_ by someone who&#039;s looking for an irresponsible shortcut to justification.  But the case doesn&#039;t show either of those things to be real threats.  Rather, it shows that _under heavily convoluted &#038; presumably rare circumstances_, a norm of conservatism might have this odd consequence.  And it seems to me the right response, if we&#039;re just intuition-mooting, would be to say: well, ok, that&#039;s one very small mark against it; but how does it do on more central sorts of cases?

But, anyway, we&#039;re not just intuition-mooting here.  Rather, we already have excellent evidence for this norm -- namely, its deployment in the suite of extraordinarily successful norms that go into the scientific evaluation of hypotheses.  Your hypothetical would have at best a small weight in the context of armchair mootage -- that weight drops effectively to null in the actual context we&#039;re considering.


This also shows why it&#039;s a mistake to suppose that conservatism rests on the antecedent rationality of the scientists.  Which is a good thing, since there&#039;s plenty of reason to think that the judgments of individual scientists, and of the scientific community at large, are influenced by all sorts of non-rational forces.  Nonetheless, the norm of conservatism is one that seems to work as part of our package, and consideration of hypothetical cases isn&#039;t going to show otherwise.]]></description>
		<content:encoded><![CDATA[<p>A few responses: first, even if we were just sitting around with no particular reasons to suspect that we should adopt conservatism, and so just mooting about our intuitions about it, I don&#8217;t see where this case would show very much.  I agree that we don&#8217;t want it to be _generally_ the case that people could get their beliefs justified so easily; and that we don&#8217;t want our norms to be easily _gameable_ by someone who&#8217;s looking for an irresponsible shortcut to justification.  But the case doesn&#8217;t show either of those things to be real threats.  Rather, it shows that _under heavily convoluted &amp; presumably rare circumstances_, a norm of conservatism might have this odd consequence.  And it seems to me the right response, if we&#8217;re just intuition-mooting, would be to say: well, ok, that&#8217;s one very small mark against it; but how does it do on more central sorts of cases?</p>
<p>But, anyway, we&#8217;re not just intuition-mooting here.  Rather, we already have excellent evidence for this norm &#8212; namely, its deployment in the suite of extraordinarily successful norms that go into the scientific evaluation of hypotheses.  Your hypothetical would have at best a small weight in the context of armchair mootage &#8212; that weight drops effectively to null in the actual context we&#8217;re considering.</p>
<p>This also shows why it&#8217;s a mistake to suppose that conservatism rests on the antecedent rationality of the scientists.  Which is a good thing, since there&#8217;s plenty of reason to think that the judgments of individual scientists, and of the scientific community at large, are influenced by all sorts of non-rational forces.  Nonetheless, the norm of conservatism is one that seems to work as part of our package, and consideration of hypothetical cases isn&#8217;t going to show otherwise.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Michael Huemer</title>
		<link>http://certaindoubts.com/507/#comment-3153</link>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
		<pubDate>Sun, 29 Jan 2006 17:39:55 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=507#comment-3153</guid>
		<description><![CDATA[By the way, JW, I&#039;m glad we agree on the merits of those philosophical appeals to simplicity. I&#039;m starting a new thread on simplicity.]]></description>
		<content:encoded><![CDATA[<p>By the way, JW, I&#8217;m glad we agree on the merits of those philosophical appeals to simplicity. I&#8217;m starting a new thread on simplicity.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Michael Huemer</title>
		<link>http://certaindoubts.com/507/#comment-3152</link>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
		<pubDate>Sat, 28 Jan 2006 15:50:14 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=507#comment-3152</guid>
		<description><![CDATA[The objection isn&#039;t that conservatism can fail to lead to the truth. For all I&#039;ve said (or for all Foley said in &quot;Epistemic Conservatism&quot;), the belief could be true.

Foley&#039;s objection was to epistemic conservatism on the individual level; his objection was that the doctrine allows cases in which a person is by hypothesis unjustified in adopting a belief, yet the belief immediately becomes justified as soon as he adopts it. I assume that most people would find this counterintuitive.

I&#039;m just adapting this to a social case -- i.e., a community irrationally adopts some belief, but as soon as they adopt it, it&#039;s rational. None of the other criteria of justification have this consequence.]]></description>
		<content:encoded><![CDATA[<p>The objection isn&#8217;t that conservatism can fail to lead to the truth. For all I&#8217;ve said (or for all Foley said in &#8220;Epistemic Conservatism&#8221;), the belief could be true.</p>
<p>Foley&#8217;s objection was to epistemic conservatism on the individual level; his objection was that the doctrine allows cases in which a person is by hypothesis unjustified in adopting a belief, yet the belief immediately becomes justified as soon as he adopts it. I assume that most people would find this counterintuitive.</p>
<p>I&#8217;m just adapting this to a social case &#8212; i.e., a community irrationally adopts some belief, but as soon as they adopt it, it&#8217;s rational. None of the other criteria of justification have this consequence.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jonathan weinberg</title>
		<link>http://certaindoubts.com/507/#comment-3151</link>
		<dc:creator><![CDATA[jonathan weinberg]]></dc:creator>
		<pubDate>Fri, 27 Jan 2006 20:25:51 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=507#comment-3151</guid>
		<description><![CDATA[Mike, I&#039;m not sure I understand what the force of the case is meant to be here.  Yes, sometimes conservatism  can pull one away from the truth.  So can the other criteria.  Simplicity is objectively non-truth-promoting when the universe fails to be simple; conservatism is objectively non-truth-promoting when we&#039;ve collectively gotten onto a wrong track.  And so on.  None of this undermines the basic claim here, which is that the criteria all together give us a good (but very fallible, of course) guide for theory selection, and that we&#039;re justified in believing in accord with inference to the best explanation.

Maybe if you filled in your take on CI a bit more I could see what you have in mind, but right now I&#039;m just not seeing the problem.]]></description>
		<content:encoded><![CDATA[<p>Mike, I&#8217;m not sure I understand what the force of the case is meant to be here.  Yes, sometimes conservatism  can pull one away from the truth.  So can the other criteria.  Simplicity is objectively non-truth-promoting when the universe fails to be simple; conservatism is objectively non-truth-promoting when we&#8217;ve collectively gotten onto a wrong track.  And so on.  None of this undermines the basic claim here, which is that the criteria all together give us a good (but very fallible, of course) guide for theory selection, and that we&#8217;re justified in believing in accord with inference to the best explanation.</p>
<p>Maybe if you filled in your take on CI a bit more I could see what you have in mind, but right now I&#8217;m just not seeing the problem.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Michael Huemer</title>
		<link>http://certaindoubts.com/507/#comment-3150</link>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
		<pubDate>Thu, 26 Jan 2006 23:40:09 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=507#comment-3150</guid>
		<description><![CDATA[Jon W,

I wonder what you think about Foley&#039;s objection to epistemic conservatism. Here&#039;s an adaptation of it to the scientific case:

Suppose there are two theories, T1 and T2, which are the only contenders for being the best explanation in some domain. Suppose that, when the scientists are trying to decide between the two, T1 is just shy of being preferred on the basis of the normal criteria for goodness of explanation. The scientists irrationally accept T1 anyway. But as soon as they form this irrational belief (or as soon as a sufficient number of them do), it becomes rational, because now, in addition to its other virtues, T1 also has the virtue of conservativeness, so that pushes it over the threshold for justified belief.

Now you might think the scientists have a defeater in my scenario, because they have evidence that they formed their belief irrationally. So imagine that 20 years later, the scientific community has pretty much forgotten how T1 came to be adopted. As soon as they forget (or as soon as a sufficient percentage of the scientists no longer know how T1 came to be the consensus view), T1 becomes the justified theory.

As an aside, I think something like this in fact happened in the case of the Copenhagen Interpretation of QM, except that CI wasn&#039;t just slightly shy of being the best explanation; it was far short of being the best. (And of course I don&#039;t think CI ever became justified, but I think it is viewed as such because conservativeness is given more weight than intelligibility.)]]></description>
		<content:encoded><![CDATA[<p>Jon W,</p>
<p>I wonder what you think about Foley&#8217;s objection to epistemic conservatism. Here&#8217;s an adaptation of it to the scientific case:</p>
<p>Suppose there are two theories, T1 and T2, which are the only contenders for being the best explanation in some domain. Suppose that, when the scientists are trying to decide between the two, T1 is just shy of being preferred on the basis of the normal criteria for goodness of explanation. The scientists irrationally accept T1 anyway. But as soon as they form this irrational belief (or as soon as a sufficient number of them do), it becomes rational, because now, in addition to its other virtues, T1 also has the virtue of conservativeness, so that pushes it over the threshold for justified belief.</p>
<p>Now you might think the scientists have a defeater in my scenario, because they have evidence that they formed their belief irrationally. So imagine that 20 years later, the scientific community has pretty much forgotten how T1 came to be adopted. As soon as they forget (or as soon as a sufficient percentage of the scientists no longer know how T1 came to be the consensus view), T1 becomes the justified theory.</p>
<p>As an aside, I think something like this in fact happened in the case of the Copenhagen Interpretation of QM, except that CI wasn&#8217;t just slightly shy of being the best explanation; it was far short of being the best. (And of course I don&#8217;t think CI ever became justified, but I think it is viewed as such because conservativeness is given more weight than intelligibility.)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jonathan Weinberg</title>
		<link>http://certaindoubts.com/507/#comment-3149</link>
		<dc:creator><![CDATA[Jonathan Weinberg]]></dc:creator>
		<pubDate>Wed, 25 Jan 2006 15:00:31 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=507#comment-3149</guid>
		<description><![CDATA[Mike,

(a) With regard to the North American anthropology case, I&#039;m certainly willing to look at the particulars.  But I&#039;d think that I can agree with your professor that it the simplicity criterion may be doing a lot (though probably not all) of the work here.  It&#039;s just that the right way to understand the simplicity criterion is not in terms of head-counting.  The one-crossing will probably be more elegant than a multi-crossing theory; it also will leave fewer open questions (I&#039;m guessing that the initial crossing date could be pinned down moderately well, whereas any later ones would be much less clear.)

Unfortunately, philosophical practices don&#039;t have anything even remotely like the track-record of scientific practices, so the quirky ontological fetishes of some metaphysicians just doesn&#039;t have standing here.

(b) Nope, nothing wrong with A&#039;s argument -- so long as the first statement is understood as &quot;CI is better &lt;i&gt;to the extent that&lt;/i&gt; it is more conservative&quot;.  This is a holistic affair, and conservatism&#039;s just one criterion among several, which may well be overridden by the others (as of course happens with many of our most celebrated scientific achievements, like natural selection or general relativity.)  What can make it look fishy is that it can sound like maybe A wants that appeal to conservativeness to &lt;i&gt;settle&lt;/i&gt; the matter, and that indeed would be a lousy argument.  But generally, a theory&#039;s being the almost-consensus view is a &lt;i&gt;pro tanto&lt;/i&gt; good-making feature of the theory.

(d) I think the epistemic circularity worries can only come into play if there is an active challenge either to the vast bulk of what we take to be our accumulated knowledge, or to the scientific methods themselves.  On my understanding of the dialectic, that won&#039;t be the case.

But I agree with you completely about the last point -- that&#039;s why I was at pains at several points to say that these criteria are not beyond revision, and that our epistemology of explanation should start, but need not end, with the fact of the bounty of scientific knowledge.  Any revisions or challenges, however, have to be derived from within the framework that is taking the science fully seriously.  E.g., one might show that in most of the cases where scientists have appealed to criterion X, it has been in defense of a theory that would later lose out to a rival that had a lower score on X.  Indeed, suppose further that you could then propose some alternative criterion Y, that would capture the minority of cases in which X seemed to work, but would have made better selections in the cases that X botched.  Then you&#039;d have an excellent case for revising our practices to dump X and adopt Y.  These norms do get debated -- cf. the current literature on Morgan&#039;s Canon -- but the criteria can only usefully be tested within and against science itself, and not from the armchair.]]></description>
		<content:encoded><![CDATA[<p>Mike,</p>
<p>(a) With regard to the North American anthropology case, I&#8217;m certainly willing to look at the particulars.  But I&#8217;d think that I can agree with your professor that it the simplicity criterion may be doing a lot (though probably not all) of the work here.  It&#8217;s just that the right way to understand the simplicity criterion is not in terms of head-counting.  The one-crossing will probably be more elegant than a multi-crossing theory; it also will leave fewer open questions (I&#8217;m guessing that the initial crossing date could be pinned down moderately well, whereas any later ones would be much less clear.)</p>
<p>Unfortunately, philosophical practices don&#8217;t have anything even remotely like the track-record of scientific practices, so the quirky ontological fetishes of some metaphysicians just doesn&#8217;t have standing here.</p>
<p>(b) Nope, nothing wrong with A&#8217;s argument &#8212; so long as the first statement is understood as &#8220;CI is better <i>to the extent that</i> it is more conservative&#8221;.  This is a holistic affair, and conservatism&#8217;s just one criterion among several, which may well be overridden by the others (as of course happens with many of our most celebrated scientific achievements, like natural selection or general relativity.)  What can make it look fishy is that it can sound like maybe A wants that appeal to conservativeness to <i>settle</i> the matter, and that indeed would be a lousy argument.  But generally, a theory&#8217;s being the almost-consensus view is a <i>pro tanto</i> good-making feature of the theory.</p>
<p>(d) I think the epistemic circularity worries can only come into play if there is an active challenge either to the vast bulk of what we take to be our accumulated knowledge, or to the scientific methods themselves.  On my understanding of the dialectic, that won&#8217;t be the case.</p>
<p>But I agree with you completely about the last point &#8212; that&#8217;s why I was at pains at several points to say that these criteria are not beyond revision, and that our epistemology of explanation should start, but need not end, with the fact of the bounty of scientific knowledge.  Any revisions or challenges, however, have to be derived from within the framework that is taking the science fully seriously.  E.g., one might show that in most of the cases where scientists have appealed to criterion X, it has been in defense of a theory that would later lose out to a rival that had a lower score on X.  Indeed, suppose further that you could then propose some alternative criterion Y, that would capture the minority of cases in which X seemed to work, but would have made better selections in the cases that X botched.  Then you&#8217;d have an excellent case for revising our practices to dump X and adopt Y.  These norms do get debated &#8212; cf. the current literature on Morgan&#8217;s Canon &#8212; but the criteria can only usefully be tested within and against science itself, and not from the armchair.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Michael Huemer</title>
		<link>http://certaindoubts.com/507/#comment-3148</link>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
		<pubDate>Wed, 25 Jan 2006 09:30:34 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=507#comment-3148</guid>
		<description><![CDATA[Continuation:

(d) You might be proposing an argument something like this:

1. Science has done a good job of getting to the truth.
2. The best explanation for this is that the criteria for explanations actually used by scientists are reliable (truth-conducive, etc.).
3. Therefore, probably, the criteria used by scientists are reliable. (From 1, 2)

We could then go on from there to defend specific criteria:

4. Scientists use the criterion of conservativeness.
5. Therefore, probably, the criterion of conservativeness is reliable.

One question about this kind of inference is what criteria of explanation are used to establish (2). If it is the same as the criteria that (3) talks about, then there&#039;s an epistemic circularity issue.

Another question is how we know that (1) is true. If, for example, we know it on the basis of the actual arguments that scientists have for thinking their theories to be true, then there&#039;s a second circularity worry, since those arguments wouldn&#039;t enable us to know (1) unless the conclusion (3) were true.

I don&#039;t have a well-developed view about epistemic circularity. But here&#039;s another issue. (1) and (2) might lead (only) to the conclusion that the set of criteria used are overall reliable; yet it might be that some &lt;i&gt;particular&lt;/i&gt; criterion in that set isn&#039;t reliable, doesn&#039;t contribute to the overall reliability of the set, and should be dropped. E.g., maybe the success of science is mostly just due to its use of the criteria of empirical adequacy and simplicity, and the other criteria are superfluous.]]></description>
		<content:encoded><![CDATA[<p>Continuation:</p>
<p>(d) You might be proposing an argument something like this:</p>
<p>1. Science has done a good job of getting to the truth.<br />
2. The best explanation for this is that the criteria for explanations actually used by scientists are reliable (truth-conducive, etc.).<br />
3. Therefore, probably, the criteria used by scientists are reliable. (From 1, 2)</p>
<p>We could then go on from there to defend specific criteria:</p>
<p>4. Scientists use the criterion of conservativeness.<br />
5. Therefore, probably, the criterion of conservativeness is reliable.</p>
<p>One question about this kind of inference is what criteria of explanation are used to establish (2). If it is the same as the criteria that (3) talks about, then there&#8217;s an epistemic circularity issue.</p>
<p>Another question is how we know that (1) is true. If, for example, we know it on the basis of the actual arguments that scientists have for thinking their theories to be true, then there&#8217;s a second circularity worry, since those arguments wouldn&#8217;t enable us to know (1) unless the conclusion (3) were true.</p>
<p>I don&#8217;t have a well-developed view about epistemic circularity. But here&#8217;s another issue. (1) and (2) might lead (only) to the conclusion that the set of criteria used are overall reliable; yet it might be that some <i>particular</i> criterion in that set isn&#8217;t reliable, doesn&#8217;t contribute to the overall reliability of the set, and should be dropped. E.g., maybe the success of science is mostly just due to its use of the criteria of empirical adequacy and simplicity, and the other criteria are superfluous.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Michael Huemer</title>
		<link>http://certaindoubts.com/507/#comment-3147</link>
		<dc:creator><![CDATA[Michael Huemer]]></dc:creator>
		<pubDate>Wed, 25 Jan 2006 09:25:21 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=507#comment-3147</guid>
		<description><![CDATA[Thanks for your replies, Jonathan. More follow-up:

(a) I don&#039;t remember the details of the example, but the Anthropology professor was comparing theories that were actually put forward by people in the field, and he specifically made a point that his view was more consistent with Occam&#039;s Razor, because it required fewer (only 1) crossings of the Bering Strait. So I don&#039;t know whether the theories fit the data equally well (probably not!), but it was clear in any event that the simplicity was being appealed to as a significant reason in itself to prefer one theory.

I&#039;m not very up on the history of science. Here are some examples of head-counting from philosophy, though: Nominalists claim that their view is better because it requires one fewer type of thing in the world. Physicalists similarly sometimes claim that their view is better because it requires one kind of thing instead of two. What do you think of these cases?

(b) Let&#039;s take a different example. My favorite scientific dispute: say two physicists are arguing over whether the Copenhagen interpretation of quantum mechanics or Bohm&#039;s interpretation is better.

A: &quot;The CI is better because it is more conservative.&quot;
B: &quot;Why is that?&quot;
A: &quot;Because most physicists believe the CI, so it is more consistent with our present beliefs.&quot;

If it is true that most physicists believe the CI, do you think A has made a good argument?

I think we might want to distinguish two kinds of appeal to conservativeness. In the first kind (call it &quot;background conservativeness&quot;), one argues that theory X is better than theory Y because X is more consistent with background knowledge, or established theories about other matters, that is not in dispute between the proponents of X and the proponents of Y. For instance, an anthropological theory should be consistent with theories in geology, genetics, etc., to the extent that they bear on one another.

In the second kind of appeal to conservativeness (call it &quot;question-begging conservativeness&quot;), one appeals to the fact that theory X &lt;i&gt;itself&lt;/i&gt; is more widely believed than Y, to show that X is better than Y.

As you might gather, I like the first kind of conservativeness better than the second.]]></description>
		<content:encoded><![CDATA[<p>Thanks for your replies, Jonathan. More follow-up:</p>
<p>(a) I don&#8217;t remember the details of the example, but the Anthropology professor was comparing theories that were actually put forward by people in the field, and he specifically made a point that his view was more consistent with Occam&#8217;s Razor, because it required fewer (only 1) crossings of the Bering Strait. So I don&#8217;t know whether the theories fit the data equally well (probably not!), but it was clear in any event that the simplicity was being appealed to as a significant reason in itself to prefer one theory.</p>
<p>I&#8217;m not very up on the history of science. Here are some examples of head-counting from philosophy, though: Nominalists claim that their view is better because it requires one fewer type of thing in the world. Physicalists similarly sometimes claim that their view is better because it requires one kind of thing instead of two. What do you think of these cases?</p>
<p>(b) Let&#8217;s take a different example. My favorite scientific dispute: say two physicists are arguing over whether the Copenhagen interpretation of quantum mechanics or Bohm&#8217;s interpretation is better.</p>
<p>A: &#8220;The CI is better because it is more conservative.&#8221;<br />
B: &#8220;Why is that?&#8221;<br />
A: &#8220;Because most physicists believe the CI, so it is more consistent with our present beliefs.&#8221;</p>
<p>If it is true that most physicists believe the CI, do you think A has made a good argument?</p>
<p>I think we might want to distinguish two kinds of appeal to conservativeness. In the first kind (call it &#8220;background conservativeness&#8221;), one argues that theory X is better than theory Y because X is more consistent with background knowledge, or established theories about other matters, that is not in dispute between the proponents of X and the proponents of Y. For instance, an anthropological theory should be consistent with theories in geology, genetics, etc., to the extent that they bear on one another.</p>
<p>In the second kind of appeal to conservativeness (call it &#8220;question-begging conservativeness&#8221;), one appeals to the fact that theory X <i>itself</i> is more widely believed than Y, to show that X is better than Y.</p>
<p>As you might gather, I like the first kind of conservativeness better than the second.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/507/#comment-3146</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Tue, 24 Jan 2006 13:33:33 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=507#comment-3146</guid>
		<description><![CDATA[Jonathan, I like very much your Quineanism about explanation here.  Even given your holistic defense here, there&#039;s still the following issue.  List all the explanatory virtues, and take them one by one.  Notice that none, or nearly none, are truth conducive.  How is it that, when combined, truth-conduciveness magically appears?  I think the best approach here is to duck the question!  :-) That is, the lesson is that the truth connection is a bit more remote than is required by this dialectic.  If I&#039;m right, then the fact that simplicity, conservativeness, et. al., are not individually truth conducive is less than ideal, but does not imply that they are not justification makers.]]></description>
		<content:encoded><![CDATA[<p>Jonathan, I like very much your Quineanism about explanation here.  Even given your holistic defense here, there&#8217;s still the following issue.  List all the explanatory virtues, and take them one by one.  Notice that none, or nearly none, are truth conducive.  How is it that, when combined, truth-conduciveness magically appears?  I think the best approach here is to duck the question!  ðŸ™‚ That is, the lesson is that the truth connection is a bit more remote than is required by this dialectic.  If I&#8217;m right, then the fact that simplicity, conservativeness, et. al., are not individually truth conducive is less than ideal, but does not imply that they are not justification makers.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
