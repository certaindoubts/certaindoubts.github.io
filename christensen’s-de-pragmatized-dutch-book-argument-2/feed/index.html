<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Christensen&#8217;s De-pragmatized Dutch Book Argument</title>
	<atom:link href="http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/#comment-8671</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Sat, 02 Jun 2007 12:10:51 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=694#comment-8671</guid>
		<description><![CDATA[Good points, David.  You&#039;re exactly right that the notion of chance can&#039;t be just the single-case probabilities of indeterministic systems.  We need some notion of objective probability so that even deterministic systems don&#039;t have probabilities of only zero or one for events in them (like the coin flip event).  If I had a theory here, I&#039;d be happy!

I agree that we don&#039;t want to require metacognition for rational belief.  My concern is that the rationality of belief is a matter of an individual&#039;s perspective, and so we shouldn&#039;t treat two individuals as sharing the same perspective when they differ at the metalevel even when the are the same at the base level of beliefs, credences, and confidences.

This point affects, I think, the account that has to be given of a fair bet.  I defer to chance in the way you suggest, thinking my degree of belief is off-track if I learn it doesn&#039;t line up with chance.  But I also think that there are perspectives from which this wouldn&#039;t be the right thing to think.  If you&#039;ve seen the Joyce piece from the Arist. Soc., it is really instructive in this regard, since when he defends deference to chance, he builds in a host of assumptions about the nature of chance and the information it encodes.  So if one&#039;s perspective includes denials of some of these assumptions, you can get a perspective from which deference to chance is inappropriate (I&#039;m assuming that the denials are not themselves irrational, of course).]]></description>
		<content:encoded><![CDATA[<p>Good points, David.  You&#8217;re exactly right that the notion of chance can&#8217;t be just the single-case probabilities of indeterministic systems.  We need some notion of objective probability so that even deterministic systems don&#8217;t have probabilities of only zero or one for events in them (like the coin flip event).  If I had a theory here, I&#8217;d be happy!</p>
<p>I agree that we don&#8217;t want to require metacognition for rational belief.  My concern is that the rationality of belief is a matter of an individual&#8217;s perspective, and so we shouldn&#8217;t treat two individuals as sharing the same perspective when they differ at the metalevel even when the are the same at the base level of beliefs, credences, and confidences.</p>
<p>This point affects, I think, the account that has to be given of a fair bet.  I defer to chance in the way you suggest, thinking my degree of belief is off-track if I learn it doesn&#8217;t line up with chance.  But I also think that there are perspectives from which this wouldn&#8217;t be the right thing to think.  If you&#8217;ve seen the Joyce piece from the Arist. Soc., it is really instructive in this regard, since when he defends deference to chance, he builds in a host of assumptions about the nature of chance and the information it encodes.  So if one&#8217;s perspective includes denials of some of these assumptions, you can get a perspective from which deference to chance is inappropriate (I&#8217;m assuming that the denials are not themselves irrational, of course).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/#comment-8670</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Sat, 02 Jun 2007 12:08:25 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=694#comment-8670</guid>
		<description><![CDATA[Good points, David.  You&#039;re exactly right that the notion of chance can&#039;t be just the single-case probabilities of indeterministic systems.  We need some notion of objective probability so that even deterministic systems don&#039;t have probabilities of only zero or one for events in them (like the coin flip event).  If I had a theory here, I&#039;d be happy!

I agree that we don&#039;t want to require metacognition for rational belief.  My concern is that the rationality of belief is a matter of an individual&#039;s perspective, and so we shouldn&#039;t treat two individuals as sharing the same perspective when they differ at the metalevel even when the are the same at the base level of beliefs, credences, and confidences.

This point affects, I think, the account that has to be given of a fair bet.  I defer to chance in the way you suggest, thinking my degree of belief is off-track if I learn it doesn&#039;t line up with chance.  But I also think that there are perspectives from which this wouldn&#039;t be the right thing to think.  If you&#039;ve seen the Joyce piece from the Arist. Soc., it is really instructive in this regard, since when he defends deference to chance, he builds in a host of assumptions about the nature of chance and the information it encodes.  So if one&#039;s perspective includes denials of some of these assumptions, you can get a perspective from which deference to chance is inappropriate (I&#039;m assuming that the denials are not themselves irrational, of course).]]></description>
		<content:encoded><![CDATA[<p>Good points, David.  You&#8217;re exactly right that the notion of chance can&#8217;t be just the single-case probabilities of indeterministic systems.  We need some notion of objective probability so that even deterministic systems don&#8217;t have probabilities of only zero or one for events in them (like the coin flip event).  If I had a theory here, I&#8217;d be happy!</p>
<p>I agree that we don&#8217;t want to require metacognition for rational belief.  My concern is that the rationality of belief is a matter of an individual&#8217;s perspective, and so we shouldn&#8217;t treat two individuals as sharing the same perspective when they differ at the metalevel even when the are the same at the base level of beliefs, credences, and confidences.</p>
<p>This point affects, I think, the account that has to be given of a fair bet.  I defer to chance in the way you suggest, thinking my degree of belief is off-track if I learn it doesn&#8217;t line up with chance.  But I also think that there are perspectives from which this wouldn&#8217;t be the right thing to think.  If you&#8217;ve seen the Joyce piece from the Arist. Soc., it is really instructive in this regard, since when he defends deference to chance, he builds in a host of assumptions about the nature of chance and the information it encodes.  So if one&#8217;s perspective includes denials of some of these assumptions, you can get a perspective from which deference to chance is inappropriate (I&#8217;m assuming that the denials are not themselves irrational, of course).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: David Christensen</title>
		<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/#comment-8669</link>
		<dc:creator><![CDATA[David Christensen]]></dc:creator>
		<pubDate>Fri, 01 Jun 2007 19:02:04 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=694#comment-8669</guid>
		<description><![CDATA[Hi Jon (and sorry for mistyping your name, as I just noticed I did in my previous post!)

I&#039;m not sure what your views on chance are.  But if what you have in mind is objective chance of the sort involved in indeterministic laws (so if a fair coin has already been flipped, out of sight, the chance of its being heads is either 1 or 0, but not .5), then I think that fairness of bets should be defined independently of chance (as I think a bet on heads at even odds would be fair in the coin case).

I do share your intuition about the case where my credence is different from what I take the objective chance to be.  I&#039;d be inclined to explain that intuition by saying that the reason that I should be indifferent to 9-to-1 odds is that (given my belief about the objective chances) I should have .1 credence in T.

About transparency: like you, I don&#039;t believe in transparency.   I&#039;d be inclined to say that what rationalizes my decisions and actions with respect to some issue T are my beliefs and desires about T and related matters, not my belief about my belief about T.  Ceteris paribus, if an agent believes that it&#039;s going to rain, then she should take an umbrella--and this holds irrespective of whether she believes that she believes that it will rain.  She should be able to reason about whether to take an umbrella by thinking about whether it will rain, how inconvenient carrying the umbrella would be, etc.  Even if she was devoid of second-order beliefs, her actions could be rationalized by her degrees of confidence and her values.  So at the basic level, transparency is not required.

I know that there are complications that arise when agents do engage in second-order reflection on their beliefs.  And I don&#039;t know how to sort them all out, especially in cases where the second-order reflection suggests that the first-order beliefs are irrational.  But I hope that the heart of basic credence-desire model of rational action doesn&#039;t require the agent to go second-order.  And I hope that we can eventually say something good about what happens when agents do reflect on their beliefs which doesn&#039;t presume transparency.]]></description>
		<content:encoded><![CDATA[<p>Hi Jon (and sorry for mistyping your name, as I just noticed I did in my previous post!)</p>
<p>I&#8217;m not sure what your views on chance are.  But if what you have in mind is objective chance of the sort involved in indeterministic laws (so if a fair coin has already been flipped, out of sight, the chance of its being heads is either 1 or 0, but not .5), then I think that fairness of bets should be defined independently of chance (as I think a bet on heads at even odds would be fair in the coin case).</p>
<p>I do share your intuition about the case where my credence is different from what I take the objective chance to be.  I&#8217;d be inclined to explain that intuition by saying that the reason that I should be indifferent to 9-to-1 odds is that (given my belief about the objective chances) I should have .1 credence in T.</p>
<p>About transparency: like you, I don&#8217;t believe in transparency.   I&#8217;d be inclined to say that what rationalizes my decisions and actions with respect to some issue T are my beliefs and desires about T and related matters, not my belief about my belief about T.  Ceteris paribus, if an agent believes that it&#8217;s going to rain, then she should take an umbrella&#8211;and this holds irrespective of whether she believes that she believes that it will rain.  She should be able to reason about whether to take an umbrella by thinking about whether it will rain, how inconvenient carrying the umbrella would be, etc.  Even if she was devoid of second-order beliefs, her actions could be rationalized by her degrees of confidence and her values.  So at the basic level, transparency is not required.</p>
<p>I know that there are complications that arise when agents do engage in second-order reflection on their beliefs.  And I don&#8217;t know how to sort them all out, especially in cases where the second-order reflection suggests that the first-order beliefs are irrational.  But I hope that the heart of basic credence-desire model of rational action doesn&#8217;t require the agent to go second-order.  And I hope that we can eventually say something good about what happens when agents do reflect on their beliefs which doesn&#8217;t presume transparency.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/#comment-8668</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Wed, 30 May 2007 21:03:36 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=694#comment-8668</guid>
		<description><![CDATA[Hi, David, thanks for the very interesting reply.  Just a quick thought here.  When I think of bets being offered to me, I think of fairness in terms of chance.  For example, if the bet is on UNC winning the national championship next year, a fair bet is one where the odds match the chance of their winning.  In order to connect this idea with the usual account of fair bets from decision theory, we would need a deference to chance principle of the sort recently defended by Joyce.  If such a principle is false, then I&#039;m not sure how to defend the usual account of fair bets.  For example, suppose I know that my credence about the tarheels is .2, but I think (I&#039;m certain) the chance is .1 (on the assumption that the deference to chance principle is false).  Should I take or give 4-to-1 odds, or should I be indifferent on taking or giving 9-to-1 odds? Strikes me that the latter is obvious.

I wondered about the infinite regress idea as well, but I think it can be avoided.  Suppose I think chances are probabilities, and probabilities are degrees of belief.  Then take the above example again, where my degree of belief is .2, but I&#039;m certain it is .1 (the chance is .1).  This couldn&#039;t happen if credences were transparent, but they aren&#039;t.  This makes me suspicious that there is too much transparency being assumed in decision theoretic accounts of rational action and rational belief.  Do these worries make any sense to you?]]></description>
		<content:encoded><![CDATA[<p>Hi, David, thanks for the very interesting reply.  Just a quick thought here.  When I think of bets being offered to me, I think of fairness in terms of chance.  For example, if the bet is on UNC winning the national championship next year, a fair bet is one where the odds match the chance of their winning.  In order to connect this idea with the usual account of fair bets from decision theory, we would need a deference to chance principle of the sort recently defended by Joyce.  If such a principle is false, then I&#8217;m not sure how to defend the usual account of fair bets.  For example, suppose I know that my credence about the tarheels is .2, but I think (I&#8217;m certain) the chance is .1 (on the assumption that the deference to chance principle is false).  Should I take or give 4-to-1 odds, or should I be indifferent on taking or giving 9-to-1 odds? Strikes me that the latter is obvious.</p>
<p>I wondered about the infinite regress idea as well, but I think it can be avoided.  Suppose I think chances are probabilities, and probabilities are degrees of belief.  Then take the above example again, where my degree of belief is .2, but I&#8217;m certain it is .1 (the chance is .1).  This couldn&#8217;t happen if credences were transparent, but they aren&#8217;t.  This makes me suspicious that there is too much transparency being assumed in decision theoretic accounts of rational action and rational belief.  Do these worries make any sense to you?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: David Christensen</title>
		<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/#comment-8667</link>
		<dc:creator><![CDATA[David Christensen]]></dc:creator>
		<pubDate>Tue, 29 May 2007 17:48:55 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=694#comment-8667</guid>
		<description><![CDATA[John, first I&#039;d like to thank you for your very kind words about my book.  Your worries about my Dutch Book argument are interesting--I had not thought of the problems you pose.  I&#039;ve thought about them a bit now, and have been meaning to comment for a while, but things have been very hectic.  Let me try out a possible response or two.

The Calvinist and the believer in &quot;finkish&quot; bets strike me as similar cases.  In both, the agent&#039;s beliefs amount to her taking the bet to have a different payoff structure than it has &quot;officially&quot; or &quot;intrinsically&quot;.  One possible response to this sort of case is to specify that, for the purposes of the Dutch Book argument, the expected payoffs of the bets include not only those that are officially part of the bet, but all expected monetary consequences of taking the bet.  This would not seem unmotivated to me.  Another response is to restrict ourselves to considering &quot;simple betting situations,&quot; i.e., to stipulate away situations where the agent&#039;s expected monetary payoffs diverge from those officially specified in the bet.

(The second of those options would, I think, be analogous to restricting our attention to simple agents.  The restriction to simple agents is to control for what you nicely term &quot;messy preferences.&quot;  And I think I might be happy to make a parallel stipulation to control for messy beliefs.  One might wonder whether this would vitiate the argument, because we&#039;re not always in simple betting situations.  I think I&#039;d want to respond in the same way I respond to the parallel worry about simple agents.)

The case of the agent who doesn&#039;t know her own degrees of belief seems different to me.  I&#039;m not sure what to say, but I&#039;m also not sure it presents a problem.  I don&#039;t envision agents evaluating bets by explicit second-order reflection on their credences.  The beliefs are supposed to inform preferences for bets directly.  (I haven&#039;t thought this through, but the alternative sounds to me like it might lead to some sort of unpleasant regress.)

David]]></description>
		<content:encoded><![CDATA[<p>John, first I&#8217;d like to thank you for your very kind words about my book.  Your worries about my Dutch Book argument are interesting&#8211;I had not thought of the problems you pose.  I&#8217;ve thought about them a bit now, and have been meaning to comment for a while, but things have been very hectic.  Let me try out a possible response or two.</p>
<p>The Calvinist and the believer in &#8220;finkish&#8221; bets strike me as similar cases.  In both, the agent&#8217;s beliefs amount to her taking the bet to have a different payoff structure than it has &#8220;officially&#8221; or &#8220;intrinsically&#8221;.  One possible response to this sort of case is to specify that, for the purposes of the Dutch Book argument, the expected payoffs of the bets include not only those that are officially part of the bet, but all expected monetary consequences of taking the bet.  This would not seem unmotivated to me.  Another response is to restrict ourselves to considering &#8220;simple betting situations,&#8221; i.e., to stipulate away situations where the agent&#8217;s expected monetary payoffs diverge from those officially specified in the bet.</p>
<p>(The second of those options would, I think, be analogous to restricting our attention to simple agents.  The restriction to simple agents is to control for what you nicely term &#8220;messy preferences.&#8221;  And I think I might be happy to make a parallel stipulation to control for messy beliefs.  One might wonder whether this would vitiate the argument, because we&#8217;re not always in simple betting situations.  I think I&#8217;d want to respond in the same way I respond to the parallel worry about simple agents.)</p>
<p>The case of the agent who doesn&#8217;t know her own degrees of belief seems different to me.  I&#8217;m not sure what to say, but I&#8217;m also not sure it presents a problem.  I don&#8217;t envision agents evaluating bets by explicit second-order reflection on their credences.  The beliefs are supposed to inform preferences for bets directly.  (I haven&#8217;t thought this through, but the alternative sounds to me like it might lead to some sort of unpleasant regress.)</p>
<p>David</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/#comment-8666</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Fri, 04 May 2007 18:40:20 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=694#comment-8666</guid>
		<description><![CDATA[Jonny, two thoughts.  First, the sentence &quot;p&#038;RB~p&quot; isn&#039;t a contradiction, since it isn&#039;t an instance of p&#038;~p.  So the more interesting question is about the status of the assertion.  In 3rd-person contexts, there is no difficulty, as in:  &quot;Frege&#039;s axioms yielded a contradiction even though it was rational for him to believe that they didn&#039;t.&quot;  Prior to learning about the Russell paradox, of course.  But 1st-person contexts would appear to be Moorean-paradox-like.  To say that p is true but it is rational for me to believe ~p is as paradoxical as saying p is true but I don&#039;t believe it.  In both cases, the paradoxicality is probably pragmatic rather than semantic, so there&#039;s no threat to any semantic principle from the paradoxical nature of such assertions.]]></description>
		<content:encoded><![CDATA[<p>Jonny, two thoughts.  First, the sentence &#8220;p&amp;RB~p&#8221; isn&#8217;t a contradiction, since it isn&#8217;t an instance of p&amp;~p.  So the more interesting question is about the status of the assertion.  In 3rd-person contexts, there is no difficulty, as in:  &#8220;Frege&#8217;s axioms yielded a contradiction even though it was rational for him to believe that they didn&#8217;t.&#8221;  Prior to learning about the Russell paradox, of course.  But 1st-person contexts would appear to be Moorean-paradox-like.  To say that p is true but it is rational for me to believe ~p is as paradoxical as saying p is true but I don&#8217;t believe it.  In both cases, the paradoxicality is probably pragmatic rather than semantic, so there&#8217;s no threat to any semantic principle from the paradoxical nature of such assertions.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jonny</title>
		<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/#comment-8665</link>
		<dc:creator><![CDATA[Jonny]]></dc:creator>
		<pubDate>Fri, 04 May 2007 16:05:44 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=694#comment-8665</guid>
		<description><![CDATA[&quot;such a theory, it will have to contain within it the resources to explain how it itself could be reasonably denied.&quot;
I agree with this and think it is fundamental. However it seems incompatible with any exceptionless law of non contradiction. Is it not contradictory to assert (p &#038; it is rational to believe not p)?]]></description>
		<content:encoded><![CDATA[<p>&#8220;such a theory, it will have to contain within it the resources to explain how it itself could be reasonably denied.&#8221;<br />
I agree with this and think it is fundamental. However it seems incompatible with any exceptionless law of non contradiction. Is it not contradictory to assert (p &amp; it is rational to believe not p)?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/#comment-8664</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Tue, 01 May 2007 15:49:56 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=694#comment-8664</guid>
		<description><![CDATA[The most that can be said is this, I think:  there is a theory of rationality that will be formulable in terms of some conditions necessary and sufficient for an attitude being rational.  What&#039;s worrisome even about this claim is that we need to account for the possibility of denying a philosophical theory of rationality just as much as we need to account for the possibility of denying any other claim.  So if there is such a theory, it will have to contain within it the resources to explain how it itself could be reasonably denied.  Maybe there&#039;s such a theory, but I don&#039;t know.

But even if there is, it is another step to think that there are lower-level necessary truths that if violated entail irrationality.  If we shoot for defeasible rules, I think we may be able to get those to come out necessarily true, but there&#039;s a problem of formulating the defeater condition so that the rule isn&#039;t trivial as a result.

What I was hinting at near the end of my talk was to quit looking for necessarily true principles and just pay attention to the actual rules that we start with and modify in the course of further learning.  Such rules will correspond to conditionals of some sort, but these conditionals won&#039;t need to be true or necessarily true to function in a way that results in the product of following the rule being rational.  So the rules one begins with are default rational and require modification when information is presented that kicks in some metarule that is also involved, in some sense, in the perspective in question and which takes the information as input and the modification or abandonment of the first rule as output.  Then if you still follow the first rule, the output is irrational.

So I hope to work out the details of this picture over the next few years, and then it may turn out to be clear enough see whether it is even possible to articulate!]]></description>
		<content:encoded><![CDATA[<p>The most that can be said is this, I think:  there is a theory of rationality that will be formulable in terms of some conditions necessary and sufficient for an attitude being rational.  What&#8217;s worrisome even about this claim is that we need to account for the possibility of denying a philosophical theory of rationality just as much as we need to account for the possibility of denying any other claim.  So if there is such a theory, it will have to contain within it the resources to explain how it itself could be reasonably denied.  Maybe there&#8217;s such a theory, but I don&#8217;t know.</p>
<p>But even if there is, it is another step to think that there are lower-level necessary truths that if violated entail irrationality.  If we shoot for defeasible rules, I think we may be able to get those to come out necessarily true, but there&#8217;s a problem of formulating the defeater condition so that the rule isn&#8217;t trivial as a result.</p>
<p>What I was hinting at near the end of my talk was to quit looking for necessarily true principles and just pay attention to the actual rules that we start with and modify in the course of further learning.  Such rules will correspond to conditionals of some sort, but these conditionals won&#8217;t need to be true or necessarily true to function in a way that results in the product of following the rule being rational.  So the rules one begins with are default rational and require modification when information is presented that kicks in some metarule that is also involved, in some sense, in the perspective in question and which takes the information as input and the modification or abandonment of the first rule as output.  Then if you still follow the first rule, the output is irrational.</p>
<p>So I hope to work out the details of this picture over the next few years, and then it may turn out to be clear enough see whether it is even possible to articulate!</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jim</title>
		<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/#comment-8663</link>
		<dc:creator><![CDATA[Jim]]></dc:creator>
		<pubDate>Tue, 01 May 2007 15:25:34 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=694#comment-8663</guid>
		<description><![CDATA[OK, I think I see. But let me press a bit. Will a subjective theory still have some &quot;principles of rationality&quot; that govern how confidence (and belief) and desire and action should come together for a rational agent? And will agents count as irrational, or less than fully rational, if they tend to violate those principles even in easy cases?

Jim]]></description>
		<content:encoded><![CDATA[<p>OK, I think I see. But let me press a bit. Will a subjective theory still have some &#8220;principles of rationality&#8221; that govern how confidence (and belief) and desire and action should come together for a rational agent? And will agents count as irrational, or less than fully rational, if they tend to violate those principles even in easy cases?</p>
<p>Jim</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/christensen%e2%80%99s-de-pragmatized-dutch-book-argument-2/#comment-8662</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Tue, 01 May 2007 13:27:10 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=694#comment-8662</guid>
		<description><![CDATA[Hi Jim, sorry, my descriptions are very vague aren&#039;t they?  :-)  So the idea involved is a special kind of holism that I think a theory of rationality needs to honor.  Maybe the easiest way to see some of its implications is to think about the requirement that debates in philosophy of logic need to honor the possibility that both parties are rational.  So take your first axiom from your paper (not #1 above), the nontriviality axiom.  It says that your never more confident about a counterexample to excluded middle than to the excluded middle claim itself.  It&#039;s hard to see that as compelling for every rational agent, especially those who think, e.g., that there are counterexamples to excluded middle in QM.  Notice that this same worry will affect the minimality axiom as well.

The general strategy here is to take each claim made and try to think of an overall belief (plus experience) system in which denying it would be rational from the point of view of that system.  In addition, there is the Harman worry lurking for right equivalence and left equivalence: violations might exist unnoticed.  This same point affects the 5&#039;s and 6&#039;s as well.

Of course, some account of how idealization is worth doing can handle some of these problems.  I&#039;d rather see such arguments starting from the way in which we always and everywhere defer to truth, logical or otherwise (that is, our prob for p given that the truth about p is x, is x).  (Of course, we&#039;ll need to accommodate theorists who deny this deference principle, but if we suppose we exclude that issue from discussion, we can account for idealizations in the following way.)  We can then specify the interaction between the fundamental theory of rationality and whatever class of truths one wishes to impute to the agent, logical or otherwise.  Some of the truths will include the specific instances of logical and probabilistic relationships, and we don&#039;t need any other theory of rationality other than the fundamental one for that either.  All we need is a special rule in the fundamental theory that prohibits rational belief in contradictions.  If we treat idealizations in this way, we can reveal what their underlying structure really is:  they just assume that the agent in question knows some stuff we don&#039;t or needn&#039;t.  That doesn&#039;t change the theory of rationality at all, though, so looked at this way, the idealizations shouldn&#039;t appeal to norms other than those that apply to us.

OK, lots of vague stuff again. . .]]></description>
		<content:encoded><![CDATA[<p>Hi Jim, sorry, my descriptions are very vague aren&#8217;t they?  🙂  So the idea involved is a special kind of holism that I think a theory of rationality needs to honor.  Maybe the easiest way to see some of its implications is to think about the requirement that debates in philosophy of logic need to honor the possibility that both parties are rational.  So take your first axiom from your paper (not #1 above), the nontriviality axiom.  It says that your never more confident about a counterexample to excluded middle than to the excluded middle claim itself.  It&#8217;s hard to see that as compelling for every rational agent, especially those who think, e.g., that there are counterexamples to excluded middle in QM.  Notice that this same worry will affect the minimality axiom as well.</p>
<p>The general strategy here is to take each claim made and try to think of an overall belief (plus experience) system in which denying it would be rational from the point of view of that system.  In addition, there is the Harman worry lurking for right equivalence and left equivalence: violations might exist unnoticed.  This same point affects the 5&#8217;s and 6&#8217;s as well.</p>
<p>Of course, some account of how idealization is worth doing can handle some of these problems.  I&#8217;d rather see such arguments starting from the way in which we always and everywhere defer to truth, logical or otherwise (that is, our prob for p given that the truth about p is x, is x).  (Of course, we&#8217;ll need to accommodate theorists who deny this deference principle, but if we suppose we exclude that issue from discussion, we can account for idealizations in the following way.)  We can then specify the interaction between the fundamental theory of rationality and whatever class of truths one wishes to impute to the agent, logical or otherwise.  Some of the truths will include the specific instances of logical and probabilistic relationships, and we don&#8217;t need any other theory of rationality other than the fundamental one for that either.  All we need is a special rule in the fundamental theory that prohibits rational belief in contradictions.  If we treat idealizations in this way, we can reveal what their underlying structure really is:  they just assume that the agent in question knows some stuff we don&#8217;t or needn&#8217;t.  That doesn&#8217;t change the theory of rationality at all, though, so looked at this way, the idealizations shouldn&#8217;t appeal to norms other than those that apply to us.</p>
<p>OK, lots of vague stuff again. . .</p>
]]></content:encoded>
	</item>
</channel>
</rss>
