<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Relative Frequencies in Infinite Sets</title>
	<atom:link href="http://certaindoubts.com/relative-frequencies-in-infinite-sets/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: molly</title>
		<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/#comment-3785</link>
		<dc:creator><![CDATA[molly]]></dc:creator>
		<pubDate>Tue, 05 Sep 2006 16:07:21 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=604#comment-3785</guid>
		<description><![CDATA[what is relative frequency??!]]></description>
		<content:encoded><![CDATA[<p>what is relative frequency??!</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jonny Blamey</title>
		<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/#comment-3771</link>
		<dc:creator><![CDATA[Jonny Blamey]]></dc:creator>
		<pubDate>Fri, 04 Aug 2006 14:34:50 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=604#comment-3771</guid>
		<description><![CDATA[How about this: each ball in the sequence gives some information about the proportion of odds and evens in the whole sequence. Suppose the whole sequence is 1 ball long, then that ball gives the total information about the proportion of odds to evens. If the sequence is 2 balls long, each ball will give 1/2 the information about how many balls are odd to even, If the sequence is n balls longs each ball will give 1/n information about the proportion of odd to even. For very large n, it does not matter that each ball gives such small amounts of information, because the large number of balls will multiply this small number up. But in an infinite sequence each ball gives zero information about how many balls are odd, so however many balls we look at it will yield no information about the relative frequency of odd to even balls.
I suppose this is what you&#039;ve been getting at all along. The only place to look is process by which the sequence was generated. But if the process is truely random, it seems wrong that this should mean that there is therefore exact parity.]]></description>
		<content:encoded><![CDATA[<p>How about this: each ball in the sequence gives some information about the proportion of odds and evens in the whole sequence. Suppose the whole sequence is 1 ball long, then that ball gives the total information about the proportion of odds to evens. If the sequence is 2 balls long, each ball will give 1/2 the information about how many balls are odd to even, If the sequence is n balls longs each ball will give 1/n information about the proportion of odd to even. For very large n, it does not matter that each ball gives such small amounts of information, because the large number of balls will multiply this small number up. But in an infinite sequence each ball gives zero information about how many balls are odd, so however many balls we look at it will yield no information about the relative frequency of odd to even balls.<br />
I suppose this is what you&#8217;ve been getting at all along. The only place to look is process by which the sequence was generated. But if the process is truely random, it seems wrong that this should mean that there is therefore exact parity.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jonny Blamey</title>
		<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/#comment-3768</link>
		<dc:creator><![CDATA[Jonny Blamey]]></dc:creator>
		<pubDate>Fri, 04 Aug 2006 13:56:43 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=604#comment-3768</guid>
		<description><![CDATA[Thank&#039;s Kenny. But surely one could (and should) apply inductive skepticism to such a &quot;traditional&quot; sampling technique, which is why I put in the Wittgenstein reference. If you took the limiting frequency of the first n numbers, and the sequence was truely random, you still have infinite numbers left, and the remaining draws n+1 to infinity could still all be odd. So even if you establish that the limiting frequency of evens in the first n of the sequence is 1/2, however large n is, the actual frequency could still end up being 0. The sampling has established nothing.]]></description>
		<content:encoded><![CDATA[<p>Thank&#8217;s Kenny. But surely one could (and should) apply inductive skepticism to such a &#8220;traditional&#8221; sampling technique, which is why I put in the Wittgenstein reference. If you took the limiting frequency of the first n numbers, and the sequence was truely random, you still have infinite numbers left, and the remaining draws n+1 to infinity could still all be odd. So even if you establish that the limiting frequency of evens in the first n of the sequence is 1/2, however large n is, the actual frequency could still end up being 0. The sampling has established nothing.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: nick shackel</title>
		<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/#comment-3764</link>
		<dc:creator><![CDATA[nick shackel]]></dc:creator>
		<pubDate>Fri, 04 Aug 2006 12:28:24 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=604#comment-3764</guid>
		<description><![CDATA[Regarding Kenny&#039;s remark that &quot;Note that this definition of randomness works quite differently if you just ignore the number and pay attention only to the parity, because a sequence of just odd numbers can still be quite complex, even though a sequence of just 1’s is very simple.&quot; That&#039;s quite true, but my thought was that  all that is required to refute &#039;all random sequences of natural numbers have limiting frequency of evens = 1/2&#039; is a single sequence of natural numbers which is random and has a limiting frequency that is not 1/2. If such a parity sequence exists (and infinitely many do) then that sequence itself refutes the claim (since it is a sequence of natural numbers) and also shows that there will be a whole class of such sequences each of which contains each natural number exactly once (which are perhaps the sort of sequence James is particularly interested in).

Regarding Kenny&#039;s last remark, here is what seems to me a way of constructing a Kolmogorov random sequence of odd numbers whose limiting frequency of odds is 1 (he said &#039; Kolmogorov random set&#039; but sets of natural numbers do not have limiting frequencies, so I presume he means that sequence which is got from a set of natural numbers taken under the usual ordering). Take any infinite binary sequence, BKR (for Binary Kolmogorov Random), that is random by the definition given by Kenny: a sequence is Kolmogorov random iff the the limit of the ratio of the smallest program length that outputs the first n of the sequence to the length of just listing the first n  is 1. Then construct the sequence ONKR as follows. For all n, m in N, the nth member of ONKR = 2m+1 iff the nth occurrence of 1 in BKR  is at the mth place in BKR. Then ONKR will be Kolmogorov random. Suppose ONKR is not Kolmogorov random and so its limiting ratio is less than 1. In that case we could use the programs of smallest program length that output the first n of ONKR, plus 1 step, to output the first n of BKR. Adding one step to each program won&#039;t change the limiting ratio, so for BKR that ratio would be less that 1,  which would contradict BKR being Kolmogorov random.]]></description>
		<content:encoded><![CDATA[<p>Regarding Kenny&#8217;s remark that &#8220;Note that this definition of randomness works quite differently if you just ignore the number and pay attention only to the parity, because a sequence of just odd numbers can still be quite complex, even though a sequence of just 1’s is very simple.&#8221; That&#8217;s quite true, but my thought was that  all that is required to refute &#8216;all random sequences of natural numbers have limiting frequency of evens = 1/2&#8217; is a single sequence of natural numbers which is random and has a limiting frequency that is not 1/2. If such a parity sequence exists (and infinitely many do) then that sequence itself refutes the claim (since it is a sequence of natural numbers) and also shows that there will be a whole class of such sequences each of which contains each natural number exactly once (which are perhaps the sort of sequence James is particularly interested in).</p>
<p>Regarding Kenny&#8217;s last remark, here is what seems to me a way of constructing a Kolmogorov random sequence of odd numbers whose limiting frequency of odds is 1 (he said &#8216; Kolmogorov random set&#8217; but sets of natural numbers do not have limiting frequencies, so I presume he means that sequence which is got from a set of natural numbers taken under the usual ordering). Take any infinite binary sequence, BKR (for Binary Kolmogorov Random), that is random by the definition given by Kenny: a sequence is Kolmogorov random iff the the limit of the ratio of the smallest program length that outputs the first n of the sequence to the length of just listing the first n  is 1. Then construct the sequence ONKR as follows. For all n, m in N, the nth member of ONKR = 2m+1 iff the nth occurrence of 1 in BKR  is at the mth place in BKR. Then ONKR will be Kolmogorov random. Suppose ONKR is not Kolmogorov random and so its limiting ratio is less than 1. In that case we could use the programs of smallest program length that output the first n of ONKR, plus 1 step, to output the first n of BKR. Adding one step to each program won&#8217;t change the limiting ratio, so for BKR that ratio would be less that 1,  which would contradict BKR being Kolmogorov random.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Kenny Easwaran</title>
		<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/#comment-3777</link>
		<dc:creator><![CDATA[Kenny Easwaran]]></dc:creator>
		<pubDate>Thu, 03 Aug 2006 20:40:16 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=604#comment-3777</guid>
		<description><![CDATA[Also, I think I&#039;ve changed my opinion since last night after thinking about things a bit further.  The proper way to think about a set of natural numbers does seem to be as a sequence of 0&#039;s and 1&#039;s, where a 1 occurs in position n iff n is in the set in question.

For a set S that only has odd numbers, we can just consider the set of k such that 2k+1 is in S, and then add the instruction to insert 0&#039;s between members of the sequence.  This instruction has finite size, so this results in a compression of 1/2 in the limit, so the sequence is no longer Kolmogorov random.

It seems plausible that if the limiting frequency of odds in the set is substantially more than 1/2, then one could compress the information in the odds by this much, and then just list the evens, and still achieve substantial compression.  (Similarly for ones substantially less than 1/2.)  Thus, contrary to what I said last night, I think it will turn out true that in any Kolmogorov random set, the limiting frequency of odd numbers will be 1/2.]]></description>
		<content:encoded><![CDATA[<p>Also, I think I&#8217;ve changed my opinion since last night after thinking about things a bit further.  The proper way to think about a set of natural numbers does seem to be as a sequence of 0&#8217;s and 1&#8217;s, where a 1 occurs in position n iff n is in the set in question.</p>
<p>For a set S that only has odd numbers, we can just consider the set of k such that 2k+1 is in S, and then add the instruction to insert 0&#8217;s between members of the sequence.  This instruction has finite size, so this results in a compression of 1/2 in the limit, so the sequence is no longer Kolmogorov random.</p>
<p>It seems plausible that if the limiting frequency of odds in the set is substantially more than 1/2, then one could compress the information in the odds by this much, and then just list the evens, and still achieve substantial compression.  (Similarly for ones substantially less than 1/2.)  Thus, contrary to what I said last night, I think it will turn out true that in any Kolmogorov random set, the limiting frequency of odd numbers will be 1/2.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Kenny Easwaran</title>
		<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/#comment-3778</link>
		<dc:creator><![CDATA[Kenny Easwaran]]></dc:creator>
		<pubDate>Thu, 03 Aug 2006 20:33:58 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=604#comment-3778</guid>
		<description><![CDATA[Jonny - when the sets are both infinite, the traditional way to consider frequencies is by taking the limit of the frequencies in the first n numbers, as n goes to infinity.  For very large n, the frequency of even numbers in the first n is very close to 1/2, so this particular infinity/infinity becomes 1/2.  However, for the squares, for very large n the ratio becomes close to 0.]]></description>
		<content:encoded><![CDATA[<p>Jonny &#8211; when the sets are both infinite, the traditional way to consider frequencies is by taking the limit of the frequencies in the first n numbers, as n goes to infinity.  For very large n, the frequency of even numbers in the first n is very close to 1/2, so this particular infinity/infinity becomes 1/2.  However, for the squares, for very large n the ratio becomes close to 0.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/#comment-3772</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Thu, 03 Aug 2006 17:44:17 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=604#comment-3772</guid>
		<description><![CDATA[Hi Kenny. I think that the 2k+1 alteration to the sample that you suggest would not remain random from a sampling point of view. Rather, the renaming scheme would amount to a biased, second sampling of the population. (Reason: We are using two categories for classification, Odd and Even, and this renaming scheme is also a reclassification scheme on these two categories that we&#039;re using to sort observations.)

The idea behind the algorithmic approach to defining random processes is to give a precise meaning to one process &quot;being more random than&quot; another process. Until Kolmogorov, being a little bit random was like being a little bit pregnant. Nevertheless, von Mises&#039;s conception of randomness and Kolmogorov&#039;s do come apart; I think von Mises randomness fails to preserve log scaling...or something like this.

Returning to 2k+1: This is a nice example. It highlights Steve&#039;s point earlier on about the categories &#039;Odd&#039; and &#039;Even&#039; being a function of the ordering relation in the population. Typically we use the positive integers to order things and count them...black and white balls, let&#039;s say. Then we sample on those things, the balls, with the fixed properties (color, uniform shape) used in the process of  categorize them from observations, and the mathematical properties of the integers to manipulate them and calculate probabilities.

James&#039;s experiment asks us to bypass the balls and go right to the positive integers themselves; so, one has to be very careful about designing a sample mechanism for the categories that you&#039;re interested, so that the categories that you use when you build your count vectors will remain fixed, and not collapse when you do calculation.]]></description>
		<content:encoded><![CDATA[<p>Hi Kenny. I think that the 2k+1 alteration to the sample that you suggest would not remain random from a sampling point of view. Rather, the renaming scheme would amount to a biased, second sampling of the population. (Reason: We are using two categories for classification, Odd and Even, and this renaming scheme is also a reclassification scheme on these two categories that we&#8217;re using to sort observations.)</p>
<p>The idea behind the algorithmic approach to defining random processes is to give a precise meaning to one process &#8220;being more random than&#8221; another process. Until Kolmogorov, being a little bit random was like being a little bit pregnant. Nevertheless, von Mises&#8217;s conception of randomness and Kolmogorov&#8217;s do come apart; I think von Mises randomness fails to preserve log scaling&#8230;or something like this.</p>
<p>Returning to 2k+1: This is a nice example. It highlights Steve&#8217;s point earlier on about the categories &#8216;Odd&#8217; and &#8216;Even&#8217; being a function of the ordering relation in the population. Typically we use the positive integers to order things and count them&#8230;black and white balls, let&#8217;s say. Then we sample on those things, the balls, with the fixed properties (color, uniform shape) used in the process of  categorize them from observations, and the mathematical properties of the integers to manipulate them and calculate probabilities.</p>
<p>James&#8217;s experiment asks us to bypass the balls and go right to the positive integers themselves; so, one has to be very careful about designing a sample mechanism for the categories that you&#8217;re interested, so that the categories that you use when you build your count vectors will remain fixed, and not collapse when you do calculation.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/#comment-3769</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Thu, 03 Aug 2006 14:39:34 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=604#comment-3769</guid>
		<description><![CDATA[Ut oh. Most of my post was lost after &#039;&#060;&#039;. (Damn!)

The general idea was to look at sampling from infinite populations that &lt;i&gt;do&lt;/i&gt; work out the way James wants his experiment to work, and then work backwards from there to see if some sampling model that works makes sense for sampling positive integers for the categories &#039;Even&#039; and &#039;Odd&#039;. The intuition was that you could work on constructing various sampling mechanisms to describe sampling of positive integers that behave exactly like sampling on infinite populations. None of these things might do what you&#039;d like to do, but you might get a nice view of where the catch is.]]></description>
		<content:encoded><![CDATA[<p>Ut oh. Most of my post was lost after &#8216;&lt;&#8216;. (Damn!)</p>
<p>The general idea was to look at sampling from infinite populations that <i>do</i> work out the way James wants his experiment to work, and then work backwards from there to see if some sampling model that works makes sense for sampling positive integers for the categories &#8216;Even&#8217; and &#8216;Odd&#8217;. The intuition was that you could work on constructing various sampling mechanisms to describe sampling of positive integers that behave exactly like sampling on infinite populations. None of these things might do what you&#8217;d like to do, but you might get a nice view of where the catch is.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jonny Blamey</title>
		<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/#comment-3766</link>
		<dc:creator><![CDATA[Jonny Blamey]]></dc:creator>
		<pubDate>Thu, 03 Aug 2006 10:50:11 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=604#comment-3766</guid>
		<description><![CDATA[Following on from Kenny, even if you named odd number 0 and even numbers 1, and thereby claimed that a sequence of only odd numbers was non random, how about an infinite sequence of odd numbers with just one even number? Perhaps you could also call this sequence non random. But whether or not it is random, we know the frequency of even numbers, it is 1/infinity which conventionally equals 0. Now consider a sequence with all but two odd numbers. The relative frequency of even numbers would still be 0. 2/infinity = 0. We can extend this argument to any number of even numbers. So however many even numbers there are in the infinte sequence, the relative frequency will still be 0. We can reverse the argument for odd numbers, so that for any n such that n is the number of odd numbers in the sequence, then the relative frequency of odd numbers is 0. There is no upper limit on n, so there are infinite sequences where the frequency of odd numbers is 0 and infinite sequences where the frequency of even numbers is 0. The only sequence where this is not the case is where both odd and even numbers are infinite, in which case the proportion is infinity/infinity which is undefined.
This argument demonstrates that the frequency of even numbers is either 0,1 or undefined in any infinite set. The intuition that it should be 1/2 comes from trying to picture infinity by picturing a finite sequence and extending it. I refer to Wittgenstein Philosophical investigations 352. Also to the St Petersburg game, which is a very close analogy. You get £2 if the first coin is heads, £4 if the first two coins are heads, £8 if the first 3 coins are heads and so on infinitely. The expected utility of this game is paradoxically infinite, since the pay off doubles as the probability halfs, creating £1 + £1 + £1....... But the real value of entering such a game cannot be infinite, since it is clear that there is a 1/2 chance of losing in the first throw.
Thanks for the post by the way, I share your intuition and it turns out much more difficult that it seems.]]></description>
		<content:encoded><![CDATA[<p>Following on from Kenny, even if you named odd number 0 and even numbers 1, and thereby claimed that a sequence of only odd numbers was non random, how about an infinite sequence of odd numbers with just one even number? Perhaps you could also call this sequence non random. But whether or not it is random, we know the frequency of even numbers, it is 1/infinity which conventionally equals 0. Now consider a sequence with all but two odd numbers. The relative frequency of even numbers would still be 0. 2/infinity = 0. We can extend this argument to any number of even numbers. So however many even numbers there are in the infinte sequence, the relative frequency will still be 0. We can reverse the argument for odd numbers, so that for any n such that n is the number of odd numbers in the sequence, then the relative frequency of odd numbers is 0. There is no upper limit on n, so there are infinite sequences where the frequency of odd numbers is 0 and infinite sequences where the frequency of even numbers is 0. The only sequence where this is not the case is where both odd and even numbers are infinite, in which case the proportion is infinity/infinity which is undefined.<br />
This argument demonstrates that the frequency of even numbers is either 0,1 or undefined in any infinite set. The intuition that it should be 1/2 comes from trying to picture infinity by picturing a finite sequence and extending it. I refer to Wittgenstein Philosophical investigations 352. Also to the St Petersburg game, which is a very close analogy. You get £2 if the first coin is heads, £4 if the first two coins are heads, £8 if the first 3 coins are heads and so on infinitely. The expected utility of this game is paradoxically infinite, since the pay off doubles as the probability halfs, creating £1 + £1 + £1&#8230;&#8230;. But the real value of entering such a game cannot be infinite, since it is clear that there is a 1/2 chance of losing in the first throw.<br />
Thanks for the post by the way, I share your intuition and it turns out much more difficult that it seems.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Kenny Easwaran</title>
		<link>http://certaindoubts.com/relative-frequencies-in-infinite-sets/#comment-3775</link>
		<dc:creator><![CDATA[Kenny Easwaran]]></dc:creator>
		<pubDate>Thu, 03 Aug 2006 06:41:19 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=604#comment-3775</guid>
		<description><![CDATA[Actually, the standard definition of Kolmogorov randomness considers the limit of the length of the smallest program to output the first n elements of the set.  If the limit of the ratio of the smallest program length to the length of just listing the first n approaches 1, then the sequence is said to be random.

I suspect that if you take some random sequence, and then replace each term k by 2k+1, then the resulting sequence will still be random, but all values will be odd.  (Basically, we haven&#039;t increased the length of the program much, but we also have only increased the length of listing the numbers by 1 bit per number.  Presumably this will be swamped by the complexity of writing down a lot of numbers, though I&#039;m not completely certain.)

Note that this definition of randomness works quite differently if you just ignore the number and pay attention only to the parity, because a sequence of just odd numbers can still be quite complex, even though a sequence of just 1&#039;s is very simple.]]></description>
		<content:encoded><![CDATA[<p>Actually, the standard definition of Kolmogorov randomness considers the limit of the length of the smallest program to output the first n elements of the set.  If the limit of the ratio of the smallest program length to the length of just listing the first n approaches 1, then the sequence is said to be random.</p>
<p>I suspect that if you take some random sequence, and then replace each term k by 2k+1, then the resulting sequence will still be random, but all values will be odd.  (Basically, we haven&#8217;t increased the length of the program much, but we also have only increased the length of listing the numbers by 1 bit per number.  Presumably this will be swamped by the complexity of writing down a lot of numbers, though I&#8217;m not completely certain.)</p>
<p>Note that this definition of randomness works quite differently if you just ignore the number and pay attention only to the parity, because a sequence of just odd numbers can still be quite complex, even though a sequence of just 1&#8217;s is very simple.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
