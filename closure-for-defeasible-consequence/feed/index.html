<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Closure for Defeasible Consequence?</title>
	<atom:link href="http://certaindoubts.com/closure-for-defeasible-consequence/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/closure-for-defeasible-consequence/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/closure-for-defeasible-consequence/#comment-1310</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Fri, 04 Feb 2005 18:46:19 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=243#comment-1310</guid>
		<description><![CDATA[Hi Stephen, point well taken. When I&#039;m more careful, I usually just talk about arguments and formulas, and wonder whether there is any interesting logical structure to non-monotonic arguments that  (non-monotonically) entail their conclusions. I think statistical arguments have enough structure to study non-monotonic consequence. They are constructed from sentences and events (which I understand better) and, if a working model were to emerge, would provide a basis for testing the effectiveness of that model--better than common sense reasoning, I think, which was the original motivation for non-mon logic. So I think of arguments as structures, or items we can reason about (or with) and think of non-monotonic arguments as candidates for structures that (may allow us to) isolate some of the relations (defeasibility; support) and properties (rational acceptance) that enter into the general discussion about defeasible reasoning &lt;i&gt;qua&lt;/i&gt; cognitive faculty. The goal or idea or intuition or hope is that there is some common structure here that we can exploit, even if only to see clearly how it doesn&#039;t at all behave like we think these properties should behave in our epistemic theories. Of course, I&#039;m hoping that there will be a more positive payoff.

I&#039;m not sure I understood your last question about closure and inference. I don&#039;t think classical probabilistic logic (which is what I&#039;ve described) would be a very good candidate for articulating closure conditions. For one, if you start with point probabilities for your premises you typically get a range of possible values for your entailed conclusion rather than another point value. It gets tricky to work with if you interpret the measure as degrees of belief, since (logically) any of these values are consistent which throws a wrench into thinking that probability provides rationality constraints for belief.

However, I think that if you model support as &#039;the probability of p is no less than n&#039; (or, probability of false acceptance is 1-n) and observe how the lower-bound depletes within probabilistic logic, then the entailed lower-value of the interval becomes a fixed lower bound for support for the entailed proposition. So, if you have a threshold point, T, you can manipulate supported propositions with your logic and compare how various logical consequences of what is supported stack up to T, your acceptance level. This gives some logical structure to &#039;greater support for&#039; and &#039;lesser support for&#039; relations. And it is formal: it holds regardless of interpretation of formulas.

Non-monotonicity is another matter. I&#039;ve been toying for a few years with an extension of default logic that incorporates this support behavior that I&#039;ve sketched above. The basic idea is that you can introduce a sentence, p, with some lower-bound of support, n, which means that, as far as we know (which means here as far as what is contained in our theory), the probability that p is no less than n.

The logic is non-monotonic since you can introduce p under these conditions but learn (that is, add a formula to the theory) that defeats the application of the rule that introduced p at n. I don&#039;t have anything that addresses defeat of a rule--something that says whether we should take the rule itself out of service for being too tough or too lenient. But, semantically, each of these rules is itself bounded by a lower-bound probability. So, a rule could be &#039;false&#039; if, given what we know, it says that a consequent q non-monotonically follows with a lower-bound of no less than m when in fact it *is* less than *m*. I like this idea, conceptually, but I haven&#039;t figured out how to exploit it.

Woe. Way too long. The short of is that I was being sloppy with the epistemology in an effort to be clear about the math.]]></description>
		<content:encoded><![CDATA[<p>Hi Stephen, point well taken. When I&#8217;m more careful, I usually just talk about arguments and formulas, and wonder whether there is any interesting logical structure to non-monotonic arguments that  (non-monotonically) entail their conclusions. I think statistical arguments have enough structure to study non-monotonic consequence. They are constructed from sentences and events (which I understand better) and, if a working model were to emerge, would provide a basis for testing the effectiveness of that model&#8211;better than common sense reasoning, I think, which was the original motivation for non-mon logic. So I think of arguments as structures, or items we can reason about (or with) and think of non-monotonic arguments as candidates for structures that (may allow us to) isolate some of the relations (defeasibility; support) and properties (rational acceptance) that enter into the general discussion about defeasible reasoning <i>qua</i> cognitive faculty. The goal or idea or intuition or hope is that there is some common structure here that we can exploit, even if only to see clearly how it doesn&#8217;t at all behave like we think these properties should behave in our epistemic theories. Of course, I&#8217;m hoping that there will be a more positive payoff.</p>
<p>I&#8217;m not sure I understood your last question about closure and inference. I don&#8217;t think classical probabilistic logic (which is what I&#8217;ve described) would be a very good candidate for articulating closure conditions. For one, if you start with point probabilities for your premises you typically get a range of possible values for your entailed conclusion rather than another point value. It gets tricky to work with if you interpret the measure as degrees of belief, since (logically) any of these values are consistent which throws a wrench into thinking that probability provides rationality constraints for belief.</p>
<p>However, I think that if you model support as &#8216;the probability of p is no less than n&#8217; (or, probability of false acceptance is 1-n) and observe how the lower-bound depletes within probabilistic logic, then the entailed lower-value of the interval becomes a fixed lower bound for support for the entailed proposition. So, if you have a threshold point, T, you can manipulate supported propositions with your logic and compare how various logical consequences of what is supported stack up to T, your acceptance level. This gives some logical structure to &#8216;greater support for&#8217; and &#8216;lesser support for&#8217; relations. And it is formal: it holds regardless of interpretation of formulas.</p>
<p>Non-monotonicity is another matter. I&#8217;ve been toying for a few years with an extension of default logic that incorporates this support behavior that I&#8217;ve sketched above. The basic idea is that you can introduce a sentence, p, with some lower-bound of support, n, which means that, as far as we know (which means here as far as what is contained in our theory), the probability that p is no less than n.</p>
<p>The logic is non-monotonic since you can introduce p under these conditions but learn (that is, add a formula to the theory) that defeats the application of the rule that introduced p at n. I don&#8217;t have anything that addresses defeat of a rule&#8211;something that says whether we should take the rule itself out of service for being too tough or too lenient. But, semantically, each of these rules is itself bounded by a lower-bound probability. So, a rule could be &#8216;false&#8217; if, given what we know, it says that a consequent q non-monotonically follows with a lower-bound of no less than m when in fact it *is* less than *m*. I like this idea, conceptually, but I haven&#8217;t figured out how to exploit it.</p>
<p>Woe. Way too long. The short of is that I was being sloppy with the epistemology in an effort to be clear about the math.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Stephen Fogdall</title>
		<link>http://certaindoubts.com/closure-for-defeasible-consequence/#comment-1309</link>
		<dc:creator><![CDATA[Stephen Fogdall]]></dc:creator>
		<pubDate>Fri, 04 Feb 2005 16:30:20 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=243#comment-1309</guid>
		<description><![CDATA[Gregory, I think you are right that our pre-theoretic conception of defeasible reasoning really can&#039;t be captured using conditional probabilities.  Still, I don&#039;t think closure is a part of that conception either.  It seems that our pre-theoretic thinking recognizes that some (undefeated) defeasible reasons are better than others and that, in consequence, a belief can be undefeated and yet not as well supported as other beliefs.  Moreover, one naturally feels more reluctant to reason on the less well supported beliefs, even if they are supported to whatever degree is required to make them justified or rational.  In that case, failure of closure seems inevitable.

By the way, am I right in thinking that the inferential monotonicity of probability that you describe is not enough to guarantee closure (assuming one were to model defeasible reasoning along those lines, which I take it you would discourage)?]]></description>
		<content:encoded><![CDATA[<p>Gregory, I think you are right that our pre-theoretic conception of defeasible reasoning really can&#8217;t be captured using conditional probabilities.  Still, I don&#8217;t think closure is a part of that conception either.  It seems that our pre-theoretic thinking recognizes that some (undefeated) defeasible reasons are better than others and that, in consequence, a belief can be undefeated and yet not as well supported as other beliefs.  Moreover, one naturally feels more reluctant to reason on the less well supported beliefs, even if they are supported to whatever degree is required to make them justified or rational.  In that case, failure of closure seems inevitable.</p>
<p>By the way, am I right in thinking that the inferential monotonicity of probability that you describe is not enough to guarantee closure (assuming one were to model defeasible reasoning along those lines, which I take it you would discourage)?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/closure-for-defeasible-consequence/#comment-1308</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Fri, 04 Feb 2005 12:16:52 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=243#comment-1308</guid>
		<description><![CDATA[Hi Mike. Right, one can think of probability as a logical operator in the object language itself or as a metalinguistic operator applying to sentences or sets of sentences. The point holds either way, but let&#039;s go with the latter. Suppose that the probability of the material conditional statement  &lt;i&gt;p&lt;/i&gt; --&gt; &lt;i&gt;q&lt;/i&gt; is &lt;i&gt;m&lt;/i&gt; and the probability of the statement &lt;i&gt;p&lt;/i&gt; is &lt;i&gt;n&lt;/i&gt;. We may infer that the probability of &lt;i&gt;q&lt;/i&gt;  is between &lt;i&gt;m&lt;/i&gt; and max(0, (m+n)-1), where 0 is included to make sure that the resulting value is a probability. The same point about monotonicity will hold if you want to just talk about the value being between &lt;i&gt;m&lt;/i&gt; and (m+n)-1 and not worry about the result being a probability, however. The point is, add more probability premises and &lt;i&gt;q&lt;/i&gt;  is still between &lt;i&gt;m&lt;/i&gt; and max(0, (m+n)-1). This holds for conditional probabilities as well, so long as we fix the point in the sample space that we&#039;re conditioning on. That is, if a set of probability premises &lt;i&gt;G&lt;/i&gt; entails that Pr(A&#124;B) is [m,n] (i.e., if the probability of &lt;i&gt;A&lt;/i&gt; conditioned on &lt;i&gt;B&lt;/i&gt; is between &lt;i&gt;m&lt;/i&gt; and &lt;i&gt;n&lt;/i&gt;), then any superset of &lt;i&gt;G&lt;/i&gt; entails that Pr(A&#124;B) is [m,n]. Hence, probability is inferentially monotonic: you may add probability premises without losing any probability conclusions.

I entirely agree with you that non-monotonicity seems to be a common property of everyday, pre-theoretic rational inference. In fact, it even seems to be a common property of inferential statistics which is an enterprise that explicitly applies probability to make reasonable inferences. There are several interesting philosophical questions that spring from these observations. One general question is whether there is any logical structure to this behavior at all or whether the apparent non-monotonic behavior of defeasible reasoning is, in the end, too content dependent to think of as a logical property,  so too content dependent to think of as a property of a defeasible closure operation. (Hmm, in fact, I suppose someone could play around with these properties and argue that defeasible closure operations don&#039;t exist....) But some, including me, think that there is some interesting logical structure to patterns of non-monotonic/defeasible reasoning--which is (partly) why I am holding out against the standard use of conditional probabilities to model defeasible reasoning.]]></description>
		<content:encoded><![CDATA[<p>Hi Mike. Right, one can think of probability as a logical operator in the object language itself or as a metalinguistic operator applying to sentences or sets of sentences. The point holds either way, but let&#8217;s go with the latter. Suppose that the probability of the material conditional statement  <i>p</i> &#8211;> <i>q</i> is <i>m</i> and the probability of the statement <i>p</i> is <i>n</i>. We may infer that the probability of <i>q</i>  is between <i>m</i> and max(0, (m+n)-1), where 0 is included to make sure that the resulting value is a probability. The same point about monotonicity will hold if you want to just talk about the value being between <i>m</i> and (m+n)-1 and not worry about the result being a probability, however. The point is, add more probability premises and <i>q</i>  is still between <i>m</i> and max(0, (m+n)-1). This holds for conditional probabilities as well, so long as we fix the point in the sample space that we&#8217;re conditioning on. That is, if a set of probability premises <i>G</i> entails that Pr(A|B) is [m,n] (i.e., if the probability of <i>A</i> conditioned on <i>B</i> is between <i>m</i> and <i>n</i>), then any superset of <i>G</i> entails that Pr(A|B) is [m,n]. Hence, probability is inferentially monotonic: you may add probability premises without losing any probability conclusions.</p>
<p>I entirely agree with you that non-monotonicity seems to be a common property of everyday, pre-theoretic rational inference. In fact, it even seems to be a common property of inferential statistics which is an enterprise that explicitly applies probability to make reasonable inferences. There are several interesting philosophical questions that spring from these observations. One general question is whether there is any logical structure to this behavior at all or whether the apparent non-monotonic behavior of defeasible reasoning is, in the end, too content dependent to think of as a logical property,  so too content dependent to think of as a property of a defeasible closure operation. (Hmm, in fact, I suppose someone could play around with these properties and argue that defeasible closure operations don&#8217;t exist&#8230;.) But some, including me, think that there is some interesting logical structure to patterns of non-monotonic/defeasible reasoning&#8211;which is (partly) why I am holding out against the standard use of conditional probabilities to model defeasible reasoning.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike Huemer</title>
		<link>http://certaindoubts.com/closure-for-defeasible-consequence/#comment-1307</link>
		<dc:creator><![CDATA[Mike Huemer]]></dc:creator>
		<pubDate>Fri, 04 Feb 2005 02:07:55 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=243#comment-1307</guid>
		<description><![CDATA[Thanks, Greg. I got all that up til the last statement: &quot;probability is inferentially monotonic: from a superset of probability premises, you get the same conclusions or a superset of them.&quot; Maybe I don&#039;t know what you mean by &quot;probability premises.&quot; You mean statements that are explicitly assessments of probability? Or statements that are themselves probably true? Or something else?

Either way, it seems like, from a superset of premises A, you could &quot;get&quot; (that is, be justified in believing) a proper subset of the conclusions that you could get from A. I say this because I assume that to be justified in believing a proposition B on the basis of (a set of propositions) A is, roughly, for B to have a high probability conditional on A (or maybe this is too simplistic, but at least it should be partly a function of that conditional probability, and going *below* some threshold level for that conditional probability should take away justification). Since conditionalizing on a proper superset of A (=a *subset* of the space of possibilities) can lower the probability of B (as we&#039;ve agreed), it follows that B might be justified by A, but not justified by some proper superset of A. Right? So, unless I misunderstood some of your terms, you should say that from a superset of premises A, you (probabilistically) can get *either more or fewer* conclusions than from A.]]></description>
		<content:encoded><![CDATA[<p>Thanks, Greg. I got all that up til the last statement: &#8220;probability is inferentially monotonic: from a superset of probability premises, you get the same conclusions or a superset of them.&#8221; Maybe I don&#8217;t know what you mean by &#8220;probability premises.&#8221; You mean statements that are explicitly assessments of probability? Or statements that are themselves probably true? Or something else?</p>
<p>Either way, it seems like, from a superset of premises A, you could &#8220;get&#8221; (that is, be justified in believing) a proper subset of the conclusions that you could get from A. I say this because I assume that to be justified in believing a proposition B on the basis of (a set of propositions) A is, roughly, for B to have a high probability conditional on A (or maybe this is too simplistic, but at least it should be partly a function of that conditional probability, and going *below* some threshold level for that conditional probability should take away justification). Since conditionalizing on a proper superset of A (=a *subset* of the space of possibilities) can lower the probability of B (as we&#8217;ve agreed), it follows that B might be justified by A, but not justified by some proper superset of A. Right? So, unless I misunderstood some of your terms, you should say that from a superset of premises A, you (probabilistically) can get *either more or fewer* conclusions than from A.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/closure-for-defeasible-consequence/#comment-1306</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Wed, 02 Feb 2005 15:23:53 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=243#comment-1306</guid>
		<description><![CDATA[Hi Mike,

Probability functions, as mathematical functions, are monotonic: if A is a subset of B, then Pr(A) is less than or equal to Pr(B). If A is a smaller part of the sample space than B, then the probability of A must be less than or equal to the probability of B. For this reason, conditional probability functions are likewise monotonic in the first position: if A is a subset of B, then Pr(A &#124; X) is less than or equal to Pr(B &#124; X), for any X with a positive measure. However, the conditional probability function is non-monotonic in the second position, since conditioning on a smaller part of the sample space may either raise or lower the conditional probability. This point is contrary to the assumption made in line 20, if I&#039;ve read this post correctly.

You can ape non-monotonicity by conditioning on different events in your sample space, of course, but this behavior isn&#039;t attributed to the function itself but rather to how the probability mass is assigned to events in your sample space: it is possible to look at different locations in your sample space and for the probability of the event you&#039;re interested in at those locations to increase, decrease or remain the same.

But, the probability function itself is a monotonic function. Hence, probability is inferentially monotonic: from a superset of probability premises, you get the same conclusions or a superset of them.

Does this answer your question?]]></description>
		<content:encoded><![CDATA[<p>Hi Mike,</p>
<p>Probability functions, as mathematical functions, are monotonic: if A is a subset of B, then Pr(A) is less than or equal to Pr(B). If A is a smaller part of the sample space than B, then the probability of A must be less than or equal to the probability of B. For this reason, conditional probability functions are likewise monotonic in the first position: if A is a subset of B, then Pr(A | X) is less than or equal to Pr(B | X), for any X with a positive measure. However, the conditional probability function is non-monotonic in the second position, since conditioning on a smaller part of the sample space may either raise or lower the conditional probability. This point is contrary to the assumption made in line 20, if I&#8217;ve read this post correctly.</p>
<p>You can ape non-monotonicity by conditioning on different events in your sample space, of course, but this behavior isn&#8217;t attributed to the function itself but rather to how the probability mass is assigned to events in your sample space: it is possible to look at different locations in your sample space and for the probability of the event you&#8217;re interested in at those locations to increase, decrease or remain the same.</p>
<p>But, the probability function itself is a monotonic function. Hence, probability is inferentially monotonic: from a superset of probability premises, you get the same conclusions or a superset of them.</p>
<p>Does this answer your question?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike Huemer</title>
		<link>http://certaindoubts.com/closure-for-defeasible-consequence/#comment-1305</link>
		<dc:creator><![CDATA[Mike Huemer]]></dc:creator>
		<pubDate>Wed, 02 Feb 2005 03:59:11 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=243#comment-1305</guid>
		<description><![CDATA[Gregory,
I failed to understand your point that conditional probability functions are monotone. Can you explain that again? I assume that monotonicity in this case would mean that P(A&#124;B&amp;C) must always be &gt; or = P(A&#124;B), because A is analogous to something that is being inferred, either from B, or from B&amp;C.]]></description>
		<content:encoded><![CDATA[<p>Gregory,<br />
I failed to understand your point that conditional probability functions are monotone. Can you explain that again? I assume that monotonicity in this case would mean that P(A|B&#038;C) must always be > or = P(A|B), because A is analogous to something that is being inferred, either from B, or from B&#038;C.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Stephen Fogdall</title>
		<link>http://certaindoubts.com/closure-for-defeasible-consequence/#comment-1304</link>
		<dc:creator><![CDATA[Stephen Fogdall]]></dc:creator>
		<pubDate>Tue, 01 Feb 2005 20:32:36 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=243#comment-1304</guid>
		<description><![CDATA[I think that Jon is ultimately correct, as he put it above (#12), that one&#039;s body of evidence is enlarged by reasoning in accord with the logic of defeasible consequence, and that this is a key part of solving the drainage problem.  But the problem is to understand what that means exactly, because on one level that&#039;s really just a restatement of the problem--what is it that entitles you to enlarge your body of evidence in that way?

Perhaps the problem can be posed like this: it is natural to assume that (undefeated) defeasible reasoning is truth conducive, meaning that, in the long run, you&#039;re more likely to hold true beliefs if you infer (undefeated) defeasible consequences of things you already believe/know, than if you infer things that aren&#039;t.  This suggests (though only suggests) that there is some relationship between a belief&#039;s being a defeasible consequence of others and its being probably true given those other beliefs (or, as Mike put it (#16), its probability being above some threshold, given those other beliefs).  It&#039;s true, this relationship might not hold, in which case one either would have to deny that defeasible reasoning is ultimately truth-conducive, or explain its truth-conducivity in some other way.

On the other hand, we clearly do engage in &quot;inference upon inference,&quot; and while in some circumstances we recognize that the support that attaches at each stage in the reasoning sort of bleeds off as we progress to later stages, in other circumstances we don&#039;t feel that it diminishes (or we just don&#039;t worry about it).

I think what may be going here is that while there is some relationship between a belief&#039;s being defeasibly supported and its being probably true, one can&#039;t apply some simple mutliplicative probabillty rule at each stage.  Most likely (and this is just hunch), in those cases where we permit stacking of inference upon inference, we&#039;re responding to some intuitive sense that the ultimate conclusion and the augmented body of evidence that Jon recognizes together form a coherent whole that is more likely to be true as a package than is apparent if one looks at the inferential stages sequentially.]]></description>
		<content:encoded><![CDATA[<p>I think that Jon is ultimately correct, as he put it above (#12), that one&#8217;s body of evidence is enlarged by reasoning in accord with the logic of defeasible consequence, and that this is a key part of solving the drainage problem.  But the problem is to understand what that means exactly, because on one level that&#8217;s really just a restatement of the problem&#8211;what is it that entitles you to enlarge your body of evidence in that way?</p>
<p>Perhaps the problem can be posed like this: it is natural to assume that (undefeated) defeasible reasoning is truth conducive, meaning that, in the long run, you&#8217;re more likely to hold true beliefs if you infer (undefeated) defeasible consequences of things you already believe/know, than if you infer things that aren&#8217;t.  This suggests (though only suggests) that there is some relationship between a belief&#8217;s being a defeasible consequence of others and its being probably true given those other beliefs (or, as Mike put it (#16), its probability being above some threshold, given those other beliefs).  It&#8217;s true, this relationship might not hold, in which case one either would have to deny that defeasible reasoning is ultimately truth-conducive, or explain its truth-conducivity in some other way.</p>
<p>On the other hand, we clearly do engage in &#8220;inference upon inference,&#8221; and while in some circumstances we recognize that the support that attaches at each stage in the reasoning sort of bleeds off as we progress to later stages, in other circumstances we don&#8217;t feel that it diminishes (or we just don&#8217;t worry about it).</p>
<p>I think what may be going here is that while there is some relationship between a belief&#8217;s being defeasibly supported and its being probably true, one can&#8217;t apply some simple mutliplicative probabillty rule at each stage.  Most likely (and this is just hunch), in those cases where we permit stacking of inference upon inference, we&#8217;re responding to some intuitive sense that the ultimate conclusion and the augmented body of evidence that Jon recognizes together form a coherent whole that is more likely to be true as a package than is apparent if one looks at the inferential stages sequentially.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/closure-for-defeasible-consequence/#comment-1303</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Tue, 01 Feb 2005 16:35:25 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=243#comment-1303</guid>
		<description><![CDATA[whoops! conditional probability functions are monotone; hence, they are not &lt;i&gt;non&lt;/i&gt;-monotonic. (blasted sign error in the first line, second paragraph of my previous post! sorry!!)]]></description>
		<content:encoded><![CDATA[<p>whoops! conditional probability functions are monotone; hence, they are not <i>non</i>-monotonic. (blasted sign error in the first line, second paragraph of my previous post! sorry!!)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/closure-for-defeasible-consequence/#comment-1302</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Tue, 01 Feb 2005 15:25:15 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=243#comment-1302</guid>
		<description><![CDATA[I want to address two points in the exchange between Jon and Stephen, lines 11 to 13. First, conditional probability functions are not the only mechanism by which to provide a probabilistic understanding of defeasible support.

(Ah, and it is important to keep in mind that conditional probability is &lt;i&gt;not&lt;/i&gt; a monotone function, since it is a probability function and probability functions are (weakly) monotonic; rather, the second place of a conditional probability function may be thought of as behaving non-monotonically in the sense that the probability of an event (set) &lt;i&gt;A&lt;/i&gt; conditioned on an event (set) &lt;i&gt;B&lt;/i&gt; may either increase or decrease when &lt;i&gt;B&lt;/i&gt; increases. Notice that the first position of this function does not share this behavior, however. I mention this only because there are many details we are glossing over in the discussion, but the way conditional probability functions ape non-monotonicity can be a key sticking point when setting out to provide the details.)

Second, perhaps the relationship between support and consequence should be thought of in terms analogous to the relationship between truth and logical consequence: namely (the philosophy of logic aside) the material conditional is very useful in mathematics and remarkably well understood, despite its rather clumsy behavior when applied to most things outside of its intended domain, which is mathematics. Perhaps, then, we shouldn&#039;t necessarily be alarmed by the depletion of support by iterative applications that Stephen is talking about and be so quick to dismiss it since, I conjecture, it would be difficult to do so without also ruling out all systems that feature a measure theoretic modeling of support for propositions and a threshold-sensitive consequence relation. That the support property depletes does not mean that a long conjunction of propositions cannot be supported; it just means that the support for each of the conjuncts plus logic isn&#039;t enough to guarantee that the conjunction shares the same degree of support. Likewise, &lt;i&gt;p&lt;/i&gt; only if &lt;i&gt;q&lt;/i&gt; and a false &lt;i&gt;p&lt;/i&gt; doesn&#039;t render &lt;i&gt;q&lt;/i&gt; hopelessly indeterminate. A long conjunction might be supported, but you have to look at the support you have for &lt;i&gt;that&lt;/i&gt; conjunction. The logic of support isn&#039;t worthless, because there are conjunctions that are supported by the relatively high degree of support shared by each conjunct. Indeed, it may even guide us to investigate the support for below-threshold-for-acceptance conjunctions that are otherwise entailed by what is supported.

The idea in short is that we don&#039;t beat up on the material conditional for failing to tell us what to do when an antecedent is false; perhaps, then, we shouldn&#039;t beat up on a formal modeling of epistemic support relation that puts a curb on arbitrary conjunctions of what is already supported.]]></description>
		<content:encoded><![CDATA[<p>I want to address two points in the exchange between Jon and Stephen, lines 11 to 13. First, conditional probability functions are not the only mechanism by which to provide a probabilistic understanding of defeasible support.</p>
<p>(Ah, and it is important to keep in mind that conditional probability is <i>not</i> a monotone function, since it is a probability function and probability functions are (weakly) monotonic; rather, the second place of a conditional probability function may be thought of as behaving non-monotonically in the sense that the probability of an event (set) <i>A</i> conditioned on an event (set) <i>B</i> may either increase or decrease when <i>B</i> increases. Notice that the first position of this function does not share this behavior, however. I mention this only because there are many details we are glossing over in the discussion, but the way conditional probability functions ape non-monotonicity can be a key sticking point when setting out to provide the details.)</p>
<p>Second, perhaps the relationship between support and consequence should be thought of in terms analogous to the relationship between truth and logical consequence: namely (the philosophy of logic aside) the material conditional is very useful in mathematics and remarkably well understood, despite its rather clumsy behavior when applied to most things outside of its intended domain, which is mathematics. Perhaps, then, we shouldn&#8217;t necessarily be alarmed by the depletion of support by iterative applications that Stephen is talking about and be so quick to dismiss it since, I conjecture, it would be difficult to do so without also ruling out all systems that feature a measure theoretic modeling of support for propositions and a threshold-sensitive consequence relation. That the support property depletes does not mean that a long conjunction of propositions cannot be supported; it just means that the support for each of the conjuncts plus logic isn&#8217;t enough to guarantee that the conjunction shares the same degree of support. Likewise, <i>p</i> only if <i>q</i> and a false <i>p</i> doesn&#8217;t render <i>q</i> hopelessly indeterminate. A long conjunction might be supported, but you have to look at the support you have for <i>that</i> conjunction. The logic of support isn&#8217;t worthless, because there are conjunctions that are supported by the relatively high degree of support shared by each conjunct. Indeed, it may even guide us to investigate the support for below-threshold-for-acceptance conjunctions that are otherwise entailed by what is supported.</p>
<p>The idea in short is that we don&#8217;t beat up on the material conditional for failing to tell us what to do when an antecedent is false; perhaps, then, we shouldn&#8217;t beat up on a formal modeling of epistemic support relation that puts a curb on arbitrary conjunctions of what is already supported.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike Huemer</title>
		<link>http://certaindoubts.com/closure-for-defeasible-consequence/#comment-1301</link>
		<dc:creator><![CDATA[Mike Huemer]]></dc:creator>
		<pubDate>Tue, 01 Feb 2005 05:44:46 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=243#comment-1301</guid>
		<description><![CDATA[Stephen--
One other observation about the drainage problem. Obviously, a defender of closure will reject that a belief is defeasibly justified iff it has a high probability, or a probability above some threshold. That&#039;s ok. But here&#039;s something I think is not okay to reject: a belief is defeasibly justified *only if* it has a probability above some threshold. For instance, surely every justified belief is more than 1% likely to be true.

Now, the really serious drainage problem, as I see it, is that it looks like you can always get the probability of a belief at the end of a chain to fall below whatever threshhold you pick, by having a sufficiently long chain.

How could this be avoided? It seems that the only way to avoid this problem is to understand defeasible support in such a way that, when A defeasibly supports B, B is *not* thereby less probable than A.

Well, here is a silly way to do this (not a plausible account of def. support, but perhaps illuminating as a mere existence proof): Suppose that
&lt;blockquote&gt;
&quot;x defeasibly supports y&quot; means &quot;P(y&#124;x) &gt; P(y), and P(y&#124;e) &gt; .9&quot;,
&lt;/blockquote&gt;
where &quot;P(y&#124;e)&quot; is the probability of y on your total evidence (including x). This stipulatively blocks the drainage problem, since the moment the probability of something in your chain of reasoning drops below .9, you no longer have &quot;defeasible support&quot;. And it&#039;s not completely uninteresting--there is some connection with an intuitive notion of support (provided by the first clause: x does have to raise the Pr. of y to count as supporting it).]]></description>
		<content:encoded><![CDATA[<p>Stephen&#8211;<br />
One other observation about the drainage problem. Obviously, a defender of closure will reject that a belief is defeasibly justified iff it has a high probability, or a probability above some threshold. That&#8217;s ok. But here&#8217;s something I think is not okay to reject: a belief is defeasibly justified *only if* it has a probability above some threshold. For instance, surely every justified belief is more than 1% likely to be true.</p>
<p>Now, the really serious drainage problem, as I see it, is that it looks like you can always get the probability of a belief at the end of a chain to fall below whatever threshhold you pick, by having a sufficiently long chain.</p>
<p>How could this be avoided? It seems that the only way to avoid this problem is to understand defeasible support in such a way that, when A defeasibly supports B, B is *not* thereby less probable than A.</p>
<p>Well, here is a silly way to do this (not a plausible account of def. support, but perhaps illuminating as a mere existence proof): Suppose that</p>
<blockquote><p>
&#8220;x defeasibly supports y&#8221; means &#8220;P(y|x) > P(y), and P(y|e) > .9&#8221;,
</p></blockquote>
<p>where &#8220;P(y|e)&#8221; is the probability of y on your total evidence (including x). This stipulatively blocks the drainage problem, since the moment the probability of something in your chain of reasoning drops below .9, you no longer have &#8220;defeasible support&#8221;. And it&#8217;s not completely uninteresting&#8211;there is some connection with an intuitive notion of support (provided by the first clause: x does have to raise the Pr. of y to count as supporting it).</p>
]]></content:encoded>
	</item>
</channel>
</rss>
