<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: More on the Preface</title>
	<atom:link href="http://certaindoubts.com/687/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/687/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/687/#comment-7320</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Mon, 23 Apr 2007 11:13:58 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=687#comment-7320</guid>
		<description><![CDATA[The second to last paragraph is particularly badly put. The random variable is the statement about the population parameter, and that is the variable that we define a prior on. The thought was that the agent is presumed to have some ideas about expected values for the particular observed data and the variable in question, but that information is put into your prior on the population parameter.]]></description>
		<content:encoded><![CDATA[<p>The second to last paragraph is particularly badly put. The random variable is the statement about the population parameter, and that is the variable that we define a prior on. The thought was that the agent is presumed to have some ideas about expected values for the particular observed data and the variable in question, but that information is put into your prior on the population parameter.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/687/#comment-7319</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Mon, 23 Apr 2007 07:55:54 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=687#comment-7319</guid>
		<description><![CDATA[This is an excellent question, Kenny.

I think that the only way to interpret the latter statement is in terms of the former, which means that there is an interpretation of probability that is fundamentally different than the measure-theoretic notion specified by the Kolmogorov axioms, and fundamentally different than the many, many variants of this classical interpretation of probability.

Many statistics textbooks maintain that Kolmogorov probability is probability enough, and their authors would pounce on my &quot;alternatively, that the probability...&quot; claim as a major blunder. Even Neyman and Pearson would bristle at my referring to this confidence interval as a probability.

Why their fuss? On the classical view of statistical estimation the confidence comes from the sampling distribution of the statistic rather than from the actual measurement values. The length of the pole is a fixed but unknown constant; this is the unknown &quot;population&quot; mean, the fixed magnitude of length in meters that is true of p. We are sampling to find this magnitude, to estimate its value. The sample mean (the average of our n measurements of pole p) is the random variable. There is therefore no random variable to attach that 95% confidence statement to; so it cannot be a Kolmogorov probability. And if this is the only probability there is, then my &quot;alternatively,...&quot; statement is a blunder, a category mistake.

The Bayesian view sticks to the classical axiomatic treatment of probability and yields a clear probability statement, but it does so at the price of assigning measure to some pretty funky looking events.  We get a probability statement for the posterior distribution of the population mean, &quot;length of pole p&quot;, &lt;i&gt;which now is a random variable&lt;/i&gt; rather than a fixed constant, given the &lt;i&gt;actual sample data&lt;/i&gt; and not the sampling distribution of the statistic. In this case the sample data are &lt;i&gt;these&lt;/i&gt; particular n measurements of p. So, you get to talk about probabilities of statements at the price of believing  that it makes sense to talk about the probability that: [the length of pole p is between 6.002 and 6.004 meters, given that measurement-1 is 6.005 meters, measurement-2 is 6.003 meters, ..., measurement-n is 5.099 meters] = 0.95.

Return now to Jim&#039;s observation. On the Bayesian view, the probability is conditional on &lt;i&gt;that&lt;/i&gt; actual data. So you have to be pretty careful defining the random variables over these values to effect inverse inference, and this information is loaded into your subjective prior. The classical statistician sees this and thinks that the bulk of the statistical inference problem is swept into this murky prior. The Bayesian sees this as simply articulating what we know about measurement.

It also doesn&#039;t help matters that I, and everyone else, pick problems that are very easy to visualize and understand. It helps to have familiar problems that have simple linear functional dependencies. We have centuries of experience measuring the length of poles, after all. There is a lot of information about this that we can put into our prior. And, if the task is to come up with an epistemology for measuring the length of flag poles, then I agree, we can do a pretty good job at this. But when epistemologists talk about rationality constraints built atop this machinery, I often become very confused by what the algebra must be like. I&#039;ve argued with a Bayesian-minded epistemologist on this blog who insisted that &lt;i&gt;I&lt;/i&gt; must know the probability of, have a degree of belief for: [my suffering an elaborate hoax involving my boarding a commercial airline in Lisbon then landing and touring an ersatz Geneva, given that my airline booking number for the flight ticket was 77777]. (!). He was consistent and a good sport, but he endorsed the consequences of orthodoxy without flinching.]]></description>
		<content:encoded><![CDATA[<p>This is an excellent question, Kenny.</p>
<p>I think that the only way to interpret the latter statement is in terms of the former, which means that there is an interpretation of probability that is fundamentally different than the measure-theoretic notion specified by the Kolmogorov axioms, and fundamentally different than the many, many variants of this classical interpretation of probability.</p>
<p>Many statistics textbooks maintain that Kolmogorov probability is probability enough, and their authors would pounce on my &#8220;alternatively, that the probability&#8230;&#8221; claim as a major blunder. Even Neyman and Pearson would bristle at my referring to this confidence interval as a probability.</p>
<p>Why their fuss? On the classical view of statistical estimation the confidence comes from the sampling distribution of the statistic rather than from the actual measurement values. The length of the pole is a fixed but unknown constant; this is the unknown &#8220;population&#8221; mean, the fixed magnitude of length in meters that is true of p. We are sampling to find this magnitude, to estimate its value. The sample mean (the average of our n measurements of pole p) is the random variable. There is therefore no random variable to attach that 95% confidence statement to; so it cannot be a Kolmogorov probability. And if this is the only probability there is, then my &#8220;alternatively,&#8230;&#8221; statement is a blunder, a category mistake.</p>
<p>The Bayesian view sticks to the classical axiomatic treatment of probability and yields a clear probability statement, but it does so at the price of assigning measure to some pretty funky looking events.  We get a probability statement for the posterior distribution of the population mean, &#8220;length of pole p&#8221;, <i>which now is a random variable</i> rather than a fixed constant, given the <i>actual sample data</i> and not the sampling distribution of the statistic. In this case the sample data are <i>these</i> particular n measurements of p. So, you get to talk about probabilities of statements at the price of believing  that it makes sense to talk about the probability that: [the length of pole p is between 6.002 and 6.004 meters, given that measurement-1 is 6.005 meters, measurement-2 is 6.003 meters, &#8230;, measurement-n is 5.099 meters] = 0.95.</p>
<p>Return now to Jim&#8217;s observation. On the Bayesian view, the probability is conditional on <i>that</i> actual data. So you have to be pretty careful defining the random variables over these values to effect inverse inference, and this information is loaded into your subjective prior. The classical statistician sees this and thinks that the bulk of the statistical inference problem is swept into this murky prior. The Bayesian sees this as simply articulating what we know about measurement.</p>
<p>It also doesn&#8217;t help matters that I, and everyone else, pick problems that are very easy to visualize and understand. It helps to have familiar problems that have simple linear functional dependencies. We have centuries of experience measuring the length of poles, after all. There is a lot of information about this that we can put into our prior. And, if the task is to come up with an epistemology for measuring the length of flag poles, then I agree, we can do a pretty good job at this. But when epistemologists talk about rationality constraints built atop this machinery, I often become very confused by what the algebra must be like. I&#8217;ve argued with a Bayesian-minded epistemologist on this blog who insisted that <i>I</i> must know the probability of, have a degree of belief for: [my suffering an elaborate hoax involving my boarding a commercial airline in Lisbon then landing and touring an ersatz Geneva, given that my airline booking number for the flight ticket was 77777]. (!). He was consistent and a good sport, but he endorsed the consequences of orthodoxy without flinching.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jim</title>
		<link>http://certaindoubts.com/687/#comment-7318</link>
		<dc:creator><![CDATA[Jim]]></dc:creator>
		<pubDate>Mon, 23 Apr 2007 07:36:41 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=687#comment-7318</guid>
		<description><![CDATA[Greg,
The boundedness assumption is not an assumption about the data &quot;before its collection&quot;. One might have the data first or have the prior distribution first, or &quot;get them at the same time&quot;. It&#039;s not really a temporal matter at all. It&#039;s just that the stable estimation theorem doesn&#039;t apply if the data (once collected) happens to fall in a region where the agent&#039;s prior distribution represents extremely small prior probabilities. If the data doesn&#039;t happen to fall in such a region, then the agent&#039;s posterior probability (his degree of confidence) that the true length lies within a 2SD margin of error of the data mean is .95.

That seems more like what we want than the usual confidence interval approach, which only says that 95 percent of the time when confidence regions are calculated this way, they will capture a true hypothesis within the interval. That is, confidence intervals make the former claim in Kenny&#039;s quote, but not the latter claim -- because on a frequentist view the probability (i.e. frequency) with which the true hypothesis is in this interval in this case is either 0 or 1. But on a Bayesian account, the probability (i.e. updated confidence strength for the agent) that the true hypothesis is in this interval in this case is .95, which is what we wanted.

Now you might object that confidence strengths on there own aren&#039;t much good when what we want is high confidence in hypotheses that are true. But convergence to truth results can be used to bolster the Bayesian confidence strengths by showing that confidence for hypotheses formed in this way are very likely to result in high confidence for true hypotheses. (See the end of section 4 of the Inductive Logic article.)]]></description>
		<content:encoded><![CDATA[<p>Greg,<br />
The boundedness assumption is not an assumption about the data &#8220;before its collection&#8221;. One might have the data first or have the prior distribution first, or &#8220;get them at the same time&#8221;. It&#8217;s not really a temporal matter at all. It&#8217;s just that the stable estimation theorem doesn&#8217;t apply if the data (once collected) happens to fall in a region where the agent&#8217;s prior distribution represents extremely small prior probabilities. If the data doesn&#8217;t happen to fall in such a region, then the agent&#8217;s posterior probability (his degree of confidence) that the true length lies within a 2SD margin of error of the data mean is .95.</p>
<p>That seems more like what we want than the usual confidence interval approach, which only says that 95 percent of the time when confidence regions are calculated this way, they will capture a true hypothesis within the interval. That is, confidence intervals make the former claim in Kenny&#8217;s quote, but not the latter claim &#8212; because on a frequentist view the probability (i.e. frequency) with which the true hypothesis is in this interval in this case is either 0 or 1. But on a Bayesian account, the probability (i.e. updated confidence strength for the agent) that the true hypothesis is in this interval in this case is .95, which is what we wanted.</p>
<p>Now you might object that confidence strengths on there own aren&#8217;t much good when what we want is high confidence in hypotheses that are true. But convergence to truth results can be used to bolster the Bayesian confidence strengths by showing that confidence for hypotheses formed in this way are very likely to result in high confidence for true hypotheses. (See the end of section 4 of the Inductive Logic article.)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Kenny Easwaran</title>
		<link>http://certaindoubts.com/687/#comment-7317</link>
		<dc:creator><![CDATA[Kenny Easwaran]]></dc:creator>
		<pubDate>Sun, 22 Apr 2007 21:39:12 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=687#comment-7317</guid>
		<description><![CDATA[&lt;i&gt;This expresses that 95% of the intervals calculated in this fashion will contain the true value of p; or, alternatively, that the probability that the true length of p is equal to a value within [6.002, 6.004] meters is 0.95.&lt;/i&gt;

I&#039;ve never quite understood how these two claims are supposed to be related to one another.  The former I understand, and it looks like we even have good justification for it.  Is this statement supposed to just give the meaning for the second claim?]]></description>
		<content:encoded><![CDATA[<p><i>This expresses that 95% of the intervals calculated in this fashion will contain the true value of p; or, alternatively, that the probability that the true length of p is equal to a value within [6.002, 6.004] meters is 0.95.</i></p>
<p>I&#8217;ve never quite understood how these two claims are supposed to be related to one another.  The former I understand, and it looks like we even have good justification for it.  Is this statement supposed to just give the meaning for the second claim?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/687/#comment-7316</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Sun, 22 Apr 2007 17:54:25 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=687#comment-7316</guid>
		<description><![CDATA[Hi Jim! Good to hear from you! In reply: To get the generality here you need the &quot;boundedness assumption&quot; you discuss in your SEP article, which is a prior assumption an agent must make about possible values of the parameter outside of the specified interval. This might be fine, from a statistical point of view. But from an epistemological point of view it is a suspicious move to assume that this property holds of data &lt;i&gt;before&lt;/i&gt; its collection. I had thought that I was being more charitable to the Bayesian view by dropping this requirement and stipulating instead a flat prior, which is presumably what one would do absent prior knowledge about the data. (Otherwise, why gather the data?)

Indeed, in your SEP article you point out that the boundedness assumption doesn&#039;t always hold. This isn&#039;t a problem for statistical practice in general, but it is a problem for epistemological practice if you are looking to build epistemic principles from this machinery.]]></description>
		<content:encoded><![CDATA[<p>Hi Jim! Good to hear from you! In reply: To get the generality here you need the &#8220;boundedness assumption&#8221; you discuss in your SEP article, which is a prior assumption an agent must make about possible values of the parameter outside of the specified interval. This might be fine, from a statistical point of view. But from an epistemological point of view it is a suspicious move to assume that this property holds of data <i>before</i> its collection. I had thought that I was being more charitable to the Bayesian view by dropping this requirement and stipulating instead a flat prior, which is presumably what one would do absent prior knowledge about the data. (Otherwise, why gather the data?)</p>
<p>Indeed, in your SEP article you point out that the boundedness assumption doesn&#8217;t always hold. This isn&#8217;t a problem for statistical practice in general, but it is a problem for epistemological practice if you are looking to build epistemic principles from this machinery.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jim</title>
		<link>http://certaindoubts.com/687/#comment-7315</link>
		<dc:creator><![CDATA[Jim]]></dc:creator>
		<pubDate>Sun, 22 Apr 2007 17:11:09 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=687#comment-7315</guid>
		<description><![CDATA[Greg,

The Bayesian doesn&#039;t need a flat prior. It can even be quite hilly -- just not too mountainous. That&#039;s what so-called &quot;stable estimation&quot; is all about. See section 4 of the Stanford Encyclopedia article &quot;on Inductive Logic&quot; for details.

Best,

Jim]]></description>
		<content:encoded><![CDATA[<p>Greg,</p>
<p>The Bayesian doesn&#8217;t need a flat prior. It can even be quite hilly &#8212; just not too mountainous. That&#8217;s what so-called &#8220;stable estimation&#8221; is all about. See section 4 of the Stanford Encyclopedia article &#8220;on Inductive Logic&#8221; for details.</p>
<p>Best,</p>
<p>Jim</p>
]]></content:encoded>
	</item>
</channel>
</rss>
