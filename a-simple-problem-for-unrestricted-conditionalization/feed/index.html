<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: A simple problem for (unrestricted) Conditionalization</title>
	<atom:link href="http://certaindoubts.com/a-simple-problem-for-unrestricted-conditionalization/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/a-simple-problem-for-unrestricted-conditionalization/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: S. Alas</title>
		<link>http://certaindoubts.com/a-simple-problem-for-unrestricted-conditionalization/#comment-324134</link>
		<dc:creator><![CDATA[S. Alas]]></dc:creator>
		<pubDate>Fri, 09 Nov 2018 19:52:07 +0000</pubDate>
		<guid isPermaLink="false">http://certaindoubts.com/?p=4890#comment-324134</guid>
		<description><![CDATA[Interesting, but I don’t necessarily see a threat to conditionalization. Let P be the proposition about flies, and Q be the proposition that at some time I have a high credence in P. That is, let Q be the set of possible worlds where at some time I have a high credence in P…

Q is relatively very small, maybe even much smaller than P. Some worlds in Q are worlds where I have no reason to believe P but do anyway, but most of them (by mass not by number), if we’re being charitable about my epistemic virtues, are worlds where I’ve got good some evidence that P. Of these, some are P-worlds and some aren’t (ie, the evidence misled me). Maybe it’s around half and half. (Or, if I’m really bullish on my epistemic skills, P is true in exactly q proportion of the Q worlds, where q is the level of my credence that P, if we fix that number for simplicity.)

The general picture is that in the space of possible worlds, P is a tiny circle and Q is a yet tinier circle, half in and half out of P. You’ve suggested that conditionalization can get my space of epistemically possible worlds down to a set which is mostly P and mostly not Q, and have pointed out that P is one such set. I agree that this would be a repugnant result, but I don’t think it’s possible. 

Could I, for example, get some evidence that shrinks my set of epistemically possible worlds to roughly P? – no more, and no less, because we still need not-Q to dominate Q. No, I could not. Suppose the UN Fly-Counting Commission publishes an unequivocal report to the effect that P. Then I’ve learned more than probably-P. I’ve also learned that this is a world where the UNFCC does such-and-such, and their report reaches me in such-and-such a way, and so on – which puts me squarely in a smaller set of worlds, call it R, where these things are true. (Now, conditional on R, P dominates not-P, which is why my credence in P is high.) And R must be a proper subset of Q, because it’s a set of worlds where things happen to make my credence in P high, which you’ll recall was the definition of Q…

So, it looks like there’s no way for me to ever learn P without also learning Q collaterally (except for weird lapses, split personalities, etc.). Even if my evidence for P is an oracle or an irresistible hunch, I’m still able to locate myself in a set within Q. And I take it as a nice piece of evidence for conditionalization, actually, that it’s able to take account of these cases. 

Or, the short version: I don&#039;t think it&#039;s possible to have evidence set P. Every world in P-and-not-Q is a world where P and I never come to believe that P. Any world where something happens to make me come to believe that P would be a world in Q, and I would know it was somewhere in Q because it doesn’t match any world in not-Q. I couldn&#039;t get evidence that P without also getting evidence that Q. Conditionalizers tend to speak as if when someone tells us X, we learn exactly X. I think what your example here shows is that sometimes, that approximation is too approximate.]]></description>
		<content:encoded><![CDATA[<p>Interesting, but I don’t necessarily see a threat to conditionalization. Let P be the proposition about flies, and Q be the proposition that at some time I have a high credence in P. That is, let Q be the set of possible worlds where at some time I have a high credence in P…</p>
<p>Q is relatively very small, maybe even much smaller than P. Some worlds in Q are worlds where I have no reason to believe P but do anyway, but most of them (by mass not by number), if we’re being charitable about my epistemic virtues, are worlds where I’ve got good some evidence that P. Of these, some are P-worlds and some aren’t (ie, the evidence misled me). Maybe it’s around half and half. (Or, if I’m really bullish on my epistemic skills, P is true in exactly q proportion of the Q worlds, where q is the level of my credence that P, if we fix that number for simplicity.)</p>
<p>The general picture is that in the space of possible worlds, P is a tiny circle and Q is a yet tinier circle, half in and half out of P. You’ve suggested that conditionalization can get my space of epistemically possible worlds down to a set which is mostly P and mostly not Q, and have pointed out that P is one such set. I agree that this would be a repugnant result, but I don’t think it’s possible. </p>
<p>Could I, for example, get some evidence that shrinks my set of epistemically possible worlds to roughly P? – no more, and no less, because we still need not-Q to dominate Q. No, I could not. Suppose the UN Fly-Counting Commission publishes an unequivocal report to the effect that P. Then I’ve learned more than probably-P. I’ve also learned that this is a world where the UNFCC does such-and-such, and their report reaches me in such-and-such a way, and so on – which puts me squarely in a smaller set of worlds, call it R, where these things are true. (Now, conditional on R, P dominates not-P, which is why my credence in P is high.) And R must be a proper subset of Q, because it’s a set of worlds where things happen to make my credence in P high, which you’ll recall was the definition of Q…</p>
<p>So, it looks like there’s no way for me to ever learn P without also learning Q collaterally (except for weird lapses, split personalities, etc.). Even if my evidence for P is an oracle or an irresistible hunch, I’m still able to locate myself in a set within Q. And I take it as a nice piece of evidence for conditionalization, actually, that it’s able to take account of these cases. </p>
<p>Or, the short version: I don&#8217;t think it&#8217;s possible to have evidence set P. Every world in P-and-not-Q is a world where P and I never come to believe that P. Any world where something happens to make me come to believe that P would be a world in Q, and I would know it was somewhere in Q because it doesn’t match any world in not-Q. I couldn&#8217;t get evidence that P without also getting evidence that Q. Conditionalizers tend to speak as if when someone tells us X, we learn exactly X. I think what your example here shows is that sometimes, that approximation is too approximate.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
