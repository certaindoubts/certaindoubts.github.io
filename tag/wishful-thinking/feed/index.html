<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>wishful thinking &#8211; </title>
	<atom:link href="http://certaindoubts.com/tag/wishful-thinking/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 01:35:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>Wishful Thinking Problems for Reliabilism</title>
		<link>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/</link>
		<comments>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/#comments</comments>
		<pubDate>Mon, 26 Mar 2012 16:00:56 +0000</pubDate>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
				<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[perception]]></category>
		<category><![CDATA[reliabilism]]></category>
		<category><![CDATA[wishful thinking]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3369</guid>
		<description><![CDATA[Phenomenal conservatism and dogmatism get a bad rep for allowing some cases of wishful thinking to provide prima facie justification.  In this post, I argue that reliabilism has wishful thinking problems that are even worse. Contrast direct and indirect wishful &#8230; <a class="more-link" href="http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Phenomenal conservatism and dogmatism get a bad rep for allowing some cases of wishful thinking to provide prima facie justification.  In this post, I argue that reliabilism has wishful thinking problems that are even worse.</p>
<p>Contrast direct and indirect wishful thinking.  The former occurs when one bases a belief that P directly on one’s desire (wish, lust, etc.) that P.  The latter occurs in any other way.  For our purposes, we can assume all cases of indirect wishful thinking fit this pattern: a desire that P causally influences the way things seem, and then a belief that P is based directly on the seeming that is so influenced.  For example, I might base my belief that the nugget is gold on its seeming that the nugget is gold, where I have that seeming, not because of relevant expertise, but because I’m lusting for gold.  Lyons holds that, as a matter of fact, most wishful thinking is indirect in this way, which sounds plausible to me.  Seemings Internalism (SI) holds that seemings necessarily provide prima facie justification.  (SI is inclusive of dogmatism and phenomenal conservatism.)  Hence, SI seems committed to allowing indirect wishful thinking to provide prima facie justification.</p>
<p>Says Lyons: “For SI to bite the bullet here would be for it to hold that the epistemology of (typical) wishful thinking perfectly parallels the epistemology of (typical) perception: an agent has an appearance as of <em>p</em>, which <em>prima facie</em> justifies her in believing that <em>p</em>.  I myself would think that this bullet just can’t be bitten, that an epistemology that licences wishful thinking in this way simply can’t be taken seriously” (pg 299 of <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1533-6077.2011.00205.x/abstract">this paper</a>).  Note that Lyons doesn’t claim that, given SI, typical cases of wishful thinking result in <em>ultima facie</em> justification.  Since it’s plausible that typical wishful thinkers have defeaters for their wishful thinking, the latter claim is dubious.</p>
<p>I agree with Lyons that it is counterintuitive to allow indirect wishful thinking to prima facie justify its content; however, reliabilists suffer from wishful thinking problems that are <em>worse</em>.  I admit it’s bad to allow typical cases of <em>indirect </em>wishful thinking to provide <em>prima facie</em> justification.  It’s worse, in my mind, to allow possible cases of <em>direct </em>wishful thinking to provide <em>ultima facie</em> justification.  Proponents of SI can say that it is impossible for desires, by themselves, to be an acceptable basis for beliefs.  Reliabilists can’t say that.  (I think the same holds for externalism more generally and possibly also for some versions of internalism.)<span id="more-3369"></span></p>
<p>To see the basic point, start with a simple version of indicator reliabilism.  On such a view, a desire that P will justify a belief that P just in case that desire is a reliable indicator of P.  Epistemic angels can bring about the required reliability by organizing the world to ensure that desires (within a certain domain) regularly come to pass.  The modal profile of P can ensure that any basis of P, including a desire for P, is a trivially reliable indicator for P.  Since Goedel’s first incompleteness theorem is necessarily true, there’s never a case in which you will be led astray by believing the theorem on the basis of desiring or wishing it to be true.  The modal profile of certain contingent truths also can make desires trivially reliable indicators of P, but I won’t go into the details here.  More sophisticated indicator reliabilisms will give more subtle accounts of reliability, but give me an account and I’ll give you a possible case in which the view allows a belief to be ultima facie justified on the basis of a desire.</p>
<p>Depending on what they say about process individuation, process reliabilists may approve of actual cases of direct wishful thinking.  A process can be wrong every time it takes a desire as an input, but still be reliable overall if desires rarely get used as inputs.  For example, I might use process R 100 times.  It&#8217;s output might be mistaken both times it took a desire as an input, but be very reliable because it was correct in all 98 other uses.  Suppose that desires do sometimes causally influence the way things seem (which Lyons accepts) and that this happens in a very small number of times relative to the number of perceptual seemings we have (which seems plausible).  When desires do get involved, are those desires unusual inputs to the normal—and reliable—process of perception or do they always indicate that a different process is at work?  I don’t think reliabilists say enough about process individuation for us to say one way or another.  But if desires are unusual inputs to a normal reliable process, then process reliabilists are committed to allowing <em>direct</em> wishful thinking to provide <em>ultima facie </em>justification in the actual world.</p>
<p>So here’s a challenge, reliabilists.  Give me a proposed account of process individuation that doesn’t allow any actual wishful thinking to count as justified, and I’ll show you that there is a possible process that (i) takes at least one desire as an input and (ii) produces mostly true beliefs (or satisfies whatever account of reliability you put forward).</p>
<p>(I’ve assumed that the relevant sort of reliability is reliability in the world of the process being evaluated (what Lyons calls “in situ” reliability).  Alternative views hold that what matters is reliability in the actual world.  Such versions of reliabilism probably don’t have wishful thinking problems, unless their account of process individuation forces them to approve of some actual case of wishful thinking.  But they achieve this advantage by relying on the most implausible feature of their view, namely that processes that don’t exist can’t yield justified beliefs.  Possible processes that don’t exist can’t yield justified beliefs, because they aren’t reliable in the actual world.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/wishful-thinking-problems-for-reliabilism/feed/</wfw:commentRss>
		<slash:comments>11</slash:comments>
		</item>
	</channel>
</rss>
