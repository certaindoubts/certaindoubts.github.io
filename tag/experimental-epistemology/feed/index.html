<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>experimental epistemology &#8211; </title>
	<atom:link href="http://certaindoubts.com/tag/experimental-epistemology/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 01:35:13 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>New empirical studies on epistemic contextualism</title>
		<link>http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/</link>
		<comments>http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/#comments</comments>
		<pubDate>Sun, 28 Feb 2016 18:26:42 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[contextualism]]></category>
		<category><![CDATA[general]]></category>
		<category><![CDATA[knowledge]]></category>
		<category><![CDATA[experimental epistemology]]></category>
		<category><![CDATA[methodology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4748</guid>
		<description><![CDATA[Epistemic contextualism is the view that the verb “know” is a context sensitive expression. As a first approximation, epistemic contextualism states that in order for us to truthfully say a person “knows” a proposition, that person must meet the standards &#8230; <a class="more-link" href="http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Epistemic contextualism is the view that the verb “know” is a context sensitive expression. As a first approximation, epistemic contextualism states that in order for us to truthfully say a person “knows” a proposition, that person must meet the standards set by our context and, critically, the standards change across contexts. The variation is thought to be theoretically important partly because it might indicate an ingredient of (the truth conditions of) &#8220;knowledge&#8221; statements beyond the traditional factors of belief, evidence, and truth.</p>
<p>Contextualists motivate their view based on a set of empirical claims about competent speakers’ linguistic behavior in certain situations. A famous way of illustrating the idea involves a pair of cases about a man who wants to deposit a check and is deciding whether to wait in a long line at the bank on a Friday afternoon, or come back on Saturday morning when the line would be short. But the question arises: is this bank actually open Saturday morning? The man visited this bank two Saturdays ago and it was open then, but banks do sometimes change their hours. In the “low stakes” version of the case, nothing serious hinges on whether he deposits the check before the weekend is over, and the man says, “I know that the bank is open tomorrow.” In the “high stakes” version of the case, something very serious hinges on whether he deposits the check before the weekend is over, and the man says, “I don’t know that the bank is open tomorrow.”</p>
<p>Contextualists claim that competent speakers will judge that the man truthfully says he “knows” in the low stakes version, and that the man truthfully says he “doesn’t know” in the high stakes version.</p>
<p>Do people behave as contextualists predict? Prior research on this empirical question has yielded mixed results. Taking into account methodological objections raised by contextualists,* I ran another series of studies to investigate the issue.** I found that, <strong><span style="color: #0000ff">just as contextualists predicted</span></strong>, people judged that the man truthfully says he “knows” in the low stakes case, and that the man truthfully says he “doesn’t know” in the high-stakes case.<span id="more-4748"></span></p>
<p>&nbsp;</p>
<p>However, I also found two other things that make it very difficult to interpret this as evidence for contextualism.</p>
<p>On the one hand, there is <span style="color: #0000ff"><strong>the general shifting problem</strong></span>: switching from low to high stakes also significantly decreased belief attributions, the evaluation of the agent’s evidence, and people’s confidence that the bank was open tomorrow. Thus, the contextualist hypothesis is not needed to explain the observed pattern in knowledge judgments: it could easily be explained by changes in underlying judgments about belief, evidence, and truth. This confirms some suspicions voiced by some philosophers over the years (e.g. Kent Bach and Jennifer Nagel).</p>
<p>On the other hand, there is <strong><span style="color: #0000ff">the deferral confound</span></strong>. Even if nothing about stakes or error possibilities is mentioned, people tend to agree that the agent speaks truthfully when he says “I know,” and they also tend to agree when he says “I don’t know.” In short, people tend to defer to another person’s self-regarding knowledge statement. (Some evidence for this might also be gleaned from earlier work by Wesley Buckwalter and Nat Hansen &amp; Emmanuel Chemla.)*** Unfortunately, this low-level agreement bias has been obscured because contextualist test cases are multiply confounded.</p>
<p>To illustrate the deferral confound, consider a pair of cases I tested, which involve not a low/high manipulation but rather a yes/no manipulation:</p>
<p style="padding-left: 30px">(Yes/No) Keith and his wife Jane are driving home from work on Friday afternoon. They just received a check from a client, which Keith plans to deposit in their bank account. As they drive past the bank, they see that the lines inside are very long. Keith says, “I hate waiting in line. I’ll just come back tomorrow morning instead.” Jane asks, “Do you know that our bank is open tomorrow?” Keith answers, “It was two Saturdays ago that I went to our bank, and it was open. So, [yes, I do/no, I don’t] know that our bank is open tomorrow.”</p>
<p>People tended to agree with the agent in both cases. Thus manipulating stakes (low/high) is not needed to produce the basic pattern in knowledge judgments that contextualists have focused on. Moreover, a follow-up study revealed that when the deferral confound is removed, manipulating stakes does not produce the relevant pattern in knowledge judgments: instead, people tend to (meta-linguistically) attribute knowledge in both low and high stakes cases (i.e. they say that the man should say “I know” in order to speak truthfully).</p>
<p>Based on these findings — all of which were replicated across multiple cover stories — I conclude that the principal extant motivation for contextualism fails. Contextualists still owe us a distinguishing prediction of their view, something we would confidently expect only if contextualism were true, or which contextualism seems uniquely suited to explain. Absent that, contextualism is an idle hypothesis and we should not accept it.</p>
<p>Of course, it is consistent with these findings that such a prediction will be made and vindicated. That would be an interesting development! But, moving forward, hopefully the theoretical debate will not get too far out ahead of available evidence. The fact that experimental epistemology is now a firmly established and growing interdisciplinary field will likely help in this regard.</p>
<p>* DeRose, K. (2011). <a href="http://link.springer.com/article/10.1007%2Fs11098-011-9799-x?LI=true" target="_blank">Contextualism, contrastivism, and X-Phi surveys</a>. <em>Philosophical Studies</em>, 156(1), 81–110.</p>
<p>** Turri, J. (in press). <a href="http://john.turri.org/research/idle.pdf" target="_blank">Epistemic contextualism: an idle hypothesis</a>. <em>Australasian Journal of Philosophy</em>.</p>
<p>*** For discussion, see Buckwalter, W. (in press). Epistemic contextualism and linguistic behavior. In Ichikawa, J. J. (Ed.), <em>Handbook of Epistemic Contextualism</em>. Routledge.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/new-empirical-studies-on-epistemic-contextualism/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
		</item>
		<item>
		<title>What philosophers think might not be what you think they think</title>
		<link>http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/</link>
		<comments>http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/#comments</comments>
		<pubDate>Sun, 14 Feb 2016 04:13:24 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4738</guid>
		<description><![CDATA[Professional philosophers often appeal to patterns in ordinary thought and talk — “commonsense” — in order to support theories or assumptions. In recent years, the emerging interdisciplinary field of experimental epistemology has revealed many instances where commonsense epistemology has been &#8230; <a class="more-link" href="http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Professional philosophers often appeal to patterns in ordinary thought and talk — “commonsense” — in order to support theories or assumptions. In recent years, the emerging interdisciplinary field of experimental epistemology has revealed many instances where commonsense epistemology has been seriously mischaracterized. But even if professional philosophers misidentify what the folk think about knowledge, certainly they know what they themselves think about knowledge. Right?</p>
<p>Wrong.</p>
<p>In a fascinating <a href="http://link.springer.com/article/10.1007/s11098-016-0627-1">paper</a> forthcoming in <em>Philosophical Studies</em>, a pair of researchers tested ordinary people and professional philosophers (“experts”) on a range of cases.* A principal finding concerns knowledge attributions in cases where an agent sees an object that is surrounded by visually indistinguishable fakes.<span id="more-4738"></span></p>
<p>Here is one case they tested:</p>
<p style="padding-left: 30px">(Sculpture) The director of a sculpture museum is so impressed with recent improvements of hologram images that she decides to perform a secret test on the visitors of her museum. To this end, she orders hologram images that even art experts cannot visually distinguish from the real sculptures in her museum, and she replaces all but one of the sculptures by their hologram image. As the director had expected, no one realizes any difference between the hologram images and the real sculptures. One day, the world’s greatest Rodin expert is visiting her museum. The expert is standing in front of a famous marble sculpture by Rodin, which is the only real sculpture that is presently on display in the museum, and she thinks to herself: “I’m facing one of Rodin’s famous marble sculptures now.”</p>
<p>Participants rated their agreement with whether &#8220;the Rodin expert knows that the sculpture in front of her is one of Rodin’s famous marble sculptures.”</p>
<p>The case is structurally similar to the famous “fake barn” case. Textbooks and review articles tell us that there is “broad agreement” among experts that these aren’t cases of knowledge. And this verdict is often treated as a litmus test for theories of knowledge: if your view implies that there is knowledge in a “fake barn&#8221; case, this is often treated as a decisive refutation of your view. Accordingly, we would expect that most experts will deny that Sculpture is a case of knowledge.</p>
<p>But that’s not what the researchers found. Instead, a majority of experts <em>attributed</em> knowledge. Surprised, the researchers tested the case again on another group of experts. And, just for good measure, they tested another case with a “fake barn” structure too. Perhaps the initial result was a fluke?</p>
<p>It wasn’t.</p>
<p>Again and again, most experts attributed knowledge. Ongoing work by another team of researchers has returned broadly similar results.**</p>
<p>The researchers also found that in a case structurally similar to a “lottery case,” the majority of experts attributed knowledge, which again contradicts “the textbook consensus.”</p>
<p>Based on these findings, the researchers concluded that “the discipline of epistemology is dysfunctional insofar” as it is “deluded about” its practitioners&#8217; verdicts about cases.</p>
<p>I’ve only covered some of the paper&#8217;s interesting findings. Check it out!</p>
<p>*Horvath, J., &amp; Wiegmann, A. (2016). Intuitive expertise and intuitions about knowledge. Philosophical Studies, 1–26. http://doi.org/10.1007/s11098-016-0627-1</p>
<p>**Carter, J. A., Pritchard, D., &amp; Sheperd, J. (ms). Knowledge-how, understanding-why and epistemic luck: an experimental study.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/what-philosophers-think-might-not-be-what-you-think-they-think/feed/</wfw:commentRss>
		<slash:comments>37</slash:comments>
		</item>
		<item>
		<title>Proto-reliabilism followup</title>
		<link>http://certaindoubts.com/proto-reliabilism-followup/</link>
		<comments>http://certaindoubts.com/proto-reliabilism-followup/#comments</comments>
		<pubDate>Sun, 24 Jan 2016 04:09:59 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[memory]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4722</guid>
		<description><![CDATA[Following up on some thoughtful suggestions in the comments to my previous post, I ran a couple follow-up studies with modified stimuli. One main question was whether people understood an &#8220;unreliable memory&#8221; to mean (1) most of the agent&#8217;s apparent memories contain false &#8230; <a class="more-link" href="http://certaindoubts.com/proto-reliabilism-followup/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Following up on some thoughtful suggestions in the comments to my <a href="http://certaindoubts.com/the-proto-reliabilist-hypothesis/">previous post</a>, I ran a couple follow-up studies with modified stimuli.<span id="more-4722"></span></p>
<p>One main question was whether people understood an &#8220;unreliable memory&#8221; to mean (1) most of the agent&#8217;s apparent memories contain false information, as opposed to (2) most of the agent apparent memories contain true information, even though the agent fails to retain information most of the time. If people understand &#8220;unreliable memory&#8221; in sense 2, then it could complicate the interpretation of one of the findings that undermine the proto-reliabilist hypothesis. Will we observe similar results if it&#8217;s made clearer that sense 1 is at issue?</p>
<p>To emphasize sense 1, I tested the following pair of cases (the reliability manipulation is bracketed):</p>
<p style="padding-left: 30px">Alvin is [unreliable/reliable] at remembering driving directions. Usually when it seems to him that he should make a particular turn, he’s [incorrect/correct]. Today Alvin is visiting a friend in an unfamiliar town. Alvin needs to pick up a prescription while he is there, so his friend gives him directions to the pharmacy. On the way, Alvin needs to turn right at Main Street. Alvin gets to Main Street and turns right, which is the correct turn.</p>
<p>People rated whether Alvin &#8220;knew&#8221; or &#8220;only thought&#8221; that &#8220;he needed to turn right at Main Street.&#8221; The rate of knowledge attribution was very high in both conditions: 83% in the unreliable condition and 97% in the reliable condition. This numerical difference did not reach statistical significance at the conventional .05 level  (N = 60, p = .098, v = .07). I then conducted a second follow-up with the same cases but a more sensitive 7-point scaled knowledge attribution. Mean knowledge attribution was again very high in both conditions: 6.13 in the unreliable condition and 5.71 in the reliable condition and the difference was not significant (N = 61, p = .290).</p>
<p>I believe that these results should make us more confident that knowledge ordinarily understood does not require reliability in sense 1. Of course, these results cannot show that there is no conceptual connection between reliability and knowledge, but the relationship does not appear to be (in the ballpark of) a necessary condition.</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilism-followups.png" rel="attachment wp-att-4723"><img class="alignnone wp-image-4723 size-full" src="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilism-followups-e1453607364487.png" alt="protoreliabilism-followups" width="500" height="360" /></a></p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/proto-reliabilism-followup/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>The proto-reliabilist hypothesis</title>
		<link>http://certaindoubts.com/the-proto-reliabilist-hypothesis/</link>
		<comments>http://certaindoubts.com/the-proto-reliabilist-hypothesis/#comments</comments>
		<pubDate>Thu, 21 Jan 2016 19:09:33 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4713</guid>
		<description><![CDATA[I conducted a simple study to determine whether knowledge, ordinarily understood, requires reliability.]]></description>
				<content:encoded><![CDATA[<p>In contemporary Anglo-American epistemology, it is very widely assumed that knowledge must be reliably produced. On this view, knowledge must be produced by abilities (processes, faculties, powers, etc.) that “will or would yield mostly true beliefs,” as William Alston put it. Call this consensus view “knowledge reliabilism.”</p>
<p>One thing I’ve always been surprised by is how little explicit, direct argumentation there is for knowledge reliabilism in the literature. An old paper by Goldman contains a weak explanatory argument, which gets cited sometimes. Aside from that, the main consideration offered in support of knowledge reliabilism is that it’s just commonsense. For instance, Edward Craig claims that reliabilism “matches our everyday practice with the concept of knowledge as actually found,” that it is “a good fit to the intuitive extension of ‘know’.” And Ernest Sosa claims that reliabilism is the theoretical “correlate” of “commonsense” epistemology. Call this “the proto-reliabilist hypothesis” about folk epistemology.</p>
<p>The proto-reliabilist hypothesis makes at least a couple straightforward predictions. First, people will tend to deny knowledge in cases of unreliably formed belief. Second, clear and explicit differences in reliability should produce large differences in people’s willingness to attribute knowledge. These predictions can be tested with some very simple experiments. Below I briefly describe one I ran.<span id="more-4713"></span></p>
<p>Participants read a brief story about Alvin. While visiting a friend in an unfamiliar town, Alvin needs to pick up a prescription. He’s on his way to the pharmacy and approaches an intersection where he needs to turn right. Some crucial details of the story differed across conditions. I manipulated whether Alvin was very unreliable or very reliable at remembering driving directions. I also manipulated whether he made the incorrect or correct turn at the intersection. Here is the text participants read, with the two manipulations noted in brackets:</p>
<p style="padding-left: 30px">Alvin is very [unreliable/reliable] at remembering driving directions. Today he is visiting a friend in an unfamiliar town. Alvin needs to pick up a prescription while he is there, so his friend gives him directions to the pharmacy. On the way, Alvin needs to make a [left/right] turn at an intersection. Alvin gets to the intersection and turns right.</p>
<p>Participants then responded to an open knowledge probe:</p>
<p style="padding-left: 30px">When he got to the intersection, Alvin _____ that he should turn right to get to the pharmacy.</p>
<p>The options were “knew” and “only thought.” Here are the results:</p>
<p><a href="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm.jpg" rel="attachment wp-att-4717"><img class="alignnone size-full wp-image-4717" src="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm.jpg" alt="protoreliabilsm" width="1004" height="710" srcset="http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm.jpg 1004w, http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm-300x212.jpg 300w, http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm-768x543.jpg 768w, http://certaindoubts.com/wp-content/uploads/2016/01/protoreliabilsm-424x300.jpg 424w" sizes="(max-width: 1004px) 100vw, 1004px" /></a></p>
<p>&nbsp;</p>
<p>The results from the two conditions where Alvin makes the incorrect turn (the &#8220;false&#8221; conditions) were exactly as you would expect: he thinks he should turn left, so people overwhelmingly denied that he knows he should turn right. But the results from the two conditions where Alvin makes the correct turn (the &#8220;true&#8221; conditions) were very different from what the proto-reliabilist hypothesis predicts. When Alvin made the correct turn, people attributed knowledge at similarly high rates, regardless of whether he was very reliable or very unreliable at remembering driving directions (80% vs. 77%).</p>
<p>This same basic pair of findings — high rates of knowledge attribution for beliefs produced by unreliable abilities, and little to no effect of reliability/unreliability on knowledge attributions — replicates across different narrative contexts, cognitive abilities, and ways of measuring knowledge attributions.</p>
<p>Overall, this leads me to conclude that the proto-reliabilist hypothesis is false. Knowledge ordinarily understood does not require reliability.</p>
<p>(A fuller description of these findings and other studies can be found in a <a href="http://john.turri.org/research/paradigm.pdf" target="_blank">paper</a> forthcoming in Ergo.)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/the-proto-reliabilist-hypothesis/feed/</wfw:commentRss>
		<slash:comments>15</slash:comments>
		</item>
		<item>
		<title>Truth-insensitive epistemology: radical or commonsense?</title>
		<link>http://certaindoubts.com/truth-insensitive-epistemology-radical-or-commonsense/</link>
		<comments>http://certaindoubts.com/truth-insensitive-epistemology-radical-or-commonsense/#comments</comments>
		<pubDate>Sat, 13 Jun 2015 20:13:06 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[internalism and externalism]]></category>
		<category><![CDATA[justification]]></category>
		<category><![CDATA[experimental epistemology]]></category>
		<category><![CDATA[experimental philosophy]]></category>
		<category><![CDATA[folk epistemology]]></category>
		<category><![CDATA[internalism]]></category>
		<category><![CDATA[issues in the profession]]></category>
		<category><![CDATA[thought experiments]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4625</guid>
		<description><![CDATA[Many philosophers endorse a truth-insensitivity hypothesis: certain core, philosophically important evaluative properties of a belief are insensitive to whether it is true. For example, if two possible agents believe the same proposition for the same reason, then either both are &#8230; <a class="more-link" href="http://certaindoubts.com/truth-insensitive-epistemology-radical-or-commonsense/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Many philosophers endorse a <em>truth-insensitivity hypothesis</em>: certain core, philosophically important evaluative properties of a belief are insensitive to whether it is true. For example, if two possible agents believe the same proposition for the same reason, then either both are justified or neither is. This does not change if it turns out that only one of the two agents has a true belief. Epitomizing this line of thought are thought experiments about radically deceived “brains in vats.”</p>
<p>Proponents claim that the truth-insensitivity hypothesis is extremely intuitive and appealing pre-theoretically — we have an “overpowering inclination” to think that it’s true (Richard Fumerton). To deny the truth-insensitivity hypothesis has been labelled “extraordinary” and “dissident” (Earl Conee). However, other philosophers claim that exactly the opposite is true: the truth-insensitivity hypothesis itself is counterintuitive and violates commonsense. The appeal of truth-insensitive epistemology, they claim, is limited to narrow circles within “the professional philosophical community” (Jonathan Sutton).</p>
<p>In a <a href="http://john.turri.org/research/radicalism.pdf" target="_blank">paper</a> forthcoming in <em>Philosophy and Phenomenological Research</em>, I investigated which side of this debate is correct. Proponents of the truth-insensitivity hypothesis illustrate their view’s plausibility with pairs of thought experiments. These pairs include mundane cases and fanciful “brain-in-a-vat” scenarios. I tested both sorts of cases.</p>
<p>Across three experiments (N = 1262), the results were absolutely clear:<span id="more-4625"></span></p>
<p>Ordinary evaluations of belief were <strong>deeply truth-sensitive</strong>. There was a consistent pattern whereby belief and evidence were judged much more favorably when the proposition in question was true rather than false. This was true across multiple narrative contexts and for evaluations elicited with a wide range of normative vocabulary (e.g. justification, evidence, rationality, reasonableness, responsibility, and what an agent should believe). It was true when people judged the pairs of cases separately (between-subjects) and when they judged the cases simultaneously (within-subjects). The basic finding appears to be very robust.</p>
<p>I find it fascinating that commonsense cuts so strongly against truth-insensitivity. I also find it somewhat disconcerting in light of the way introductory texts tend to treat the matter. For instance, how many epistemology students in recent decades have had their own judgments marginalized or contradicted by what “we” find intuitively compelling, and to what effect? That seems like a question researchers in the field should take seriously.</p>
<p>(<em>x-posted at the x-blog</em>)</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/truth-insensitive-epistemology-radical-or-commonsense/feed/</wfw:commentRss>
		<slash:comments>19</slash:comments>
		</item>
		<item>
		<title>The final nail</title>
		<link>http://certaindoubts.com/the-final-nail/</link>
		<comments>http://certaindoubts.com/the-final-nail/#comments</comments>
		<pubDate>Sat, 06 Jul 2013 19:16:48 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[testimony and social epistemology]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=4077</guid>
		<description><![CDATA[Going back to at least G.E. Moore, philosophers have steadily built a strong case that the social practice of assertion is constituted by a knowledge norm: you should assert Q only if you know Q is true. As best I &#8230; <a class="more-link" href="http://certaindoubts.com/the-final-nail/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Going back to at least G.E. Moore, philosophers have steadily built a strong case that the social practice of assertion is constituted by a knowledge norm: you should assert Q only if you know Q is true. As best I can tell, this &#8220;knowledge account,&#8221; as it&#8217;s often called, is by now the best supported hypothesis in contemporary epistemology. It teaches us something deep and important about an absolutely central aspect of our lives as social beings. It&#8217;s a hard-won discovery that illustrates philosophy&#8217;s value, exemplifies genuine philosophical progress, and is something we as a discipline can be proud of.</p>
<p>Whenever I explain the knowledge account as part of a presentation or in conversation, the primary &#8212; indeed, pretty much the only &#8212; objection I hear is that it&#8217;s counterintuitive and, by way of illustration, purported counterexamples are adduced. The examples feature subjects who assert false but well justified beliefs. This is usually followed by the proposal that justified belief, not knowledge, is the norm of assertion. I&#8217;m also often told that this is the &#8220;ordinary&#8221; or &#8220;commonsense&#8221; view and that it&#8217;s a foible of epistemologists to place knowledge, or anything other factive state, into that role.</p>
<p>In a <span style="text-decoration: underline;color: #0000ff"><a href="http://john.turri.org/research/Truth_Test.pdf"><span style="color: #0000ff;text-decoration: underline">new paper to appear in <em>Cognition</em></span></a></span>, I report a series of experimental studies which strongly suggest that these objections and examples do not reflect the commonsense view. Instead, just the opposite seems to be true: the ordinary view is that we should <em>not</em> assert false claims, even ones extremely well supported by the evidence. By contrast, asserting well justified true claims is perfectly fine.</p>
<p>Interestingly, it turns out that resistance to a factive account of assertion&#8217;s norm is at least partly driven by a general psychological tendency that many people have to excuse blameless transgressions by (falsely) denying that any transgression has occurred.</p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/the-final-nail/feed/</wfw:commentRss>
		<slash:comments>29</slash:comments>
		</item>
		<item>
		<title>Testy Gettier</title>
		<link>http://certaindoubts.com/testy-gettier/</link>
		<pubDate>Thu, 02 Aug 2012 02:03:59 +0000</pubDate>
		<dc:creator><![CDATA[John Turri]]></dc:creator>
				<category><![CDATA[knowledge]]></category>
		<category><![CDATA[experimental epistemology]]></category>

		<guid isPermaLink="false">http://certaindoubts.com/?p=3653</guid>
		<description><![CDATA[Some of you might be interested in this paper. Title and abstract: A conspicuous art: putting Gettier to the test Professional philosophers say it’s obvious that a Gettier subject does not know. But experimental philosophers and psychologists have argued that &#8230; <a class="more-link" href="http://certaindoubts.com/testy-gettier/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Some of you might be interested in <a href="http://john.turri.org/research/TestyGettier.pdf">this paper</a>. Title and abstract:</p>
<blockquote>
<p lang="en-CA">A conspicuous art: putting Gettier to the test</p>
<p lang="en-CA">Professional philosophers say it’s obvious that a Gettier subject does not know. But experimental philosophers and psychologists have argued that laypeople and non-Westerners view Gettier subjects very differently, based on experiments where they ascribe knowledge to Gettier subjects at statistically significant rates. I argue that when effectively probed, laypeople and non-Westerners unambiguously agree that Gettier subjects do not know.</p>
</blockquote>
<p>Come on over to <a href="http://experimentalphilosophy.typepad.com/experimental_philosophy/2012/08/gettier-and-the-folk.html">the X-phi blog</a> to discuss. (Comments closed here.)</p>
]]></content:encoded>
			</item>
		<item>
		<title>Experimental Epistemology in NYC</title>
		<link>http://certaindoubts.com/experimental-epistemology-in-nyc/</link>
		<comments>http://certaindoubts.com/experimental-epistemology-in-nyc/#respond</comments>
		<pubDate>Fri, 14 Jan 2011 14:21:11 +0000</pubDate>
		<dc:creator><![CDATA[Mark Phelan]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[conferences]]></category>
		<category><![CDATA[experimental epistemology]]></category>
		<category><![CDATA[experimental philosophy]]></category>
		<category><![CDATA[talks]]></category>

		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=2378</guid>
		<description><![CDATA[I wanted to alert readers of this blog to upcoming experimental philosophy talks in New York City. Many of the talks this semester will be of interest to epistemologists, including our first two talks, Jonathan Schaffer&#8217;s, &#8220;Knowledge, Stakes, and Mistakes&#8221;, &#8230; <a class="more-link" href="http://certaindoubts.com/experimental-epistemology-in-nyc/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>I wanted to alert readers of this blog to upcoming experimental philosophy talks in New York City. Many of the talks this semester will be of interest to epistemologists, including our first two talks, Jonathan Schaffer&#8217;s, &#8220;Knowledge, Stakes, and Mistakes&#8221;, and Martin Peterson and Krist Vaesen&#8217;s, &#8220;Knowledge According to 654 Philosophers&#8221;, to be delivered on January 28th. You can learn about these talks, as well as the whole schedule of talks for the Metro Experimental Research Group, at http://www.yale.edu/cogsci/mergcalendar.htm.</p>
<p>Also, we&#8217;ll be hosting an experimental philosophy conference on March 26th. The invited portion of this conference is on attributions of consciousness. But abstracts discussing experimental work on ANY TOPIC of philosophy are invited for the contributed portion of the conference. You can see our call for abstracts at: http://www.yale.edu/cogsci/conscxphi.htm</p>
<p>Any questions can be directed to me here, or by email at mark(dot)phelan(at)yale(dot)edu. </p>
]]></content:encoded>
			<wfw:commentRss>http://certaindoubts.com/experimental-epistemology-in-nyc/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
	</channel>
</rss>
