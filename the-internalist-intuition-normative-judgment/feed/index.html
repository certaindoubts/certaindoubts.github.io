<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: The Internalist Intuition &#038; Normative Judgment</title>
	<atom:link href="http://certaindoubts.com/the-internalist-intuition-normative-judgment/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/the-internalist-intuition-normative-judgment/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Chris Tucker</title>
		<link>http://certaindoubts.com/the-internalist-intuition-normative-judgment/#comment-8868</link>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
		<pubDate>Tue, 09 Jun 2009 21:43:17 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=1162#comment-8868</guid>
		<description><![CDATA[This reply is a bit late and perhaps of little interest to anyone, but here are a few more thoughts on the topic.

1. Thanks for the paper suggestion.  I’ve printed it out, but I haven’t read it yet.

2. Your application of Ex. 2.  I agree that it sounds bizarre to say “It is epistemically irrational to believe that it’s right for me to eat a stranger, but it’s right for me to eat a stranger.”  Yet the problem here seems entirely epistemic.  When one asserts “it’s right for me to eat a stranger,” they seem to express the belief that it is right for that person to eat a stranger.  But it is (epistemically) irrational to hold a belief when one regards that belief as irrational.  The intuitions, then, concerning your application of Ex. 2 are intuitions about epistemic statuses, not moral ones.

3.  Some Disconnects between Moral and Epistemic Value.  I agree that it seems weird to talk about being morally justified in believing something.  Suppose that being morally justified can’t be properly ascribed to beliefs.  We have found a relevant difference between epistemic and moral justification, because epistemic justification clearly applies to beliefs.  I’m also inclined to think that it is far more plausible that the “ought implies can” principle applies to moral justification than it does for epistemic justification.  Suppose a subject’s evidence strongly supports P.  Due to malfunction the subject is determined to believe ~P in light of that evidence.  The subject can’t believe P, but he epistemically should have, i.e. he had epistemic justification to do so.  I submit, then, that our intuitions concerning moral and epistemic justification may suggest some deep differences between the two kinds of normative status.  We shouldn’t assume by default that moral and epistemic normativity are parallel in every/most respects. 

4. If I had to make moral and epistemic normativity parallel, I might endorse the following view (which may take back some things I said previously):
   E1:   You are epistemically justified in believing P only if it isn’t irrational to believe P.
   M1:  You are morally justified in doing A only if it isn’t irrational to do A.
However, I also would be careful to say the following.
   E2:  A belief can be blameworthy even if it is epistemically justified.
   M2: An action can be blameworthy even if it is morally justified.
Blamelessness and justification will come apart when my perspective justifies me in believing something, and I only have my perspective due to some forgotten past sin.  I’d also say that:
   E3: Epistemic justification is not sufficient for warrant.
   M3: Moral justification is not sufficient for moral rightness.
Is this the sort of thing you were trying to push me toward at the end of your first reply to me?

5. Based on your clarification in the first reply, I think I misunderstood your cannibal case.  Sorry about that.]]></description>
		<content:encoded><![CDATA[<p>This reply is a bit late and perhaps of little interest to anyone, but here are a few more thoughts on the topic.</p>
<p>1. Thanks for the paper suggestion.  I’ve printed it out, but I haven’t read it yet.</p>
<p>2. Your application of Ex. 2.  I agree that it sounds bizarre to say “It is epistemically irrational to believe that it’s right for me to eat a stranger, but it’s right for me to eat a stranger.”  Yet the problem here seems entirely epistemic.  When one asserts “it’s right for me to eat a stranger,” they seem to express the belief that it is right for that person to eat a stranger.  But it is (epistemically) irrational to hold a belief when one regards that belief as irrational.  The intuitions, then, concerning your application of Ex. 2 are intuitions about epistemic statuses, not moral ones.</p>
<p>3.  Some Disconnects between Moral and Epistemic Value.  I agree that it seems weird to talk about being morally justified in believing something.  Suppose that being morally justified can’t be properly ascribed to beliefs.  We have found a relevant difference between epistemic and moral justification, because epistemic justification clearly applies to beliefs.  I’m also inclined to think that it is far more plausible that the “ought implies can” principle applies to moral justification than it does for epistemic justification.  Suppose a subject’s evidence strongly supports P.  Due to malfunction the subject is determined to believe ~P in light of that evidence.  The subject can’t believe P, but he epistemically should have, i.e. he had epistemic justification to do so.  I submit, then, that our intuitions concerning moral and epistemic justification may suggest some deep differences between the two kinds of normative status.  We shouldn’t assume by default that moral and epistemic normativity are parallel in every/most respects. </p>
<p>4. If I had to make moral and epistemic normativity parallel, I might endorse the following view (which may take back some things I said previously):<br />
   E1:   You are epistemically justified in believing P only if it isn’t irrational to believe P.<br />
   M1:  You are morally justified in doing A only if it isn’t irrational to do A.<br />
However, I also would be careful to say the following.<br />
   E2:  A belief can be blameworthy even if it is epistemically justified.<br />
   M2: An action can be blameworthy even if it is morally justified.<br />
Blamelessness and justification will come apart when my perspective justifies me in believing something, and I only have my perspective due to some forgotten past sin.  I’d also say that:<br />
   E3: Epistemic justification is not sufficient for warrant.<br />
   M3: Moral justification is not sufficient for moral rightness.<br />
Is this the sort of thing you were trying to push me toward at the end of your first reply to me?</p>
<p>5. Based on your clarification in the first reply, I think I misunderstood your cannibal case.  Sorry about that.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Clayton</title>
		<link>http://certaindoubts.com/the-internalist-intuition-normative-judgment/#comment-8854</link>
		<dc:creator><![CDATA[Clayton]]></dc:creator>
		<pubDate>Tue, 02 Jun 2009 18:35:08 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=1162#comment-8854</guid>
		<description><![CDATA[Hey Chris,

There&#039;s an argument in for the claim that what there&#039;s reason to do and believe is determined by your perspective in Gibbons&#039; &quot;Things that make things reasonable&quot; (&lt;a href=&quot;http://www.unl.edu/philosop/people/faculty/gibbons/ThingsMakeReasonable.pdf&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;) that proceeds from the assumption that it can&#039;t be that you ought to do/believe what you&#039;d be irrational to do/believe.  He&#039;s not committed to (PC), but he&#039;s sympathetic to something more in the neighborhood of (KD).  (There might also be similar moves made by Fantl and McGrath in their new book, but I need to double check that.)

Both Huemer and Silins seem sympathetic to the idea that it can&#039;t be that the attitude you ought to take (believe, disbelieve, suspend judgment) is one that is deeply irrational for you to take.  You&#039;re right that neither of them seem to make the general assumption that &quot;the thing you ought to do can never be the thing that you’d be deeply irrational to judge that you ought to do&quot; because they don&#039;t discuss action.  Here&#039;s Huemer on p. 151 of his APQ article: 

&lt;i&gt;The preceding argument suggests that a natural characterization of the central intuition of internalism about justification.  It is that there cannot be a pair of cases in which everything seems the same in all epistemically relevant respects, and yet the subject ought, rationally, to take different doxastic attitudes in the two cases--for instance, to affirm a proposition and in the other to withhold.&lt;/i&gt;

It would be odd to think that this assumption (i.e., that there can be epistemic obligations that you&#039;d be irrational to believe in) is one we should accept without argument unless there&#039;s something about the relationship between rationality and obligation generally that Huemer thinks we can all appreciate.  (As Gibbons puts it, if there are these differences between theoretical and practical rationality we&#039;d want some explanation as to why such differences arise.  The similarities have built in explanations since when we&#039;re talking about practical and theoretical rationality, reasons, and oughts we&#039;re talking about rationality, reasons, and oughts.)  

At any rate, I think you can undermine the rationale for a view by showing that the view can be defended only by saying things that are deeply implausible or seemingly ad hoc (e.g., that while you can never be obliged to have irrational doxastic attitudes you can nevertheless be obliged to perform irrational actions without changing your attitudes).  Anyone who holds such a view has to explain why it seems that those who believe they must A but don&#039;t A aren&#039;t as they ought to be while maintaining that there&#039;s no reason for them not to be this way.

Your examples are interesting, I&#039;m not quite sure what to say about Ex. 2.  I suspect that&#039;s because I&#039;m not entirely sure I buy the idea of beliefs that are or aren&#039;t morally justified.  (Are there non-instrumental reasons to refrain from believing on moral grounds? I can&#039;t think of any.)  Suppose I&#039;m wrong.  Here&#039;s an account of morally unjustified beliefs:  

MJ: A belief is morally unjustified when the belief tells you to do something wrong.  

Then Ex. 2 would come to something like this: It is epistemically irrational to believe that it&#039;s right for me to eat a stranger but it&#039;s right for me to eat a stranger.  That seems as incoherent as Ex. 1.  Maybe there&#039;s something other than (MJ) that captures the idea of a morally unjustified belief.]]></description>
		<content:encoded><![CDATA[<p>Hey Chris,</p>
<p>There&#8217;s an argument in for the claim that what there&#8217;s reason to do and believe is determined by your perspective in Gibbons&#8217; &#8220;Things that make things reasonable&#8221; (<a href="http://www.unl.edu/philosop/people/faculty/gibbons/ThingsMakeReasonable.pdf" rel="nofollow">here</a>) that proceeds from the assumption that it can&#8217;t be that you ought to do/believe what you&#8217;d be irrational to do/believe.  He&#8217;s not committed to (PC), but he&#8217;s sympathetic to something more in the neighborhood of (KD).  (There might also be similar moves made by Fantl and McGrath in their new book, but I need to double check that.)</p>
<p>Both Huemer and Silins seem sympathetic to the idea that it can&#8217;t be that the attitude you ought to take (believe, disbelieve, suspend judgment) is one that is deeply irrational for you to take.  You&#8217;re right that neither of them seem to make the general assumption that &#8220;the thing you ought to do can never be the thing that you’d be deeply irrational to judge that you ought to do&#8221; because they don&#8217;t discuss action.  Here&#8217;s Huemer on p. 151 of his APQ article: </p>
<p><i>The preceding argument suggests that a natural characterization of the central intuition of internalism about justification.  It is that there cannot be a pair of cases in which everything seems the same in all epistemically relevant respects, and yet the subject ought, rationally, to take different doxastic attitudes in the two cases&#8211;for instance, to affirm a proposition and in the other to withhold.</i></p>
<p>It would be odd to think that this assumption (i.e., that there can be epistemic obligations that you&#8217;d be irrational to believe in) is one we should accept without argument unless there&#8217;s something about the relationship between rationality and obligation generally that Huemer thinks we can all appreciate.  (As Gibbons puts it, if there are these differences between theoretical and practical rationality we&#8217;d want some explanation as to why such differences arise.  The similarities have built in explanations since when we&#8217;re talking about practical and theoretical rationality, reasons, and oughts we&#8217;re talking about rationality, reasons, and oughts.)  </p>
<p>At any rate, I think you can undermine the rationale for a view by showing that the view can be defended only by saying things that are deeply implausible or seemingly ad hoc (e.g., that while you can never be obliged to have irrational doxastic attitudes you can nevertheless be obliged to perform irrational actions without changing your attitudes).  Anyone who holds such a view has to explain why it seems that those who believe they must A but don&#8217;t A aren&#8217;t as they ought to be while maintaining that there&#8217;s no reason for them not to be this way.</p>
<p>Your examples are interesting, I&#8217;m not quite sure what to say about Ex. 2.  I suspect that&#8217;s because I&#8217;m not entirely sure I buy the idea of beliefs that are or aren&#8217;t morally justified.  (Are there non-instrumental reasons to refrain from believing on moral grounds? I can&#8217;t think of any.)  Suppose I&#8217;m wrong.  Here&#8217;s an account of morally unjustified beliefs:  </p>
<p>MJ: A belief is morally unjustified when the belief tells you to do something wrong.  </p>
<p>Then Ex. 2 would come to something like this: It is epistemically irrational to believe that it&#8217;s right for me to eat a stranger but it&#8217;s right for me to eat a stranger.  That seems as incoherent as Ex. 1.  Maybe there&#8217;s something other than (MJ) that captures the idea of a morally unjustified belief.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Chris Tucker</title>
		<link>http://certaindoubts.com/the-internalist-intuition-normative-judgment/#comment-8853</link>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
		<pubDate>Tue, 02 Jun 2009 11:56:24 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=1162#comment-8853</guid>
		<description><![CDATA[Thanks for the thoughtful replies.  I&#039;ll try to respond to some of the other comments later, but here I&#039;ll focus on this point: &quot;Suppose that among the considerations that motivates (PC) is the though that the thing you ought to do can never be the thing that you’d be deeply irrational to judge that you ought to do. I worry that you’ve just undermined the rationale for (PC).&quot;

I&#039;m not sure, as stated, that anyone has accepted such a motivation for PC (if you have a reference, I&#039;d be interested).  Off the top of my head, Huemer&#039;s &quot;PC and Internalist Intuition&quot; (APQ?) paper says something similar, but I don&#039;t remember it being completely general in the way (I think) you suggest. In any case, one can motivate PC with a more restricted version of that claim.  Compare:

RR1: the thing you ought to do can never be the thing that you’d be deeply irrational to judge that you ought to do.

RR2: the doxastic attitutde that you are justified in taking can&#039;t be one that would be deeply irrational for you to take.

I think RR2 is enough to support PC in the way that you are imagining.  (I worry about the counterfactual element in RR2 causing problems with this formulation, but I&#039;ll ignore them.)  As far as I know, nothing I said ruled out RR2.  I confess that it does seem strange to me to say:

Ex 1: It is epistemically irrational for me to believe P, but I am epistemically justified in believing it anyway.

When we mix normative statuses, my intuitions are less clear.  For example, this sounds less weird to me:

Ex. 2: It is epistemically irrational for me to believe P, but I am morally justified in believing it anyway.

To the extent that Ex 2 sounds less weird to me than Ex 1, I find RR2 is more plausible than RR1.  Even supposing RR1 is true, I think that what I said was compatible with RR2 and that is enough to get the kind of motivation you are imagining.]]></description>
		<content:encoded><![CDATA[<p>Thanks for the thoughtful replies.  I&#8217;ll try to respond to some of the other comments later, but here I&#8217;ll focus on this point: &#8220;Suppose that among the considerations that motivates (PC) is the though that the thing you ought to do can never be the thing that you’d be deeply irrational to judge that you ought to do. I worry that you’ve just undermined the rationale for (PC).&#8221;</p>
<p>I&#8217;m not sure, as stated, that anyone has accepted such a motivation for PC (if you have a reference, I&#8217;d be interested).  Off the top of my head, Huemer&#8217;s &#8220;PC and Internalist Intuition&#8221; (APQ?) paper says something similar, but I don&#8217;t remember it being completely general in the way (I think) you suggest. In any case, one can motivate PC with a more restricted version of that claim.  Compare:</p>
<p>RR1: the thing you ought to do can never be the thing that you’d be deeply irrational to judge that you ought to do.</p>
<p>RR2: the doxastic attitutde that you are justified in taking can&#8217;t be one that would be deeply irrational for you to take.</p>
<p>I think RR2 is enough to support PC in the way that you are imagining.  (I worry about the counterfactual element in RR2 causing problems with this formulation, but I&#8217;ll ignore them.)  As far as I know, nothing I said ruled out RR2.  I confess that it does seem strange to me to say:</p>
<p>Ex 1: It is epistemically irrational for me to believe P, but I am epistemically justified in believing it anyway.</p>
<p>When we mix normative statuses, my intuitions are less clear.  For example, this sounds less weird to me:</p>
<p>Ex. 2: It is epistemically irrational for me to believe P, but I am morally justified in believing it anyway.</p>
<p>To the extent that Ex 2 sounds less weird to me than Ex 1, I find RR2 is more plausible than RR1.  Even supposing RR1 is true, I think that what I said was compatible with RR2 and that is enough to get the kind of motivation you are imagining.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Clayton</title>
		<link>http://certaindoubts.com/the-internalist-intuition-normative-judgment/#comment-8852</link>
		<dc:creator><![CDATA[Clayton]]></dc:creator>
		<pubDate>Mon, 01 Jun 2009 20:56:03 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=1162#comment-8852</guid>
		<description><![CDATA[Hey Chris,

Good questions and comments.  

I didn&#039;t spell out the details of the cannibal case, sorry about that.  I&#039;m thinking of morally right actions as actions that the agent is obligated or permitted to perform.  There&#039;s no moral reason _to_ eat the people, but in the absence of moral reasons to refrain from eating something (e.g., ice cream, strangers), I&#039;d classify the eating of something there&#039;s no reason not to eat as right.  As for the reasons to think he shouldn&#039;t eat the stranger, I&#039;ve basically stipulated that he&#039;s unaware of any.  All the reasons he can think of not to eat people stem from relations between him and these people that he doesn&#039;t stand in with respect to the stranger.  

Anyway, I&#039;m primarily interested in people&#039;s intuitions about the rationality of their moral judgments and whether we&#039;d want to go so far as to say that the cannibals and terrorists are justified in their moral judgments.  It seems we have one vote for justified and rational.

I&#039;m trying to stay out of the discussion of the correctness of these verdicts, but I think that for a few of the authors I have in mind they will have to take issue with something you said this: 

&lt;i&gt;The first possible explanation of your resistance is the ambiguity of “justified.” I feel no pull toward saying that her terrorist beliefs or actions would be morally justified. But I do feel pull toward saying her beliefs are epistemically justified (as long as she really has no defeaters for her terrorist beilefs). Believing and acting on P might violate moral norms without violating epistemic ones.&lt;/i&gt;

If I&#039;m reading you correctly, you think that when the terrorists judge that they should engage in acts of terrorism, the belief isn&#039;t one they necessarily ought to abandon but they ought to nevertheless refrain from doing what they believe they ought to do.  Suppose that they manage to do this.  They seem pretty deeply irrational.  Suppose that among the considerations that motivates (PC) is the though that the thing you ought to do can never be the thing that you&#039;d be deeply irrational to judge that you ought to do.  I worry that you&#039;ve just undermined the rationale for (PC).

Also, I&#039;d want to know why you&#039;d deny that the actions are justified.  It seems that if you do what you judge what you ought to do when your judgments about what you ought to do are themselves epistemically justified, you are at the very least blameless for acting in accordance with your normative judgment.  What&#039;s the difference between a justified action and a blameless action rationalized by justified mental states?  (Whatever your answer to that question is, I&#039;d wonder why we can&#039;t draw the same sort of distinction on the epistemic side and say that the attitudes of the terrorists and cannibals are similarly unjustified but have some other thing going for them, like rationality.)]]></description>
		<content:encoded><![CDATA[<p>Hey Chris,</p>
<p>Good questions and comments.  </p>
<p>I didn&#8217;t spell out the details of the cannibal case, sorry about that.  I&#8217;m thinking of morally right actions as actions that the agent is obligated or permitted to perform.  There&#8217;s no moral reason _to_ eat the people, but in the absence of moral reasons to refrain from eating something (e.g., ice cream, strangers), I&#8217;d classify the eating of something there&#8217;s no reason not to eat as right.  As for the reasons to think he shouldn&#8217;t eat the stranger, I&#8217;ve basically stipulated that he&#8217;s unaware of any.  All the reasons he can think of not to eat people stem from relations between him and these people that he doesn&#8217;t stand in with respect to the stranger.  </p>
<p>Anyway, I&#8217;m primarily interested in people&#8217;s intuitions about the rationality of their moral judgments and whether we&#8217;d want to go so far as to say that the cannibals and terrorists are justified in their moral judgments.  It seems we have one vote for justified and rational.</p>
<p>I&#8217;m trying to stay out of the discussion of the correctness of these verdicts, but I think that for a few of the authors I have in mind they will have to take issue with something you said this: </p>
<p><i>The first possible explanation of your resistance is the ambiguity of “justified.” I feel no pull toward saying that her terrorist beliefs or actions would be morally justified. But I do feel pull toward saying her beliefs are epistemically justified (as long as she really has no defeaters for her terrorist beilefs). Believing and acting on P might violate moral norms without violating epistemic ones.</i></p>
<p>If I&#8217;m reading you correctly, you think that when the terrorists judge that they should engage in acts of terrorism, the belief isn&#8217;t one they necessarily ought to abandon but they ought to nevertheless refrain from doing what they believe they ought to do.  Suppose that they manage to do this.  They seem pretty deeply irrational.  Suppose that among the considerations that motivates (PC) is the though that the thing you ought to do can never be the thing that you&#8217;d be deeply irrational to judge that you ought to do.  I worry that you&#8217;ve just undermined the rationale for (PC).</p>
<p>Also, I&#8217;d want to know why you&#8217;d deny that the actions are justified.  It seems that if you do what you judge what you ought to do when your judgments about what you ought to do are themselves epistemically justified, you are at the very least blameless for acting in accordance with your normative judgment.  What&#8217;s the difference between a justified action and a blameless action rationalized by justified mental states?  (Whatever your answer to that question is, I&#8217;d wonder why we can&#8217;t draw the same sort of distinction on the epistemic side and say that the attitudes of the terrorists and cannibals are similarly unjustified but have some other thing going for them, like rationality.)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Chris Tucker</title>
		<link>http://certaindoubts.com/the-internalist-intuition-normative-judgment/#comment-8851</link>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
		<pubDate>Mon, 01 Jun 2009 18:08:43 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=1162#comment-8851</guid>
		<description><![CDATA[The White (cannibal) case seems described in a way that both there is nothing going for White&#039;s belief that cannibalism is morally good and there are reasons for him to think that cannibalism is morally bad (&quot;agent relative reasons not to eat a stranger&quot;).  Hence, White seems neither rational nor justified in believing that cannibalism is morally permissible.  

I assume that the Peacock (terrorist) case was supposed to be such that Peacock had no mental states that counted against her terrorist beliefs.  If so, then I&#039;m inclined to allow that her terrorist beliefs can be epistemically justified.  You say &quot;you feel no pull toward&quot; that position.  I wonder whether either of the following two things explains your resistance to say they are justified.

The first possible explanation of your resistance is the ambiguity of &quot;justified.&quot;  I feel no pull toward saying that her terrorist beliefs or actions would be morally justified.  But I do feel pull toward saying her beliefs are epistemically justified (as long as she really has no defeaters for her terrorist beilefs). Believing and acting on P might violate moral norms without violating epistemic ones.

The second possible explanation is that we tend to find it hard to imagine that someone would have no reason to reject terrorist beliefs.  So it is hard for us to imagine Peacock as having no defeaters for her terrorist beliefs.  Hence, it is hard for us to imagine that her terrorist beliefs are justified.  

Maybe neither one of those two things explains your resistance.  In any case, I tend to think:
i) you can have justified belief in false contingent propositions.
ii) you can have justified belief in necessarily false propositions.
iii) you can have justified belief in necessarily false normative propositions (even moral ones).

If those three things are right, why wouldn&#039;t it be possible for someone to be epistemically justified in believing that some action is morally good when, unbeknownst to the subject, it is morally atrocious?]]></description>
		<content:encoded><![CDATA[<p>The White (cannibal) case seems described in a way that both there is nothing going for White&#8217;s belief that cannibalism is morally good and there are reasons for him to think that cannibalism is morally bad (&#8220;agent relative reasons not to eat a stranger&#8221;).  Hence, White seems neither rational nor justified in believing that cannibalism is morally permissible.  </p>
<p>I assume that the Peacock (terrorist) case was supposed to be such that Peacock had no mental states that counted against her terrorist beliefs.  If so, then I&#8217;m inclined to allow that her terrorist beliefs can be epistemically justified.  You say &#8220;you feel no pull toward&#8221; that position.  I wonder whether either of the following two things explains your resistance to say they are justified.</p>
<p>The first possible explanation of your resistance is the ambiguity of &#8220;justified.&#8221;  I feel no pull toward saying that her terrorist beliefs or actions would be morally justified.  But I do feel pull toward saying her beliefs are epistemically justified (as long as she really has no defeaters for her terrorist beilefs). Believing and acting on P might violate moral norms without violating epistemic ones.</p>
<p>The second possible explanation is that we tend to find it hard to imagine that someone would have no reason to reject terrorist beliefs.  So it is hard for us to imagine Peacock as having no defeaters for her terrorist beliefs.  Hence, it is hard for us to imagine that her terrorist beliefs are justified.  </p>
<p>Maybe neither one of those two things explains your resistance.  In any case, I tend to think:<br />
i) you can have justified belief in false contingent propositions.<br />
ii) you can have justified belief in necessarily false propositions.<br />
iii) you can have justified belief in necessarily false normative propositions (even moral ones).</p>
<p>If those three things are right, why wouldn&#8217;t it be possible for someone to be epistemically justified in believing that some action is morally good when, unbeknownst to the subject, it is morally atrocious?</p>
]]></content:encoded>
	</item>
</channel>
</rss>
