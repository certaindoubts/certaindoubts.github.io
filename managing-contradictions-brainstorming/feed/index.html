<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: managing contradictions &#8211; brainstorming</title>
	<atom:link href="http://certaindoubts.com/managing-contradictions-brainstorming/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/managing-contradictions-brainstorming/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: J.D.</title>
		<link>http://certaindoubts.com/managing-contradictions-brainstorming/#comment-7379</link>
		<dc:creator><![CDATA[J.D.]]></dc:creator>
		<pubDate>Sun, 03 Jun 2007 19:03:01 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=703#comment-7379</guid>
		<description><![CDATA[Well, this topic continues to be interesting but I am getting a bit confused now.  Let me make sure I am clear on the proposed situation. With respect to topic A, S is an expert and clearly sees if p then q.  With respect to topic B, S sees that p follows but disbelieves q, that is thinks ~q, and this creates a contradiction.  However, there is also the possibility that S could be wrong about q in topic B, but S realizes, or hopes, the matter will be resolved through consultation with an expert and additional information.  If all that has been said so far is correct, I would like to add a Peircean turn here and claim S does not in fact have an actual belief with respect to topic B, but is simply mired in doubt and in need of a resolution to an indeterminate situation.  Additionally, it seems to me topic B presupposes q must always have an independent relationship with p.  Why?  Any number of things can follow from p, and ~q does not necessarily have to represent a contradiction as much as it simply points out the absence of q in some given situation with respect to p.  Here&#039;s an example, though not as novel as I might like, which I think exemplifies the points.  I am curious to see if with a little sympathy this will go through.

S is an ambitious and dreamy young person who imagines himself saving the lives of other people in heroic scenarios.  In particular S is imaging what traits he may need to posses to prevent people from falling to their death.  He is envisioning those scenes in movies where the hero is holding a person who is dangling over the side of a building.  Now, S is thinking of two basic types of characteristics of hero&#039;s, which he takes to be strength and luck.  With respect to strength S believes, if he has a weak grip then person q will fall to their death.  With respect to luck S believes, if he has a weak grip then person q will not fall to their death.  The reason for S not thinking q will fall to their death with resect to luck is because he thinks that by being lucky there will be some type of awning beneath him which will prevent person q from falling to death.  But S does not know very much about physics and formal mathematics so he thinks that it is possible the awning will not prevent person q from falling to their death.  However, S has the opportunity to go and speak with a physics professor in a couple of days, and that individual can give him the information he needs.  After this occurs S comes to believe person q will indeed not fall to their death.

I will freely admit the example has a few weak points and some holes, but I think a little sympathy can patch those up fine so I will just leave things as they stand.  Here&#039;s how I think it breaks down.  Prior to speaking with the physics professor, S does not have an actual belief regarding the fate of person q, he merely thinks it is possible the awning can prevent the persons death.  But, I believe the presence of doubt prevents S&#039;s notion from attaining the status of belief.  Now, after S speaks with the professor, he is able to consecrate his thoughts about ~q into an actual belief and this creates a potential contradiction with the first scenario, where he clearly saw if p then q .  However, I do not think this is really a contradiction because what is actually taking place is not if p then ~q, but rather if p then (r and ~q).

Ultimately, what I am saying, is I cannot foresee a situation where a person believes if p then q follows from topic A, and then believes p follows from topic B, but has an actual belief in ~q while ~q is considered independent of any other statement in the same way q is considered in topic A.]]></description>
		<content:encoded><![CDATA[<p>Well, this topic continues to be interesting but I am getting a bit confused now.  Let me make sure I am clear on the proposed situation. With respect to topic A, S is an expert and clearly sees if p then q.  With respect to topic B, S sees that p follows but disbelieves q, that is thinks ~q, and this creates a contradiction.  However, there is also the possibility that S could be wrong about q in topic B, but S realizes, or hopes, the matter will be resolved through consultation with an expert and additional information.  If all that has been said so far is correct, I would like to add a Peircean turn here and claim S does not in fact have an actual belief with respect to topic B, but is simply mired in doubt and in need of a resolution to an indeterminate situation.  Additionally, it seems to me topic B presupposes q must always have an independent relationship with p.  Why?  Any number of things can follow from p, and ~q does not necessarily have to represent a contradiction as much as it simply points out the absence of q in some given situation with respect to p.  Here&#8217;s an example, though not as novel as I might like, which I think exemplifies the points.  I am curious to see if with a little sympathy this will go through.</p>
<p>S is an ambitious and dreamy young person who imagines himself saving the lives of other people in heroic scenarios.  In particular S is imaging what traits he may need to posses to prevent people from falling to their death.  He is envisioning those scenes in movies where the hero is holding a person who is dangling over the side of a building.  Now, S is thinking of two basic types of characteristics of hero&#8217;s, which he takes to be strength and luck.  With respect to strength S believes, if he has a weak grip then person q will fall to their death.  With respect to luck S believes, if he has a weak grip then person q will not fall to their death.  The reason for S not thinking q will fall to their death with resect to luck is because he thinks that by being lucky there will be some type of awning beneath him which will prevent person q from falling to death.  But S does not know very much about physics and formal mathematics so he thinks that it is possible the awning will not prevent person q from falling to their death.  However, S has the opportunity to go and speak with a physics professor in a couple of days, and that individual can give him the information he needs.  After this occurs S comes to believe person q will indeed not fall to their death.</p>
<p>I will freely admit the example has a few weak points and some holes, but I think a little sympathy can patch those up fine so I will just leave things as they stand.  Here&#8217;s how I think it breaks down.  Prior to speaking with the physics professor, S does not have an actual belief regarding the fate of person q, he merely thinks it is possible the awning can prevent the persons death.  But, I believe the presence of doubt prevents S&#8217;s notion from attaining the status of belief.  Now, after S speaks with the professor, he is able to consecrate his thoughts about ~q into an actual belief and this creates a potential contradiction with the first scenario, where he clearly saw if p then q .  However, I do not think this is really a contradiction because what is actually taking place is not if p then ~q, but rather if p then (r and ~q).</p>
<p>Ultimately, what I am saying, is I cannot foresee a situation where a person believes if p then q follows from topic A, and then believes p follows from topic B, but has an actual belief in ~q while ~q is considered independent of any other statement in the same way q is considered in topic A.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/managing-contradictions-brainstorming/#comment-7378</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Sun, 03 Jun 2007 12:48:21 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=703#comment-7378</guid>
		<description><![CDATA[I am very sympathetic to Adam&#039;s view that we shouldn&#039;t be blinkered by inconsistency. If you discover that you endorse (however you would like to cash out &#039;endorse&#039;) both p and not-p, this means that there isn&#039;t a (standard) model satisfying your endorsements. So what? This doesn&#039;t mean that you haven&#039;t good reason for endorsing both sides of p, nor does your discovery that you do license you to binge inferencing.

It is a fine strategy to put some modal distance between you and your inconsistent commitments w.r.t. p, but I don&#039;t know why we should worry whether this trick can always be pressed into play.

Logic, and probability for that matter, have very little to do with rational belief and reasoning, after all.]]></description>
		<content:encoded><![CDATA[<p>I am very sympathetic to Adam&#8217;s view that we shouldn&#8217;t be blinkered by inconsistency. If you discover that you endorse (however you would like to cash out &#8216;endorse&#8217;) both p and not-p, this means that there isn&#8217;t a (standard) model satisfying your endorsements. So what? This doesn&#8217;t mean that you haven&#8217;t good reason for endorsing both sides of p, nor does your discovery that you do license you to binge inferencing.</p>
<p>It is a fine strategy to put some modal distance between you and your inconsistent commitments w.r.t. p, but I don&#8217;t know why we should worry whether this trick can always be pressed into play.</p>
<p>Logic, and probability for that matter, have very little to do with rational belief and reasoning, after all.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Adam Morton</title>
		<link>http://certaindoubts.com/managing-contradictions-brainstorming/#comment-8672</link>
		<dc:creator><![CDATA[Adam Morton]]></dc:creator>
		<pubDate>Sun, 03 Jun 2007 01:01:32 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=703#comment-8672</guid>
		<description><![CDATA[A short reaction to the helpful comments.
   It is not hard to find examples where it makes sense to resist both the temptation to draw a simple conclusion and the temptation to clear up a contradiction.  You see that if p then q follows from what seems clear to you about topic  A, on which you are an expert, and that p follows from what seems right to you about confusing and novel topic B.  But you absolutely disbelieve q.  There is a temptation to derive q, see there is a contradiction with your prior belief, and clean it up by abandoning q, since you knew you were wobbly on B questions.  But: suppose you expect to be thinking about B day after tomorrow, or talking to an expert on it.  Then you should leave things as they are. When you know your way around B you may find out that p is definitely not something to abandon, or that implausible as q may be it is nothing like as implausible as not p.  (This is using what Gregory Wheel
   While waiting for things to get clearer, there may be a helpful strategy related to what Jonathan Kvanvig says.  Concentrate not on ironing out contradictions when belief is collapsed to a yes/no level, but on getting your degrees of belief to make sense. I suspect that probabilistic coherence is not exactly what we need, but some way of ranking conflicting possibilities so that one can guide action by them while waiting for a deeper resolution is clearly something to aim for.  More to think about here, in particular about what ways of massaging one&#039;s degrees of belief can leave open the questions one wants to resolve when one thinks more deeply or becomes better informed.
   Believing an outright contradiction is clearly a more dire situation than having beliefs that entail one another&#039;s negation. And of course the latter fix comes in degrees, depending on how much thinking is required to fill out the entailment.  (With possibilities of mistakes, hidden premises, and so on.) The essence of compartmentalisation is to prevent the latter turning into the former.  But, I suggest, there are some situations in which even an outright p&#038;~p is to be left in place. Contradictions are bearable when ambiguity, vagueness, or contextuality is in play. In a standard sort of case one is happy to think &quot;that is green -- for ripe/un-ripe berry classification-- and not green -- for definite/washed-out photo background choice.&quot;  Now suppose that you expect that there is some such clarification that will make the p&#038;~p your thinking is pushing you towards ok.  But you can&#039;t figure out what it is.  Mightn&#039;t you just leave it in place while you wait?  An obvious example for epistemologists turns on &quot;know&quot;.  I think that my daughter knows I am her father.  She has ample evidence, and it is true. But I also think that there are many mistakes of this kind -- it&#039;s a wise child .. -- and if she reflected on some of her friends&#039; situations doubts would pass through her mind. So she just thinks she knows. She knows and she doesn&#039;t. Easily resolved if we become contextualists, but there are reasons not to, and anyway there are so many contextualisms. Just as one can leave an inconsistent set of beliefs in place and lessen the crisis by finding a usable assignment of degrees of belief to them, one can leave a contradiction in place and as palliation describe the factors that suggest some semantic subtlety, even though you don&#039;t yet know what the subtlety is.]]></description>
		<content:encoded><![CDATA[<p>A short reaction to the helpful comments.<br />
   It is not hard to find examples where it makes sense to resist both the temptation to draw a simple conclusion and the temptation to clear up a contradiction.  You see that if p then q follows from what seems clear to you about topic  A, on which you are an expert, and that p follows from what seems right to you about confusing and novel topic B.  But you absolutely disbelieve q.  There is a temptation to derive q, see there is a contradiction with your prior belief, and clean it up by abandoning q, since you knew you were wobbly on B questions.  But: suppose you expect to be thinking about B day after tomorrow, or talking to an expert on it.  Then you should leave things as they are. When you know your way around B you may find out that p is definitely not something to abandon, or that implausible as q may be it is nothing like as implausible as not p.  (This is using what Gregory Wheel<br />
   While waiting for things to get clearer, there may be a helpful strategy related to what Jonathan Kvanvig says.  Concentrate not on ironing out contradictions when belief is collapsed to a yes/no level, but on getting your degrees of belief to make sense. I suspect that probabilistic coherence is not exactly what we need, but some way of ranking conflicting possibilities so that one can guide action by them while waiting for a deeper resolution is clearly something to aim for.  More to think about here, in particular about what ways of massaging one&#8217;s degrees of belief can leave open the questions one wants to resolve when one thinks more deeply or becomes better informed.<br />
   Believing an outright contradiction is clearly a more dire situation than having beliefs that entail one another&#8217;s negation. And of course the latter fix comes in degrees, depending on how much thinking is required to fill out the entailment.  (With possibilities of mistakes, hidden premises, and so on.) The essence of compartmentalisation is to prevent the latter turning into the former.  But, I suggest, there are some situations in which even an outright p&amp;~p is to be left in place. Contradictions are bearable when ambiguity, vagueness, or contextuality is in play. In a standard sort of case one is happy to think &#8220;that is green &#8212; for ripe/un-ripe berry classification&#8211; and not green &#8212; for definite/washed-out photo background choice.&#8221;  Now suppose that you expect that there is some such clarification that will make the p&amp;~p your thinking is pushing you towards ok.  But you can&#8217;t figure out what it is.  Mightn&#8217;t you just leave it in place while you wait?  An obvious example for epistemologists turns on &#8220;know&#8221;.  I think that my daughter knows I am her father.  She has ample evidence, and it is true. But I also think that there are many mistakes of this kind &#8212; it&#8217;s a wise child .. &#8212; and if she reflected on some of her friends&#8217; situations doubts would pass through her mind. So she just thinks she knows. She knows and she doesn&#8217;t. Easily resolved if we become contextualists, but there are reasons not to, and anyway there are so many contextualisms. Just as one can leave an inconsistent set of beliefs in place and lessen the crisis by finding a usable assignment of degrees of belief to them, one can leave a contradiction in place and as palliation describe the factors that suggest some semantic subtlety, even though you don&#8217;t yet know what the subtlety is.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/managing-contradictions-brainstorming/#comment-7377</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Fri, 01 Jun 2007 14:32:59 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=703#comment-7377</guid>
		<description><![CDATA[Adam it may also be useful to consider which norm one is considering to be under attack by logical difficulties in a system of belief.  Do the envisioned norms under attack counsel against sets of beliefs from which a contradiction can be derived?  Or against believing p while at the same time believing ~p?  Or against believing (p &#038; ~p)?

If we begin by controlling for additional elements in belief (e.g., modes of presentation to address examples like the Kripke puzzle and more standard cases such as Cicero/Tully cases), epistemologists typically begin from the latter point and try to work toward the former views.  Foley, for example, thinks the latter two norms are true (no justified self-contradictions and no justified contradictory beliefs) but disagrees with the former (no justified inconsistent beliefs).  I think it is an interesting question whether the two he endorses stand or fall together.  I&#039;m inclined to agree that there can&#039;t be justified self-contradictions, but I&#039;m unconvinced that there can&#039;t be cases where one is justified in believing p while at the same time being justified in believing ~p (still assuming sameness of mode of presentation).  The only arguments I have seen and can imagine assume the principle from the outset, or commit one to the impossibility of justified inconsistent beliefs.  So maybe the only defensible norm is the one about no justified self-contradictions.      To defend that norm, more has to be said about the effects of rational endorsement of dialetheism than has been said to this point, but I&#039;ll ignore that issue here!]]></description>
		<content:encoded><![CDATA[<p>Adam it may also be useful to consider which norm one is considering to be under attack by logical difficulties in a system of belief.  Do the envisioned norms under attack counsel against sets of beliefs from which a contradiction can be derived?  Or against believing p while at the same time believing ~p?  Or against believing (p &amp; ~p)?</p>
<p>If we begin by controlling for additional elements in belief (e.g., modes of presentation to address examples like the Kripke puzzle and more standard cases such as Cicero/Tully cases), epistemologists typically begin from the latter point and try to work toward the former views.  Foley, for example, thinks the latter two norms are true (no justified self-contradictions and no justified contradictory beliefs) but disagrees with the former (no justified inconsistent beliefs).  I think it is an interesting question whether the two he endorses stand or fall together.  I&#8217;m inclined to agree that there can&#8217;t be justified self-contradictions, but I&#8217;m unconvinced that there can&#8217;t be cases where one is justified in believing p while at the same time being justified in believing ~p (still assuming sameness of mode of presentation).  The only arguments I have seen and can imagine assume the principle from the outset, or commit one to the impossibility of justified inconsistent beliefs.  So maybe the only defensible norm is the one about no justified self-contradictions.      To defend that norm, more has to be said about the effects of rational endorsement of dialetheism than has been said to this point, but I&#8217;ll ignore that issue here!</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: kvanvig</title>
		<link>http://certaindoubts.com/managing-contradictions-brainstorming/#comment-7376</link>
		<dc:creator><![CDATA[kvanvig]]></dc:creator>
		<pubDate>Wed, 30 May 2007 11:48:48 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=703#comment-7376</guid>
		<description><![CDATA[Hi Adam, I find the idea here of comparing rational inconsistent belief to rational disagreement quite interesting.  One cost of doing so, though, is that it makes the notion of defeat quite messy, especially the notion of a rebutting defeater.  Or maybe it is in tension with this principle:  evidence for p is evidence against ~p.]]></description>
		<content:encoded><![CDATA[<p>Hi Adam, I find the idea here of comparing rational inconsistent belief to rational disagreement quite interesting.  One cost of doing so, though, is that it makes the notion of defeat quite messy, especially the notion of a rebutting defeater.  Or maybe it is in tension with this principle:  evidence for p is evidence against ~p.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/managing-contradictions-brainstorming/#comment-7375</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Tue, 29 May 2007 15:31:41 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=703#comment-7375</guid>
		<description><![CDATA[There is one line of thought about inconsistency and reasonable belief which holds that inconsistency is informative and (potentially) an opportunity to improve one&#039;s epistemic position, rather than a cause for despair or a sign of irrationality.

van Benthem has expressed this view, for instance, but the idea is implicit in any theory of belief revision that includes a contraction principle. Or, more generally, any cognitive agent that can learn. My colleague Reinhard Kahle has worked on &lt;i&gt; syntactic&lt;/i&gt; belief revision operators, for instance, which address some of the options you mention in your post. &quot;Structured belief bases&quot; is what he calls them, I believe.

The common idea behind these strategies is that inconsistency represents an opportunity to the agent for him to learn something new, about his own beliefs, about the source of the information, about the content of the message, about his own priorities,... rather signal a crisis in rationality that must be attended to immediately. And inconsistent input is an &lt;i&gt;opportunity&lt;/i&gt; rather than a cause of forced resolution, for reasons you mention. It might be more important to finish eating lunch than attend to one&#039;s inconsistent beliefs, for instance.]]></description>
		<content:encoded><![CDATA[<p>There is one line of thought about inconsistency and reasonable belief which holds that inconsistency is informative and (potentially) an opportunity to improve one&#8217;s epistemic position, rather than a cause for despair or a sign of irrationality.</p>
<p>van Benthem has expressed this view, for instance, but the idea is implicit in any theory of belief revision that includes a contraction principle. Or, more generally, any cognitive agent that can learn. My colleague Reinhard Kahle has worked on <i> syntactic</i> belief revision operators, for instance, which address some of the options you mention in your post. &#8220;Structured belief bases&#8221; is what he calls them, I believe.</p>
<p>The common idea behind these strategies is that inconsistency represents an opportunity to the agent for him to learn something new, about his own beliefs, about the source of the information, about the content of the message, about his own priorities,&#8230; rather signal a crisis in rationality that must be attended to immediately. And inconsistent input is an <i>opportunity</i> rather than a cause of forced resolution, for reasons you mention. It might be more important to finish eating lunch than attend to one&#8217;s inconsistent beliefs, for instance.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: J.D.</title>
		<link>http://certaindoubts.com/managing-contradictions-brainstorming/#comment-7374</link>
		<dc:creator><![CDATA[J.D.]]></dc:creator>
		<pubDate>Tue, 29 May 2007 06:03:46 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=703#comment-7374</guid>
		<description><![CDATA[This is a very interesting topic, and though I am not positive this will be helpful, I would like to partake in the discussion (if you can&#039;t tell already I am a virgin blog participator).
What I found to be most intriguing on my initial reading of your post was the realization or the &quot;pressure to q&quot; in (4).  It seems to me that person S has a certain epistemic responsibility to acknowledge the relevance of the relationship they have come to understand between p and q (in this case p -&#062; q).  Is what you mean by &quot;pressure&quot; that S now has an intuition or at least good evidence to believe if p then q?  If that is the case, I do not think a person would be legitimate in withdrawing the belief, or even not allowing the interference of the X and Y beliefs if that means ignoring the consequences of either X or Y.  Do you have an example of how a &quot;pressure to q&quot;, that is an awareness of the plausibility of if p then q might lead to a profitable fragmentation?

On a side note: I agree wholeheartedly that people can agree to disagree as you I said about Z in (5); especially with respect to perceptual beliefs like color recognition or tastes.]]></description>
		<content:encoded><![CDATA[<p>This is a very interesting topic, and though I am not positive this will be helpful, I would like to partake in the discussion (if you can&#8217;t tell already I am a virgin blog participator).<br />
What I found to be most intriguing on my initial reading of your post was the realization or the &#8220;pressure to q&#8221; in (4).  It seems to me that person S has a certain epistemic responsibility to acknowledge the relevance of the relationship they have come to understand between p and q (in this case p -&gt; q).  Is what you mean by &#8220;pressure&#8221; that S now has an intuition or at least good evidence to believe if p then q?  If that is the case, I do not think a person would be legitimate in withdrawing the belief, or even not allowing the interference of the X and Y beliefs if that means ignoring the consequences of either X or Y.  Do you have an example of how a &#8220;pressure to q&#8221;, that is an awareness of the plausibility of if p then q might lead to a profitable fragmentation?</p>
<p>On a side note: I agree wholeheartedly that people can agree to disagree as you I said about Z in (5); especially with respect to perceptual beliefs like color recognition or tastes.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
