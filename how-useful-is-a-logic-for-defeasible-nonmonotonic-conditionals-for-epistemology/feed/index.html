<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: How useful is a logic for Defeasible / Nonmonotonic Conditionals for Epistemology?</title>
	<atom:link href="http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Jim Hawthorne</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comment-1410</link>
		<dc:creator><![CDATA[Jim Hawthorne]]></dc:creator>
		<pubDate>Sun, 20 Feb 2005 20:27:49 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259#comment-1410</guid>
		<description><![CDATA[Andy,

Good questions!!! You make me realize I didn&#039;t say enough about how these axioms (and the conditionals in R more generally) are often supposed to be &quot;applied&quot;. So here is one such account (though not the only possible account) of how these conditionals are supposed to function in an agent&#039;s doxastic economy.

The usual idea is that the agent has a &quot;belief base&quot; (what artificial intelligence researchers often call a &quot;knowledge base&quot;). Let&#039;s call it &#039;K&#039;. The beliefs represented in K (as statements) are some sort of &quot;more basic beliefs&quot; on the basis of which other beliefs are supposed to be inferred. The agent is then supposed to employ some conditional -- for our purposes, a conditional that satisfies the rules of R -- for defeasibly inferring (or updating to) additional beliefs based on her belief basis K. There may be many possible such conditionals, just as Bayesian agents, for example, are supposed to have available a number of possible &quot;degree of belief functions&quot;. But (like the Bayesian analogy) each (ideal) agent is presumed to employ just one of the possible R conditionals. So let &#039;--&gt;&#039; be the conditional for a given agent whose belief basis is K. Now read &#039;B--&gt;A&#039; to say that if B were added to K, then this (i.e. B together with K) is prima facie strong reason to believe A. Notice that we will be keeping track of two separate &quot;belief lists&quot;, the basis K and an inferred list, which I&#039;ll call &#039;DK&#039; -- the list of Defeasibly Inferred beliefs based on K. As new information B is added to K we get a new basis K+{B} (K union {B}) and a new inferred list DK+{B}, which contains just those sentences A such that B--&gt;A.

By the way, before updating, DK contains just those sentence A such that &#039;tautology--&gt;A&#039; -- which are just the sentences that the agent is taken to have prima facie strong reason to believe based on K alone, before any (additional) updating (though K itself may have come from updates to a previous belief basis). This DK, based only on K, will include, of course, all sentences in K, and usually much more.)

With this understanding of --&gt;, let me address your questions.

Axiom 1: &#039;A--&gt;A&#039; just says that all basic beliefs in K also go on the &quot;defeasibly inferred list&quot; DK. Also, if a new basic belief A is added to K, it also goes on the new inferred list. In other words, &quot;based on a given (more basic) belief that A, the agent has prima facie strong reason to believe A&quot;

Axiom 2: I take your point. The idea is that the agent has prima facie strong reason to believe the logical implications of her beliefs -- provided she is aware of (or in a position to be aware of) those logical implications. The logic of the conditionals in R tends to be aimed at &quot;logically ideal&quot; agents. But perhaps these conditionals can be interpreted in a way that takes account of the fact that real agents are less than logically ideal by building the appropriate qualification into the interpretation of the conditional itself.

Axiom 3: roughly the same issue as raised for axiom 2

Axiom 4: seems OK to you for now

Axiom 5: See if it might sound even better given the above explanation. This is a version of a rule that logicians call CUT.

Axiom 6: The way R is usually understood, no nesting of the conditional is permitted. So there is no &quot;exportation&quot; from &#039;C&amp;B--&gt;A&#039; to &#039;B--&gt;(C--&gt;A)&#039;. Indeed, --&gt; is usually thought of as a metalinguistic relation (just as logical entailment is metalinguistic). So even expressions of form &#039;C&amp;(B--&gt;A)&#039; are not taken to be proper expressions, just as C&amp;(B&#124;=A) is considered an improper mixing of object language and metalanguage. The closest to &#039;C&amp;(B--&gt;A)&#039; one might come is to say (metalinguistically) &quot;C is in K (C is a more basic belief) and B--&gt;A (adding B to the more basic beliefs would  constitute prima facie strong reason to believe that A)&quot;.

All of this is really worth going into. So, thanks for the questions!!! And if you have more, please keep them coming.]]></description>
		<content:encoded><![CDATA[<p>Andy,</p>
<p>Good questions!!! You make me realize I didn&#8217;t say enough about how these axioms (and the conditionals in R more generally) are often supposed to be &#8220;applied&#8221;. So here is one such account (though not the only possible account) of how these conditionals are supposed to function in an agent&#8217;s doxastic economy.</p>
<p>The usual idea is that the agent has a &#8220;belief base&#8221; (what artificial intelligence researchers often call a &#8220;knowledge base&#8221;). Let&#8217;s call it &#8216;K&#8217;. The beliefs represented in K (as statements) are some sort of &#8220;more basic beliefs&#8221; on the basis of which other beliefs are supposed to be inferred. The agent is then supposed to employ some conditional &#8212; for our purposes, a conditional that satisfies the rules of R &#8212; for defeasibly inferring (or updating to) additional beliefs based on her belief basis K. There may be many possible such conditionals, just as Bayesian agents, for example, are supposed to have available a number of possible &#8220;degree of belief functions&#8221;. But (like the Bayesian analogy) each (ideal) agent is presumed to employ just one of the possible R conditionals. So let &#8216;&#8211;>&#8217; be the conditional for a given agent whose belief basis is K. Now read &#8216;B&#8211;>A&#8217; to say that if B were added to K, then this (i.e. B together with K) is prima facie strong reason to believe A. Notice that we will be keeping track of two separate &#8220;belief lists&#8221;, the basis K and an inferred list, which I&#8217;ll call &#8216;DK&#8217; &#8212; the list of Defeasibly Inferred beliefs based on K. As new information B is added to K we get a new basis K+{B} (K union {B}) and a new inferred list DK+{B}, which contains just those sentences A such that B&#8211;>A.</p>
<p>By the way, before updating, DK contains just those sentence A such that &#8216;tautology&#8211;>A&#8217; &#8212; which are just the sentences that the agent is taken to have prima facie strong reason to believe based on K alone, before any (additional) updating (though K itself may have come from updates to a previous belief basis). This DK, based only on K, will include, of course, all sentences in K, and usually much more.)</p>
<p>With this understanding of &#8211;>, let me address your questions.</p>
<p>Axiom 1: &#8216;A&#8211;>A&#8217; just says that all basic beliefs in K also go on the &#8220;defeasibly inferred list&#8221; DK. Also, if a new basic belief A is added to K, it also goes on the new inferred list. In other words, &#8220;based on a given (more basic) belief that A, the agent has prima facie strong reason to believe A&#8221;</p>
<p>Axiom 2: I take your point. The idea is that the agent has prima facie strong reason to believe the logical implications of her beliefs &#8212; provided she is aware of (or in a position to be aware of) those logical implications. The logic of the conditionals in R tends to be aimed at &#8220;logically ideal&#8221; agents. But perhaps these conditionals can be interpreted in a way that takes account of the fact that real agents are less than logically ideal by building the appropriate qualification into the interpretation of the conditional itself.</p>
<p>Axiom 3: roughly the same issue as raised for axiom 2</p>
<p>Axiom 4: seems OK to you for now</p>
<p>Axiom 5: See if it might sound even better given the above explanation. This is a version of a rule that logicians call CUT.</p>
<p>Axiom 6: The way R is usually understood, no nesting of the conditional is permitted. So there is no &#8220;exportation&#8221; from &#8216;C&#038;B&#8211;>A&#8217; to &#8216;B&#8211;>(C&#8211;>A)&#8217;. Indeed, &#8211;> is usually thought of as a metalinguistic relation (just as logical entailment is metalinguistic). So even expressions of form &#8216;C&#038;(B&#8211;>A)&#8217; are not taken to be proper expressions, just as C&#038;(B|=A) is considered an improper mixing of object language and metalanguage. The closest to &#8216;C&#038;(B&#8211;>A)&#8217; one might come is to say (metalinguistically) &#8220;C is in K (C is a more basic belief) and B&#8211;>A (adding B to the more basic beliefs would  constitute prima facie strong reason to believe that A)&#8221;.</p>
<p>All of this is really worth going into. So, thanks for the questions!!! And if you have more, please keep them coming.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Andrew Cling</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comment-1379</link>
		<dc:creator><![CDATA[Andrew Cling]]></dc:creator>
		<pubDate>Sun, 20 Feb 2005 13:42:57 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259#comment-1379</guid>
		<description><![CDATA[Jim,

Thanks for the axioms. It&#039;s a good idea to test them against our intuitions. I still think non-monotonic conditionals have an important role to play in epistemology, but I don&#039;t think that `-&gt;&#039; in R captures the concept of  &quot;given B there is prima facie strong reason to believe A.&quot;

Axiom 1 seems false. In my own view, there are no propositions A such that A&#039;s truth is a prima facie strong reason (PFSR) to believe A, and it certainly isn&#039;t the case that this is true for all propositions. Either Goldbach&#039;s conjecture (G) or its negation is true but neither G-&gt;G nor ~G-&gt;~G. (I am assuming that `given that P&#039; is short for `given that P is true&#039;; if it is short for `given that one has PFSR for,&#039; then axiom 1 is ok.)

Axiom 2 (if C-&gt;B and B&#124;=A, then C-&gt;A) seems wrong. It seems that I might lack PFSR to believe some of the more complex entailments of what I have a reason to believe. Let C be the conjunction of the axioms of Peano arithmetic and let B be the most complex of their consequences that I can grasp. There will be an A such that B&#124;=A but I cannot grasp A and thus C is not a PFSR for A because it cannot be any part of my evidence for A because I am incapable of having evidence for A. One way to block this counterexample is to insist that whether or not one proposition is evidence for another and whether or not one has evidence for a proposition is not a psychological matter and thus does not depend upon what any particular agent can or cannot understand. I am sympathetic to this response. Another type of problem arises for axiom 2, however. Since any necessary truth is entailed by any proposition, axiom 2 implies that any proposition that is a PFSR for another is a PFSR for any necessary truth.

Axiom 3 (if C&#124;=B and B&#124;=C and B-&gt;A, then C-&gt;A) seems false. There can be a C and a B that are logically equivalent but, if I fail to see this or cannot see it, one can be a PFSR for some A but not the other. Perhaps the anti-psychological response to the counterexample to axiom 2 will work here, too. Another problem, however, is that since any necessary truth entails and is entailed by any other, axiom 3 implies that for any C and B such that C and B are necessary truths, then C is a PFSR to believe anything that B is a PFSR to believe.

Axiom 4 seems ok to me right now.

Axiom 5 (if C-&gt;B and (C&amp;B)-&gt;A, then C-&gt;A) seems dubious, but I cannot come up with a counterexample now.

Axiom 6 (if B-&gt;A and B-/-&gt;~C, then (C&amp;B)-&gt;A) seems wrong to me even reading `-&gt;&#039; in terms of the concept of PFSR. For suppose that both (1) B-&gt;A and (2) B-/-&gt;~C. If axiom 6 is true, then (3) (C&amp;B)-&gt;A. It follows that (4) (B&amp;C)-&gt;A whence (by exportation) (5) B-&gt;(C-&gt;A). Now let A=I have a daughter, B=I have a child named `Madeline&#039; and C=Gretzky is the all-time NHL scoring leader. Substituting in we have (i) that I have a child named Madeline is a PFSR to believe that I have a daughter, (ii) that I have a child named `Madeline&#039; is not a PFSR to believe that Gretzky is the all-time NHL scoring leader, and (v) that I have a child named `Madeline&#039; is a PFSR to believe that (Wayne Gretzky is the all-time NHL scoring leader is a PFSR to believe that I have a daughter). Both (i) and (ii) seem true while (v) seems false. One way out is to reject exportation. Does it hold in R?

(I&#039;d like to work on this post some more, but Madeline and her brother Nicholas are awake and hungry. Why do children have to be dragged out of bed on school days but are up before the sun on weekends?)

--Andy]]></description>
		<content:encoded><![CDATA[<p>Jim,</p>
<p>Thanks for the axioms. It&#8217;s a good idea to test them against our intuitions. I still think non-monotonic conditionals have an important role to play in epistemology, but I don&#8217;t think that `->&#8217; in R captures the concept of  &#8220;given B there is prima facie strong reason to believe A.&#8221;</p>
<p>Axiom 1 seems false. In my own view, there are no propositions A such that A&#8217;s truth is a prima facie strong reason (PFSR) to believe A, and it certainly isn&#8217;t the case that this is true for all propositions. Either Goldbach&#8217;s conjecture (G) or its negation is true but neither G->G nor ~G->~G. (I am assuming that `given that P&#8217; is short for `given that P is true&#8217;; if it is short for `given that one has PFSR for,&#8217; then axiom 1 is ok.)</p>
<p>Axiom 2 (if C->B and B|=A, then C->A) seems wrong. It seems that I might lack PFSR to believe some of the more complex entailments of what I have a reason to believe. Let C be the conjunction of the axioms of Peano arithmetic and let B be the most complex of their consequences that I can grasp. There will be an A such that B|=A but I cannot grasp A and thus C is not a PFSR for A because it cannot be any part of my evidence for A because I am incapable of having evidence for A. One way to block this counterexample is to insist that whether or not one proposition is evidence for another and whether or not one has evidence for a proposition is not a psychological matter and thus does not depend upon what any particular agent can or cannot understand. I am sympathetic to this response. Another type of problem arises for axiom 2, however. Since any necessary truth is entailed by any proposition, axiom 2 implies that any proposition that is a PFSR for another is a PFSR for any necessary truth.</p>
<p>Axiom 3 (if C|=B and B|=C and B->A, then C->A) seems false. There can be a C and a B that are logically equivalent but, if I fail to see this or cannot see it, one can be a PFSR for some A but not the other. Perhaps the anti-psychological response to the counterexample to axiom 2 will work here, too. Another problem, however, is that since any necessary truth entails and is entailed by any other, axiom 3 implies that for any C and B such that C and B are necessary truths, then C is a PFSR to believe anything that B is a PFSR to believe.</p>
<p>Axiom 4 seems ok to me right now.</p>
<p>Axiom 5 (if C->B and (C&#038;B)->A, then C->A) seems dubious, but I cannot come up with a counterexample now.</p>
<p>Axiom 6 (if B->A and B-/->~C, then (C&#038;B)->A) seems wrong to me even reading `->&#8217; in terms of the concept of PFSR. For suppose that both (1) B->A and (2) B-/->~C. If axiom 6 is true, then (3) (C&#038;B)->A. It follows that (4) (B&#038;C)->A whence (by exportation) (5) B->(C->A). Now let A=I have a daughter, B=I have a child named `Madeline&#8217; and C=Gretzky is the all-time NHL scoring leader. Substituting in we have (i) that I have a child named Madeline is a PFSR to believe that I have a daughter, (ii) that I have a child named `Madeline&#8217; is not a PFSR to believe that Gretzky is the all-time NHL scoring leader, and (v) that I have a child named `Madeline&#8217; is a PFSR to believe that (Wayne Gretzky is the all-time NHL scoring leader is a PFSR to believe that I have a daughter). Both (i) and (ii) seem true while (v) seems false. One way out is to reject exportation. Does it hold in R?</p>
<p>(I&#8217;d like to work on this post some more, but Madeline and her brother Nicholas are awake and hungry. Why do children have to be dragged out of bed on school days but are up before the sun on weekends?)</p>
<p>&#8211;Andy</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jim Hawthorne</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comment-1385</link>
		<dc:creator><![CDATA[Jim Hawthorne]]></dc:creator>
		<pubDate>Sat, 19 Feb 2005 06:46:41 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259#comment-1385</guid>
		<description><![CDATA[Greg,

It seems to me that if each of two (or any number, for that matter) of possibilities Bi is prima facie strong reason to believe A, then their disjunction should be as well. That holds even if the disjunction is a tautology. However, &quot;prima facie strong reason to believe A given a tautology&quot; just amounts to &quot;prima facia reason to believe A on the basis of whatever other presuppositions are brought to the context that the conditional represents&quot;.

That is, think of a conditional --&gt; as analogous to a conditional probability function P[*&#124;*]. The probability of A on a tautology, P[A&#124;taut], is not usually taken to be the probability of A relative to &quot;no background beliefs at all&quot;. Rather, when we use probabilities (even conditional ones) to represent belief strengths, we usually suppose that the probability function already presupposes a lot of background beliefs. The idea then is that P[A&#124;B] represents how strongly the agent believes A when B is added to everything else the agent knows (or believes). The same idea applies for how a defeasible conditional --&gt; is supposed to work. So, for a specific conditional --&gt;, &quot;taut--&gt;A&quot; represents prima facie strong belief that A, given some implicit set of background beliefs. If we then also have B--&gt;~A, for example, this means that adding B to those background beliefs provides prima facie strong reason to believe ~A.]]></description>
		<content:encoded><![CDATA[<p>Greg,</p>
<p>It seems to me that if each of two (or any number, for that matter) of possibilities Bi is prima facie strong reason to believe A, then their disjunction should be as well. That holds even if the disjunction is a tautology. However, &#8220;prima facie strong reason to believe A given a tautology&#8221; just amounts to &#8220;prima facia reason to believe A on the basis of whatever other presuppositions are brought to the context that the conditional represents&#8221;.</p>
<p>That is, think of a conditional &#8211;> as analogous to a conditional probability function P[*|*]. The probability of A on a tautology, P[A|taut], is not usually taken to be the probability of A relative to &#8220;no background beliefs at all&#8221;. Rather, when we use probabilities (even conditional ones) to represent belief strengths, we usually suppose that the probability function already presupposes a lot of background beliefs. The idea then is that P[A|B] represents how strongly the agent believes A when B is added to everything else the agent knows (or believes). The same idea applies for how a defeasible conditional &#8211;> is supposed to work. So, for a specific conditional &#8211;>, &#8220;taut&#8211;>A&#8221; represents prima facie strong belief that A, given some implicit set of background beliefs. If we then also have B&#8211;>~A, for example, this means that adding B to those background beliefs provides prima facie strong reason to believe ~A.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comment-1384</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Fri, 18 Feb 2005 22:29:28 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259#comment-1384</guid>
		<description><![CDATA[ps-  this is the worry i had the other day about the disjunction rule; the idea is that you could simply list the measured events in your sample space on the left hand side of the rule and replace the set of outcomes, W, on the righthand side. On the lefthand side the measure on events and that event occuring is giving the action to the conditional; while on the righthand side there simply being an experimental set (the set of possible events, W) would, if (4) holds, give the same action to the conditional. This would be weird, wouldn&#039;t it? Or are you willing to bite this bullet too?

My ride is here. (*&amp;@!) Check back with you on Monday--good weekend to all, -gw]]></description>
		<content:encoded><![CDATA[<p>ps-  this is the worry i had the other day about the disjunction rule; the idea is that you could simply list the measured events in your sample space on the left hand side of the rule and replace the set of outcomes, W, on the righthand side. On the lefthand side the measure on events and that event occuring is giving the action to the conditional; while on the righthand side there simply being an experimental set (the set of possible events, W) would, if (4) holds, give the same action to the conditional. This would be weird, wouldn&#8217;t it? Or are you willing to bite this bullet too?</p>
<p>My ride is here. (*&#038;@!) Check back with you on Monday&#8211;good weekend to all, -gw</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comment-1383</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Fri, 18 Feb 2005 22:16:06 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259#comment-1383</guid>
		<description><![CDATA[This one is clumsy, but a counter-example to

(4) if B -&gt; A and C -&gt; A, then B v C -&gt; A

might be this:

Suppose B: coin lands heads; C: coin lands tails; A: coin was tossed.

Coin landing heads is pfsr that the coin was tossed; Coin landing tails is pfsr that the coin was tossed; but, either landing heads or tails isn&#039;t pfsr that the coin was tossed since (the idea is) a tautology wouldn&#039;t/shouldn&#039;t be pfsr for any empirical event.

It is clumsy, but the idea is to game up an example where the disjunction is a tautology but each disjunct isn&#039;t.]]></description>
		<content:encoded><![CDATA[<p>This one is clumsy, but a counter-example to</p>
<p>(4) if B -> A and C -> A, then B v C -> A</p>
<p>might be this:</p>
<p>Suppose B: coin lands heads; C: coin lands tails; A: coin was tossed.</p>
<p>Coin landing heads is pfsr that the coin was tossed; Coin landing tails is pfsr that the coin was tossed; but, either landing heads or tails isn&#8217;t pfsr that the coin was tossed since (the idea is) a tautology wouldn&#8217;t/shouldn&#8217;t be pfsr for any empirical event.</p>
<p>It is clumsy, but the idea is to game up an example where the disjunction is a tautology but each disjunct isn&#8217;t.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comment-1382</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Fri, 18 Feb 2005 20:42:05 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259#comment-1382</guid>
		<description><![CDATA[Jim,

So whatever reasons we have for our beliefs transfer to all consequences? This would make epistemic closure a non-problem by impoverishing what we have spfr to believe, wouldn&#039;t it?]]></description>
		<content:encoded><![CDATA[<p>Jim,</p>
<p>So whatever reasons we have for our beliefs transfer to all consequences? This would make epistemic closure a non-problem by impoverishing what we have spfr to believe, wouldn&#8217;t it?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jim Hawthorne</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comment-1381</link>
		<dc:creator><![CDATA[Jim Hawthorne]]></dc:creator>
		<pubDate>Fri, 18 Feb 2005 20:11:47 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259#comment-1381</guid>
		<description><![CDATA[Greg,

My intuition on this is that if B&#124;=A but &quot;C is not prima facie strong reason to believe A&quot;, then &quot;C should not be prima facie strong reason to believe B&quot; either. (For, B &quot;contains within it&quot; the weaker claim that A -- weaker unless B and A are logically equivalent.)]]></description>
		<content:encoded><![CDATA[<p>Greg,</p>
<p>My intuition on this is that if B|=A but &#8220;C is not prima facie strong reason to believe A&#8221;, then &#8220;C should not be prima facie strong reason to believe B&#8221; either. (For, B &#8220;contains within it&#8221; the weaker claim that A &#8212; weaker unless B and A are logically equivalent.)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comment-1380</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Fri, 18 Feb 2005 19:42:14 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259#comment-1380</guid>
		<description><![CDATA[re: post 24;

(2) would be problematic on the prima facie strong reason to believe (pfsr) reading of &#039;-&gt;&#039;; If C is pfsr B, B entails A: that goldbach&#039;s conjecture is (false, say), it does not follow that C is pfsr for A.]]></description>
		<content:encoded><![CDATA[<p>re: post 24;</p>
<p>(2) would be problematic on the prima facie strong reason to believe (pfsr) reading of &#8216;->&#8217;; If C is pfsr B, B entails A: that goldbach&#8217;s conjecture is (false, say), it does not follow that C is pfsr for A.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Andrew Cling</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comment-1386</link>
		<dc:creator><![CDATA[Andrew Cling]]></dc:creator>
		<pubDate>Fri, 18 Feb 2005 18:28:40 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259#comment-1386</guid>
		<description><![CDATA[Jim, I think my misstatment of the Rule of Rational Monotony was a typo but could have been what Stew Cohen calls a &quot;thinko.&quot; Condition (iii) should have read: it is not the case that B provides evidence that ~C. In any case, many thanks to Stephen for clarifying my deep concern. I&#039;ll think some more about your new suggestions.
--Andy]]></description>
		<content:encoded><![CDATA[<p>Jim, I think my misstatment of the Rule of Rational Monotony was a typo but could have been what Stew Cohen calls a &#8220;thinko.&#8221; Condition (iii) should have read: it is not the case that B provides evidence that ~C. In any case, many thanks to Stephen for clarifying my deep concern. I&#8217;ll think some more about your new suggestions.<br />
&#8211;Andy</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jim Hawthorne</title>
		<link>http://certaindoubts.com/how-useful-is-a-logic-for-defeasible-nonmonotonic-conditionals-for-epistemology/#comment-1387</link>
		<dc:creator><![CDATA[Jim Hawthorne]]></dc:creator>
		<pubDate>Fri, 18 Feb 2005 17:19:48 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=259#comment-1387</guid>
		<description><![CDATA[Stephen,

I agree that interpreting the conditional to mean &quot;makes almost certain&quot; in the sense of &quot;measure 1&quot; (making the negation have measure 0) seems too stong. Suppose we read B--&gt;A as &quot;given B there is prima facie strong reason to believe A&quot;. Now the question is weather it is plausible to require such a conditional --&gt; to satisfy the rules of R.

There are several equivalent axiomatizations of R. Here is the most common one. See if these axioms intuitively sustain that reading (where &#039;&#124;=&#039; is logical entailment).

1. A--&gt;A
2. if C--&gt;B and B&#124;=A, then C--&gt;A
3. if C&#124;=B and B&#124;=C and B--&gt;A, then C--&gt;A
4. if B--&gt;A and C--&gt;A, then (BvC)--&gt;A
5. if C--&gt;B and (C&amp;B)--&gt;A, then C--&gt;A
6. if B--&gt;A and B-/-&gt;~C, then (C&amp;B)--&gt;A

Only axioms 4 through 6 require much scrutiny. Try reading them with the &quot;prima facie strong reason to believe&quot; reading, and see if you think they hold up.]]></description>
		<content:encoded><![CDATA[<p>Stephen,</p>
<p>I agree that interpreting the conditional to mean &#8220;makes almost certain&#8221; in the sense of &#8220;measure 1&#8221; (making the negation have measure 0) seems too stong. Suppose we read B&#8211;>A as &#8220;given B there is prima facie strong reason to believe A&#8221;. Now the question is weather it is plausible to require such a conditional &#8211;> to satisfy the rules of R.</p>
<p>There are several equivalent axiomatizations of R. Here is the most common one. See if these axioms intuitively sustain that reading (where &#8216;|=&#8217; is logical entailment).</p>
<p>1. A&#8211;>A<br />
2. if C&#8211;>B and B|=A, then C&#8211;>A<br />
3. if C|=B and B|=C and B&#8211;>A, then C&#8211;>A<br />
4. if B&#8211;>A and C&#8211;>A, then (BvC)&#8211;>A<br />
5. if C&#8211;>B and (C&#038;B)&#8211;>A, then C&#8211;>A<br />
6. if B&#8211;>A and B-/->~C, then (C&#038;B)&#8211;>A</p>
<p>Only axioms 4 through 6 require much scrutiny. Try reading them with the &#8220;prima facie strong reason to believe&#8221; reading, and see if you think they hold up.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
