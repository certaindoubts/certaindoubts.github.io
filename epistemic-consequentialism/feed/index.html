<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Epistemic Consequentialism</title>
	<atom:link href="http://certaindoubts.com/epistemic-consequentialism/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/epistemic-consequentialism/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Dennis Whitcomb</title>
		<link>http://certaindoubts.com/epistemic-consequentialism/#comment-1985</link>
		<dc:creator><![CDATA[Dennis Whitcomb]]></dc:creator>
		<pubDate>Thu, 16 Jun 2005 20:14:21 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=354#comment-1985</guid>
		<description><![CDATA[Carrie,

Thanks for raising these questions.  The short answers are (1) &quot;yeah, pretty much&quot;, and (2) &quot;probably, but we should look into the details&quot;.

Here&#039;s the long answer to the first question.  EUp is determined by S&#039;s truth goal for p.  But the nature of S&#039;s truth goal for p is not something about which S has any say; the nature of that goal is determined by real normative facts that are &quot;out here&quot; and which apply to S in virtue of the fact that she&#039;s an epistemic agent.  Perhaps they are ultimately rooted in something like the essential aims of belief.  If so, then distributive truth-consequentialism needs to appeal to the considerations that you conjectured to underlie the &quot;only truth-of-p-related facts matter&quot; intuition.

Earlier in this thread I said that for any p, the individual truth goal for p is [believe p only if p].  That is, of course, only one among many candidates.  Others are [believe p iff p], [if you consider p, then believe p iff p], [be such that if you were to believe p, then p would be true], etc etc.  Suppose that we inquire into the issue of which of these really are the individual truth goals, and that we succeed, thereby coming to know what the individual truth goals are.  Perhaps these goals will turn out to be complex, as in the [believe p iff p] case; if so, then through our inquiry we will have come to know the relative weights of their various parts.  Then, with all of those issues taken care of, we&#039;ll be able to see that something close to what you asked about in question #1 holds.

Let me go through it with a specific version of the truth goals.  I suspect that a similar story would work with any other specific version of the truth goals.  Anyway, in this specific version, the truth goals are all the goals of the form [believe p iff p], where the two conjuncts [Bp if p] and [Bp only if p] are given equal weights.  On this version of the truth goals, there are agents and propositions where those agents have probabilities that give rise to equal expected EUp&#039;s to every cognitive act.  Here I say &quot;equal&quot; instead of &quot;zero&quot; because utility functions don&#039;t have fixed zero-points.  And I say &quot;expected EUp&quot; instead of &quot;EUp&quot; because there is an important sense in which people donâ??t really &lt;i&gt;assign&lt;/i&gt; EUpâ??s:  the structure of EUp functions is determined by truth goals, not persons.  Hereâ??s a toy example where the relevant ties obtain:

----
states: p, not-p
acts: believing p, not believing p
probabilities: p = .5 and not-p = .5
EUp&#039;s: p,Bp = 2, not-p,Bp = 1, p,not-Bp = 1, not-p,not-Bp = 2.  (This idea here is that an outcome gets a point every time it satisfies one of the goalâ??s conjuncts).
-----

So, yeah, in cases like this one, the acts all have equal expected EUp&#039;s, and therefore are all epistemically rational according to distributive truth-consequentialism.  Sorry for the pedantry and long-windedness!...are these ties-cases a problem for the theory?

On to the long answer to question #2.  I guess that whether there are counterexamples depends on what the theory says about the nature of the truth goals.  Maybe the theory&#039;s position on those goals can be defensibly straightened out in such a way that the theory doesn&#039;t have any counterexamples.  More likely, though, there will be counterexamples on every defensible precisification of the truth goals, so that the only way to keep the overall theory afloat is by being imprecise where it counts.  But really to adjudicate these issues we&#039;d need to explore various versions of the theory based on the plausible accounts of the truth goals, and see what sorts of hard cases we can come up with...]]></description>
		<content:encoded><![CDATA[<p>Carrie,</p>
<p>Thanks for raising these questions.  The short answers are (1) &#8220;yeah, pretty much&#8221;, and (2) &#8220;probably, but we should look into the details&#8221;.</p>
<p>Here&#8217;s the long answer to the first question.  EUp is determined by S&#8217;s truth goal for p.  But the nature of S&#8217;s truth goal for p is not something about which S has any say; the nature of that goal is determined by real normative facts that are &#8220;out here&#8221; and which apply to S in virtue of the fact that she&#8217;s an epistemic agent.  Perhaps they are ultimately rooted in something like the essential aims of belief.  If so, then distributive truth-consequentialism needs to appeal to the considerations that you conjectured to underlie the &#8220;only truth-of-p-related facts matter&#8221; intuition.</p>
<p>Earlier in this thread I said that for any p, the individual truth goal for p is [believe p only if p].  That is, of course, only one among many candidates.  Others are [believe p iff p], [if you consider p, then believe p iff p], [be such that if you were to believe p, then p would be true], etc etc.  Suppose that we inquire into the issue of which of these really are the individual truth goals, and that we succeed, thereby coming to know what the individual truth goals are.  Perhaps these goals will turn out to be complex, as in the [believe p iff p] case; if so, then through our inquiry we will have come to know the relative weights of their various parts.  Then, with all of those issues taken care of, we&#8217;ll be able to see that something close to what you asked about in question #1 holds.</p>
<p>Let me go through it with a specific version of the truth goals.  I suspect that a similar story would work with any other specific version of the truth goals.  Anyway, in this specific version, the truth goals are all the goals of the form [believe p iff p], where the two conjuncts [Bp if p] and [Bp only if p] are given equal weights.  On this version of the truth goals, there are agents and propositions where those agents have probabilities that give rise to equal expected EUp&#8217;s to every cognitive act.  Here I say &#8220;equal&#8221; instead of &#8220;zero&#8221; because utility functions don&#8217;t have fixed zero-points.  And I say &#8220;expected EUp&#8221; instead of &#8220;EUp&#8221; because there is an important sense in which people donâ??t really <i>assign</i> EUpâ??s:  the structure of EUp functions is determined by truth goals, not persons.  Hereâ??s a toy example where the relevant ties obtain:</p>
<p>&#8212;-<br />
states: p, not-p<br />
acts: believing p, not believing p<br />
probabilities: p = .5 and not-p = .5<br />
EUp&#8217;s: p,Bp = 2, not-p,Bp = 1, p,not-Bp = 1, not-p,not-Bp = 2.  (This idea here is that an outcome gets a point every time it satisfies one of the goalâ??s conjuncts).<br />
&#8212;&#8211;</p>
<p>So, yeah, in cases like this one, the acts all have equal expected EUp&#8217;s, and therefore are all epistemically rational according to distributive truth-consequentialism.  Sorry for the pedantry and long-windedness!&#8230;are these ties-cases a problem for the theory?</p>
<p>On to the long answer to question #2.  I guess that whether there are counterexamples depends on what the theory says about the nature of the truth goals.  Maybe the theory&#8217;s position on those goals can be defensibly straightened out in such a way that the theory doesn&#8217;t have any counterexamples.  More likely, though, there will be counterexamples on every defensible precisification of the truth goals, so that the only way to keep the overall theory afloat is by being imprecise where it counts.  But really to adjudicate these issues we&#8217;d need to explore various versions of the theory based on the plausible accounts of the truth goals, and see what sorts of hard cases we can come up with&#8230;</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Carrie Jenkins</title>
		<link>http://certaindoubts.com/epistemic-consequentialism/#comment-1984</link>
		<dc:creator><![CDATA[Carrie Jenkins]]></dc:creator>
		<pubDate>Tue, 14 Jun 2005 11:47:15 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=354#comment-1984</guid>
		<description><![CDATA[Hi Dennis,
A couple of questions about this proposal:
1.What if S assigns zero EUp to all cognitive acts, including BSp?  Then, by your condition 2, BSp is rational.  Is that right?
2. If S assigns expected EUp to acts in a highly idiosyncratic way, S might end up rationally believing p (by condition 2) in cases where intuitively we wouldn&#039;t want to say BSp was rational.]]></description>
		<content:encoded><![CDATA[<p>Hi Dennis,<br />
A couple of questions about this proposal:<br />
1.What if S assigns zero EUp to all cognitive acts, including BSp?  Then, by your condition 2, BSp is rational.  Is that right?<br />
2. If S assigns expected EUp to acts in a highly idiosyncratic way, S might end up rationally believing p (by condition 2) in cases where intuitively we wouldn&#8217;t want to say BSp was rational.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Dennis Whitcomb</title>
		<link>http://certaindoubts.com/epistemic-consequentialism/#comment-1983</link>
		<dc:creator><![CDATA[Dennis Whitcomb]]></dc:creator>
		<pubDate>Mon, 13 Jun 2005 05:03:10 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=354#comment-1983</guid>
		<description><![CDATA[Carrie,

That sounds right, given the assumption that on the distributive reading, truth goals other than the individual truth goal for p can make a difference to the epistemic rationality of believing p.

But the distributive truth-consequentialist theory of epistemic rationality I had in mind was a bit more radical in its isolation of relevant consequences to believed propositions.  A bit better (though still pretty rough) formulation of that theory would go something like this:

-----
1.  For every proposition p, S has an epistemic utility function, EUp, that ranks outcomes according to the extent to which they fulfill S&#039;s individual truth goal for p.

2.  Bsp is epistemically rational iff there is no alternative cognitive act to which S assigns a higher expected EUp.
-----

The theory gets to have its consequentialist cake while eating its isolationist intuitions, roughly by indexing the rationality of believing to the individual truth goal concerning the particular proposition believed...]]></description>
		<content:encoded><![CDATA[<p>Carrie,</p>
<p>That sounds right, given the assumption that on the distributive reading, truth goals other than the individual truth goal for p can make a difference to the epistemic rationality of believing p.</p>
<p>But the distributive truth-consequentialist theory of epistemic rationality I had in mind was a bit more radical in its isolation of relevant consequences to believed propositions.  A bit better (though still pretty rough) formulation of that theory would go something like this:</p>
<p>&#8212;&#8211;<br />
1.  For every proposition p, S has an epistemic utility function, EUp, that ranks outcomes according to the extent to which they fulfill S&#8217;s individual truth goal for p.</p>
<p>2.  Bsp is epistemically rational iff there is no alternative cognitive act to which S assigns a higher expected EUp.<br />
&#8212;&#8211;</p>
<p>The theory gets to have its consequentialist cake while eating its isolationist intuitions, roughly by indexing the rationality of believing to the individual truth goal concerning the particular proposition believed&#8230;</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Carrie Jenkins</title>
		<link>http://certaindoubts.com/epistemic-consequentialism/#comment-1982</link>
		<dc:creator><![CDATA[Carrie Jenkins]]></dc:creator>
		<pubDate>Sun, 12 Jun 2005 12:39:17 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=354#comment-1982</guid>
		<description><![CDATA[Dennis,
Thanks for the pointer.  On what you call the distributive reading, is it still assumed that all the individual goals are relevant, although (presumably) the most important one is that relating to the particular proposition under consideration?  If so, that doesn&#039;t quite to match up with my intuition that consequences relating to other propositions shouldn&#039;t be relevant *at all*.]]></description>
		<content:encoded><![CDATA[<p>Dennis,<br />
Thanks for the pointer.  On what you call the distributive reading, is it still assumed that all the individual goals are relevant, although (presumably) the most important one is that relating to the particular proposition under consideration?  If so, that doesn&#8217;t quite to match up with my intuition that consequences relating to other propositions shouldn&#8217;t be relevant *at all*.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Dennis Whitcomb</title>
		<link>http://certaindoubts.com/epistemic-consequentialism/#comment-1981</link>
		<dc:creator><![CDATA[Dennis Whitcomb]]></dc:creator>
		<pubDate>Sat, 11 Jun 2005 22:57:48 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=354#comment-1981</guid>
		<description><![CDATA[Hi Carrie,

Some of the epistemic goals literature seems relevant here, especially Marian David&#039;s work.

Consider the view that &quot;the epistemic goal&quot; is the truth goal, and that the truth goal is &lt;i&gt;believing p only if p is true&lt;/i&gt;.  There are many objections to this view.  One of the more interesting ones is that it is ambiguous between collective and distributive readings.  On the collective reading, to have the truth goal is to have a unique goal that, for all propositions p, one believes p only if p.  On the distributive reading, to have the truth goal is to have an enormous collection of goals, one for every proposition p, each of the form [one believes p only if p].

It seems to me that the views of &quot;the epistemic goal&quot; produced by these two disambiguations are naturally associated with distinct consequentialist accounts of epistemic rationality, one of which is in line with your (and Foleyâ??s) intuitions and the other of which is not.

On the distributive reading, there is no unique goal by which consequentialists can rank their outcomes epistemically.  There are just different goals, one for each proposition, and no overall goal that combines them.  If we take this multiplicity of goals as a datum, then it seems natural to say that there is also a multiplicity of epistemic orderings of consequences:  one ordering for each goal.  It also seems natural to say that for each act of believing, the facts about whether that act is epistemically rational are sensitive only to a particular one of the orderings:  namely, the ordering associated with the proposition at which that particular act of believing is aimed.  So consequentialist theories of epistemic rationality seem to be in line with the Jenkins/Foley intuitions, if those theories understand the epistemic goal as a distributive goal such as the distributive truth goal articulated above.

But suppose we take the epistemic goal to be the truth goal on its collective reading.  Then, since there is a unique epistemic goal, it would seem that consequentialists ought to countenance a unique epistemic ordering of outcomes.  Presumably, these outcomes will be ordered according to the relative numbers of true vs. false beliefs that they contain, whatever that might mean.  And certainly there are cases in which one can gain many true beliefs by purposely believing one falsehood.  So if epistemic rationality is a matter of producing the epistemically best consequences, and consequences are epistemically ranked by the extent to which they fulfill the collective truth goal, then in these cases it is epistemically rational to purposely believe the falsehood.  By believing that falsehood, one gains other true beliefs that more than make up for the loss.  So if epistemic goals are understood in the collective sense that is exemplified by our collective truth goal, then consequentialist theories of epistemic rationality do not seem to be in line with the Jenkins/Foley intuitions.

(Cf. Davidâ??s papers in KTD and the Blackwell debates volume for relevant discussion, particularly of the collective/distributive distinction â?? though Iâ??ve forgotten whether that is his terminology.)]]></description>
		<content:encoded><![CDATA[<p>Hi Carrie,</p>
<p>Some of the epistemic goals literature seems relevant here, especially Marian David&#8217;s work.</p>
<p>Consider the view that &#8220;the epistemic goal&#8221; is the truth goal, and that the truth goal is <i>believing p only if p is true</i>.  There are many objections to this view.  One of the more interesting ones is that it is ambiguous between collective and distributive readings.  On the collective reading, to have the truth goal is to have a unique goal that, for all propositions p, one believes p only if p.  On the distributive reading, to have the truth goal is to have an enormous collection of goals, one for every proposition p, each of the form [one believes p only if p].</p>
<p>It seems to me that the views of &#8220;the epistemic goal&#8221; produced by these two disambiguations are naturally associated with distinct consequentialist accounts of epistemic rationality, one of which is in line with your (and Foleyâ??s) intuitions and the other of which is not.</p>
<p>On the distributive reading, there is no unique goal by which consequentialists can rank their outcomes epistemically.  There are just different goals, one for each proposition, and no overall goal that combines them.  If we take this multiplicity of goals as a datum, then it seems natural to say that there is also a multiplicity of epistemic orderings of consequences:  one ordering for each goal.  It also seems natural to say that for each act of believing, the facts about whether that act is epistemically rational are sensitive only to a particular one of the orderings:  namely, the ordering associated with the proposition at which that particular act of believing is aimed.  So consequentialist theories of epistemic rationality seem to be in line with the Jenkins/Foley intuitions, if those theories understand the epistemic goal as a distributive goal such as the distributive truth goal articulated above.</p>
<p>But suppose we take the epistemic goal to be the truth goal on its collective reading.  Then, since there is a unique epistemic goal, it would seem that consequentialists ought to countenance a unique epistemic ordering of outcomes.  Presumably, these outcomes will be ordered according to the relative numbers of true vs. false beliefs that they contain, whatever that might mean.  And certainly there are cases in which one can gain many true beliefs by purposely believing one falsehood.  So if epistemic rationality is a matter of producing the epistemically best consequences, and consequences are epistemically ranked by the extent to which they fulfill the collective truth goal, then in these cases it is epistemically rational to purposely believe the falsehood.  By believing that falsehood, one gains other true beliefs that more than make up for the loss.  So if epistemic goals are understood in the collective sense that is exemplified by our collective truth goal, then consequentialist theories of epistemic rationality do not seem to be in line with the Jenkins/Foley intuitions.</p>
<p>(Cf. Davidâ??s papers in KTD and the Blackwell debates volume for relevant discussion, particularly of the collective/distributive distinction â?? though Iâ??ve forgotten whether that is his terminology.)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/epistemic-consequentialism/#comment-1980</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Sat, 11 Jun 2005 17:38:06 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=354#comment-1980</guid>
		<description><![CDATA[Carrie, you may be right; I was just talking about the motivation for the restriction.]]></description>
		<content:encoded><![CDATA[<p>Carrie, you may be right; I was just talking about the motivation for the restriction.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Carrie Jenkins</title>
		<link>http://certaindoubts.com/epistemic-consequentialism/#comment-1979</link>
		<dc:creator><![CDATA[Carrie Jenkins]]></dc:creator>
		<pubDate>Sat, 11 Jun 2005 17:25:35 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=354#comment-1979</guid>
		<description><![CDATA[Jon,
Thanks for your response.  I guess I don&#039;t see how Foley&#039;s restriction helps (at least, as you state it, which is also how I remember it; though maybe it has more bells and whistles in the book).  Suppose I tried to say that S&#039;s believing p was rational because it resulted in S&#039;s NOW believing q, r, s etc., i.e. a lot of true propositions other than p.  I still have the same intuition that this kind of consequence shouldn&#039;t count towards an assessment of the rationality of believing p.  (I should go back and check over what Foley says about this though; maybe there is more to it than I&#039;m remembering.)

Clayton,
Thanks very much - I will look those up.]]></description>
		<content:encoded><![CDATA[<p>Jon,<br />
Thanks for your response.  I guess I don&#8217;t see how Foley&#8217;s restriction helps (at least, as you state it, which is also how I remember it; though maybe it has more bells and whistles in the book).  Suppose I tried to say that S&#8217;s believing p was rational because it resulted in S&#8217;s NOW believing q, r, s etc., i.e. a lot of true propositions other than p.  I still have the same intuition that this kind of consequence shouldn&#8217;t count towards an assessment of the rationality of believing p.  (I should go back and check over what Foley says about this though; maybe there is more to it than I&#8217;m remembering.)</p>
<p>Clayton,<br />
Thanks very much &#8211; I will look those up.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Clayton</title>
		<link>http://certaindoubts.com/epistemic-consequentialism/#comment-1978</link>
		<dc:creator><![CDATA[Clayton]]></dc:creator>
		<pubDate>Sat, 11 Jun 2005 16:35:24 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=354#comment-1978</guid>
		<description><![CDATA[Carrie,

You might want to look at Stephen Maitzen, &quot;Our Errant Epistemic Aim&quot; Philosophy and Phenomenological Research 1995 where he argues that an act-consequentialist reading of the truth goal is preferable to a rule-consequentialist one.

The intuition you have concerning the kinds of consequences that matter for cognition and the ones that might matter but only in some other way is one discussed in some detail in some of Pamela Hieronymi&#039;s work.  I&#039;d recommend her paper &lt;a href=&quot;http://www.humnet.ucla.edu/humnet/phil/faculty/Phieronymi/PH,WKR.pdf&quot;&gt;&#039;The Wrong Kind of Reason&#039;&lt;/a&gt; (I don&#039;t know whether links work.  If not, you can find the paper on her UCLA page).

Hopefully there is something useful there.]]></description>
		<content:encoded><![CDATA[<p>Carrie,</p>
<p>You might want to look at Stephen Maitzen, &#8220;Our Errant Epistemic Aim&#8221; Philosophy and Phenomenological Research 1995 where he argues that an act-consequentialist reading of the truth goal is preferable to a rule-consequentialist one.</p>
<p>The intuition you have concerning the kinds of consequences that matter for cognition and the ones that might matter but only in some other way is one discussed in some detail in some of Pamela Hieronymi&#8217;s work.  I&#8217;d recommend her paper <a href="http://www.humnet.ucla.edu/humnet/phil/faculty/Phieronymi/PH,WKR.pdf">&#8216;The Wrong Kind of Reason&#8217;</a> (I don&#8217;t know whether links work.  If not, you can find the paper on her UCLA page).</p>
<p>Hopefully there is something useful there.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/epistemic-consequentialism/#comment-1977</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Sat, 11 Jun 2005 14:43:50 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=354#comment-1977</guid>
		<description><![CDATA[Foley, in the Theory of Epistemic Rationality, talks about the epistemic goal of believing the truth and avoiding error NOW, and uses precisely the example you give here to motivate the restriction.]]></description>
		<content:encoded><![CDATA[<p>Foley, in the Theory of Epistemic Rationality, talks about the epistemic goal of believing the truth and avoiding error NOW, and uses precisely the example you give here to motivate the restriction.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
