<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: X-Phi on Bank Cases and Pragmatic Encroachment</title>
	<atom:link href="http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Ram Neta</title>
		<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/#comment-8067</link>
		<dc:creator><![CDATA[Ram Neta]]></dc:creator>
		<pubDate>Sat, 09 Aug 2008 18:26:39 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=851#comment-8067</guid>
		<description><![CDATA[Jason, you write:  &quot;If people try to align their subjective credences with their epistemic (rational) credences, then we have the link to rational credences in place. Since I believe that people do in general try to align their subjective credences with their rational credences, we have the desired conclusion.&quot;

As you recognize yourself, the link between drop in actual credence and drop in rational credence comes from the claim that people SUCCESSFULLY try to align their subjective credence with their rational credence.  So, you say, your view is more charitable than our anti-intellectualist view because it grants that peoples&#039; changes in actual credence are rational.

Now, that&#039;s a helpful clarification of how you&#039;re thinking about the bearing of the psychological literature on the present issue about evidence.  My worry, though, is about whether the principle of charity should be applied to our behavior, to make that behavior come out as rational as possible, or whether it should be applied to our intuitive judgments about rationality, to make those intuitive judgments come out as true as possible.  What this exchange shows, I think, is that, in this particular instance, you get incompatible results depending on what you apply the principle to.

In fact, though, this sort of conflict should be clear from our data, which suggests that people (at least 44% of people) tend towards the view that anti-intellectualism is right, even though their own verdicts about particular hypothetical cases are (assuming CE, which is itself neutral concerning whether intellectualism is true) in conflict with anti-intellectualism.  So there&#039;s just no way of reading their thinking as fully consistent.]]></description>
		<content:encoded><![CDATA[<p>Jason, you write:  &#8220;If people try to align their subjective credences with their epistemic (rational) credences, then we have the link to rational credences in place. Since I believe that people do in general try to align their subjective credences with their rational credences, we have the desired conclusion.&#8221;</p>
<p>As you recognize yourself, the link between drop in actual credence and drop in rational credence comes from the claim that people SUCCESSFULLY try to align their subjective credence with their rational credence.  So, you say, your view is more charitable than our anti-intellectualist view because it grants that peoples&#8217; changes in actual credence are rational.</p>
<p>Now, that&#8217;s a helpful clarification of how you&#8217;re thinking about the bearing of the psychological literature on the present issue about evidence.  My worry, though, is about whether the principle of charity should be applied to our behavior, to make that behavior come out as rational as possible, or whether it should be applied to our intuitive judgments about rationality, to make those intuitive judgments come out as true as possible.  What this exchange shows, I think, is that, in this particular instance, you get incompatible results depending on what you apply the principle to.</p>
<p>In fact, though, this sort of conflict should be clear from our data, which suggests that people (at least 44% of people) tend towards the view that anti-intellectualism is right, even though their own verdicts about particular hypothetical cases are (assuming CE, which is itself neutral concerning whether intellectualism is true) in conflict with anti-intellectualism.  So there&#8217;s just no way of reading their thinking as fully consistent.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jason Stanley</title>
		<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/#comment-8079</link>
		<dc:creator><![CDATA[Jason Stanley]]></dc:creator>
		<pubDate>Sat, 09 Aug 2008 14:46:26 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=851#comment-8079</guid>
		<description><![CDATA[Ram,

Here is how the psychological literature bears on rational credences. First, it shows that people in fact change their degrees of confidence in response to raised stakes. If people try to align their subjective credences with their epistemic (rational) credences, then we have the link to rational credences in place. Since I believe that people do in general try to align their subjective credences with their rational credences, we have the desired conclusion.

On my view in epistemology, in many cases in which people lower their credences in response to raised stakes, they are in fact correctly aligning their subjective credences with their rational credences. So my view in epistemology gives a charitable interpretation to people&#039;s tendencies to lower their credences in response to raised stakes. The opposing intellectualist view is not charitable. It says that people, when facing raised stakes, make mistakes about their rational credences (since they are trying to align their subjective credences with their rational credences).]]></description>
		<content:encoded><![CDATA[<p>Ram,</p>
<p>Here is how the psychological literature bears on rational credences. First, it shows that people in fact change their degrees of confidence in response to raised stakes. If people try to align their subjective credences with their epistemic (rational) credences, then we have the link to rational credences in place. Since I believe that people do in general try to align their subjective credences with their rational credences, we have the desired conclusion.</p>
<p>On my view in epistemology, in many cases in which people lower their credences in response to raised stakes, they are in fact correctly aligning their subjective credences with their rational credences. So my view in epistemology gives a charitable interpretation to people&#8217;s tendencies to lower their credences in response to raised stakes. The opposing intellectualist view is not charitable. It says that people, when facing raised stakes, make mistakes about their rational credences (since they are trying to align their subjective credences with their rational credences).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Ram Neta</title>
		<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/#comment-8078</link>
		<dc:creator><![CDATA[Ram Neta]]></dc:creator>
		<pubDate>Sat, 09 Aug 2008 14:20:29 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=851#comment-8078</guid>
		<description><![CDATA[Jason,

I don&#039;t think you characterize our disagreement accurately.  I agree with everything you say in the first paragraph of 74.  I also agree that we do in fact lower our confidence in a belief in response to raised stakes.  And I agree that the psychological literature shows this.  So on all those points, we are, and have been throughout, on the same page.

The only point you make in 74 that I do not agree with is the one that you express by including the phrase &quot;contra your paper&quot; in your second paragraph.  Our paper makes no predictions at all about how peoples&#039; actual degrees of confidence will be effected by raising stakes.  Our paper makes predictions only about how peoples&#039; rational degrees of confidence will (or will not) be effected by raising stakes.

So what I was asking you in 73 was just this:  how is it possible to glean, from the psychological literature that you cite, any predictions about how peoples&#039; rational degrees of confidence will or will not be effected by raising stakes?]]></description>
		<content:encoded><![CDATA[<p>Jason,</p>
<p>I don&#8217;t think you characterize our disagreement accurately.  I agree with everything you say in the first paragraph of 74.  I also agree that we do in fact lower our confidence in a belief in response to raised stakes.  And I agree that the psychological literature shows this.  So on all those points, we are, and have been throughout, on the same page.</p>
<p>The only point you make in 74 that I do not agree with is the one that you express by including the phrase &#8220;contra your paper&#8221; in your second paragraph.  Our paper makes no predictions at all about how peoples&#8217; actual degrees of confidence will be effected by raising stakes.  Our paper makes predictions only about how peoples&#8217; rational degrees of confidence will (or will not) be effected by raising stakes.</p>
<p>So what I was asking you in 73 was just this:  how is it possible to glean, from the psychological literature that you cite, any predictions about how peoples&#8217; rational degrees of confidence will or will not be effected by raising stakes?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jason Stanley</title>
		<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/#comment-8073</link>
		<dc:creator><![CDATA[Jason Stanley]]></dc:creator>
		<pubDate>Fri, 08 Aug 2008 23:36:06 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=851#comment-8073</guid>
		<description><![CDATA[Ram,

For better or for worse, the view I hold in epistemology is that it is in fact rational to lower one&#039;s confidence in response to raised stakes. No doubt, you find this philosophical position counter-intuitive. But I thought the dispute we were having on this blog was not over whether philosophers (or psychologists) find this conception of rationality counter-intuitive, but whether the view is reflected in basic folk intuitions.

If you&#039;re now prepared to concede what the psychological literature appears to show, that, contra your paper, we do in fact lower our confidence in a belief in response to raised stakes, then we can move on to the question about whether the anti-intellectualist account of these intuitions is philosophically defensible.]]></description>
		<content:encoded><![CDATA[<p>Ram,</p>
<p>For better or for worse, the view I hold in epistemology is that it is in fact rational to lower one&#8217;s confidence in response to raised stakes. No doubt, you find this philosophical position counter-intuitive. But I thought the dispute we were having on this blog was not over whether philosophers (or psychologists) find this conception of rationality counter-intuitive, but whether the view is reflected in basic folk intuitions.</p>
<p>If you&#8217;re now prepared to concede what the psychological literature appears to show, that, contra your paper, we do in fact lower our confidence in a belief in response to raised stakes, then we can move on to the question about whether the anti-intellectualist account of these intuitions is philosophically defensible.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Ram Neta</title>
		<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/#comment-8076</link>
		<dc:creator><![CDATA[Ram Neta]]></dc:creator>
		<pubDate>Fri, 08 Aug 2008 21:50:33 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=851#comment-8076</guid>
		<description><![CDATA[Jason writes:  &quot;The upshot of the research is rather that two people with different stakes, confronted with the same piece of evidence, report it as being differentially persuasive.&quot;

How does it follow from the thing said here to be the upshot of the research that raising stakes lowers RATIONAL confidence?  When people are under pressure, they make all sorts of mistakes.]]></description>
		<content:encoded><![CDATA[<p>Jason writes:  &#8220;The upshot of the research is rather that two people with different stakes, confronted with the same piece of evidence, report it as being differentially persuasive.&#8221;</p>
<p>How does it follow from the thing said here to be the upshot of the research that raising stakes lowers RATIONAL confidence?  When people are under pressure, they make all sorts of mistakes.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jason Stanley</title>
		<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/#comment-8075</link>
		<dc:creator><![CDATA[Jason Stanley]]></dc:creator>
		<pubDate>Fri, 08 Aug 2008 21:10:33 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=851#comment-8075</guid>
		<description><![CDATA[Ram,

Umm...it wouldn&#039;t really be an interesting and controversial topic of psychological research if the upshot was that people rigorously adhere to expected utility theory. The upshot of the research is rather that two people with different stakes, confronted with the same piece of evidence, report it as being differentially persuasive. In particular (judging e.g. from the description in Kunda&#039;s summary article of the 1979 Petty &#038; Cacioppo study), people with different stakes report different confidence levels in a proposition, when given the same piece of evidence. They do not (as you claim they should) report having the same degree of confidence, but act on that basis differently.

In short, the data you are getting in your study directly conflicts with this data. So someone is doing something strange. I suspect your non-juxtaposed cases do not really elicit stakes-sensitive intuitions. Perhaps we need something like the techniques used by psychologists (on the other hand, the fact that you are getting substantial stakes-sensitive intuitions in your juxtaposed cases shows that one can perhaps elicit them more cheaply than giving subjects an actual financial incentive).]]></description>
		<content:encoded><![CDATA[<p>Ram,</p>
<p>Umm&#8230;it wouldn&#8217;t really be an interesting and controversial topic of psychological research if the upshot was that people rigorously adhere to expected utility theory. The upshot of the research is rather that two people with different stakes, confronted with the same piece of evidence, report it as being differentially persuasive. In particular (judging e.g. from the description in Kunda&#8217;s summary article of the 1979 Petty &amp; Cacioppo study), people with different stakes report different confidence levels in a proposition, when given the same piece of evidence. They do not (as you claim they should) report having the same degree of confidence, but act on that basis differently.</p>
<p>In short, the data you are getting in your study directly conflicts with this data. So someone is doing something strange. I suspect your non-juxtaposed cases do not really elicit stakes-sensitive intuitions. Perhaps we need something like the techniques used by psychologists (on the other hand, the fact that you are getting substantial stakes-sensitive intuitions in your juxtaposed cases shows that one can perhaps elicit them more cheaply than giving subjects an actual financial incentive).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Ram Neta</title>
		<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/#comment-8074</link>
		<dc:creator><![CDATA[Ram Neta]]></dc:creator>
		<pubDate>Fri, 08 Aug 2008 19:56:54 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=851#comment-8074</guid>
		<description><![CDATA[Jason writes, in 69, &quot;In short - according to this summary of a very large body of empirical research in psychology, when you increase the stakes involved in making a wrong judgment, people regard ordinary methods of gathering evidence as less reliable than they ordinarily do.&quot;

But I don&#039;t see a single quote in 69 to substantiate this interpretation of the summary.  There&#039;s nothing about people regarding certain &quot;methods of evidence gathering&quot; as &quot;less reliable&quot;.  What the survey article says is just that, when the stakes go up, people expend more effort with the aim of accuracy.  But that&#039;s perfectly consistent with every position (including ours) on the debate concerning anti-intellectualism about evidence!  Suppose my current evidence makes it the case that I should be .8 confident that Obama will win the election.  Now you ask me to bet $10 at 1:1 odds that Obama will win.  Fine by me.  But now suppose you ask me to bet my life savings at 1:1 odds that Obama will win.  No way!  Given the massive cost to me of being wrong, I better go out and gather more evidence before I make such a bet!  And that&#039;s NOT because I have less than .8 confidence, or because I ought to have less than .8 confidence.  It&#039;s because I&#039;m not willing to take a .2 chance of losing my life savings!]]></description>
		<content:encoded><![CDATA[<p>Jason writes, in 69, &#8220;In short &#8211; according to this summary of a very large body of empirical research in psychology, when you increase the stakes involved in making a wrong judgment, people regard ordinary methods of gathering evidence as less reliable than they ordinarily do.&#8221;</p>
<p>But I don&#8217;t see a single quote in 69 to substantiate this interpretation of the summary.  There&#8217;s nothing about people regarding certain &#8220;methods of evidence gathering&#8221; as &#8220;less reliable&#8221;.  What the survey article says is just that, when the stakes go up, people expend more effort with the aim of accuracy.  But that&#8217;s perfectly consistent with every position (including ours) on the debate concerning anti-intellectualism about evidence!  Suppose my current evidence makes it the case that I should be .8 confident that Obama will win the election.  Now you ask me to bet $10 at 1:1 odds that Obama will win.  Fine by me.  But now suppose you ask me to bet my life savings at 1:1 odds that Obama will win.  No way!  Given the massive cost to me of being wrong, I better go out and gather more evidence before I make such a bet!  And that&#8217;s NOT because I have less than .8 confidence, or because I ought to have less than .8 confidence.  It&#8217;s because I&#8217;m not willing to take a .2 chance of losing my life savings!</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Ram Neta</title>
		<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/#comment-8077</link>
		<dc:creator><![CDATA[Ram Neta]]></dc:creator>
		<pubDate>Fri, 08 Aug 2008 16:25:12 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=851#comment-8077</guid>
		<description><![CDATA[Hi Jason,

Concerning your question in note 63 about our PPR exchange.  Here&#039;s what you say:

&quot;My point was that the anti-intellectualist about evidence has a simple response to your objection in your PPR piece. Whether a method of acquiring beliefs provides good enough evidence for X’s belief that p on time t depends upon what is at stake for X at t. If a lot is at stake in finding Main street, a certain method M of gathering evidence might not be sufficiently good evidence, not just for X’s belief that p at time t, but for any other belief X might form on the basis of M at t.&quot;

And now here&#039;s what puzzles me:  to whatever extent this reply works, what makes it work seems -- so far as I can tell -- to have nothing whatsoever to do with any view about evidence.  Why couldn&#039;t you just as well have said the following:

Whether a method of acquiring beliefs provides X with knowledge that p on time t depends upon what is at stake for X at t. If a lot is at stake in finding Main street, a certain method M of forming beliefs might not provide knowledge, not just for X’s belief that p at time t, but for any other belief X might form on the basis of M at t.

In other words, suppose you eliminate the reference to evidence, just talk about methods of forming beliefs, and you lose ... what?  Is your reply to me now any worse off than it otherwise would have been?]]></description>
		<content:encoded><![CDATA[<p>Hi Jason,</p>
<p>Concerning your question in note 63 about our PPR exchange.  Here&#8217;s what you say:</p>
<p>&#8220;My point was that the anti-intellectualist about evidence has a simple response to your objection in your PPR piece. Whether a method of acquiring beliefs provides good enough evidence for X’s belief that p on time t depends upon what is at stake for X at t. If a lot is at stake in finding Main street, a certain method M of gathering evidence might not be sufficiently good evidence, not just for X’s belief that p at time t, but for any other belief X might form on the basis of M at t.&#8221;</p>
<p>And now here&#8217;s what puzzles me:  to whatever extent this reply works, what makes it work seems &#8212; so far as I can tell &#8212; to have nothing whatsoever to do with any view about evidence.  Why couldn&#8217;t you just as well have said the following:</p>
<p>Whether a method of acquiring beliefs provides X with knowledge that p on time t depends upon what is at stake for X at t. If a lot is at stake in finding Main street, a certain method M of forming beliefs might not provide knowledge, not just for X’s belief that p at time t, but for any other belief X might form on the basis of M at t.</p>
<p>In other words, suppose you eliminate the reference to evidence, just talk about methods of forming beliefs, and you lose &#8230; what?  Is your reply to me now any worse off than it otherwise would have been?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mark Phelan</title>
		<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/#comment-8683</link>
		<dc:creator><![CDATA[Mark Phelan]]></dc:creator>
		<pubDate>Fri, 08 Aug 2008 12:12:25 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=851#comment-8683</guid>
		<description><![CDATA[&quot;But surely the interesting question is not whether the specific cases discussed by philosophers support IRI about evidence, but whether there is good evidence that stakes undermine rational confidence. And the latter seems strongly supported by extant psychological literature.&quot;

I would agree that the first is not an interesting question.  What does strike me as an interesting question is whether the philosophical method of contrasting cases is a good way to get evidence in favor of certain views. Our studies suggest that it may be problematic to claim on the basis of reactions to contrast cases that our intuitions about a certain concept ordinarily (i.e. in non-contrast cases) vary in reaction to certain features which are manipulated in these contrast cases.

&quot;The proponent of IRI about evidence claims that our judgments about the quality of evidence is affected by practical stakes.&quot;

The studies you and Jennifer cite suggest that this claim is true of first-person judgments of the quality of evidence.  Our studies suggest that this claim is not true of third-person judgments of the quality of others evidence.  (So far as I can see, neither of you has cited empirical data that contradicts this.)  Therefore, our studies present a challenge to the generality of the claim made by the proponent of IRI about evidence.]]></description>
		<content:encoded><![CDATA[<p>&#8220;But surely the interesting question is not whether the specific cases discussed by philosophers support IRI about evidence, but whether there is good evidence that stakes undermine rational confidence. And the latter seems strongly supported by extant psychological literature.&#8221;</p>
<p>I would agree that the first is not an interesting question.  What does strike me as an interesting question is whether the philosophical method of contrasting cases is a good way to get evidence in favor of certain views. Our studies suggest that it may be problematic to claim on the basis of reactions to contrast cases that our intuitions about a certain concept ordinarily (i.e. in non-contrast cases) vary in reaction to certain features which are manipulated in these contrast cases.</p>
<p>&#8220;The proponent of IRI about evidence claims that our judgments about the quality of evidence is affected by practical stakes.&#8221;</p>
<p>The studies you and Jennifer cite suggest that this claim is true of first-person judgments of the quality of evidence.  Our studies suggest that this claim is not true of third-person judgments of the quality of others evidence.  (So far as I can see, neither of you has cited empirical data that contradicts this.)  Therefore, our studies present a challenge to the generality of the claim made by the proponent of IRI about evidence.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jason Stanley</title>
		<link>http://certaindoubts.com/x-phi-on-bank-cases-and-pragmatic-encroachment/#comment-8081</link>
		<dc:creator><![CDATA[Jason Stanley]]></dc:creator>
		<pubDate>Fri, 08 Aug 2008 10:43:27 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=851#comment-8081</guid>
		<description><![CDATA[Here are some quotes from the 1990 Kunda survey article in The Psychological Bulletin brought to our attention by Jennifer Nagel:

&quot;The work on accuracy-driven reasoning suggests that when people are motivated to be accurate, they expend more cognitive effort on issue-related reasoning, attend to relevant information more carefully, and process it more deeply, often using more complex rules.&quot;

&quot;In these studies, accuracy goals are typically created by increasing the stakes involved in making a wrong judgment or in drawing the wrong conclusion, without increasing the attractiveness of any particular conclusion.&quot;

&quot;In sum, the case for accuracy-motivated reasoning appears quite strong. In the above studies subjects had no reason to prefer one conclusion or outcome over another; their sole goal was to be accurate. The evidence that people process information more carefully under such circumstances is considerable and persuasive.&quot;

In short - according to this summary of a very large body of empirical research in psychology, when you increase the stakes involved in making a wrong judgment, people regard ordinary methods of gathering evidence as less reliable than they ordinarily do. The most *straightforward* explanation of this large body of research in psychology is that IRI about evidence is true.]]></description>
		<content:encoded><![CDATA[<p>Here are some quotes from the 1990 Kunda survey article in The Psychological Bulletin brought to our attention by Jennifer Nagel:</p>
<p>&#8220;The work on accuracy-driven reasoning suggests that when people are motivated to be accurate, they expend more cognitive effort on issue-related reasoning, attend to relevant information more carefully, and process it more deeply, often using more complex rules.&#8221;</p>
<p>&#8220;In these studies, accuracy goals are typically created by increasing the stakes involved in making a wrong judgment or in drawing the wrong conclusion, without increasing the attractiveness of any particular conclusion.&#8221;</p>
<p>&#8220;In sum, the case for accuracy-motivated reasoning appears quite strong. In the above studies subjects had no reason to prefer one conclusion or outcome over another; their sole goal was to be accurate. The evidence that people process information more carefully under such circumstances is considerable and persuasive.&#8221;</p>
<p>In short &#8211; according to this summary of a very large body of empirical research in psychology, when you increase the stakes involved in making a wrong judgment, people regard ordinary methods of gathering evidence as less reliable than they ordinarily do. The most *straightforward* explanation of this large body of research in psychology is that IRI about evidence is true.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
