<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Fantl &#038; McGrath&#8217;s EPC Principle</title>
	<atom:link href="http://certaindoubts.com/fantl-mcgraths-epc-principle/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/#comment-1570</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Fri, 01 Apr 2005 21:34:38 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=273#comment-1570</guid>
		<description><![CDATA[Jeremy, no, I&#039;m not interpreting (3) as about rational preference.  The claim about carrying an assumption is about whether (4) follows from (3), which I (have to) claim it doesn&#039;t.  (On the assumption-carrying metaphor:  think of Lemon-style proof systems that track assumptions in the left margin--then any line of a good proof expresses the claim that if the assumptions are correct then the content of the line is true.  My suggestion is that rational preferences might sometimes work like that, so if the knowledge claims depend on p, then the rational preference isn&#039;t for A over B, but for A&amp;p over B&amp;p.) Also note that A and B are states of affairs, so talk about doing A rather than doing B is ill-formed.

Bottom line for me is I think Matt has outlined the logical structure of the issue very plainly.  It makes clear what any counterexample must do:  it must make it plausible to deny that, in that case, (4) is true even though (3) is.  Reaching the point of seeing that as the central point of contention is a nice accomplishment, since it clarifies what is at stake and the burden that any purported counterexample must carry, since, I take it, the plausible initial reaction to the suggested inference is that it looks pretty good.]]></description>
		<content:encoded><![CDATA[<p>Jeremy, no, I&#8217;m not interpreting (3) as about rational preference.  The claim about carrying an assumption is about whether (4) follows from (3), which I (have to) claim it doesn&#8217;t.  (On the assumption-carrying metaphor:  think of Lemon-style proof systems that track assumptions in the left margin&#8211;then any line of a good proof expresses the claim that if the assumptions are correct then the content of the line is true.  My suggestion is that rational preferences might sometimes work like that, so if the knowledge claims depend on p, then the rational preference isn&#8217;t for A over B, but for A&#038;p over B&#038;p.) Also note that A and B are states of affairs, so talk about doing A rather than doing B is ill-formed.</p>
<p>Bottom line for me is I think Matt has outlined the logical structure of the issue very plainly.  It makes clear what any counterexample must do:  it must make it plausible to deny that, in that case, (4) is true even though (3) is.  Reaching the point of seeing that as the central point of contention is a nice accomplishment, since it clarifies what is at stake and the burden that any purported counterexample must carry, since, I take it, the plausible initial reaction to the suggested inference is that it looks pretty good.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jeremy Fantl</title>
		<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/#comment-1569</link>
		<dc:creator><![CDATA[Jeremy Fantl]]></dc:creator>
		<pubDate>Fri, 01 Apr 2005 20:35:55 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=273#comment-1569</guid>
		<description><![CDATA[Jon, I guess I just haven&#039;t been convinced by the examples.  I don&#039;t, for example, have the intuition that I am rational to prefer hoping.  This is because I know that hoping will have the worst consequences for me.  You seem to be interpreting 3 as a claim about rational preference.  But it&#039;s not.  It&#039;s the claim that A will have better overall consequences in fact than B.  Certainly one could know this without knowing whether p is in fact the case.  The fact that I can also learn it by knowing p doesn&#039;t seem all that relevant.
   It seems quite clear in the case of action.  When A and B are actions, I don&#039;t know how 3 &quot;carries the assumption&quot; of p with it.  (I&#039;m not even sure what this means.)  We don&#039;t normally think that closure results in knowledge that &quot;carries the argument&quot; with it.  We just think we get to know the consequent.  All 3 says is that doing A will in fact have better overall consequences than B.
   So, I can know that doing A will in fact have better overall consequences than B.  When you agree to this and deny 4, then it seems like you are committed to say something like, &quot;I know that doing A is better than B -- doing B is worse than A -- but I should do B, not A.&quot;  And I suspect that there are going to be cases in which it gets even worse, in which you may end up committed to saying things like, &quot;I know that doing B is the worst thing I can do -- but I should do B.&quot;
   This all may hinge on whether there is sense to be made out of 3 &quot;carrying the assumption&quot; of p with it.  But, because 3 is not a claim about rational preference but about the in fact consequences of actions or the in fact ramifications of states of affairs being the case, I&#039;m not sure how sense can be made of it.]]></description>
		<content:encoded><![CDATA[<p>Jon, I guess I just haven&#8217;t been convinced by the examples.  I don&#8217;t, for example, have the intuition that I am rational to prefer hoping.  This is because I know that hoping will have the worst consequences for me.  You seem to be interpreting 3 as a claim about rational preference.  But it&#8217;s not.  It&#8217;s the claim that A will have better overall consequences in fact than B.  Certainly one could know this without knowing whether p is in fact the case.  The fact that I can also learn it by knowing p doesn&#8217;t seem all that relevant.<br />
   It seems quite clear in the case of action.  When A and B are actions, I don&#8217;t know how 3 &#8220;carries the assumption&#8221; of p with it.  (I&#8217;m not even sure what this means.)  We don&#8217;t normally think that closure results in knowledge that &#8220;carries the argument&#8221; with it.  We just think we get to know the consequent.  All 3 says is that doing A will in fact have better overall consequences than B.<br />
   So, I can know that doing A will in fact have better overall consequences than B.  When you agree to this and deny 4, then it seems like you are committed to say something like, &#8220;I know that doing A is better than B &#8212; doing B is worse than A &#8212; but I should do B, not A.&#8221;  And I suspect that there are going to be cases in which it gets even worse, in which you may end up committed to saying things like, &#8220;I know that doing B is the worst thing I can do &#8212; but I should do B.&#8221;<br />
   This all may hinge on whether there is sense to be made out of 3 &#8220;carrying the assumption&#8221; of p with it.  But, because 3 is not a claim about rational preference but about the in fact consequences of actions or the in fact ramifications of states of affairs being the case, I&#8217;m not sure how sense can be made of it.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/#comment-1567</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Fri, 01 Apr 2005 19:59:37 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=273#comment-1567</guid>
		<description><![CDATA[Matt, yes I agree that this is the logical structure of the issue (and glad you posted this comment about our emails, since it is so helpful to others following the discussion), and that the key is whether the knowledge claims in question allow one to derive (4) from (3).  On the one side of the issue is that (4) seems such a natural claim to say follows from (3).  On the other side are the examples, and the only way to read them as I do is to say that the account of rational preference is going to &quot;carry the assumptions&quot; on which (3) depends into the preferences in question (i.e., since A&#039;s being better than B depends on p, the account of rational preference need only claim that what is preferable is A&amp;p over B&amp;p).]]></description>
		<content:encoded><![CDATA[<p>Matt, yes I agree that this is the logical structure of the issue (and glad you posted this comment about our emails, since it is so helpful to others following the discussion), and that the key is whether the knowledge claims in question allow one to derive (4) from (3).  On the one side of the issue is that (4) seems such a natural claim to say follows from (3).  On the other side are the examples, and the only way to read them as I do is to say that the account of rational preference is going to &#8220;carry the assumptions&#8221; on which (3) depends into the preferences in question (i.e., since A&#8217;s being better than B depends on p, the account of rational preference need only claim that what is preferable is A&#038;p over B&#038;p).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: mcgrath</title>
		<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/#comment-1568</link>
		<dc:creator><![CDATA[mcgrath]]></dc:creator>
		<pubDate>Fri, 01 Apr 2005 14:07:00 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=273#comment-1568</guid>
		<description><![CDATA[Jon, one last comment concerning the &quot;key principle&quot; you mention.  Let&#039;s just assume a restriction on A/B/p such that whether A or B obtains is suitably independent of p (probabilistically, causally, or what you have).  Assuming the closure of knowledge under modus ponens, then from 1 and 2:

1. S knows p
2. S knows that if p then A is better than B,

one can infer:

3. S knows that A is better than B.

The issue is then whether from 3 we can infer:

4. S is rational to prefer A to B.

If so, we&#039;re in good shape.  If not, we&#039;re not.
     That&#039;s how the logical situation looks from here! Thanks for an interesting discussion.]]></description>
		<content:encoded><![CDATA[<p>Jon, one last comment concerning the &#8220;key principle&#8221; you mention.  Let&#8217;s just assume a restriction on A/B/p such that whether A or B obtains is suitably independent of p (probabilistically, causally, or what you have).  Assuming the closure of knowledge under modus ponens, then from 1 and 2:</p>
<p>1. S knows p<br />
2. S knows that if p then A is better than B,</p>
<p>one can infer:</p>
<p>3. S knows that A is better than B.</p>
<p>The issue is then whether from 3 we can infer:</p>
<p>4. S is rational to prefer A to B.</p>
<p>If so, we&#8217;re in good shape.  If not, we&#8217;re not.<br />
     That&#8217;s how the logical situation looks from here! Thanks for an interesting discussion.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/#comment-1566</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Wed, 30 Mar 2005 00:55:16 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=273#comment-1566</guid>
		<description><![CDATA[Jeremy, this is very nice; it at least shows what I&#039;m committed to in order to deny the principle.  Here&#039;s what I think, though.  First, you can&#039;t help me be hopeful for an afterlife, so I can&#039;t imagine what I&#039;d be betting on or paying for.  And being a money pump in this way just means that I shouldn&#039;t pay you in such cases.  It doesn&#039;t show that my preferences are irrational.

More helpful, however, is to sketch the picture of what I think happens in such cases to preferences. Here&#039;s the key principle I think is false:  Kp  &amp;   K(p-&gt;A is better than B)  =&gt; Rational to prefer A to B.  What follows from the two knowledge assumptions, I claim, is that it is rational to prefer A&amp;p to B&amp;p.  What learning p does to the mental life of a person is put in place an overriding structure among their mental states (if they are rational); it doesn&#039;t need to eliminate some of the mental states in question.  Prior to learning p, my preference for B over A might override my preference for A&amp;p over B&amp;p.  After learning p, this overriding structure changes.

So the question is whether to prefer this picture to the one you cite (and, as you might expect, I&#039;m unmoved by arguments that require that I think of rational preferences in terms of utilities or expected utilities--I assess these proposals by considering particular cases that I&#039;m very confident about... cases such as this one, for instance).  Here&#039;s why I think my picture is better--it explains my reactions when various possible futures develop better than the alternative that has me dropping a preference on pain of irrationality.]]></description>
		<content:encoded><![CDATA[<p>Jeremy, this is very nice; it at least shows what I&#8217;m committed to in order to deny the principle.  Here&#8217;s what I think, though.  First, you can&#8217;t help me be hopeful for an afterlife, so I can&#8217;t imagine what I&#8217;d be betting on or paying for.  And being a money pump in this way just means that I shouldn&#8217;t pay you in such cases.  It doesn&#8217;t show that my preferences are irrational.</p>
<p>More helpful, however, is to sketch the picture of what I think happens in such cases to preferences. Here&#8217;s the key principle I think is false:  Kp  &#038;   K(p->A is better than B)  => Rational to prefer A to B.  What follows from the two knowledge assumptions, I claim, is that it is rational to prefer A&#038;p to B&#038;p.  What learning p does to the mental life of a person is put in place an overriding structure among their mental states (if they are rational); it doesn&#8217;t need to eliminate some of the mental states in question.  Prior to learning p, my preference for B over A might override my preference for A&#038;p over B&#038;p.  After learning p, this overriding structure changes.</p>
<p>So the question is whether to prefer this picture to the one you cite (and, as you might expect, I&#8217;m unmoved by arguments that require that I think of rational preferences in terms of utilities or expected utilities&#8211;I assess these proposals by considering particular cases that I&#8217;m very confident about&#8230; cases such as this one, for instance).  Here&#8217;s why I think my picture is better&#8211;it explains my reactions when various possible futures develop better than the alternative that has me dropping a preference on pain of irrationality.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jeremy Fantl</title>
		<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/#comment-1565</link>
		<dc:creator><![CDATA[Jeremy Fantl]]></dc:creator>
		<pubDate>Tue, 29 Mar 2005 22:23:48 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=273#comment-1565</guid>
		<description><![CDATA[At the risk of stepping into a horrible decision-theoretic trap, I&#039;m going to say that I do like this rule, assuming that it&#039;s appropriately restricted and that &quot;Given: ~A&quot; means that ~A is known.  One problem with denying the rule is that, if you reason out of accord with the rule, it looks like you can fall victim to a Dutch book.  After all, if you prefer H to ~H, then presumably you will pay a little bit if I could help you achieve H.  But, once I do, ~A&amp;H will be the case, and you will know that this is so.  But you prefer ~A&amp;~H to that, so presumably you will pay me just a little bit to make it the case that ~A&amp;~H.  But now ~H is once again the case, and you prefer H to that.  This makes you a money pump.
   I know that Dutch book arguments aren&#039;t all that convincing, but the general worry, it seems to me, is that by denying the rule, you end up saying that you are rational prefer the state of affairs that you know will, if it obtains, result in the state of affairs that you prefer least of all.
   Perhaps there is some ambiguity between a notion of rational preference abstracted from what people in fact know to be the case, and a notion of rational preference in fact.  We&#039;re definitely talking about the latter.  But I also don&#039;t want this discussion to get too bogged down in details of PC.  All that is needed for pragmatic encroachment is that what Matt labeled &quot;FM&quot; be true.  Once the discussion turns to stronger propositions (like PC), there might be others issues involved: what is meant by &quot;given p&quot;, whether there is ambiguity in the notion of rational preference, etc.  But none of these issues touch FM, and so none of them seem to touch the core of the case for pragmatic encroachment.]]></description>
		<content:encoded><![CDATA[<p>At the risk of stepping into a horrible decision-theoretic trap, I&#8217;m going to say that I do like this rule, assuming that it&#8217;s appropriately restricted and that &#8220;Given: ~A&#8221; means that ~A is known.  One problem with denying the rule is that, if you reason out of accord with the rule, it looks like you can fall victim to a Dutch book.  After all, if you prefer H to ~H, then presumably you will pay a little bit if I could help you achieve H.  But, once I do, ~A&#038;H will be the case, and you will know that this is so.  But you prefer ~A&#038;~H to that, so presumably you will pay me just a little bit to make it the case that ~A&#038;~H.  But now ~H is once again the case, and you prefer H to that.  This makes you a money pump.<br />
   I know that Dutch book arguments aren&#8217;t all that convincing, but the general worry, it seems to me, is that by denying the rule, you end up saying that you are rational prefer the state of affairs that you know will, if it obtains, result in the state of affairs that you prefer least of all.<br />
   Perhaps there is some ambiguity between a notion of rational preference abstracted from what people in fact know to be the case, and a notion of rational preference in fact.  We&#8217;re definitely talking about the latter.  But I also don&#8217;t want this discussion to get too bogged down in details of PC.  All that is needed for pragmatic encroachment is that what Matt labeled &#8220;FM&#8221; be true.  Once the discussion turns to stronger propositions (like PC), there might be others issues involved: what is meant by &#8220;given p&#8221;, whether there is ambiguity in the notion of rational preference, etc.  But none of these issues touch FM, and so none of them seem to touch the core of the case for pragmatic encroachment.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/#comment-1564</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Tue, 29 Mar 2005 18:22:00 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=273#comment-1564</guid>
		<description><![CDATA[Jeremy, I think if you symbolize the relationships here, you&#039;ll see that I&#039;m denying the use of certain first-order rules within the scope of a rational preferability operator (and maybe this is a mistake I&#039;m making).  Here&#039;s the details:
~RP(~A&amp;H) to it&#039;s opposite.
RP(H) to it&#039;s opposite.
Given:  ~A.
Therefore, ~RP(H).

So the question is how to get ~RP(H) to follow from the first and third claims here.  One way is to allow &amp;-E within the scope of the operator in the first premise when one of the claims is true (or given).  That&#039;s the rule that I&#039;m denying here, and because I deny it, I claim there&#039;s no inconsistency between the first and third premises and the second.  Do you think this rule is a good one?]]></description>
		<content:encoded><![CDATA[<p>Jeremy, I think if you symbolize the relationships here, you&#8217;ll see that I&#8217;m denying the use of certain first-order rules within the scope of a rational preferability operator (and maybe this is a mistake I&#8217;m making).  Here&#8217;s the details:<br />
~RP(~A&#038;H) to it&#8217;s opposite.<br />
RP(H) to it&#8217;s opposite.<br />
Given:  ~A.<br />
Therefore, ~RP(H).</p>
<p>So the question is how to get ~RP(H) to follow from the first and third claims here.  One way is to allow &#038;-E within the scope of the operator in the first premise when one of the claims is true (or given).  That&#8217;s the rule that I&#8217;m denying here, and because I deny it, I claim there&#8217;s no inconsistency between the first and third premises and the second.  Do you think this rule is a good one?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jeremy Fantl</title>
		<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/#comment-1563</link>
		<dc:creator><![CDATA[Jeremy Fantl]]></dc:creator>
		<pubDate>Tue, 29 Mar 2005 17:07:40 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=273#comment-1563</guid>
		<description><![CDATA[Jon, I still find myself confused, and I&#039;m beginning to think that I&#039;m at fault.  Here&#039;s the state of affairs that will be worst for me: no afterlife + hope.  You grant that, I guess, because that&#039;s the antecedent from above.  Now I find out that there is no afterlife.  So, I know that there is only one way to avoid that (worst) state of affairs, and that&#039;s by not hoping.  So, I know that, if I do hope, I will not avoid that worst state of affairs.  And that&#039;s the consequent.  If there were some probabilistic relation between hoping and there being an afterlife, things might be different.  But we are supposing there is not.  What am I missing?]]></description>
		<content:encoded><![CDATA[<p>Jon, I still find myself confused, and I&#8217;m beginning to think that I&#8217;m at fault.  Here&#8217;s the state of affairs that will be worst for me: no afterlife + hope.  You grant that, I guess, because that&#8217;s the antecedent from above.  Now I find out that there is no afterlife.  So, I know that there is only one way to avoid that (worst) state of affairs, and that&#8217;s by not hoping.  So, I know that, if I do hope, I will not avoid that worst state of affairs.  And that&#8217;s the consequent.  If there were some probabilistic relation between hoping and there being an afterlife, things might be different.  But we are supposing there is not.  What am I missing?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: mcgrath</title>
		<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/#comment-1562</link>
		<dc:creator><![CDATA[mcgrath]]></dc:creator>
		<pubDate>Tue, 29 Mar 2005 15:18:04 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=273#comment-1562</guid>
		<description><![CDATA[Jon, I wonder if it would help here to distinguish value from expected value.  I agree that, for her parents, the value of Schiavo living is higher than the value of her dying.  But for her parents the expected value of her living is rather low, I think, because the probability of her living in a non-vegetative state is extremely small.

I know decision theorists sometimes speak of worlds as having value and not only expected value.  Expected value of state of affairs or propositions, in the end, is explained in terms of the value simpliciter of worlds.  I would think that one might be able to extend this notion of the value of a world to apply to states of affairs.  (We quickly will get ourselves into tricky issues about intrinsic value and its relation to final value.)

We mean our principle PC to apply to the expected value of states of affairs, not their value simpliciter.  That&#039;s what we have in mind by talk of &#039;rational to prefer&#039;.

Does that help a bit?]]></description>
		<content:encoded><![CDATA[<p>Jon, I wonder if it would help here to distinguish value from expected value.  I agree that, for her parents, the value of Schiavo living is higher than the value of her dying.  But for her parents the expected value of her living is rather low, I think, because the probability of her living in a non-vegetative state is extremely small.</p>
<p>I know decision theorists sometimes speak of worlds as having value and not only expected value.  Expected value of state of affairs or propositions, in the end, is explained in terms of the value simpliciter of worlds.  I would think that one might be able to extend this notion of the value of a world to apply to states of affairs.  (We quickly will get ourselves into tricky issues about intrinsic value and its relation to final value.)</p>
<p>We mean our principle PC to apply to the expected value of states of affairs, not their value simpliciter.  That&#8217;s what we have in mind by talk of &#8216;rational to prefer&#8217;.</p>
<p>Does that help a bit?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/fantl-mcgraths-epc-principle/#comment-1561</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Tue, 29 Mar 2005 15:10:04 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=273#comment-1561</guid>
		<description><![CDATA[Jeremy, don&#039;t worry, I was joking about the irrationality charge.  And besides, there&#039;s at least some chance that I *am* irrational...:-)

Here&#039;s the sentence that I think is false in the argument you give above:
&lt;blockquote&gt;And if I that it will be worst for me if I hope and there is no afterlife, then I know that, if there is no afterlife, it will be worst for me to hope.&lt;/blockquote&gt;
The antecedent here is true (suitably corrected), but the consequent is false.  I rationally prefer not to hope and there be no afterlife.  But that doesn&#039;t imply that if there is no afterlife, it is better not to hope for an afterlife.  It implies that if I know there is no afterlife, then my inner mental life is structured in such a way (given that I&#039;m being rational) that actions depending on these features answer to the overriding conditions and not to the hope in question.]]></description>
		<content:encoded><![CDATA[<p>Jeremy, don&#8217;t worry, I was joking about the irrationality charge.  And besides, there&#8217;s at least some chance that I *am* irrational&#8230;:-)</p>
<p>Here&#8217;s the sentence that I think is false in the argument you give above:</p>
<blockquote><p>And if I that it will be worst for me if I hope and there is no afterlife, then I know that, if there is no afterlife, it will be worst for me to hope.</p></blockquote>
<p>The antecedent here is true (suitably corrected), but the consequent is false.  I rationally prefer not to hope and there be no afterlife.  But that doesn&#8217;t imply that if there is no afterlife, it is better not to hope for an afterlife.  It implies that if I know there is no afterlife, then my inner mental life is structured in such a way (given that I&#8217;m being rational) that actions depending on these features answer to the overriding conditions and not to the hope in question.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
