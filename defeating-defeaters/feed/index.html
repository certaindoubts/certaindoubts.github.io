<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Defeating Defeaters</title>
	<atom:link href="http://certaindoubts.com/defeating-defeaters/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/defeating-defeaters/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Matt Skene</title>
		<link>http://certaindoubts.com/defeating-defeaters/#comment-29749</link>
		<dc:creator><![CDATA[Matt Skene]]></dc:creator>
		<pubDate>Tue, 15 May 2012 15:00:55 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3441#comment-29749</guid>
		<description><![CDATA[I guess I wasn&#039;t individuating methods as finely as you are.  I would have thought that checking for coherence among various methods of solving a problem would have counted as an aspect of mathematical reasoning, not a separate form of reasoning on its own.  In general, I would think that methods that cover any broad range of beliefs are very complex, and that most if not all of them include self-regulating and self-correcting aspects such as checking their outputs for coherence.  Since I thought of the methods as complex in this way, I thought that a defeater would have to cut off all of the routes available for self-correction from within the method before we should say that we can&#039;t use the method itself as a basis for rebutting the defeater.  A general reason to think one is not good as mathematical reasoning, such as the one you suggested, wouldn&#039;t do the work because it would leave enough available resources to test whether or not the defeating evidence was sound.  I guess if we&#039;re individuating methods more finely, so as not to include those self-correcting aspects, then this wouldn&#039;t work, but I have a hard time understanding why we should think that mathematical reasoning isn&#039;t more complex.

As for the other case, I was trying to think of a simple situation where all the available internal tests were corrupted in the same way.  I figured that the simplest way to do so was to give you good evidence that an outside intelligence was directly and deliberately misleading you in all of your intellectual endeavors.  I was assuming that in this case your belief was correct; the demon really is messing with your mind, and the one thing he lets you know is that he is doing so.  Anti-invincibility seems to require that we can never be put into an epistemically doomed situation and still become aware of this fact.  I can&#039;t see why we should think that isn&#039;t possible, though.  

It&#039;s worth pointing out in this case, though, that the reason the defeater is invincible isn&#039;t merely because of its generality; it&#039;s because it is a sufficiently broad and specific type of defeater to cut off all avenues of approach for fixing the problem.]]></description>
		<content:encoded><![CDATA[<p>I guess I wasn&#8217;t individuating methods as finely as you are.  I would have thought that checking for coherence among various methods of solving a problem would have counted as an aspect of mathematical reasoning, not a separate form of reasoning on its own.  In general, I would think that methods that cover any broad range of beliefs are very complex, and that most if not all of them include self-regulating and self-correcting aspects such as checking their outputs for coherence.  Since I thought of the methods as complex in this way, I thought that a defeater would have to cut off all of the routes available for self-correction from within the method before we should say that we can&#8217;t use the method itself as a basis for rebutting the defeater.  A general reason to think one is not good as mathematical reasoning, such as the one you suggested, wouldn&#8217;t do the work because it would leave enough available resources to test whether or not the defeating evidence was sound.  I guess if we&#8217;re individuating methods more finely, so as not to include those self-correcting aspects, then this wouldn&#8217;t work, but I have a hard time understanding why we should think that mathematical reasoning isn&#8217;t more complex.</p>
<p>As for the other case, I was trying to think of a simple situation where all the available internal tests were corrupted in the same way.  I figured that the simplest way to do so was to give you good evidence that an outside intelligence was directly and deliberately misleading you in all of your intellectual endeavors.  I was assuming that in this case your belief was correct; the demon really is messing with your mind, and the one thing he lets you know is that he is doing so.  Anti-invincibility seems to require that we can never be put into an epistemically doomed situation and still become aware of this fact.  I can&#8217;t see why we should think that isn&#8217;t possible, though.  </p>
<p>It&#8217;s worth pointing out in this case, though, that the reason the defeater is invincible isn&#8217;t merely because of its generality; it&#8217;s because it is a sufficiently broad and specific type of defeater to cut off all avenues of approach for fixing the problem.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Chris Tucker</title>
		<link>http://certaindoubts.com/defeating-defeaters/#comment-29659</link>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
		<pubDate>Sun, 13 May 2012 21:06:59 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3441#comment-29659</guid>
		<description><![CDATA[Hi Matt,

That&#039;s very helpful.  I now see the problem with the drug/mathematics case as it was described, but I don&#039;t think it matters for the main argument of the post.  What you (and perhaps James) point out is that one could rely on the coherence of the different mathematical checks to determine that it&#039;s unlikely that I&#039;ve been given the drug.  I see the point.  But relying on the coherence of mathematical checks doesn&#039;t violate Independence, because, by engaging in coherence-based reasoning, I&#039;m relying, in part, on a type of non-mathematical reasoning. So this case doesn&#039;t seem to motivate Independence very well.  But, since the point of the post was to object to Independence, I&#039;m not sure why the main argument would inherit the defects of my motivation for Independence. (I&#039;m not sure I understand the final three sentences of your first paragraph.  If you still think the overall argument has a problem, could you clarify?)

As far as Anti-Invincibility goes, I don&#039;t share the intuitions in your cases.  If I acquire evidence E1 that an evil demon is going to cause me to make mistakes quite often, and I acquire evidence that E1 is misleading, then wouldn&#039;t E1 be at least partially defeated?  As long it is possible for some subject to have E1 and acquire evidence that E1 is misleading, then E1 doesn&#039;t seem invincible to me in the sense I intended.  A similar point applies to the &quot;screwing with your mind&quot; case.  Now, the word &quot;know&quot; features prominently in your two cases (the demon let you &lt;i&gt;know&lt;/i&gt;..., and you &lt;i&gt;know&lt;/i&gt; that someone is screwing with you).  Was that fact that you &lt;i&gt;know&lt;/i&gt; about the demon activity--rather than just having evidence about it--supposed to do some important work that I&#039;m missing?]]></description>
		<content:encoded><![CDATA[<p>Hi Matt,</p>
<p>That&#8217;s very helpful.  I now see the problem with the drug/mathematics case as it was described, but I don&#8217;t think it matters for the main argument of the post.  What you (and perhaps James) point out is that one could rely on the coherence of the different mathematical checks to determine that it&#8217;s unlikely that I&#8217;ve been given the drug.  I see the point.  But relying on the coherence of mathematical checks doesn&#8217;t violate Independence, because, by engaging in coherence-based reasoning, I&#8217;m relying, in part, on a type of non-mathematical reasoning. So this case doesn&#8217;t seem to motivate Independence very well.  But, since the point of the post was to object to Independence, I&#8217;m not sure why the main argument would inherit the defects of my motivation for Independence. (I&#8217;m not sure I understand the final three sentences of your first paragraph.  If you still think the overall argument has a problem, could you clarify?)</p>
<p>As far as Anti-Invincibility goes, I don&#8217;t share the intuitions in your cases.  If I acquire evidence E1 that an evil demon is going to cause me to make mistakes quite often, and I acquire evidence that E1 is misleading, then wouldn&#8217;t E1 be at least partially defeated?  As long it is possible for some subject to have E1 and acquire evidence that E1 is misleading, then E1 doesn&#8217;t seem invincible to me in the sense I intended.  A similar point applies to the &#8220;screwing with your mind&#8221; case.  Now, the word &#8220;know&#8221; features prominently in your two cases (the demon let you <i>know</i>&#8230;, and you <i>know</i> that someone is screwing with you).  Was that fact that you <i>know</i> about the demon activity&#8211;rather than just having evidence about it&#8211;supposed to do some important work that I&#8217;m missing?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Matt Skene</title>
		<link>http://certaindoubts.com/defeating-defeaters/#comment-29602</link>
		<dc:creator><![CDATA[Matt Skene]]></dc:creator>
		<pubDate>Fri, 11 May 2012 14:36:45 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3441#comment-29602</guid>
		<description><![CDATA[I&#039;m pretty sure that James&#039; point was that it is impossible for a drug to cause you to make such specific errors no matter how you approach the question.  A drug that makes your mathematical reasoning unreliable would lead to random errors, not to the same wrong answer no matter how you approach the problem.  Because of this, finding the same answer from different approaches seems to defeat your evidence for the view that your mathematical reasoning is unreliable.    To create an undercutting defeater that is compatible with such systematic error, you would likely need intelligent, deliberate deception each time.  This matters for creating the problem you have in mind because it means that the generality of a defeater by itself isn&#039;t doing the work.  You need the defeater to have specific features that negate standard methods for confirming our beliefs that are internal to the area of belief formation.  This means that Independence isn&#039;t true if it is supposed to be read as a universal generalization.  

However, you don&#039;t seem to need a universal version of Independence to create an inconsistency.  If there are specific types of undercutting defeaters that can&#039;t be overridden by evidence internal to the method, then there could still be examples of undercutting defeaters that violate Anti-invincibility.  However, in a case where you add in enough features to get around all these internal measures of confirmation, I don&#039;t see why we should accept Anti-Invincibility.  Suppose an evil demon let you know that he existed and that he was going to cause you to have erroneous beliefs quite often.  In that situation, there doesn&#039;t seem to be anything you could do to fix this problem.  If you know that someone is actually directly screwing with your mind, and you can&#039;t do anything to stop them, there&#039;s probably nothing you can do to overcome this sort of defeating evidence.  So, if you&#039;re trying to show that you can&#039;t create an Invincible defeater just by creating a general defeater, that seems correct.  But I don&#039;t see why we should think that there can&#039;t be invincible defeaters.]]></description>
		<content:encoded><![CDATA[<p>I&#8217;m pretty sure that James&#8217; point was that it is impossible for a drug to cause you to make such specific errors no matter how you approach the question.  A drug that makes your mathematical reasoning unreliable would lead to random errors, not to the same wrong answer no matter how you approach the problem.  Because of this, finding the same answer from different approaches seems to defeat your evidence for the view that your mathematical reasoning is unreliable.    To create an undercutting defeater that is compatible with such systematic error, you would likely need intelligent, deliberate deception each time.  This matters for creating the problem you have in mind because it means that the generality of a defeater by itself isn&#8217;t doing the work.  You need the defeater to have specific features that negate standard methods for confirming our beliefs that are internal to the area of belief formation.  This means that Independence isn&#8217;t true if it is supposed to be read as a universal generalization.  </p>
<p>However, you don&#8217;t seem to need a universal version of Independence to create an inconsistency.  If there are specific types of undercutting defeaters that can&#8217;t be overridden by evidence internal to the method, then there could still be examples of undercutting defeaters that violate Anti-invincibility.  However, in a case where you add in enough features to get around all these internal measures of confirmation, I don&#8217;t see why we should accept Anti-Invincibility.  Suppose an evil demon let you know that he existed and that he was going to cause you to have erroneous beliefs quite often.  In that situation, there doesn&#8217;t seem to be anything you could do to fix this problem.  If you know that someone is actually directly screwing with your mind, and you can&#8217;t do anything to stop them, there&#8217;s probably nothing you can do to overcome this sort of defeating evidence.  So, if you&#8217;re trying to show that you can&#8217;t create an Invincible defeater just by creating a general defeater, that seems correct.  But I don&#8217;t see why we should think that there can&#8217;t be invincible defeaters.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Chris Tucker</title>
		<link>http://certaindoubts.com/defeating-defeaters/#comment-29554</link>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
		<pubDate>Thu, 10 May 2012 22:24:39 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3441#comment-29554</guid>
		<description><![CDATA[Hi James,

The used car case wasn&#039;t intended as an analogy.  It was just a case that elicits the intuition in favor of Independence.  I think that there is an important disanalogy between that case and some of the others, which explains what&#039;s wrong with the &quot;circular&quot; reasoning in the used car case which is not available in the other cases.  But I&#039;ll leave that for another day.  I&#039;m not sure I understand your concerns about the switches between honesty and reliability, but the key points all concern reliability.  So mentally &quot;re-write&quot; the case in that way, if it makes it clearer.

Do you really think it is &lt;i&gt;im&lt;/i&gt;possible for a drug to make our mathematical reasoning unreliable?  And, more importantly, do think it is impossible for someone to have strong evidence that they have just ingested such a drug?  In any event, the case seems to work just as well if you have evidence that a demon has targeted your mathematical reasoning in the relevant way.]]></description>
		<content:encoded><![CDATA[<p>Hi James,</p>
<p>The used car case wasn&#8217;t intended as an analogy.  It was just a case that elicits the intuition in favor of Independence.  I think that there is an important disanalogy between that case and some of the others, which explains what&#8217;s wrong with the &#8220;circular&#8221; reasoning in the used car case which is not available in the other cases.  But I&#8217;ll leave that for another day.  I&#8217;m not sure I understand your concerns about the switches between honesty and reliability, but the key points all concern reliability.  So mentally &#8220;re-write&#8221; the case in that way, if it makes it clearer.</p>
<p>Do you really think it is <i>im</i>possible for a drug to make our mathematical reasoning unreliable?  And, more importantly, do think it is impossible for someone to have strong evidence that they have just ingested such a drug?  In any event, the case seems to work just as well if you have evidence that a demon has targeted your mathematical reasoning in the relevant way.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: james</title>
		<link>http://certaindoubts.com/defeating-defeaters/#comment-29510</link>
		<dc:creator><![CDATA[james]]></dc:creator>
		<pubDate>Wed, 09 May 2012 22:30:44 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3441#comment-29510</guid>
		<description><![CDATA[The used car salesman strikes me as a really bad analogy because the example makes us think of a dishonest used car salesman who is trying to cheat us, and obviously someone like that would lie and say he was honest.  In fact, you even switch between &quot;reliable&quot; and &quot;honest&quot;.

If you have evidence that an evil demon is systematically screwing with your mathematics reasoning so that you keep arriving at the same wrong answers by different methods then, yeah, you shouldn&#039;t trust the checks you are doing.  But no drug could have that sort of intelligence, I would say in the drug case you are right to think that you are reliable after all.]]></description>
		<content:encoded><![CDATA[<p>The used car salesman strikes me as a really bad analogy because the example makes us think of a dishonest used car salesman who is trying to cheat us, and obviously someone like that would lie and say he was honest.  In fact, you even switch between &#8220;reliable&#8221; and &#8220;honest&#8221;.</p>
<p>If you have evidence that an evil demon is systematically screwing with your mathematics reasoning so that you keep arriving at the same wrong answers by different methods then, yeah, you shouldn&#8217;t trust the checks you are doing.  But no drug could have that sort of intelligence, I would say in the drug case you are right to think that you are reliable after all.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Chris Tucker</title>
		<link>http://certaindoubts.com/defeating-defeaters/#comment-29506</link>
		<dc:creator><![CDATA[Chris Tucker]]></dc:creator>
		<pubDate>Wed, 09 May 2012 21:21:09 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3441#comment-29506</guid>
		<description><![CDATA[Hi Dan,

Good questions.  It was concerns like these that led me to formulate the worry in the way that I did.  I&#039;m not just concerned with undercutting evidence that makes it irrational to believe something; I&#039;m also concerned with undercutting which makes me less justified in believing P (e.g. I should lower my credence from .99, say, to .98).  If I have reliable testimony of the sort described that all of my belief-forming methods are unreliable, it is very plausible that I should have at least some marginally less confidence in my beliefs than I did before I acquired that testimony.  And this is so, because it is plausible that reliable testimony of the sort describe provides evidence against the reliability of your belief-forming methods.  But if that undercutting evidence is invincible, than I can&#039;t recoup that lost, perhaps minute, degree of justification even if I discover evidence that the whole thing is a gag.  But that seems strange.  

I hope this clarification shows two things.  First, we can grant that we can raise doubts about some beliefs only by taking others for granted and the problem still remains--at least, this is so as long as &#039;taking for granted&#039; doesn&#039;t require absolute certainty.  And it shouldn&#039;t require absolute certainty: I can doubt that there is purple elephant in the room because I take the reliability of perception for granted without being certain that perception is reliable.  Second, in saying that the testimony of the described sort to provide evidence of global unreliability, I am making a very weak and plausible claim.  This evidence need only be strong enough to lead to a minute loss of justification, and it needn&#039;t make it irrational to believe all of my beliefs.

I think, then, I have responded to the main points in your comment.  That leaves the worries about method individuation.  I do think there are some tricky issues here, but I think they only affect the precision with which the argument can be given.  We have some intuitive grasp of the distinction between belief-forming methods that are &quot;natural&quot; and those that are &quot;gerrymandered&quot;.  The method of visual perception seems more natural than the method of believing something on the basis of an argument on Tuesdays when you are at work with the window open.  We should restrict our focus solely to &quot;natural&quot; methods rather than gerrymandered ones, because it is less clear to me that I have undercutting evidence when I take the unreliable method to be gerrymandered.  I don&#039;t think this should introduce any problems, but who knows.]]></description>
		<content:encoded><![CDATA[<p>Hi Dan,</p>
<p>Good questions.  It was concerns like these that led me to formulate the worry in the way that I did.  I&#8217;m not just concerned with undercutting evidence that makes it irrational to believe something; I&#8217;m also concerned with undercutting which makes me less justified in believing P (e.g. I should lower my credence from .99, say, to .98).  If I have reliable testimony of the sort described that all of my belief-forming methods are unreliable, it is very plausible that I should have at least some marginally less confidence in my beliefs than I did before I acquired that testimony.  And this is so, because it is plausible that reliable testimony of the sort describe provides evidence against the reliability of your belief-forming methods.  But if that undercutting evidence is invincible, than I can&#8217;t recoup that lost, perhaps minute, degree of justification even if I discover evidence that the whole thing is a gag.  But that seems strange.  </p>
<p>I hope this clarification shows two things.  First, we can grant that we can raise doubts about some beliefs only by taking others for granted and the problem still remains&#8211;at least, this is so as long as &#8216;taking for granted&#8217; doesn&#8217;t require absolute certainty.  And it shouldn&#8217;t require absolute certainty: I can doubt that there is purple elephant in the room because I take the reliability of perception for granted without being certain that perception is reliable.  Second, in saying that the testimony of the described sort to provide evidence of global unreliability, I am making a very weak and plausible claim.  This evidence need only be strong enough to lead to a minute loss of justification, and it needn&#8217;t make it irrational to believe all of my beliefs.</p>
<p>I think, then, I have responded to the main points in your comment.  That leaves the worries about method individuation.  I do think there are some tricky issues here, but I think they only affect the precision with which the argument can be given.  We have some intuitive grasp of the distinction between belief-forming methods that are &#8220;natural&#8221; and those that are &#8220;gerrymandered&#8221;.  The method of visual perception seems more natural than the method of believing something on the basis of an argument on Tuesdays when you are at work with the window open.  We should restrict our focus solely to &#8220;natural&#8221; methods rather than gerrymandered ones, because it is less clear to me that I have undercutting evidence when I take the unreliable method to be gerrymandered.  I don&#8217;t think this should introduce any problems, but who knows.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Daniel Greco</title>
		<link>http://certaindoubts.com/defeating-defeaters/#comment-29504</link>
		<dc:creator><![CDATA[Daniel Greco]]></dc:creator>
		<pubDate>Wed, 09 May 2012 20:41:35 +0000</pubDate>
		<guid isPermaLink="false">http://el-prod.baylor.edu/certain_doubts/?p=3441#comment-29504</guid>
		<description><![CDATA[You suggest that we&#039;re faced with a choice of rejecting Independence or Anti-Invincibility. I might be happy to reject one of those, but I&#039;m also pretty suspicious about the possibility of global undercutting. Lots of philosophers have doubted the intelligibility/possibility of questioning all one&#039;s beliefs at once. On a broadly coherentist/Neurathian/Wittgensteinian position, it&#039;s only by taking some beliefs (and probably belief forming methods) for granted that we can raise doubts about others. If you&#039;re at all sympathetic to that line of thought, then you should be skeptical that any evidence could simultaneously throw all our beliefs/belief forming methods into doubt. 

That still leaves the question of what&#039;s to be said about the case when a reliable source testifies that all your belief forming methods are unreliable. I&#039;m not sure what to say about the case, but it strikes me as at the very least a tricky case, rather than as a clear example in which you get evidence that all your belief forming methods are unreliable. For one, it seems like it&#039;s only by taking the testifier(s) to be a reliable source of evidence that you can treat the testimony as undercutting the rest of your beliefs. Perhaps this will turn on how we individuate belief-forming methods?]]></description>
		<content:encoded><![CDATA[<p>You suggest that we&#8217;re faced with a choice of rejecting Independence or Anti-Invincibility. I might be happy to reject one of those, but I&#8217;m also pretty suspicious about the possibility of global undercutting. Lots of philosophers have doubted the intelligibility/possibility of questioning all one&#8217;s beliefs at once. On a broadly coherentist/Neurathian/Wittgensteinian position, it&#8217;s only by taking some beliefs (and probably belief forming methods) for granted that we can raise doubts about others. If you&#8217;re at all sympathetic to that line of thought, then you should be skeptical that any evidence could simultaneously throw all our beliefs/belief forming methods into doubt. </p>
<p>That still leaves the question of what&#8217;s to be said about the case when a reliable source testifies that all your belief forming methods are unreliable. I&#8217;m not sure what to say about the case, but it strikes me as at the very least a tricky case, rather than as a clear example in which you get evidence that all your belief forming methods are unreliable. For one, it seems like it&#8217;s only by taking the testifier(s) to be a reliable source of evidence that you can treat the testimony as undercutting the rest of your beliefs. Perhaps this will turn on how we individuate belief-forming methods?</p>
]]></content:encoded>
	</item>
</channel>
</rss>
