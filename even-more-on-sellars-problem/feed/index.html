<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Even more on Sellars&#8217; Problem</title>
	<atom:link href="http://certaindoubts.com/even-more-on-sellars-problem/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/even-more-on-sellars-problem/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/even-more-on-sellars-problem/#comment-190</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Wed, 30 Jun 2004 18:51:01 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=36#comment-190</guid>
		<description><![CDATA[Excellent stuff, Steven!  On the hardwired worry, I think I know a way around your concern.  The normativity that is epistemic is different because it is defeasible by further information one can acquire, even when the disposition is hardwired.  Moreover, such hardwired dispositions can only be part of the epistemic story, since learned recognition skills are clearly part of what needs to be accounted for.  I think you&#039;re right that the kind of normativity would be different from the paradigm cases of epistemic assessment, but I think that&#039;s OK as long as there is a way to distinguish the normativity here from cases like the digestive cases.

On the pain case, I really don&#039;t know what to say anymore.  There was a time when I was thoroughly convinced that cases like the one you imagine should be handled linguistically in terms of not knowing the meaning of the term.  But Lehrer&#039;s pain/itch example has led me to think that there can be something much more theoretical going on, even with the very first experiences of pain. The linguistic approach is necessary, I think, if you want to preserve infallible access here, but I don&#039;t, and the result is that I don&#039;t know what to say about the case.  But, if the matter isn&#039;t purely linguistic, then I don&#039;t see why we should say that the person is justified in thinking he&#039;s in pain.  Does that seem right to you?]]></description>
		<content:encoded><![CDATA[<p>Excellent stuff, Steven!  On the hardwired worry, I think I know a way around your concern.  The normativity that is epistemic is different because it is defeasible by further information one can acquire, even when the disposition is hardwired.  Moreover, such hardwired dispositions can only be part of the epistemic story, since learned recognition skills are clearly part of what needs to be accounted for.  I think you&#8217;re right that the kind of normativity would be different from the paradigm cases of epistemic assessment, but I think that&#8217;s OK as long as there is a way to distinguish the normativity here from cases like the digestive cases.</p>
<p>On the pain case, I really don&#8217;t know what to say anymore.  There was a time when I was thoroughly convinced that cases like the one you imagine should be handled linguistically in terms of not knowing the meaning of the term.  But Lehrer&#8217;s pain/itch example has led me to think that there can be something much more theoretical going on, even with the very first experiences of pain. The linguistic approach is necessary, I think, if you want to preserve infallible access here, but I don&#8217;t, and the result is that I don&#8217;t know what to say about the case.  But, if the matter isn&#8217;t purely linguistic, then I don&#8217;t see why we should say that the person is justified in thinking he&#8217;s in pain.  Does that seem right to you?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Steven Reynolds</title>
		<link>http://certaindoubts.com/even-more-on-sellars-problem/#comment-189</link>
		<dc:creator><![CDATA[Steven Reynolds]]></dc:creator>
		<pubDate>Wed, 30 Jun 2004 16:09:36 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=36#comment-189</guid>
		<description><![CDATA[This pain case is interesting. I think some distinction between carrying information and having content is needed -- the dust on the floor carries information (e.g., about the shoes that have walked in it) but something more is needed for content. Even perceptual systems carry information that doesn&#039;t get reflected in representational content --e.g., the info in the optic nerve about the cells in the retina that were stimulated, which mostly gets &quot;thrown away&quot; in the later processing. Representational content, even of the non-conceptual sort, needs to be something more than information, or even information in a system whose proper functioning makes use of that information, as in the example just given. Real representational content seems to require a certain kind of role in a psychological system. So would the person who has just now started to have pain sensations be able to believe that he was in pain? Maybe he has the concept in virtue of talking about pain with other people, and he knows that what he is about to feel is pain. Then he feels something unpleasant and quite different from the unpleasant sensations he has before (slimy, stinking, nauseating, etc.), so he is now justified in believing that he is in pain. But if we don&#039;t set up that background, could he believe that he is in pain, just because he has suddenly started have pain sensations? &quot;Doctor, I&#039;ve started having very unpleasant sensations and I&#039;m wondering if it could be pain. Is there any chance that that surgery...?&quot; Is this person justified in believing that he has pain? Maybe this is one of those cases where we say he does believe that he has pain, but doesn&#039;t know whether the English word &#039;pain&#039; is correctly used to express his belief? Is it enough to believe that he has pain that he can focus on a sensation that is in fact pain, and think &quot;I&#039;m having that sensation&quot;? I&#039;m sort of inclined to say in this case that he is in pain, but doesn&#039;t know it.

The idea of hardwired skills raises problems too. I like the idea of learned and even socially inculcated skills in the epistemic judgments because it seems to give a more robust normativity, a sort of right and wrong that doesn&#039;t apply to, e.g., digestion. We do have norms for digestion -- there are times when it isn&#039;t working properly. But epistemic judgments -- knows, doesn&#039;t know, is justified, isn&#039;t justified, reasonable, not reasonable -- seem to have a different kind of normativity (a reason for being a little dissatisfied with Plantinga&#039;s talk of proper function). I worry about losing that if we allow some of the skills (as opposed to the machinery that allows us to develop skills) to be hardwired. Maybe the fact that our judgments can cause those skills to develop in different ways is sufficient to allow that some justifications are as it were &quot;hard-wired&quot;?]]></description>
		<content:encoded><![CDATA[<p>This pain case is interesting. I think some distinction between carrying information and having content is needed &#8212; the dust on the floor carries information (e.g., about the shoes that have walked in it) but something more is needed for content. Even perceptual systems carry information that doesn&#8217;t get reflected in representational content &#8211;e.g., the info in the optic nerve about the cells in the retina that were stimulated, which mostly gets &#8220;thrown away&#8221; in the later processing. Representational content, even of the non-conceptual sort, needs to be something more than information, or even information in a system whose proper functioning makes use of that information, as in the example just given. Real representational content seems to require a certain kind of role in a psychological system. So would the person who has just now started to have pain sensations be able to believe that he was in pain? Maybe he has the concept in virtue of talking about pain with other people, and he knows that what he is about to feel is pain. Then he feels something unpleasant and quite different from the unpleasant sensations he has before (slimy, stinking, nauseating, etc.), so he is now justified in believing that he is in pain. But if we don&#8217;t set up that background, could he believe that he is in pain, just because he has suddenly started have pain sensations? &#8220;Doctor, I&#8217;ve started having very unpleasant sensations and I&#8217;m wondering if it could be pain. Is there any chance that that surgery&#8230;?&#8221; Is this person justified in believing that he has pain? Maybe this is one of those cases where we say he does believe that he has pain, but doesn&#8217;t know whether the English word &#8216;pain&#8217; is correctly used to express his belief? Is it enough to believe that he has pain that he can focus on a sensation that is in fact pain, and think &#8220;I&#8217;m having that sensation&#8221;? I&#8217;m sort of inclined to say in this case that he is in pain, but doesn&#8217;t know it.</p>
<p>The idea of hardwired skills raises problems too. I like the idea of learned and even socially inculcated skills in the epistemic judgments because it seems to give a more robust normativity, a sort of right and wrong that doesn&#8217;t apply to, e.g., digestion. We do have norms for digestion &#8212; there are times when it isn&#8217;t working properly. But epistemic judgments &#8212; knows, doesn&#8217;t know, is justified, isn&#8217;t justified, reasonable, not reasonable &#8212; seem to have a different kind of normativity (a reason for being a little dissatisfied with Plantinga&#8217;s talk of proper function). I worry about losing that if we allow some of the skills (as opposed to the machinery that allows us to develop skills) to be hardwired. Maybe the fact that our judgments can cause those skills to develop in different ways is sufficient to allow that some justifications are as it were &#8220;hard-wired&#8221;?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/even-more-on-sellars-problem/#comment-188</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Tue, 29 Jun 2004 17:20:20 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=36#comment-188</guid>
		<description><![CDATA[Drats, I&#039;m having another Mike Loux experience:  Mike tells grad students that everything in philosophy is connected to everything else.  I was happy just doing epistemology, and here it looks like I&#039;m going to have to venture into phil of mind.  And in doing phil of religion, especially freedom/foreknowledge, I&#039;ve now gotten entangled in the free will literature and the implications of Frankfurt-style counterexamples.  I&#039;m happy about the latter connections, but phil of mind is another matter entirely...

I think that the crucial issue in what you say concerns the notion of informational content.  Somehow, pain sensations carry the information that one is in pain, and serve to justify believing that one is in pain.  And it can do so on the very first experience of such (imagine an individual with a disorder that disables pain-receptors, who later in life is finally cured by new technology).  Here it&#039;s not a matter of learned recognition that explains justification.  Perhaps the skills are innate?  Maybe so, but that seems a bit too easy to me, and can be given as an explanation without any appeal to informational content of any literal sort (though we might still describe the skill in the mentalistic language of the sort that we find when describing the information found in DNA and the like--in these cases, the language is, I think, shorthand for some more complicated physico-chemical language).  Of course, it&#039;s not clear how non-conceptual informational content could be used to answer Sellars&#039; problem, and I guess I think you have to be right that not all experiential states can have conceptual content.  So I need to think more about informational content that isn&#039;t conceptual...]]></description>
		<content:encoded><![CDATA[<p>Drats, I&#8217;m having another Mike Loux experience:  Mike tells grad students that everything in philosophy is connected to everything else.  I was happy just doing epistemology, and here it looks like I&#8217;m going to have to venture into phil of mind.  And in doing phil of religion, especially freedom/foreknowledge, I&#8217;ve now gotten entangled in the free will literature and the implications of Frankfurt-style counterexamples.  I&#8217;m happy about the latter connections, but phil of mind is another matter entirely&#8230;</p>
<p>I think that the crucial issue in what you say concerns the notion of informational content.  Somehow, pain sensations carry the information that one is in pain, and serve to justify believing that one is in pain.  And it can do so on the very first experience of such (imagine an individual with a disorder that disables pain-receptors, who later in life is finally cured by new technology).  Here it&#8217;s not a matter of learned recognition that explains justification.  Perhaps the skills are innate?  Maybe so, but that seems a bit too easy to me, and can be given as an explanation without any appeal to informational content of any literal sort (though we might still describe the skill in the mentalistic language of the sort that we find when describing the information found in DNA and the like&#8211;in these cases, the language is, I think, shorthand for some more complicated physico-chemical language).  Of course, it&#8217;s not clear how non-conceptual informational content could be used to answer Sellars&#8217; problem, and I guess I think you have to be right that not all experiential states can have conceptual content.  So I need to think more about informational content that isn&#8217;t conceptual&#8230;</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Steven Reynolds</title>
		<link>http://certaindoubts.com/even-more-on-sellars-problem/#comment-187</link>
		<dc:creator><![CDATA[Steven Reynolds]]></dc:creator>
		<pubDate>Tue, 29 Jun 2004 16:50:12 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=36#comment-187</guid>
		<description><![CDATA[I suspect that&#039;s the main reason most people don&#039;t go for the view that qualitative states need not have content. A cursory phenomenology is definitely against it. I think that &quot;seeing as&quot; (hearing as, feeling as?) does involve content, indeed conceptual content, and that it is most of what we are aware of in perception, and certainly what we are aware of when we focus on our perceptions in that deliberate way that philosophy encourages. However a lot of our visual input, for example, is just not processed that way -- e.g. most of our peripheral vision, much of what affects us when we are attending to something else (e.g. thinking about a philosophical problem) and so on. I think that that sort of relatively unprocessed perceptual stuff is the starting point for developing concepts and recognitional abilities, and while I readily admit that how we sense  changes as our expertise develops (at the very least we focus (literally) on different things), I think there are some qualitative commonalities between the baby, who doesn&#039;t think about colors but has color sensations, and the adult who sees colors. I suppose the main alternative to my view  is the one that claims two kinds of content (at least)(Evans, Heck, Burge), conceptual content (in beliefs, desires, thoughts) and non-conceptual content, which is exemplified in the sorts of perception I&#039;ve just been mentioning, and also (according to Burge) in lower animals such as insects, frogs, and octopi. I&#039;m trying to make do without that second sort of content. (I don&#039;t like what seem to me to be dodges in explaining behavior by perception without explicitly invoking propositional attitudes analogous to desire.) I think that that is consistent with acknowledging that those perceptual phenomena do carry information about the world and that such information is processed in various ways short of the conceptual processing involved in seeing as. That&#039;s not much to answer your objection, I&#039;m afraid, but these are large issues and my views on them aren&#039;t fully worked out.]]></description>
		<content:encoded><![CDATA[<p>I suspect that&#8217;s the main reason most people don&#8217;t go for the view that qualitative states need not have content. A cursory phenomenology is definitely against it. I think that &#8220;seeing as&#8221; (hearing as, feeling as?) does involve content, indeed conceptual content, and that it is most of what we are aware of in perception, and certainly what we are aware of when we focus on our perceptions in that deliberate way that philosophy encourages. However a lot of our visual input, for example, is just not processed that way &#8212; e.g. most of our peripheral vision, much of what affects us when we are attending to something else (e.g. thinking about a philosophical problem) and so on. I think that that sort of relatively unprocessed perceptual stuff is the starting point for developing concepts and recognitional abilities, and while I readily admit that how we sense  changes as our expertise develops (at the very least we focus (literally) on different things), I think there are some qualitative commonalities between the baby, who doesn&#8217;t think about colors but has color sensations, and the adult who sees colors. I suppose the main alternative to my view  is the one that claims two kinds of content (at least)(Evans, Heck, Burge), conceptual content (in beliefs, desires, thoughts) and non-conceptual content, which is exemplified in the sorts of perception I&#8217;ve just been mentioning, and also (according to Burge) in lower animals such as insects, frogs, and octopi. I&#8217;m trying to make do without that second sort of content. (I don&#8217;t like what seem to me to be dodges in explaining behavior by perception without explicitly invoking propositional attitudes analogous to desire.) I think that that is consistent with acknowledging that those perceptual phenomena do carry information about the world and that such information is processed in various ways short of the conceptual processing involved in seeing as. That&#8217;s not much to answer your objection, I&#8217;m afraid, but these are large issues and my views on them aren&#8217;t fully worked out.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/even-more-on-sellars-problem/#comment-186</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Mon, 28 Jun 2004 22:06:49 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=36#comment-186</guid>
		<description><![CDATA[Steven, this is helpful.  So, I take it, we can hold that experiences can have a qualitative character, but still lack any sort of propositional or semantic content.  I do understand that distinction with respect to sensation states, such as being in pain, where there is a qualitative character but no content (i.e., nothing that a semantic theory would latch onto in explaining the truth conditions of propositions).  My worry here is that what I recognize introspectively about sensation states isn&#039;t the same as what I introspectively recognize about visual inputs.  When I&#039;m in pain, if you ask me what the experience is like, I resort to analogies:  it&#039;s like having a fire in my leg, or like a pin pricking my leg, etc.  But when you ask me what my visual experience is like, I just tell you:  I see a tree, or I finally see the missing shade of blue.  That leads me to think that not all perceptual states are like sensation states.]]></description>
		<content:encoded><![CDATA[<p>Steven, this is helpful.  So, I take it, we can hold that experiences can have a qualitative character, but still lack any sort of propositional or semantic content.  I do understand that distinction with respect to sensation states, such as being in pain, where there is a qualitative character but no content (i.e., nothing that a semantic theory would latch onto in explaining the truth conditions of propositions).  My worry here is that what I recognize introspectively about sensation states isn&#8217;t the same as what I introspectively recognize about visual inputs.  When I&#8217;m in pain, if you ask me what the experience is like, I resort to analogies:  it&#8217;s like having a fire in my leg, or like a pin pricking my leg, etc.  But when you ask me what my visual experience is like, I just tell you:  I see a tree, or I finally see the missing shade of blue.  That leads me to think that not all perceptual states are like sensation states.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Steven Reynolds</title>
		<link>http://certaindoubts.com/even-more-on-sellars-problem/#comment-185</link>
		<dc:creator><![CDATA[Steven Reynolds]]></dc:creator>
		<pubDate>Mon, 28 Jun 2004 20:27:12 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=36#comment-185</guid>
		<description><![CDATA[Sorry-- that last post was definitely muddled. Suppose we try: the difference is in the qualitative nature of the experience. Hume&#039;s disposition to say it is the missing shade of blue is a response to that qualitative nature, one created by his previous review of other shades of blue lined up and noticing the gap. His disposition to judge that it is not the missing shade doesn&#039;t result from reviewing the shades however, but (maybe) from being offered lots of samples of blue and so coming to have an exasperated response to the act of offereing him a shade of blue for his appraisal. &quot;Oh not another one. Of course it&#039;s not the missing shade.&quot;

If you say that it isn&#039;t a response that ignores the qualitative nature of the experience, as the exasperated response would, then I suspect that it still won&#039;t have the right sort of history to count as justifying. It doesn&#039;t amount to using an idea (in Hume&#039;s sense) to classify it, but rather just to a cognitive malfunction of some sort.]]></description>
		<content:encoded><![CDATA[<p>Sorry&#8211; that last post was definitely muddled. Suppose we try: the difference is in the qualitative nature of the experience. Hume&#8217;s disposition to say it is the missing shade of blue is a response to that qualitative nature, one created by his previous review of other shades of blue lined up and noticing the gap. His disposition to judge that it is not the missing shade doesn&#8217;t result from reviewing the shades however, but (maybe) from being offered lots of samples of blue and so coming to have an exasperated response to the act of offereing him a shade of blue for his appraisal. &#8220;Oh not another one. Of course it&#8217;s not the missing shade.&#8221;</p>
<p>If you say that it isn&#8217;t a response that ignores the qualitative nature of the experience, as the exasperated response would, then I suspect that it still won&#8217;t have the right sort of history to count as justifying. It doesn&#8217;t amount to using an idea (in Hume&#8217;s sense) to classify it, but rather just to a cognitive malfunction of some sort.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/even-more-on-sellars-problem/#comment-184</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Mon, 28 Jun 2004 18:51:34 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=36#comment-184</guid>
		<description><![CDATA[I don&#039;t think you have a disposition to believe that things you encounter are not a unicorn, but I suppose you could.  In the example, Hume actually forms the beliefs in question, though, so this is a different case than when you could form the belief but actually don&#039;t.]]></description>
		<content:encoded><![CDATA[<p>I don&#8217;t think you have a disposition to believe that things you encounter are not a unicorn, but I suppose you could.  In the example, Hume actually forms the beliefs in question, though, so this is a different case than when you could form the belief but actually don&#8217;t.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Steven Reynolds</title>
		<link>http://certaindoubts.com/even-more-on-sellars-problem/#comment-183</link>
		<dc:creator><![CDATA[Steven Reynolds]]></dc:creator>
		<pubDate>Mon, 28 Jun 2004 17:18:41 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=36#comment-183</guid>
		<description><![CDATA[I don&#039;t have an answer to the challenge as posed, but it strikes me that this disposition to say it&#039;s not the missing shade of blue is a funny sort of disposition. Do I also have dispositions to think or say that everything I encounter is not a unicorn? Negative dispositions are odd things. The tree outside my window never says much. Does it have a (reliable) disposition not to talk? On the other hand I do have a disposition not to eat liver, and that one seems explanatory. So I&#039;m not sure there&#039;s anything wrong here.]]></description>
		<content:encoded><![CDATA[<p>I don&#8217;t have an answer to the challenge as posed, but it strikes me that this disposition to say it&#8217;s not the missing shade of blue is a funny sort of disposition. Do I also have dispositions to think or say that everything I encounter is not a unicorn? Negative dispositions are odd things. The tree outside my window never says much. Does it have a (reliable) disposition not to talk? On the other hand I do have a disposition not to eat liver, and that one seems explanatory. So I&#8217;m not sure there&#8217;s anything wrong here.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
