<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Epistemic constraints on Jeffrey conditioning</title>
	<atom:link href="http://certaindoubts.com/epistemic-constraints-on-jeffrey-conditioning/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/epistemic-constraints-on-jeffrey-conditioning/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/epistemic-constraints-on-jeffrey-conditioning/#comment-1447</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Mon, 28 Feb 2005 17:30:01 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=266#comment-1447</guid>
		<description><![CDATA[A bird&#039;s eye view:

Suppose a fair die is tossed on a normal surface in a normally lit room. Given that the die lands showing a face with a dot in the center, the probability that the die lands showing an odd face is 1---not a terribly exciting example, but it will do.

Jeffrey&#039;s rule is motivated by the following variation on this experiment: Suppose the setup is the same except that the room is dimly lit: You observe that the die has landed but you aren&#039;t quite sure whether the die is showing a face with a dot in the center or not. However, standard conditioning on event A presumes that the actual world is in A not that you aren&#039;t quite sure that it is in A. So, what to do?

-If the agent (you) are able to assign a point probability to your uncertainty---that is, if it is reasonable for you to ascribe probability .8 (say) to &#039;center dot&#039; and .2 to &#039;no center dot&#039;---then Jeffrey&#039;s rule may be applied.

-However, if you want to express (i) that the probability of center dot is at least .8, or to express (the belief) (ii) that the probability of center dot is .8 and the probability of center dot is .3 (to represent overlapping sets: nobody says &lt;i&gt;evidence&lt;/i&gt; has got to be consistent, after all; usually it isn&#039;t.), Jeffrey&#039;s rule won&#039;t be applicable on either case. Thus, Jeffrey&#039;s rule only allows one to express a narrow class of uncertainty claims about evidence.

-Personalists aren&#039;t completely out of luck, however: folk have turned to relative entropy approaches as one example in attempts to handle cases like this, seeing Jeffrey&#039;s rule as a special case. The problem then is that sentences like (i) and (ii) (typically) yield a range of values, so the question then is which one is best. This question takes the form of whether such-in-such proposed metric induces an order that allows us to evaluate the distance from our original measure to each member of the class of induced measures, and to consider various selection criteria based upon some notion of minimal change. One might then ask whether this machinery corresponds to how we would or should expect &#039;best&#039; to behave. And, moreover, if you&#039;re a traditional personalist, you&#039;d like your machinery to spit out a unique value---which motivates various add-ons for yielding one. But perhaps you&#039;re just left with the class induced by these constraints, full stop. The literature picks up around here.]]></description>
		<content:encoded><![CDATA[<p>A bird&#8217;s eye view:</p>
<p>Suppose a fair die is tossed on a normal surface in a normally lit room. Given that the die lands showing a face with a dot in the center, the probability that the die lands showing an odd face is 1&#8212;not a terribly exciting example, but it will do.</p>
<p>Jeffrey&#8217;s rule is motivated by the following variation on this experiment: Suppose the setup is the same except that the room is dimly lit: You observe that the die has landed but you aren&#8217;t quite sure whether the die is showing a face with a dot in the center or not. However, standard conditioning on event A presumes that the actual world is in A not that you aren&#8217;t quite sure that it is in A. So, what to do?</p>
<p>-If the agent (you) are able to assign a point probability to your uncertainty&#8212;that is, if it is reasonable for you to ascribe probability .8 (say) to &#8216;center dot&#8217; and .2 to &#8216;no center dot&#8217;&#8212;then Jeffrey&#8217;s rule may be applied.</p>
<p>-However, if you want to express (i) that the probability of center dot is at least .8, or to express (the belief) (ii) that the probability of center dot is .8 and the probability of center dot is .3 (to represent overlapping sets: nobody says <i>evidence</i> has got to be consistent, after all; usually it isn&#8217;t.), Jeffrey&#8217;s rule won&#8217;t be applicable on either case. Thus, Jeffrey&#8217;s rule only allows one to express a narrow class of uncertainty claims about evidence.</p>
<p>-Personalists aren&#8217;t completely out of luck, however: folk have turned to relative entropy approaches as one example in attempts to handle cases like this, seeing Jeffrey&#8217;s rule as a special case. The problem then is that sentences like (i) and (ii) (typically) yield a range of values, so the question then is which one is best. This question takes the form of whether such-in-such proposed metric induces an order that allows us to evaluate the distance from our original measure to each member of the class of induced measures, and to consider various selection criteria based upon some notion of minimal change. One might then ask whether this machinery corresponds to how we would or should expect &#8216;best&#8217; to behave. And, moreover, if you&#8217;re a traditional personalist, you&#8217;d like your machinery to spit out a unique value&#8212;which motivates various add-ons for yielding one. But perhaps you&#8217;re just left with the class induced by these constraints, full stop. The literature picks up around here.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jim Hawthorne</title>
		<link>http://certaindoubts.com/epistemic-constraints-on-jeffrey-conditioning/#comment-1446</link>
		<dc:creator><![CDATA[Jim Hawthorne]]></dc:creator>
		<pubDate>Sun, 27 Feb 2005 08:07:56 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=266#comment-1446</guid>
		<description><![CDATA[Tim,

On Jeffrey conditionalization, you might take a look at my paper in the Journal of Phil. Logic, Feb., 2004.

Also, you mentioned &quot;rigidity of likelihoods&quot; in Jeffrey conditionalization. It turns out that the likelihoods cannot be rigid, except in very special cases (though of course posterior probabilities are taken to be rigid in Jeffrey Cond.). I prove a theorem about the impossibility of keeping both likelihoods and posteriors rigid at the same time in an appendix to a paper that should be out soon in Mind (in April, I think).]]></description>
		<content:encoded><![CDATA[<p>Tim,</p>
<p>On Jeffrey conditionalization, you might take a look at my paper in the Journal of Phil. Logic, Feb., 2004.</p>
<p>Also, you mentioned &#8220;rigidity of likelihoods&#8221; in Jeffrey conditionalization. It turns out that the likelihoods cannot be rigid, except in very special cases (though of course posterior probabilities are taken to be rigid in Jeffrey Cond.). I prove a theorem about the impossibility of keeping both likelihoods and posteriors rigid at the same time in an appendix to a paper that should be out soon in Mind (in April, I think).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Branden Fitelson</title>
		<link>http://certaindoubts.com/epistemic-constraints-on-jeffrey-conditioning/#comment-1445</link>
		<dc:creator><![CDATA[Branden Fitelson]]></dc:creator>
		<pubDate>Sat, 26 Feb 2005 22:07:41 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=266#comment-1445</guid>
		<description><![CDATA[Tim,

I recommend the following three papers on JC:

(1) Diaconis, Persi and Sandy L. Zabell (1982), â��Updating Subjective Probabilityâ��, Journal of the American Statistical Association 77(380): 822â�� 830.
(2) Field, Hartry, (1978), â��A Note on Jeffrey Conditionalizationâ��, Philosophy of Science 45: 361â��367.
(3) Carl Wagner&#039;s: http://www.princeton.edu/~bayesway/Wagner.pdf

-B]]></description>
		<content:encoded><![CDATA[<p>Tim,</p>
<p>I recommend the following three papers on JC:</p>
<p>(1) Diaconis, Persi and Sandy L. Zabell (1982), â��Updating Subjective Probabilityâ��, Journal of the American Statistical Association 77(380): 822â�� 830.<br />
(2) Field, Hartry, (1978), â��A Note on Jeffrey Conditionalizationâ��, Philosophy of Science 45: 361â��367.<br />
(3) Carl Wagner&#8217;s: <a href="http://www.princeton.edu/~bayesway/Wagner.pdf" rel="nofollow">http://www.princeton.edu/~bayesway/Wagner.pdf</a></p>
<p>-B</p>
]]></content:encoded>
	</item>
</channel>
</rss>
