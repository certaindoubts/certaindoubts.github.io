<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Irresponsible Ignorance</title>
	<atom:link href="http://certaindoubts.com/irresponsible-ignorance/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/irresponsible-ignorance/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Trent Dougherty</title>
		<link>http://certaindoubts.com/irresponsible-ignorance/#comment-2073</link>
		<dc:creator><![CDATA[Trent Dougherty]]></dc:creator>
		<pubDate>Tue, 28 Jun 2005 05:05:00 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=368#comment-2073</guid>
		<description><![CDATA[Alas, but I&#039;m not trying to defend, apply, or invoke (1).  I&#039;m only trying to explain the way my utility assignments and confidence states would lead me to behave.

I think this shows that I *can&#039;t* be appealing to (1), for ex hypothesi at the time at which I&#039;m deciding whether to investigate further, E&#039; doesn&#039;t describe any of my belief-states, so I can&#039;t have (Eâ??confirms P) as a premise.  I&#039;ve been in full-on personalist mode the whole time.]]></description>
		<content:encoded><![CDATA[<p>Alas, but I&#8217;m not trying to defend, apply, or invoke (1).  I&#8217;m only trying to explain the way my utility assignments and confidence states would lead me to behave.</p>
<p>I think this shows that I *can&#8217;t* be appealing to (1), for ex hypothesi at the time at which I&#8217;m deciding whether to investigate further, E&#8217; doesn&#8217;t describe any of my belief-states, so I can&#8217;t have (Eâ??confirms P) as a premise.  I&#8217;ve been in full-on personalist mode the whole time.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike</title>
		<link>http://certaindoubts.com/irresponsible-ignorance/#comment-2072</link>
		<dc:creator><![CDATA[Mike]]></dc:creator>
		<pubDate>Tue, 28 Jun 2005 02:02:21 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=368#comment-2072</guid>
		<description><![CDATA[Toss all of it in, if you like. Let&#039;s include R,E,B...add C and D. If I&#039;ve left out a letter or two, say E or F, toss those in too. Even G, if you like. Makes not a jot of difference. You wind up with (1).

1. [(E&#039; confirms P) &amp; (R&amp;E&amp;B&amp;C&amp;D disconfirms P)]--&gt; (R&amp;E&amp;B&amp;C&amp;D disconfirms E&#039;)

(1) is a flatly false principle of confirmation. There any number of  counterexamples to this sort of principle. Takes an historical inquiry to find them all: Jeffreys, Otte, Carnap, and on and on. Hope that clarifies my &quot;position&quot;.]]></description>
		<content:encoded><![CDATA[<p>Toss all of it in, if you like. Let&#8217;s include R,E,B&#8230;add C and D. If I&#8217;ve left out a letter or two, say E or F, toss those in too. Even G, if you like. Makes not a jot of difference. You wind up with (1).</p>
<p>1. [(E&#8217; confirms P) &#038; (R&#038;E&#038;B&#038;C&#038;D disconfirms P)]&#8211;> (R&#038;E&#038;B&#038;C&#038;D disconfirms E&#8217;)</p>
<p>(1) is a flatly false principle of confirmation. There any number of  counterexamples to this sort of principle. Takes an historical inquiry to find them all: Jeffreys, Otte, Carnap, and on and on. Hope that clarifies my &#8220;position&#8221;.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Trent Dougherty</title>
		<link>http://certaindoubts.com/irresponsible-ignorance/#comment-2071</link>
		<dc:creator><![CDATA[Trent Dougherty]]></dc:creator>
		<pubDate>Mon, 27 Jun 2005 22:32:55 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=368#comment-2071</guid>
		<description><![CDATA[My statement about my prior wasn&#039;t supposed to &quot;follow&quot; it was merely a report of my subjective probability in that case.  It wouldn&#039;t be E that would disconfirm E&#039; in any event, it would be the total state of my background beliefs (including the relative (in)frequency of tampering and the lack of any evidence thereof).

So let P and Q be as before; let &#039;R&#039; state my belief about the relative frequency of tampering and let &#039;E&#039; state the evidence I have for P (ex hypothesi none), let &#039;B&#039; state all my other background beliefs.  I&#039;m saying that Pr(Q/R&amp;E&amp;B) is, for me, very low.  Hope that helps clarify my position. Thanks for the discussion, epistemic responsibility is one of my main areas of interest.  I hope Jon will blog sometime on the relationship between responsibility and praise/blame (hint hint).]]></description>
		<content:encoded><![CDATA[<p>My statement about my prior wasn&#8217;t supposed to &#8220;follow&#8221; it was merely a report of my subjective probability in that case.  It wouldn&#8217;t be E that would disconfirm E&#8217; in any event, it would be the total state of my background beliefs (including the relative (in)frequency of tampering and the lack of any evidence thereof).</p>
<p>So let P and Q be as before; let &#8216;R&#8217; state my belief about the relative frequency of tampering and let &#8216;E&#8217; state the evidence I have for P (ex hypothesi none), let &#8216;B&#8217; state all my other background beliefs.  I&#8217;m saying that Pr(Q/R&#038;E&#038;B) is, for me, very low.  Hope that helps clarify my position. Thanks for the discussion, epistemic responsibility is one of my main areas of interest.  I hope Jon will blog sometime on the relationship between responsibility and praise/blame (hint hint).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike</title>
		<link>http://certaindoubts.com/irresponsible-ignorance/#comment-2070</link>
		<dc:creator><![CDATA[Mike]]></dc:creator>
		<pubDate>Mon, 27 Jun 2005 15:44:05 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=368#comment-2070</guid>
		<description><![CDATA[_I think he [Swinburne] rightly says that one important consideration is the probability that further investigation will lead to change in evidential status of important beliefs. In the case you describe my prior on there being any tampering is going to be so low I wonâ??t expect investigation to change things.

Agreed, your prior is low, or Pr(P/E) is low. So this makes it very unlikely on E that there is a wired explosive. But you say &quot;In the case you describe my prior on there being any tampering is going to be so low I wonâ??t expect investigation to change things.&quot; But this doesn&#039;t follow. The fact that E is strong evidence we possess against P, and E&#039; is strong evidence in favor of P, it does not follow that E is strong evidence against E&#039;. That is, your strong evidence against P is not strong evidence that investigation won&#039;t discover E&#039;. In the strongest case, you might expect the following to be true.

1. [(E&#039; entails P) &amp; (E disconfirms P)] -&gt; (E disconfirms E&#039;).

But (1) is not a valid rule of (dis)confirmation. Indeed, it is possible that E&#039; entails P, E disconfirms P and E *confirms* E&#039;. So (1) is false. A fortiori (2) is false.

2. [(E&#039;confirms P) &amp; (E disconfirms P)] -&gt; (E disconfirms E&#039;).

But then you can&#039;t conclude that E is evidence that there is no E&#039;. Therefore E is not evidence against investigating further. I agree that we ought not to investigate further. But E cannot be the reason.]]></description>
		<content:encoded><![CDATA[<p>_I think he [Swinburne] rightly says that one important consideration is the probability that further investigation will lead to change in evidential status of important beliefs. In the case you describe my prior on there being any tampering is going to be so low I wonâ??t expect investigation to change things.</p>
<p>Agreed, your prior is low, or Pr(P/E) is low. So this makes it very unlikely on E that there is a wired explosive. But you say &#8220;In the case you describe my prior on there being any tampering is going to be so low I wonâ??t expect investigation to change things.&#8221; But this doesn&#8217;t follow. The fact that E is strong evidence we possess against P, and E&#8217; is strong evidence in favor of P, it does not follow that E is strong evidence against E&#8217;. That is, your strong evidence against P is not strong evidence that investigation won&#8217;t discover E&#8217;. In the strongest case, you might expect the following to be true.</p>
<p>1. [(E&#8217; entails P) &#038; (E disconfirms P)] -> (E disconfirms E&#8217;).</p>
<p>But (1) is not a valid rule of (dis)confirmation. Indeed, it is possible that E&#8217; entails P, E disconfirms P and E *confirms* E&#8217;. So (1) is false. A fortiori (2) is false.</p>
<p>2. [(E&#8217;confirms P) &#038; (E disconfirms P)] -> (E disconfirms E&#8217;).</p>
<p>But then you can&#8217;t conclude that E is evidence that there is no E&#8217;. Therefore E is not evidence against investigating further. I agree that we ought not to investigate further. But E cannot be the reason.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Trent Dougherty</title>
		<link>http://certaindoubts.com/irresponsible-ignorance/#comment-2069</link>
		<dc:creator><![CDATA[Trent Dougherty]]></dc:creator>
		<pubDate>Mon, 27 Jun 2005 06:05:22 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=368#comment-2069</guid>
		<description><![CDATA[I&#039;d say probably not (i.e. it&#039;s not the case that you should check, not to be confused with it&#039;s being the case that you shouldn&#039;t check: I think it&#039;s permissible).  You needn&#039;t check because you&#039;ve got no reason to believe further investigation would uncover evidence of tampering. You say &quot;the fact that Pr(P/E) is low gives me no reason to believe that, if I gather more easiy [sic] obtainable evidence Eâ??, Pr(P/E&amp;Eâ??) will also be low. So it gives me no reason not to investigate.&quot;  But of course not having a reason not to investigate doesn&#039;t entail that you have a reason *to* investigate.  Swinburne, in his _Epistemic Justification_ explicitly discusses the issue of when further investigation makes sense and I think he rightly says that one important consideration is the probability that further investigation will lead to change in evidential status of important beliefs.  In the case you describe my prior on there being any tampering is going to be so low I won&#039;t expect investigation to change things.  Let P = &quot;The car&#039;s been tampered with.&quot;  Let Q = &quot;If I inquire further, Pr(P) will change significantly.&quot;  My prior on Q is very low.  If I&#039;ve got no special reason to check (as I don&#039;t in your story) and I&#039;ve got no reason not to check, the default is probably not to check.  [It gets tough to calculate because paranoia-elimination has some utility but getting down and checking has some disutility as does starting the habit of indulging paranoid urges, etc.]  So if I had reason to believe that I wouldn&#039;t be starting a bad habit and checking had very little disutility, then maybe I&#039;d check, but here&#039;s what I&#039;m worried about: there might be a murderous gunman in my closet.  If there were, it would be really bad and it&#039;s so easy to check. But there might be a gunman under my bed or in my shower or in the attic or the other room.  The disutility of endorsing a policy of checking on such things is huge.  It&#039;s not clear I&#039;d value that life much.  At any rate, I think it&#039;s quite excusable not check on such things even if doing so has positive expected utility (as I think it has not for reasons stated (i.e. no evidence of badness therefore negligible (or no) expected disutility) though I hasten to add once more that almost any positive evidence whatsoever would make it (inexcusably) irrational not to check.  [This went much longer than I&#039;d hoped, but I wanted to do your excellent question some kind of justice.]]]></description>
		<content:encoded><![CDATA[<p>I&#8217;d say probably not (i.e. it&#8217;s not the case that you should check, not to be confused with it&#8217;s being the case that you shouldn&#8217;t check: I think it&#8217;s permissible).  You needn&#8217;t check because you&#8217;ve got no reason to believe further investigation would uncover evidence of tampering. You say &#8220;the fact that Pr(P/E) is low gives me no reason to believe that, if I gather more easiy [sic] obtainable evidence Eâ??, Pr(P/E&#038;Eâ??) will also be low. So it gives me no reason not to investigate.&#8221;  But of course not having a reason not to investigate doesn&#8217;t entail that you have a reason *to* investigate.  Swinburne, in his _Epistemic Justification_ explicitly discusses the issue of when further investigation makes sense and I think he rightly says that one important consideration is the probability that further investigation will lead to change in evidential status of important beliefs.  In the case you describe my prior on there being any tampering is going to be so low I won&#8217;t expect investigation to change things.  Let P = &#8220;The car&#8217;s been tampered with.&#8221;  Let Q = &#8220;If I inquire further, Pr(P) will change significantly.&#8221;  My prior on Q is very low.  If I&#8217;ve got no special reason to check (as I don&#8217;t in your story) and I&#8217;ve got no reason not to check, the default is probably not to check.  [It gets tough to calculate because paranoia-elimination has some utility but getting down and checking has some disutility as does starting the habit of indulging paranoid urges, etc.]  So if I had reason to believe that I wouldn&#8217;t be starting a bad habit and checking had very little disutility, then maybe I&#8217;d check, but here&#8217;s what I&#8217;m worried about: there might be a murderous gunman in my closet.  If there were, it would be really bad and it&#8217;s so easy to check. But there might be a gunman under my bed or in my shower or in the attic or the other room.  The disutility of endorsing a policy of checking on such things is huge.  It&#8217;s not clear I&#8217;d value that life much.  At any rate, I think it&#8217;s quite excusable not check on such things even if doing so has positive expected utility (as I think it has not for reasons stated (i.e. no evidence of badness therefore negligible (or no) expected disutility) though I hasten to add once more that almost any positive evidence whatsoever would make it (inexcusably) irrational not to check.  [This went much longer than I&#8217;d hoped, but I wanted to do your excellent question some kind of justice.]</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike</title>
		<link>http://certaindoubts.com/irresponsible-ignorance/#comment-2068</link>
		<dc:creator><![CDATA[Mike]]></dc:creator>
		<pubDate>Sun, 26 Jun 2005 18:06:21 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=368#comment-2068</guid>
		<description><![CDATA[Thanks, Trent. Let me see whether we agree on the following. Let E be my evidence that there is an explosive device wired to my car. Presumably E will include the evidence for this sort of thing happening in general and in my locale, etc. Let P be &quot;there is an explosive device wired to my car&quot;. Let&#039;s agree that Pr(P/E) low. The disutility U(P) is high. We have some disagreement on the value of Pr(P)U(P),(where Pr(P) is my updated probability of P on E).
Sound right?
Here&#039;s the worry. I am standing beside my car and the idea crosses my mind that there might be an explosive device wired to it. I KNOW that there is evidence available to me that I do not possess (I haven&#039;t looked under the car and I can do so). I KNOW that the evidence is easily obtained. And I KNOW that the evidence obtained might radically affect the value of Pr(P)U(P).
Now you say, &quot;but the value of Pr(P/E) is very low (and so is the value of Pr(P)U(P)), so you have no reason to check&quot;. But the fact that Pr(P/E) is low does not entail that Pr(P/E &amp; E&#039;) is low. The evidence that I have for P is meagre, but that does not show that the *evidence available* for P is meagre. So the fact that Pr(P/E) is low gives me no reason to believe that, if I gather more easiy obtainable evidence E&#039;, Pr(P/E&amp;E&#039;) will also be low. So it gives me no reason not to investigate. For all I know Pr(P/E&amp;E&#039;) might be very high (as in fact it is, as the case is described). So, we arrive here: For all I know
Pr(P/E&amp;E&#039;) is high, if it is high then not investigating will have a very bad outcome, I can easily look under the car. Should I investigate?]]></description>
		<content:encoded><![CDATA[<p>Thanks, Trent. Let me see whether we agree on the following. Let E be my evidence that there is an explosive device wired to my car. Presumably E will include the evidence for this sort of thing happening in general and in my locale, etc. Let P be &#8220;there is an explosive device wired to my car&#8221;. Let&#8217;s agree that Pr(P/E) low. The disutility U(P) is high. We have some disagreement on the value of Pr(P)U(P),(where Pr(P) is my updated probability of P on E).<br />
Sound right?<br />
Here&#8217;s the worry. I am standing beside my car and the idea crosses my mind that there might be an explosive device wired to it. I KNOW that there is evidence available to me that I do not possess (I haven&#8217;t looked under the car and I can do so). I KNOW that the evidence is easily obtained. And I KNOW that the evidence obtained might radically affect the value of Pr(P)U(P).<br />
Now you say, &#8220;but the value of Pr(P/E) is very low (and so is the value of Pr(P)U(P)), so you have no reason to check&#8221;. But the fact that Pr(P/E) is low does not entail that Pr(P/E &#038; E&#8217;) is low. The evidence that I have for P is meagre, but that does not show that the *evidence available* for P is meagre. So the fact that Pr(P/E) is low gives me no reason to believe that, if I gather more easiy obtainable evidence E&#8217;, Pr(P/E&#038;E&#8217;) will also be low. So it gives me no reason not to investigate. For all I know Pr(P/E&#038;E&#8217;) might be very high (as in fact it is, as the case is described). So, we arrive here: For all I know<br />
Pr(P/E&#038;E&#8217;) is high, if it is high then not investigating will have a very bad outcome, I can easily look under the car. Should I investigate?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Trent Dougherty</title>
		<link>http://certaindoubts.com/irresponsible-ignorance/#comment-2067</link>
		<dc:creator><![CDATA[Trent Dougherty]]></dc:creator>
		<pubDate>Sun, 26 Jun 2005 16:00:43 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=368#comment-2067</guid>
		<description><![CDATA[One last quick thought.  As I said, it wouldn&#039;t take much evidence to get the expected disutility high enough to make it formally irresponsible not to check.  However, I think there might be a category of excusable irresponsibility where we leave off blame.  I only post this idea because Jon raised a similar issue earlier and Peter Vallentyne uses the idea for the following kind of case: It&#039;s just plain wrong to harm an innocent that good may come of it or that evil may be avoided.  Standard case: I&#039;m going to shoot everybody in the class if  you don&#039;t pick one person (not yourself) and shoot them in the stomach.  Justice does not permit it and I think most would consider it reprehensible.  However, it&#039;s just a fact that when you start making the case extreme people admit they&#039;d probably do it and most of us admit this to ourselves before we admit it to others.  Case in point: It would be unjust to lock Saddam Hussein in prison for the rest of his life (though surely better than he deserves, he apparently just loves Doritos) without a trial.  But suppose in some crazy scenario you face this choice: either you arrange for him to be imprisoned without a trial (as if we don&#039;t know what the outcome would be) or I&#039;ll torture every living creature on Earth for everlasting time.  Well, I think you&#039;d do it and I don&#039;t think anyone (except perhaps the ACLU and AI) would really blame you.  It would be an excusable injustice.  We formally admit it unjust but don&#039;t blame you (though we might have to punish you even but maybe not).

I don&#039;t like excusable injustices or separating blame from irresponsibility, but it might be forced upon us in the end even if only in rare cases.

So my own suspicion is that almost any concrete evidence raises disutility (so to speak) enough to require investigation.  But if it turned out that there were just too many cases which resulted from this, the above is probably the first thing I&#039;d fall back upon while trying to work out the idea I mentioned earlier about the diminished utility of a life ridden with checking everything.]]></description>
		<content:encoded><![CDATA[<p>One last quick thought.  As I said, it wouldn&#8217;t take much evidence to get the expected disutility high enough to make it formally irresponsible not to check.  However, I think there might be a category of excusable irresponsibility where we leave off blame.  I only post this idea because Jon raised a similar issue earlier and Peter Vallentyne uses the idea for the following kind of case: It&#8217;s just plain wrong to harm an innocent that good may come of it or that evil may be avoided.  Standard case: I&#8217;m going to shoot everybody in the class if  you don&#8217;t pick one person (not yourself) and shoot them in the stomach.  Justice does not permit it and I think most would consider it reprehensible.  However, it&#8217;s just a fact that when you start making the case extreme people admit they&#8217;d probably do it and most of us admit this to ourselves before we admit it to others.  Case in point: It would be unjust to lock Saddam Hussein in prison for the rest of his life (though surely better than he deserves, he apparently just loves Doritos) without a trial.  But suppose in some crazy scenario you face this choice: either you arrange for him to be imprisoned without a trial (as if we don&#8217;t know what the outcome would be) or I&#8217;ll torture every living creature on Earth for everlasting time.  Well, I think you&#8217;d do it and I don&#8217;t think anyone (except perhaps the ACLU and AI) would really blame you.  It would be an excusable injustice.  We formally admit it unjust but don&#8217;t blame you (though we might have to punish you even but maybe not).</p>
<p>I don&#8217;t like excusable injustices or separating blame from irresponsibility, but it might be forced upon us in the end even if only in rare cases.</p>
<p>So my own suspicion is that almost any concrete evidence raises disutility (so to speak) enough to require investigation.  But if it turned out that there were just too many cases which resulted from this, the above is probably the first thing I&#8217;d fall back upon while trying to work out the idea I mentioned earlier about the diminished utility of a life ridden with checking everything.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Trent Dougherty</title>
		<link>http://certaindoubts.com/irresponsible-ignorance/#comment-2066</link>
		<dc:creator><![CDATA[Trent Dougherty]]></dc:creator>
		<pubDate>Sun, 26 Jun 2005 15:41:27 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=368#comment-2066</guid>
		<description><![CDATA[I greatly disvalue the death of any number of persons, it&#039;s just, as I said, the probability you get from &quot;no evidence at all&quot; is very low indeed, I only post to say that I don&#039;t think it needs to be infinitesimal(though perhaps it is in the &quot;no evidence at all&quot; case).  I think we&#039;re not so far apart as we might seem on this.]]></description>
		<content:encoded><![CDATA[<p>I greatly disvalue the death of any number of persons, it&#8217;s just, as I said, the probability you get from &#8220;no evidence at all&#8221; is very low indeed, I only post to say that I don&#8217;t think it needs to be infinitesimal(though perhaps it is in the &#8220;no evidence at all&#8221; case).  I think we&#8217;re not so far apart as we might seem on this.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Mike</title>
		<link>http://certaindoubts.com/irresponsible-ignorance/#comment-2064</link>
		<dc:creator><![CDATA[Mike]]></dc:creator>
		<pubDate>Sun, 26 Jun 2005 13:39:54 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=368#comment-2064</guid>
		<description><![CDATA[I can&#039;t think of many things of greater disvalue than the untimely death of human beings. In these cases we have a low probability of the untimely death of several human beings. It is not hard to imagine a case with the untimely death of many more (if you think numbers count). The probability of this happening is low, sure, but not infinitesimal. So, the expected disutility of not investigating should be quite high. I agree that the probability is low. The only place we disagree is on the disvalue of the death of several human beings. I&#039;m not sure how to argue for that.]]></description>
		<content:encoded><![CDATA[<p>I can&#8217;t think of many things of greater disvalue than the untimely death of human beings. In these cases we have a low probability of the untimely death of several human beings. It is not hard to imagine a case with the untimely death of many more (if you think numbers count). The probability of this happening is low, sure, but not infinitesimal. So, the expected disutility of not investigating should be quite high. I agree that the probability is low. The only place we disagree is on the disvalue of the death of several human beings. I&#8217;m not sure how to argue for that.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Trent Dougherty</title>
		<link>http://certaindoubts.com/irresponsible-ignorance/#comment-2065</link>
		<dc:creator><![CDATA[Trent Dougherty]]></dc:creator>
		<pubDate>Sun, 26 Jun 2005 05:12:48 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=368#comment-2065</guid>
		<description><![CDATA[Hi Mike, I said that &quot;if all goes well&quot; conditionalized epistemic probability will track objective probability.  Rarely if ever does all go well, but I think we all hope that epistemic probability tracks objective probabilities where objective probabilities exist.  I would be happy to take one step back to personalist subjective probability (which is all I need) and say that if all goes well it tracks epistemic probability as understood as what a suitably idealized agent would hold (&quot;suitably&quot; would have to carefully avoid the conditional fallacy for one thing).

Regarding the cases: we are agreed that it&#039;s not irresponsible not to check, that I never questioned.  Only I explained that fact by claiming that the expected disutility is sufficiently small owing to the fact that though the outcome would be extremely disutile, the probability (whether subjective or quasi-objective epistemic) of it occurring is so very small (your words: &quot;I have no evidence at all&quot;).

Now low expected disutility *would* explain the excusibility and I&#039;m calculating expected utility in the standard way and I&#039;m reading low subjective probability off of &quot;I have no evidence&quot;, so I feel pretty good about this so far.  We&#039;re in agreement about the cases, so we&#039;re together on the first-order stuff.]]></description>
		<content:encoded><![CDATA[<p>Hi Mike, I said that &#8220;if all goes well&#8221; conditionalized epistemic probability will track objective probability.  Rarely if ever does all go well, but I think we all hope that epistemic probability tracks objective probabilities where objective probabilities exist.  I would be happy to take one step back to personalist subjective probability (which is all I need) and say that if all goes well it tracks epistemic probability as understood as what a suitably idealized agent would hold (&#8220;suitably&#8221; would have to carefully avoid the conditional fallacy for one thing).</p>
<p>Regarding the cases: we are agreed that it&#8217;s not irresponsible not to check, that I never questioned.  Only I explained that fact by claiming that the expected disutility is sufficiently small owing to the fact that though the outcome would be extremely disutile, the probability (whether subjective or quasi-objective epistemic) of it occurring is so very small (your words: &#8220;I have no evidence at all&#8221;).</p>
<p>Now low expected disutility *would* explain the excusibility and I&#8217;m calculating expected utility in the standard way and I&#8217;m reading low subjective probability off of &#8220;I have no evidence&#8221;, so I feel pretty good about this so far.  We&#8217;re in agreement about the cases, so we&#8217;re together on the first-order stuff.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
