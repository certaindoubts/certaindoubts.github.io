<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Expected Utility, Evidence, and Reference Classes</title>
	<atom:link href="http://certaindoubts.com/on-expected-utility-evidence/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/on-expected-utility-evidence/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Adam</title>
		<link>http://certaindoubts.com/on-expected-utility-evidence/#comment-3915</link>
		<dc:creator><![CDATA[Adam]]></dc:creator>
		<pubDate>Tue, 26 Sep 2006 15:28:57 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=619#comment-3915</guid>
		<description><![CDATA[Hello Greg,
Thank you for the clarification. I misunderstood you. I apologize for the delay in replying: I do not know what to add.]]></description>
		<content:encoded><![CDATA[<p>Hello Greg,<br />
Thank you for the clarification. I misunderstood you. I apologize for the delay in replying: I do not know what to add.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/on-expected-utility-evidence/#comment-3914</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Mon, 25 Sep 2006 09:28:04 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=619#comment-3914</guid>
		<description><![CDATA[Thanks Christian, I enjoyed the talk too. I think you&#039;re pressing the EP-based decision theory in precisely the right places.

I should add that the theory of Imprecise Probabilities might be a more natural framework to look at than EP; and my discussion in the last post actually moved back and forth between imprecise probability (IP) and evidential probability. (More vague and false things said.)

The nice thing about IP is that mathematically it can be viewed as a generalization of de Finetti&#039;s behaviorist interpretation of probability. So if you&#039;re comfortable thinking in terms of linear previsions, and I gather from this talk what you would be, then you can view the theory of upper/lower previsions as the general theory within which de Finneti&#039;s lives as a special case (namely when upper and lower previsions are identical). So, you could approach the subject as a project of how to get more expressive power building atop what you are familiar. Peter Walley&#039;s (1991) &lt;i&gt;Statistical Reasoning with Imprecise Probabilities&lt;/i&gt; is the standard text, and it is a very beautiful book.

The Harper and Wheeler will contain a contribution from Gert de Cooman and Enrique Miranda on imprecise probability. In fact they have a very exciting new result in this paper from which de Finneti&#039;s exchangeability theorem drops out as a special case. The collection should, I hope, be out in the next few months, but might spill over into early 2007.

In contrast, the idea to have in mind when you are reading Kyburg is maybe this one: Carnap made much of there being two kinds of probability, the probability of credal functions and relative frequencies, both of which, he claimed, were important to science, neither of which could be reduced to the other. But, he largely ignored the latter in developing his logical theory of confirmation, and we&#039;ve been living in the long shadow of this choice since. Kyburg gives you a picture of what happens when you take a logical theory and put relative frequencies as the primary notion of probability, including the costs and benefits from doing so.]]></description>
		<content:encoded><![CDATA[<p>Thanks Christian, I enjoyed the talk too. I think you&#8217;re pressing the EP-based decision theory in precisely the right places.</p>
<p>I should add that the theory of Imprecise Probabilities might be a more natural framework to look at than EP; and my discussion in the last post actually moved back and forth between imprecise probability (IP) and evidential probability. (More vague and false things said.)</p>
<p>The nice thing about IP is that mathematically it can be viewed as a generalization of de Finetti&#8217;s behaviorist interpretation of probability. So if you&#8217;re comfortable thinking in terms of linear previsions, and I gather from this talk what you would be, then you can view the theory of upper/lower previsions as the general theory within which de Finneti&#8217;s lives as a special case (namely when upper and lower previsions are identical). So, you could approach the subject as a project of how to get more expressive power building atop what you are familiar. Peter Walley&#8217;s (1991) <i>Statistical Reasoning with Imprecise Probabilities</i> is the standard text, and it is a very beautiful book.</p>
<p>The Harper and Wheeler will contain a contribution from Gert de Cooman and Enrique Miranda on imprecise probability. In fact they have a very exciting new result in this paper from which de Finneti&#8217;s exchangeability theorem drops out as a special case. The collection should, I hope, be out in the next few months, but might spill over into early 2007.</p>
<p>In contrast, the idea to have in mind when you are reading Kyburg is maybe this one: Carnap made much of there being two kinds of probability, the probability of credal functions and relative frequencies, both of which, he claimed, were important to science, neither of which could be reduced to the other. But, he largely ignored the latter in developing his logical theory of confirmation, and we&#8217;ve been living in the long shadow of this choice since. Kyburg gives you a picture of what happens when you take a logical theory and put relative frequencies as the primary notion of probability, including the costs and benefits from doing so.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Christian</title>
		<link>http://certaindoubts.com/on-expected-utility-evidence/#comment-3913</link>
		<dc:creator><![CDATA[Christian]]></dc:creator>
		<pubDate>Sun, 24 Sep 2006 18:18:14 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=619#comment-3913</guid>
		<description><![CDATA[Greg,

I&#039;m inclined to think the probability that I will understand this view given that I&#039;m trying to do so by blogging is rather low. There are definitely nooks and crannies to be considered and the view is quite a bit different than what I&#039;m familiar with, which isn&#039;t saying much, since I&#039;m not familiar with much.

&quot;Another feature, perhaps the crown jewel of the account, is that EP can update on trivial [0,1] priors and so offers an account of learning about a parameter about which we previous had absolutely no evidence.&quot;

That is a jewel.  I&#039;ll check out Kyburg and then (how long?) Harper and Wheeler. Anyway, thanks for the talk, interesting stuff!]]></description>
		<content:encoded><![CDATA[<p>Greg,</p>
<p>I&#8217;m inclined to think the probability that I will understand this view given that I&#8217;m trying to do so by blogging is rather low. There are definitely nooks and crannies to be considered and the view is quite a bit different than what I&#8217;m familiar with, which isn&#8217;t saying much, since I&#8217;m not familiar with much.</p>
<p>&#8220;Another feature, perhaps the crown jewel of the account, is that EP can update on trivial [0,1] priors and so offers an account of learning about a parameter about which we previous had absolutely no evidence.&#8221;</p>
<p>That is a jewel.  I&#8217;ll check out Kyburg and then (how long?) Harper and Wheeler. Anyway, thanks for the talk, interesting stuff!</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/on-expected-utility-evidence/#comment-3912</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Sun, 24 Sep 2006 09:43:24 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=619#comment-3912</guid>
		<description><![CDATA[Hi Christian,

Remember that this view bases probability assessment on evidence, and you may not have evidence for a particular act. So, it is not necessarily the case that you always have a probability assignment.

Another way to put this is is that there is no assumption that all gambles have a fair price. One&#039;s selling and buying price may not be equal, and any gamble appearing between the buying and selling points are incomparable. Hence, the expression of no preference is not identified as indifference to outcomes.

You are right that the view faces the reference class problem, but it does so square on. Since the account is built atop Evidential Probability, there is a method for resolving conflicting reference classes to yield a single (even if interval valued) probability assignment (for events). So, the reference class problem isn&#039;t viewed as a deal breaker but rather the cost of dealing with real evidence.

On this view, what changes in the smoking example (in either the causal structure you imagine, or the one that I imagined) is that the agent learns that his choosing to remove  himself from the class of smokers does not change his
risk of cancer.  When he learns he has a brain lesion, he learns that in addition to being a member of the class of smokers he also is a member of the class of people with brain lesions. So, his expectation for &#039;no cancer&#039; conditioned on his stopping smoking is not what he initially thought it would be. The interpretation of probability is important here.

Probability here is treated as a meta-linguistic relation on sentences of a first-order language, like provability. It is not a measure function. All probabilities are conditional probabilities, although they are not defined by ratios. Bayesian conditionalization is not a valid principle for updating evidence, but the theorem is applicable in certain limited cases. Thus, you can run book arguments against EP, although they don&#039;t make too much sense from an evidential point of view. One can view probability as a type of inference relation here, one that is genuinely non-monotonic. Another feature, perhaps the crown jewel of the account, is that EP can update on trivial [0,1] priors and so offers an account of learning about a parameter about which we previous had absolutely no evidence. All this is a consequence of taking seriously the idea that probability assignments are based upon evidence.

Betting and believing are very different things on this account, which might help explain my informal talk that puts some distance between an agent&#039;s epistemic standing and his disposition to take bets.

If this theory of probability sounds at all interesting, I&#039;d steer you to Kyburg and Teng &lt;i&gt;Uncertain Inference&lt;/i&gt; CUP 2001, and plug a book Bill Harper and I are editing &lt;i&gt;Probability and Inference&lt;/i&gt;, forthcoming from King&#039;s College.]]></description>
		<content:encoded><![CDATA[<p>Hi Christian,</p>
<p>Remember that this view bases probability assessment on evidence, and you may not have evidence for a particular act. So, it is not necessarily the case that you always have a probability assignment.</p>
<p>Another way to put this is is that there is no assumption that all gambles have a fair price. One&#8217;s selling and buying price may not be equal, and any gamble appearing between the buying and selling points are incomparable. Hence, the expression of no preference is not identified as indifference to outcomes.</p>
<p>You are right that the view faces the reference class problem, but it does so square on. Since the account is built atop Evidential Probability, there is a method for resolving conflicting reference classes to yield a single (even if interval valued) probability assignment (for events). So, the reference class problem isn&#8217;t viewed as a deal breaker but rather the cost of dealing with real evidence.</p>
<p>On this view, what changes in the smoking example (in either the causal structure you imagine, or the one that I imagined) is that the agent learns that his choosing to remove  himself from the class of smokers does not change his<br />
risk of cancer.  When he learns he has a brain lesion, he learns that in addition to being a member of the class of smokers he also is a member of the class of people with brain lesions. So, his expectation for &#8216;no cancer&#8217; conditioned on his stopping smoking is not what he initially thought it would be. The interpretation of probability is important here.</p>
<p>Probability here is treated as a meta-linguistic relation on sentences of a first-order language, like provability. It is not a measure function. All probabilities are conditional probabilities, although they are not defined by ratios. Bayesian conditionalization is not a valid principle for updating evidence, but the theorem is applicable in certain limited cases. Thus, you can run book arguments against EP, although they don&#8217;t make too much sense from an evidential point of view. One can view probability as a type of inference relation here, one that is genuinely non-monotonic. Another feature, perhaps the crown jewel of the account, is that EP can update on trivial [0,1] priors and so offers an account of learning about a parameter about which we previous had absolutely no evidence. All this is a consequence of taking seriously the idea that probability assignments are based upon evidence.</p>
<p>Betting and believing are very different things on this account, which might help explain my informal talk that puts some distance between an agent&#8217;s epistemic standing and his disposition to take bets.</p>
<p>If this theory of probability sounds at all interesting, I&#8217;d steer you to Kyburg and Teng <i>Uncertain Inference</i> CUP 2001, and plug a book Bill Harper and I are editing <i>Probability and Inference</i>, forthcoming from King&#8217;s College.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Christian</title>
		<link>http://certaindoubts.com/on-expected-utility-evidence/#comment-8628</link>
		<dc:creator><![CDATA[Christian]]></dc:creator>
		<pubDate>Sat, 23 Sep 2006 19:05:17 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=619#comment-8628</guid>
		<description><![CDATA[I&#039;m posting from ignorance so bear with me.

&quot;If I learn that I&#039;m mistaken about the outcomes, or that my assessment of either their value to me (in a currency satisfying the axioms of utility) or uncertainty is incorrect, I can call off the bet by refusing to enter that lottery.&quot;

I would have thought that you cannot refuse to enter the lottery. You either perform A or not-A and you assign probabilities to outcomes of performing A and not-A and you assign utiles to these outcomes. By refraining from acting, you perform not-A, so you cannot refuse to play the lottery. Perhaps all you mean is that if your beliefs or preferences with respect to the outcomes of the acts change, then you can refuse to play the lottery is the sense that you no longer act on the basis of the changed beliefs or preferences. It sounds odd to call that refusing, but that&#039;s unimportant.

&quot;The two features of Kyburg&#039;s sketch that differ from the classical picture are that (1) an agent&#039;s assessment of outcomes is based upon statistical distributions, which may yield interval valued probabilities, and (2) the agent&#039;s free will (from his perspective) is taken seriously as a constraint on evidence.&quot;

I don&#039;t like that picture. Statistical distributions face the reference class problem, we sometimes assign values to outcomes when we have no statistical evidence, we assign a priori probabilities that ignore stats and we typically take stats as relevant only when they provide evidence for causal relations that are relevant to outcomes and our acts. I&#039;m not sure what it means to say free will is a constraint on evidence, so I just leave that as an open question.

&quot;The new evidence that would bias his assessment is blocked because it undermines the conditions of his making a choice.&quot;

I&#039;m sorry, I&#039;m not seeing it yet. I would think his free will is independent of the information he has about the exam or his beliefs about the likelihood of his being ruthless given that fires Parker. I don&#039;t either see that the information is blocked, rather, it seems available by stipulation but then it might turn out to be irrelevant evidence for some other reason. I&#039;m not sure what this other reason is.  The way I see it, firing Parker gives him evidence that he is ruthless, which gives him evidence that he was ruthless, which gives him evidence that he passed the exam. But, this is irrelevant evidence because it is causally irrelevant. His firing Parker will not cause him to pass the exam.

&quot;So, he acts freely but the penalties/rewards that enter into his calculation for whether to stop smoking are moot, since the lesion has at least as great of a causal influence on cancer as smoking does.&quot;

I&#039;m not sure what&#039;s going on but it&#039;s part of the case that smoking has no causal influence at all on one&#039;s getting cancer, getting cancer and smoking are effects of a common cause, the lesion, and so there is no overdetermination.

&quot;That is, in the smoking lottery, if he chooses &quot;Stop smoking&quot; he now knows that the expected value of &quot;no cancer&quot; won&#039;t change, contrary to his initial assumption. Hence it would be reasonable for him call off entering this lottery.&quot;

I don&#039;t understand. The expected value of &quot;no cancer&quot; doesn&#039;t change nor did it ever. I also don&#039;t see how he can call off entering the lottery since he must either smoke or not. As far as I can tell, his preferences stay fixed and so do his credences, he just learns something new, that smoking does not cause cancer and it turns out this information is relevant since it show that his belief that P(cancer/smoke) is high and yet irrelevant since there is no causal connection between smoking and cancer.

&quot;But it isn&#039;t clear to me that these structures should be thought of as a basis for decision, if only because we often only have incomplete knowledge of causal structure or no knowledge at all, but we still can make reasonable decisions.&quot;

Sure, we can still make reasonable decisions when ignorant of the relevant causal fatcs. I don&#039;t deny this. But this just shows that we need a principled way of assigning priors, perhaps via a version of the indifference principle. It may even show that other information can be relevant, although I&#039;d like to know what information is relevant that is not, in the end, information about causation.]]></description>
		<content:encoded><![CDATA[<p>I&#8217;m posting from ignorance so bear with me.</p>
<p>&#8220;If I learn that I&#8217;m mistaken about the outcomes, or that my assessment of either their value to me (in a currency satisfying the axioms of utility) or uncertainty is incorrect, I can call off the bet by refusing to enter that lottery.&#8221;</p>
<p>I would have thought that you cannot refuse to enter the lottery. You either perform A or not-A and you assign probabilities to outcomes of performing A and not-A and you assign utiles to these outcomes. By refraining from acting, you perform not-A, so you cannot refuse to play the lottery. Perhaps all you mean is that if your beliefs or preferences with respect to the outcomes of the acts change, then you can refuse to play the lottery is the sense that you no longer act on the basis of the changed beliefs or preferences. It sounds odd to call that refusing, but that&#8217;s unimportant.</p>
<p>&#8220;The two features of Kyburg&#8217;s sketch that differ from the classical picture are that (1) an agent&#8217;s assessment of outcomes is based upon statistical distributions, which may yield interval valued probabilities, and (2) the agent&#8217;s free will (from his perspective) is taken seriously as a constraint on evidence.&#8221;</p>
<p>I don&#8217;t like that picture. Statistical distributions face the reference class problem, we sometimes assign values to outcomes when we have no statistical evidence, we assign a priori probabilities that ignore stats and we typically take stats as relevant only when they provide evidence for causal relations that are relevant to outcomes and our acts. I&#8217;m not sure what it means to say free will is a constraint on evidence, so I just leave that as an open question.</p>
<p>&#8220;The new evidence that would bias his assessment is blocked because it undermines the conditions of his making a choice.&#8221;</p>
<p>I&#8217;m sorry, I&#8217;m not seeing it yet. I would think his free will is independent of the information he has about the exam or his beliefs about the likelihood of his being ruthless given that fires Parker. I don&#8217;t either see that the information is blocked, rather, it seems available by stipulation but then it might turn out to be irrelevant evidence for some other reason. I&#8217;m not sure what this other reason is.  The way I see it, firing Parker gives him evidence that he is ruthless, which gives him evidence that he was ruthless, which gives him evidence that he passed the exam. But, this is irrelevant evidence because it is causally irrelevant. His firing Parker will not cause him to pass the exam.</p>
<p>&#8220;So, he acts freely but the penalties/rewards that enter into his calculation for whether to stop smoking are moot, since the lesion has at least as great of a causal influence on cancer as smoking does.&#8221;</p>
<p>I&#8217;m not sure what&#8217;s going on but it&#8217;s part of the case that smoking has no causal influence at all on one&#8217;s getting cancer, getting cancer and smoking are effects of a common cause, the lesion, and so there is no overdetermination.</p>
<p>&#8220;That is, in the smoking lottery, if he chooses &#8220;Stop smoking&#8221; he now knows that the expected value of &#8220;no cancer&#8221; won&#8217;t change, contrary to his initial assumption. Hence it would be reasonable for him call off entering this lottery.&#8221;</p>
<p>I don&#8217;t understand. The expected value of &#8220;no cancer&#8221; doesn&#8217;t change nor did it ever. I also don&#8217;t see how he can call off entering the lottery since he must either smoke or not. As far as I can tell, his preferences stay fixed and so do his credences, he just learns something new, that smoking does not cause cancer and it turns out this information is relevant since it show that his belief that P(cancer/smoke) is high and yet irrelevant since there is no causal connection between smoking and cancer.</p>
<p>&#8220;But it isn&#8217;t clear to me that these structures should be thought of as a basis for decision, if only because we often only have incomplete knowledge of causal structure or no knowledge at all, but we still can make reasonable decisions.&#8221;</p>
<p>Sure, we can still make reasonable decisions when ignorant of the relevant causal fatcs. I don&#8217;t deny this. But this just shows that we need a principled way of assigning priors, perhaps via a version of the indifference principle. It may even show that other information can be relevant, although I&#8217;d like to know what information is relevant that is not, in the end, information about causation.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/on-expected-utility-evidence/#comment-3911</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Sat, 23 Sep 2006 08:37:38 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=619#comment-3911</guid>
		<description><![CDATA[That&#039;s probably because I said vague and false things.

If I consider an act A with possible outcomes O1,.., On, but I do not know which, I can view performing act A as entering a lottery with prizes (penalties) O1,...,On. Then, I view my uncertainty as a probability measure Pr over O1,...,On. If I learn that I&#039;m mistaken about the outcomes, or that my assessment of either their value to me (in a currency satisfying the axioms of utility) or uncertainty is incorrect, I can call off the bet by refusing to enter that lottery. This is different than if I accept the &quot;scoring&quot; of two distinct lotteries, L1 and L2, but don&#039;t like a consequence of expressing these two preferences. This picture conforms to the classical one.

The two features of Kyburg&#039;s sketch that differ from the classical picture are that (1) an agent&#039;s assessment of outcomes is based upon statistical distributions, which may yield interval valued probabilities, and (2) the agent&#039;s free will (from his perspective) is taken seriously as a constraint on evidence.

The way causal information is filtered through this theory may be thought of (roughly) as defeaters of one of these two conditions. The Johnson/Parker example exercises both of them. Johnson views himself to be a *random* member of the pool of applicants w.r.t. the top score on the ruthlessness exam. The new evidence that would bias his assessment is blocked because it undermines the conditions of his making a choice.

I imagined the smoking example having a different causal structure, one in which the cancer was overdetermined by his smoking and the brain lesion. So, he acts freely but the penalties/rewards that enter into his calculation for whether to stop smoking are moot, since the lesion has at least as great of a causal influence on cancer as smoking does. If he doesn&#039;t know about the lesion, then there is no problem from a theoretical point of view: he can only reasonably act on what he knows, after all. If he does know about the lesion, then the problem is to explain how this causal information impacts his assessments.

The intuitive idea is that he no longer considers the structure of the smoking lottery to accurately represent his expectations of his choosing to smoke or not, because he&#039;s learned that he is in two relevant reference classes: smokers and brain lacerated. That is, in the smoking lottery, if he chooses &quot;Stop smoking&quot; he now knows that the expected value of &quot;no cancer&quot; won&#039;t change, contrary to his initial assumption. Hence it would be reasonable for him call off entering this lottery.

I don&#039;t know how far this model will go; I haven&#039;t played much with this model. But one thing that I find attractive about the idea behind it is that it attempts to find a middle ground between causal and evidential theories. Clearly causal information is important, and we often wish to learn about causal structures. But it isn&#039;t clear to me that these structures should be thought of as a basis for decision, if only because we often only have incomplete knowledge of causal structure or no knowledge at all, but we still can make reasonable decisions. Taking causality too seriously risks punting on the hard problem of reasoning and decision making under conditions of uncertainty.

Now this post may error on the side of wordiness. In sum, the reference class approach has two mechanisms to explain the influence of causal structure, one of which is to claim that it violates the conditions for first-person choice, the other that it violates epistemic randomness conditions on reference classes. The former is a metaphysical condition on agent choice, while the latter is an epistemic condition built into his representation of what he knows about the decision problem at hand.]]></description>
		<content:encoded><![CDATA[<p>That&#8217;s probably because I said vague and false things.</p>
<p>If I consider an act A with possible outcomes O1,.., On, but I do not know which, I can view performing act A as entering a lottery with prizes (penalties) O1,&#8230;,On. Then, I view my uncertainty as a probability measure Pr over O1,&#8230;,On. If I learn that I&#8217;m mistaken about the outcomes, or that my assessment of either their value to me (in a currency satisfying the axioms of utility) or uncertainty is incorrect, I can call off the bet by refusing to enter that lottery. This is different than if I accept the &#8220;scoring&#8221; of two distinct lotteries, L1 and L2, but don&#8217;t like a consequence of expressing these two preferences. This picture conforms to the classical one.</p>
<p>The two features of Kyburg&#8217;s sketch that differ from the classical picture are that (1) an agent&#8217;s assessment of outcomes is based upon statistical distributions, which may yield interval valued probabilities, and (2) the agent&#8217;s free will (from his perspective) is taken seriously as a constraint on evidence.</p>
<p>The way causal information is filtered through this theory may be thought of (roughly) as defeaters of one of these two conditions. The Johnson/Parker example exercises both of them. Johnson views himself to be a *random* member of the pool of applicants w.r.t. the top score on the ruthlessness exam. The new evidence that would bias his assessment is blocked because it undermines the conditions of his making a choice.</p>
<p>I imagined the smoking example having a different causal structure, one in which the cancer was overdetermined by his smoking and the brain lesion. So, he acts freely but the penalties/rewards that enter into his calculation for whether to stop smoking are moot, since the lesion has at least as great of a causal influence on cancer as smoking does. If he doesn&#8217;t know about the lesion, then there is no problem from a theoretical point of view: he can only reasonably act on what he knows, after all. If he does know about the lesion, then the problem is to explain how this causal information impacts his assessments.</p>
<p>The intuitive idea is that he no longer considers the structure of the smoking lottery to accurately represent his expectations of his choosing to smoke or not, because he&#8217;s learned that he is in two relevant reference classes: smokers and brain lacerated. That is, in the smoking lottery, if he chooses &#8220;Stop smoking&#8221; he now knows that the expected value of &#8220;no cancer&#8221; won&#8217;t change, contrary to his initial assumption. Hence it would be reasonable for him call off entering this lottery.</p>
<p>I don&#8217;t know how far this model will go; I haven&#8217;t played much with this model. But one thing that I find attractive about the idea behind it is that it attempts to find a middle ground between causal and evidential theories. Clearly causal information is important, and we often wish to learn about causal structures. But it isn&#8217;t clear to me that these structures should be thought of as a basis for decision, if only because we often only have incomplete knowledge of causal structure or no knowledge at all, but we still can make reasonable decisions. Taking causality too seriously risks punting on the hard problem of reasoning and decision making under conditions of uncertainty.</p>
<p>Now this post may error on the side of wordiness. In sum, the reference class approach has two mechanisms to explain the influence of causal structure, one of which is to claim that it violates the conditions for first-person choice, the other that it violates epistemic randomness conditions on reference classes. The former is a metaphysical condition on agent choice, while the latter is an epistemic condition built into his representation of what he knows about the decision problem at hand.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Christian</title>
		<link>http://certaindoubts.com/on-expected-utility-evidence/#comment-3910</link>
		<dc:creator><![CDATA[Christian]]></dc:creator>
		<pubDate>Fri, 22 Sep 2006 18:33:28 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=619#comment-3910</guid>
		<description><![CDATA[Hey,

I&#039;m not sure how to respond to that last post. I think you are considering the cases in a framework that I&#039;m unfamiliar with. For example, I don&#039;t know what &#039;scoring&#039; or &#039;the lottery&#039; or &#039;consequences of scoring&#039; mean. That makes it hard for me to assess the proposal.

You wrote that &quot;you’ve got a lesion, with no chance of pleasure against a good one (the same one) for the misery of lung cancer.&quot;

Perhaps my statement of the case was unclear. In the smoking lesion you don&#039;t think you have a lesion, only that lesions cause both smoking and cancer. I&#039;m also not understanding the idea that if one has a lesion, then one has no chance of pleasure. The pleasure accosiated with smoking is, well, the satisfaction of some craving I suppose. The cost is early death.  And the idea is that one should smoke because smoking doesn&#039;t cause death, the lesion does, and one&#039;s smoking doesn&#039;t cause one to have the lesion. One should go on smoking since it doesn&#039;t make a causal difference to the costs, but it makes an evidential difference to likelihood of the cost accruing. This is supposed to be consistent with smoking giving one evidence that one has the lesion and cancer, but then the idea is that this evidence is irrelevant since it is causally irrelevant.

I&#039;m not sure what the moral is. Maybe it&#039;s that which evidence is relevant evidence can change, sometimes only causal evidence is relevant, but sometimes other evidence is relevant as well. Maybe instead the moral is that causal evidence is the only relevant evidence and that all other evidence will wind up being causal evidence upon analysis.  For example, suppose I get statistical evidence that 9 out of 10 smokers die of cancer. That should effect whether I smoke. But, the statistical evidence may wind up making this &quot;refraining from smoking&quot; rational only because it gives my evidence that there is a causal relation between smoking and getting cancer. So, stats can give me evidence about which causal relations obtain and so are relevant evidence in that sense, but which act I should perform need only consider which which causal relations I think there are.

If that&#039;s right, then &quot;perhaps&quot; the right answer to the psychopath case is that pushing the button causes one to be a psychopath after all.  It&#039;s not just that P(being a psychopath/pushing the button) is high, but that P(pushing the button causes one to be a psychopath) is high and the this second judgment entails the former.]]></description>
		<content:encoded><![CDATA[<p>Hey,</p>
<p>I&#8217;m not sure how to respond to that last post. I think you are considering the cases in a framework that I&#8217;m unfamiliar with. For example, I don&#8217;t know what &#8216;scoring&#8217; or &#8216;the lottery&#8217; or &#8216;consequences of scoring&#8217; mean. That makes it hard for me to assess the proposal.</p>
<p>You wrote that &#8220;you’ve got a lesion, with no chance of pleasure against a good one (the same one) for the misery of lung cancer.&#8221;</p>
<p>Perhaps my statement of the case was unclear. In the smoking lesion you don&#8217;t think you have a lesion, only that lesions cause both smoking and cancer. I&#8217;m also not understanding the idea that if one has a lesion, then one has no chance of pleasure. The pleasure accosiated with smoking is, well, the satisfaction of some craving I suppose. The cost is early death.  And the idea is that one should smoke because smoking doesn&#8217;t cause death, the lesion does, and one&#8217;s smoking doesn&#8217;t cause one to have the lesion. One should go on smoking since it doesn&#8217;t make a causal difference to the costs, but it makes an evidential difference to likelihood of the cost accruing. This is supposed to be consistent with smoking giving one evidence that one has the lesion and cancer, but then the idea is that this evidence is irrelevant since it is causally irrelevant.</p>
<p>I&#8217;m not sure what the moral is. Maybe it&#8217;s that which evidence is relevant evidence can change, sometimes only causal evidence is relevant, but sometimes other evidence is relevant as well. Maybe instead the moral is that causal evidence is the only relevant evidence and that all other evidence will wind up being causal evidence upon analysis.  For example, suppose I get statistical evidence that 9 out of 10 smokers die of cancer. That should effect whether I smoke. But, the statistical evidence may wind up making this &#8220;refraining from smoking&#8221; rational only because it gives my evidence that there is a causal relation between smoking and getting cancer. So, stats can give me evidence about which causal relations obtain and so are relevant evidence in that sense, but which act I should perform need only consider which which causal relations I think there are.</p>
<p>If that&#8217;s right, then &#8220;perhaps&#8221; the right answer to the psychopath case is that pushing the button causes one to be a psychopath after all.  It&#8217;s not just that P(being a psychopath/pushing the button) is high, but that P(pushing the button causes one to be a psychopath) is high and the this second judgment entails the former.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/on-expected-utility-evidence/#comment-3909</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Fri, 22 Sep 2006 12:11:59 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=619#comment-3909</guid>
		<description><![CDATA[Imagine you are considering outcomes from smoking, its pleasures against the misery of lung cancer. What happens in the smoking example is that you learn that the outcomes {pleasure, misery} aren&#039;t disjoint: you&#039;ve got a lesion, with no chance of pleasure against a good one (the same one) for the misery of lung cancer.

What you&#039;ve learned is that the lottery you thought characterized smoking isn&#039;t correct, and so you should no longer enter it. This is legal, since it concerns the scoring of outcomes of the lottery and not unhappiness over the consequences of your scoring. You thought your credal measure was over disjoint outcomes, pleasure versus misery; but, then you learn that these outcomes are not disjoint. Whether you choose pleasure or not, you still can expect to suffer.

This seems evidential to me, too. And not to count against EDT.]]></description>
		<content:encoded><![CDATA[<p>Imagine you are considering outcomes from smoking, its pleasures against the misery of lung cancer. What happens in the smoking example is that you learn that the outcomes {pleasure, misery} aren&#8217;t disjoint: you&#8217;ve got a lesion, with no chance of pleasure against a good one (the same one) for the misery of lung cancer.</p>
<p>What you&#8217;ve learned is that the lottery you thought characterized smoking isn&#8217;t correct, and so you should no longer enter it. This is legal, since it concerns the scoring of outcomes of the lottery and not unhappiness over the consequences of your scoring. You thought your credal measure was over disjoint outcomes, pleasure versus misery; but, then you learn that these outcomes are not disjoint. Whether you choose pleasure or not, you still can expect to suffer.</p>
<p>This seems evidential to me, too. And not to count against EDT.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Christian</title>
		<link>http://certaindoubts.com/on-expected-utility-evidence/#comment-3908</link>
		<dc:creator><![CDATA[Christian]]></dc:creator>
		<pubDate>Fri, 22 Sep 2006 02:14:43 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=619#comment-3908</guid>
		<description><![CDATA[I may be mischaracterizing Egan here, but he gives an example like this:

You desire that the world be rid of psychopaths. In front of you is a button that says: If you push this button all psychopaths will be annihilated. You believe that. However, you also believe that only a psychopath would push the button. What do you do?

Causal decision theory says push, but that would be irrational. So, CDT is the wrong theory of rational decision making.

Smoking lesion: You want to smoke but you know that the likelihood of having cancer, given that you smoke is high. So, smoking gives you evidence that you have cancer. But you then learn that smoking and cancer are effects of having some lesion that cause both. So, you should smoke, since whether you smoke or not will not effect whether you have the lesion so it will not effect whether you have cancer.

Evidential decision theory says don&#039;t smoke, but that would be irrational. So, EDT is the wrong theory of rational decision making.

You say that stats can give us evidence relevant to decision making. I wonder whether we can make this out in a way where the stats give us relevant causal evidence since I like causal decision theory. But maybe this isn&#039;t necessary, I&#039;m not sure. I&#039;d like a single utility function too. Can we get it?]]></description>
		<content:encoded><![CDATA[<p>I may be mischaracterizing Egan here, but he gives an example like this:</p>
<p>You desire that the world be rid of psychopaths. In front of you is a button that says: If you push this button all psychopaths will be annihilated. You believe that. However, you also believe that only a psychopath would push the button. What do you do?</p>
<p>Causal decision theory says push, but that would be irrational. So, CDT is the wrong theory of rational decision making.</p>
<p>Smoking lesion: You want to smoke but you know that the likelihood of having cancer, given that you smoke is high. So, smoking gives you evidence that you have cancer. But you then learn that smoking and cancer are effects of having some lesion that cause both. So, you should smoke, since whether you smoke or not will not effect whether you have the lesion so it will not effect whether you have cancer.</p>
<p>Evidential decision theory says don&#8217;t smoke, but that would be irrational. So, EDT is the wrong theory of rational decision making.</p>
<p>You say that stats can give us evidence relevant to decision making. I wonder whether we can make this out in a way where the stats give us relevant causal evidence since I like causal decision theory. But maybe this isn&#8217;t necessary, I&#8217;m not sure. I&#8217;d like a single utility function too. Can we get it?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Gregory Wheeler</title>
		<link>http://certaindoubts.com/on-expected-utility-evidence/#comment-3907</link>
		<dc:creator><![CDATA[Gregory Wheeler]]></dc:creator>
		<pubDate>Thu, 21 Sep 2006 16:39:07 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=619#comment-3907</guid>
		<description><![CDATA[Christian,

I was thinking of decision problems on outcomes where the measure of uncertainty is supplied by a statistical distribution over those outcomes I am considering, and my credal probability agrees with this distribution. I can, and often do, base my expectations on statistical distributions of properties that I&#039;m interested in, or proportions of subjects bearing one property that also bear another. This seems purely evidential to me. (This yields a gappy decision theory, but I already embrace imprecise probabilities.)

I&#039;m unfamilar with Egan&#039;s class of examples. Is it possible to offer a description of one?]]></description>
		<content:encoded><![CDATA[<p>Christian,</p>
<p>I was thinking of decision problems on outcomes where the measure of uncertainty is supplied by a statistical distribution over those outcomes I am considering, and my credal probability agrees with this distribution. I can, and often do, base my expectations on statistical distributions of properties that I&#8217;m interested in, or proportions of subjects bearing one property that also bear another. This seems purely evidential to me. (This yields a gappy decision theory, but I already embrace imprecise probabilities.)</p>
<p>I&#8217;m unfamilar with Egan&#8217;s class of examples. Is it possible to offer a description of one?</p>
]]></content:encoded>
	</item>
</channel>
</rss>
