<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Tom Kelly on Evidence</title>
	<atom:link href="http://certaindoubts.com/tom-kelly-on-evidence/feed/" rel="self" type="application/rss+xml" />
	<link>http://certaindoubts.com/tom-kelly-on-evidence/</link>
	<description>devoted to matters epistemic</description>
	<lastBuildDate>Wed, 10 Apr 2019 16:37:28 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.10</generator>
	<item>
		<title>By: Mathijs de Boer</title>
		<link>http://certaindoubts.com/tom-kelly-on-evidence/#comment-1722</link>
		<dc:creator><![CDATA[Mathijs de Boer]]></dc:creator>
		<pubDate>Fri, 27 May 2005 10:05:16 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=317#comment-1722</guid>
		<description><![CDATA[Imagine they had ALL the facts and wholeheartedly disagreed about only one, just tipping the scale to either side: their disagreement would be total.

From a statistical perspective this could be somewhat rational. Both proponent and opponent get a bigger slice of facts, their preferences/distributions move closer to the center and each other but their uncertainty/deviation decreases with a higher rate if I recall correctly.]]></description>
		<content:encoded><![CDATA[<p>Imagine they had ALL the facts and wholeheartedly disagreed about only one, just tipping the scale to either side: their disagreement would be total.</p>
<p>From a statistical perspective this could be somewhat rational. Both proponent and opponent get a bigger slice of facts, their preferences/distributions move closer to the center and each other but their uncertainty/deviation decreases with a higher rate if I recall correctly.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/tom-kelly-on-evidence/#comment-1718</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Tue, 03 May 2005 15:14:40 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=317#comment-1718</guid>
		<description><![CDATA[Barry, exactly right.  That&#039;s what I get for typing and talking on the phone at the same time...!]]></description>
		<content:encoded><![CDATA[<p>Barry, exactly right.  That&#8217;s what I get for typing and talking on the phone at the same time&#8230;!</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Barry Lam</title>
		<link>http://certaindoubts.com/tom-kelly-on-evidence/#comment-1717</link>
		<dc:creator><![CDATA[Barry Lam]]></dc:creator>
		<pubDate>Tue, 03 May 2005 15:13:55 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=317#comment-1717</guid>
		<description><![CDATA[Jon, the last question should probably read &quot;And perhaps it can be rational not to look for ways of explaining away studies that DON&#039;T conflict with one&#039;s view.&quot; That might be made stronger &quot;Perhaps it can be rational not to look for ways of explaining away studies that support one&#039;s view&quot;.]]></description>
		<content:encoded><![CDATA[<p>Jon, the last question should probably read &#8220;And perhaps it can be rational not to look for ways of explaining away studies that DON&#8217;T conflict with one&#8217;s view.&#8221; That might be made stronger &#8220;Perhaps it can be rational not to look for ways of explaining away studies that support one&#8217;s view&#8221;.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: jon kvanvig</title>
		<link>http://certaindoubts.com/tom-kelly-on-evidence/#comment-1716</link>
		<dc:creator><![CDATA[jon kvanvig]]></dc:creator>
		<pubDate>Tue, 03 May 2005 15:01:29 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=317#comment-1716</guid>
		<description><![CDATA[Here&#039;s a hint about Tom&#039;s view.  Isn&#039;t it sometimes rational to look for ways of explaining away studies that conflict with one&#039;s view?  And perhaps it can be rational not to look for ways of explaining away studies that conflict with one&#039;s view.]]></description>
		<content:encoded><![CDATA[<p>Here&#8217;s a hint about Tom&#8217;s view.  Isn&#8217;t it sometimes rational to look for ways of explaining away studies that conflict with one&#8217;s view?  And perhaps it can be rational not to look for ways of explaining away studies that conflict with one&#8217;s view.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Jonathan Weinberg</title>
		<link>http://certaindoubts.com/tom-kelly-on-evidence/#comment-1719</link>
		<dc:creator><![CDATA[Jonathan Weinberg]]></dc:creator>
		<pubDate>Sun, 01 May 2005 18:24:47 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=317#comment-1719</guid>
		<description><![CDATA[I don&#039;t know whether this fact is relevant to the epistemological significance of the polarization phenomenon -- partly because I am uncertain about the epistemological significance of the phenomenon in the first place -- but it may lead someone to think twice before trying to rationalize it: the polarization phenomenon seems to be culturally local.

According to, e.g., Peng &amp; Nisbett, &quot;Culture, Dialectics, and Reasoning About Contradiction&quot;, American Psychologist. Vol. 54 (9) September 1999, pp. 741-754, especially experiment 5, East Asian subjects in situations similar to (though, I should note, not exactly the same as) the one under discussion tend to &lt;i&gt;increase&lt;/i&gt; their evaluation of the plausibility of the proposition that they did not antecedently agree with.  They are anti-polarizing, following what as Peng &amp; Nisbett term a &quot;naive dialecticism&quot;.]]></description>
		<content:encoded><![CDATA[<p>I don&#8217;t know whether this fact is relevant to the epistemological significance of the polarization phenomenon &#8212; partly because I am uncertain about the epistemological significance of the phenomenon in the first place &#8212; but it may lead someone to think twice before trying to rationalize it: the polarization phenomenon seems to be culturally local.</p>
<p>According to, e.g., Peng &#038; Nisbett, &#8220;Culture, Dialectics, and Reasoning About Contradiction&#8221;, American Psychologist. Vol. 54 (9) September 1999, pp. 741-754, especially experiment 5, East Asian subjects in situations similar to (though, I should note, not exactly the same as) the one under discussion tend to <i>increase</i> their evaluation of the plausibility of the proposition that they did not antecedently agree with.  They are anti-polarizing, following what as Peng &#038; Nisbett term a &#8220;naive dialecticism&#8221;.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Wai-hung Wong</title>
		<link>http://certaindoubts.com/tom-kelly-on-evidence/#comment-1721</link>
		<dc:creator><![CDATA[Wai-hung Wong]]></dc:creator>
		<pubDate>Sun, 01 May 2005 16:23:56 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=317#comment-1721</guid>
		<description><![CDATA[The polarization seems irrational because evidence for P is evidence against not-P, and evidence for not-P is evidence against P.  One way of justifying the polarization is by defending an asymmetry of force between evidence for P and evidence against not-P: although evidence for P is evidence against not-P, its force for P is stronger than its force against not-P.  Suppose my evidence for P and your evidence for not-P support P and not-P (respectively) to the same degree; given the asymmetry, I am justified in being more confident about the truth of P (than when I have no evidence for P) even though your evidence for not-P is evidence against P; and same for your being more confident about the truth of not-P.]]></description>
		<content:encoded><![CDATA[<p>The polarization seems irrational because evidence for P is evidence against not-P, and evidence for not-P is evidence against P.  One way of justifying the polarization is by defending an asymmetry of force between evidence for P and evidence against not-P: although evidence for P is evidence against not-P, its force for P is stronger than its force against not-P.  Suppose my evidence for P and your evidence for not-P support P and not-P (respectively) to the same degree; given the asymmetry, I am justified in being more confident about the truth of P (than when I have no evidence for P) even though your evidence for not-P is evidence against P; and same for your being more confident about the truth of not-P.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Andrew Cling</title>
		<link>http://certaindoubts.com/tom-kelly-on-evidence/#comment-1720</link>
		<dc:creator><![CDATA[Andrew Cling]]></dc:creator>
		<pubDate>Sun, 01 May 2005 15:19:12 +0000</pubDate>
		<guid isPermaLink="false">http://fleetwood.baylor.edu/certain_doubts/?p=317#comment-1720</guid>
		<description><![CDATA[I conjecture that, psychologically, such mixed evidence might tend to strenghthen our incompatible opinions because of our tendency to attend to evidence that reinforces our prejudices and to discount evidence that supports their falsehood.

Prima facie, I didn&#039;t see an epistemic problem here. For if the new evidence, taken as a whole, supports my belief that P exactly to the extent that it supports your belief that ~P, then neither of us is epistemically any better off. For if we grant--as seems plausible--that justification should be proportional to evidence, there is no change in this case in the relative strength of the evidence for and the evidence against our competing beliefs. Each of us remains as (un)justified as before. If rationality is, ceteris paribus, a function of evidence and justification, increased confidence would be irrational.

A bit more reflection suggested a problem, though. For perhaps the fact that (presumably objective) studies are unable to support P any better than ~P, it might be rational for us to have less confidence than before in our commitments despite there being no relative change in the amount and quality of the evidence for and against. For perhaps new, strong evidence against our view should give us a reason to reconsider our commitments even in the face of new confirming evidence that is just as strong. If we assume that we each had as much evidence for our belief before as after the new evidence became available, and we assume that the new evidence is as strong for P as for ~P, the result is puzzling because if confidence should only be fixed by the quality of our evidence, we should not change our confidence and our justification will remain unchanged. But perhaps such results should actually reduce our confidence in our beliefs. This case might show that justification is more than just a matter of the amount of evidence available for a belief. If so, it&#039;s a problem for strong evidentialism: the view that epistemic justification is determined only by the amount and quality of one&#039;s evidence. In either case, however, an increase in confidence in our respective beliefs seems irrational. If belief is justified only by the amount and quality of evidence available, then justification remains unchanged. If strong evidence against one&#039;s view makes it rational to reassess, then the new evidence make it rational to have less confidence in our prior beliefs. In either case, increased confidence seems irrational. The strong evidentialist has a powerful reply here: once we become aware of all of the relevant evidence, the rational thing to do is to suspend judgment, since, ex hypothesi, all of the evidence is counterbalainced. Again, to repeat, strengthening our commitments seems irrational.]]></description>
		<content:encoded><![CDATA[<p>I conjecture that, psychologically, such mixed evidence might tend to strenghthen our incompatible opinions because of our tendency to attend to evidence that reinforces our prejudices and to discount evidence that supports their falsehood.</p>
<p>Prima facie, I didn&#8217;t see an epistemic problem here. For if the new evidence, taken as a whole, supports my belief that P exactly to the extent that it supports your belief that ~P, then neither of us is epistemically any better off. For if we grant&#8211;as seems plausible&#8211;that justification should be proportional to evidence, there is no change in this case in the relative strength of the evidence for and the evidence against our competing beliefs. Each of us remains as (un)justified as before. If rationality is, ceteris paribus, a function of evidence and justification, increased confidence would be irrational.</p>
<p>A bit more reflection suggested a problem, though. For perhaps the fact that (presumably objective) studies are unable to support P any better than ~P, it might be rational for us to have less confidence than before in our commitments despite there being no relative change in the amount and quality of the evidence for and against. For perhaps new, strong evidence against our view should give us a reason to reconsider our commitments even in the face of new confirming evidence that is just as strong. If we assume that we each had as much evidence for our belief before as after the new evidence became available, and we assume that the new evidence is as strong for P as for ~P, the result is puzzling because if confidence should only be fixed by the quality of our evidence, we should not change our confidence and our justification will remain unchanged. But perhaps such results should actually reduce our confidence in our beliefs. This case might show that justification is more than just a matter of the amount of evidence available for a belief. If so, it&#8217;s a problem for strong evidentialism: the view that epistemic justification is determined only by the amount and quality of one&#8217;s evidence. In either case, however, an increase in confidence in our respective beliefs seems irrational. If belief is justified only by the amount and quality of evidence available, then justification remains unchanged. If strong evidence against one&#8217;s view makes it rational to reassess, then the new evidence make it rational to have less confidence in our prior beliefs. In either case, increased confidence seems irrational. The strong evidentialist has a powerful reply here: once we become aware of all of the relevant evidence, the rational thing to do is to suspend judgment, since, ex hypothesi, all of the evidence is counterbalainced. Again, to repeat, strengthening our commitments seems irrational.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
